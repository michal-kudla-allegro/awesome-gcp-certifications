

hej, tu anthony tavelos, twoja chmura
instruktor w firmie egzamin pro
przynosząc ci kompletny kurs nauki dla
Google Cloud Associate Cloud
inżynier udostępniony tutaj na
darmowy obóz kodowania i taki jest ten kurs
zaprojektowany, aby pomóc Ci zdać i osiągnąć
Google wydał certyfikat sposób
zamierzamy to zrobić
jest przejrzenie wielu treści wykładów
postępuj zgodnie ze wskazówkami i korzystaj z moich ściągawek
w dniu egzaminu, więc zdajesz
i możesz wziąć ten certyfikat i
umieść to w swoim CV lub na linkedin
więc możesz dostać tę pracę w chmurze lub
promocja, której szukałeś
i tak trochę o mnie jest to, że mam 18 lat
wieloletnie doświadczenie w branży
siedem z nich specjalizuje się w chmurze i
cztery lata jako trener w chmurze, tj
wcześniej była chmura i devops
inżynier i ja również opublikowałem
wiele kursów w chmurze i jestem ogromny
także fanem kreskówek Looney Tunes
jako koneser kawy i tak chciałem
poświęcić chwilę, aby podziękować widzom takim jak
Ty
ponieważ robisz te darmowe kursy
możliwe, więc jeśli szukasz
więcej sposobów wspierania więcej za darmo
kursy takie jak ten
najlepszym sposobem jest zakup dodatkowego badania
materiał o godz
co example.com w szczególności w tym celu
certyfikat można znaleźć na stronie gcp
łącznik as tam można uzyskać notatki do nauki
quizy z kartami flash
wykłady do pobrania, które są
slajdy do wszystkich filmów z wykładami
Ściągawki do pobrania, które według
sposób są bezpłatne, jeśli po prostu się zarejestrujesz
egzaminy praktyczne
a także możesz zadawać pytania i otrzymywać
wsparcie w nauce i jeśli chcesz je zachować
na bieżąco z nowymi kursami, nad którymi pracuję
NA
najlepszym sposobem jest śledzenie mnie na Twitterze
w chmurze Antoniusza
i chciałbym usłyszeć od ciebie, jeśli ty
zdałeś egzamin
a także chciałbym usłyszeć, co chcesz
chciałbym zobaczyć następny
[Muzyka]
Witamy spowrotem
w tej lekcji chciałem szybko przejść
jak uzyskać dostęp do zasobów kursu
teraz zasoby w tym kursie są
zaprojektowany, aby towarzyszyć lekcjom i
pomóc zrozumieć nie tylko teorię
ale aby pomóc w lekcjach demonstracyjnych, które
naprawdę jazdy do domu składnika
nauka własnoręcznie
będą one obejmować lekcję z notatkami do nauki
skrypty plików, a także zasoby, które
są używane w lekcjach demonstracyjnych
te pliki można znaleźć w githubie
repozytorium, które dołączę
poniżej, które są zawsze aktualne
i to dzięki tym plikom ty
będzie mógł nadążyć i
ukończyć dema na własną rękę, aby naprawdę
ugruntować zdobytą wiedzę
jest to dość prosty proces, ale jest różny
przez różne systemy operacyjne
przejdę przez to demo, żeby to pokazać
jak uzyskać dostęp przez
trzy główne systemy operacyjne
Windows Mac OS i Ubuntu Linux
więc najpierw zacznę od okien
a pierwszym krokiem byłoby otwarcie się
przeglądarka internetowa
i przejdź do tego adresu URL, który zrobię
uwzględnić w uwagach poniżej
a to jest repozytorium github kursu
który pomieści wszystkie pliki kursów
o których wspomniałem wcześniej
utrzymywanie kursu na bieżąco będzie oznaczać
że pliki mogą wymagać zmiany i tak dalej
jak je zaktualizuję, zawsze będą
odbite
i przesłane tutaj w repo
więc wracając do tego są dwa sposoby
aby uzyskać dostęp do tego repozytorium, więc najłatwiej
sposób uzyskania kopii tych plików
być kliknąć na klon lub pobrać
przycisk i kliknij Pobierz zip
po pobraniu pliku
następnie można go otworzyć, klikając go
Tutaj
a oto pliki tutaj w plikach do pobrania
a to da ci migawkę wszystkiego
pliki i foldery tak, jak je widzisz
z tego repozytorium
teraz, chociaż może się to wydawać
prosty sposób, aby przejść to nie jest
zalecana metoda pobierania, jak gdyby istniała
pliki uległy zmianie, nie nadążysz
date z najnowszymi plikami i will only
być aktualne od daty, w której to zrobiłeś
pobrał je teraz w ten sposób
zalecane jest użycie kontroli źródła
system o nazwie git i tak najłatwiej
aby go zainstalować, należy przejść do tego adresu URL
https
dwukropek ukośnik ukośnik
git dash scm.com
a to zaprowadzi cię do git
strona internetowa, z której można pobrać
niezbędne oprogramowanie dla systemu Windows lub dowolnego
inny obsługiwany system operacyjny
i dlatego zamierzam go pobrać tutaj
i to powinno pobrać najnowsze
wersja gita
dla okien i zajęło to kilka sekund
tam, ale jest zrobione
i nie musisz się martwić, czy lub
nie masz właściwej wersji
zwykle po kliknięciu tego pobierania
przycisk spowoduje pobranie najnowszego
wersję dla twojego systemu operacyjnego
więc pójdę tutaj i otworzę
to u góry
pojawi się monit, w którym chcesz po prostu
Powiedz tak
i pójdziemy dalej i zaakceptujemy
wszystkie ustawienia domyślne są tutaj
zamierzam go zainstalować, przejdźmy dalej
to są wszystkie elementy, które
zostaną zainstalowane
kliknij dalej
i znowu przejdziemy
wszystko
ze wszystkimi ustawieniami domyślnymi
a kiedy już dotarliśmy
instalując wszystkie ustawienia domyślne, które zamierza
poświęć kilka minut na instalację
i znowu zajęło to około minuty
po prostu klikniemy dalej
i zapyta, czy chcesz
przeglądać informacje o wydaniu, a my nie
naprawdę ich potrzebuję
możemy kliknąć ok
i po prostu to zamknij
a my po prostu pójdziemy i zobaczymy
jeśli git jest zainstalowany
uruchomimy wiersz polecenia
i zamierzam po prostu powiększyć tutaj, więc my
widać trochę lepiej
i tam idziemy i po prostu idziemy
wpisz w git
i jak widać został zainstalowany
a więc teraz, gdy zainstalowaliśmy git we
chce mieć możliwość ściągnięcia wszystkich
folderów i znajdujących się w nich plików
repozytorium do naszego lokalnego systemu i
więc po prostu wyczyszczę ekran
Tutaj
i dla pewności nagramy płytę
że jestem w moim katalogu domowym
a następnie utworzymy katalog
zwane repozytoriami
i aby to zrobić, zamierzamy to zrobić
zrób mkdir
przestrzeń
repos, a następnie przejdziemy do
ten katalog
więc cd
repozytoria kosmiczne i znowu tutaj chcemy
sklonuj te pliki, które są w
repozytorium do naszego lokalnego systemu
więc aby to zrobić, zrobimy to
użyj polecenia git clone, aby uzyskać miejsce
klon
a potem będziemy potrzebować naszego
lokalizacja repozytorium git, więc zróbmy to
wróć do przeglądarki
i pójdziemy tutaj, żeby sklonować
lub pobierz
a tutaj zobaczysz klon z https
więc upewnij się, że to mówi https i
możesz po prostu kliknąć ten przycisk
który skopiuje to do schowka
a potem wrócimy do naszej komendy
podpowiedź
i wklej to
a kiedy to zostanie wklejone, po prostu naciśnij enter
i sklonuje twoje repozytorium do
katalog repos i tak po prostu
sprawdź, czy sklonowaliśmy wszystkie
niezbędne pliki
idziemy do cd do mastera
katalog, który właśnie sklonowaliśmy
i zrobimy reż
i tam masz wszystkie pliki
są klonowane dokładnie tak, jak to jest tutaj w
magazyn
teraz tylko jako notatkę, aby zachować
te pliki na bieżąco musimy uruchomić
inne polecenie, które byłoby git
ciągnąć
i można to uruchomić w dowolnym momencie w kolejności
aby rozebrać wszystkie pliki lub foldery, które
zostały zaktualizowane od czasu, gdy to zrobiłeś
najpierw pociągnij który w tym przypadku
byłoby sklonowaniem repozytorium
ponownie zapewni ci to
najnowsze i najbardziej aktualne pliki w dowolnym miejscu
danym momencie w czasie iw tym przypadku
odkąd nic się nie zmieniło, byłem
monit z komunikatem stwierdzającym, że jestem
na bieżąco, jeśli nic się nie zmieniło
zawsze będzie o to proszony
wiadomość
gdyby było
ściągnie twoje zmiany do twojego
zsynchronizowana kopia lokalna i proces dla
Windows jest ukończony i jest podobny w
mac os i przeniosę się na mój mac os
maszynę wirtualną i zaloguj się
a kiedy już się zalogujesz, po prostu zamierzam to zrobić
idź tutaj do terminala i jestem
właśnie idę na cd
aby upewnić się, że jestem w moim katalogu domowym
wtedy zrobię dokładnie to, co zrobiliśmy
w systemie Windows, więc zamierzam uruchomić
komenda mk
reż
repo przestrzeni
i utwórz katalog repos i jestem
zamierzam przejść do katalogu repozytoriów
a potem uruchomię git
teraz dla tych z was, którzy nie mają dostać
zainstalowany, zostaniesz o to poproszony
wiadomość, aby ją zainstalować i możesz iść
do przodu i po prostu zainstaluj, będziesz
monitowany wraz z niniejszą umową licencyjną
może po prostu nacisnąć „Zgadzam się”.
i w zależności od twojego internetu
połączenie zajmie to kilka minut
pobrać i zainstalować tak jak jest
Zajmie mi to kilka minut
zatrzymaj wideo tutaj i wróć kiedy
instalacja jest zakończona
ok i oprogramowanie powiodło się
zainstalowany
więc tylko po to, żeby się upewnić, że jadę
uruchomić git
i jak widać został zainstalowany
więc teraz, gdy mamy zainstalowanego git, my
chcesz sklonować wszystkie katalogi i
pliki z repozytorium github do
nasz lokalny folder repozytoriów, więc zamierzam to zrobić
otwórz moją przeglądarkę i zamierzam
wklej mój adres URL repozytorium github w prawo
Tutaj
I
zobaczysz przycisk klonowania tutaj, więc
klikniemy w ten przycisk
i tutaj możemy pobrać zip, ale jak ja
powiedział, że nie będziemy tego robić
idziemy tutaj
i skopiuj ten adres URL dla github
repozytorium ponownie upewnij się, że jest napisane https
i skopiujemy to do naszego
schowek
i wracamy do swoich
terminal
i zamierzamy
uruchom polecenie git space
klon
i zamierzamy wkleić nasz adres URL
i jak widać tutaj sklonowałem plik
repozytorium oraz wszystkie pliki i foldery
w nim i zgodnie z moją najlepszą praktyką
zawsze lubię sprawdzać, czy pliki
zostały odpowiednio sklonowane, więc ja też
zamierzam uruchomić polecenie ls
tylko po to, żeby się upewnić i wejść do mistrza
informator
i zrób podwójne sprawdzenie i jak widać
klon odniósł sukces, jak wszystkie
pliki i foldery są tu i tam
pobierać aktualizacje do dowolnych plików lub
katalogi, które możemy po prostu uruchomić
polecenie git space poll i ponieważ my
już sklonowałem, to już jest do zrobienia
data i tak będzie przebiegał proces
bardzo podobny na Linuksie, więc idę
aby po prostu przejść na moją maszynę z Linuksem
i zaloguj się
zamierzam otworzyć terminal
i zamierzam uczynić mój terminal a
trochę większy dla lepszego oglądania i
więc podobnie jak inne systemy operacyjne, tj
chcesz sklonować wszystkie pliki i
katalogi z repozytorium github
do mojego komputera, więc idę na cd
tutaj, aby upewnić się, że jestem w moim domu
katalog i tak jak zrobiliśmy to wcześniej
aby utworzyć katalog o nazwie repos so
zamierzam uruchomić polecenie mkdir space
repos i zamierzamy to zrobić
utwórz katalog repozytoriów, w którym teraz jesteśmy
zamierza przenieść się do katalogu repozytoriów
i tutaj uruchomimy git
Komenda
a ponieważ git nie jest zainstalowany na moim
maszyna, o którą poproszono mnie
polecenie, aby go zainstalować, więc jestem
zamierza uruchomić to teraz, więc polecenie brzmi
Sudo
przestrzeń
trafny
przestrzeń
zainstalować
przestrzeń
Dostawać
i zamierzam wpisać swoje hasło
i zainstaluj go
i tylko po to, aby sprawdzić, czy zamierzam uruchomić plik
polecenie git i widzę, że to było
zainstalowany, więc teraz przejdę
tutaj do mojej przeglądarki i zamierzam to zrobić
wklej adres URL do mojego repozytorium i
tutaj będziemy mieli tego samego klona
przycisk, a kiedy go kliknę, mogę uzyskać
adres URL repozytorium github w
aby sklonować go ponownie, upewnij się wcześniej
klonujesz, że to mówi https
jeśli nie mówi https, będziesz mieć
możliwość kliknięcia przycisku, który to zrobi
pozwól ci to zrobić, gdy pojawi się https
następnie możesz po prostu skopiować ten adres URL do
schowek, klikając przycisk
a następnie przejdź z powrotem do terminala
i zamierzamy to sklonować
repozytorium, wpisując spację get
polecenie klonowania
wraz z adresem URL repozytorium
a kiedy wciśniemy enter, sklonuje to
aż do naszego katalogu, więc jestem po prostu
przejdzie do katalogu głównego
tylko po to, aby sprawdzić, czy pliki tam są
i znowu wszyscy tu są, więc znowu jeśli
chcesz zaktualizować swoje repozytorium
z wszelkimi nowymi zaktualizowanymi zmianami, które możesz
po prostu biegnij
komenda get space pull
zaktualizować te pliki
i to jest konfiguracja Linuksa, więc ty
mieć lokalną kopię plików lekcji
teraz jest jeszcze jedna rzecz, którą ja
gorąco polecam zrobić i zrobić
zademonstruj to, cofnę się
teraz na moją maszynę wirtualną z systemem Windows
zamierzam otworzyć przeglądarkę internetową
Ponownie
otwórz nową kartę
i zamierzam przejść do tego adresu URL
https dwukropek ukośnik ukośnik
kod.visualstudio.com
[Muzyka]
i upewnię się, że adres URL jest w środku
tekst poniżej jest wersją
ten edytor kodu dostępny dla systemu Windows
mac os i linux, które możesz po prostu kliknąć
to menu rozwijane, a znajdziesz link
aby pobrać go dla swojego systemu operacyjnego
ale w większości przypadków powinno
automatycznie pokaż poprawną wersję
więc po prostu idź dalej i kliknij pobierz
i powinno rozpocząć się pobieranie
automatycznie i powinieneś być w stanie to zrobić
uruchomić go od razu
teraz powód, dla którego cię proszę
install to narzędzie służy do edycji kodu
różnego rodzaju
niezależnie od tego, czy dostosowujesz yaml, czy python
dokumenty dla kierownika wdrażania
lub nawet zarządzanie skryptami
edytor kodu zapewni ci łatwość
używać, jeśli chodzi o zarządzanie edycją
a nawet podświetlanie składniowe
kod, jak pokazano tutaj poniżej
podświetli kod, aby to zrobić
łatwiejsze do zrozumienia teraz, jeśli masz
własnego edytora, którego wolisz
użyj śmiało i użyj tego, ale dla tych
że nie moja rekomendacja będzie
użyj kodu Visual Studio, aby zainstalować
Visual Studio, do którego właśnie zamierzamy przejść
zaakceptować niniejszą umowę licencyjną
a następnie klikniemy dalej
i będziemy po prostu śledzić wszystkie
domyślne
aby go zainstalować
zajmie to minutę lub dwie
i dla tych uruchomionych okien, które chcesz
aby upewnić się, że to pole jest zaznaczone
wyłączony, aby można było go od razu uruchomić
zakończmy
kolejną rekomendacją byłoby pójście
tutaj do paska zadań, abyś mógł przypiąć
umieścić go na miejscu, aby łatwiej go było znaleźć
i tak teraz masz dostęp do wszystkich
zasoby potrzebne do tego kursu
ale z tym to wszystko, co ja
chciałem pokryć tę lekcję, więc ty
może teraz oznaczyć tę lekcję jako ukończoną i
przejdźmy do następnego
[Muzyka]
witaj z powrotem iw tej lekcji chciałem
w celu omówienia różnych certyfikatów
dostępne dla Google Cloud jako to
liczba stale rośnie i szukam
aby ta lekcja była jak najbardziej aktualna
możliwe, więc z tym powiedziawszy
nurkować w
teraz chmura Google wydała mnóstwo
certyfikaty z wielu dziedzin
specjalistycznej, jak i różnej
poziomy doświadczenia
teraz są dwa poziomy trudności
jeśli chodzi o chmurę Google
certyfikaty zaczynające się na
poziomie stowarzyszonym widzimy, że istnieje
tylko jeden certyfikat, którym jest
inżynier chmury poziom współpracownika
certyfikacja koncentruje się na
podstawowe umiejętności rozmieszczania
monitorowanie i utrzymywanie projektów na
Google Cloud to świetny początek
punkt dla tych, którzy są zupełnie nowi w chmurze
a Google poleca współpracownika
inżynier chmury jako punkt wyjścia
w trakcie Twojej podróży certyfikacyjnej
to była pierwsza chmura Google
certyfikat i do mnie był wpis
punkt, w którym chcesz dowiedzieć się więcej jako
moim zdaniem inżynier w chmurze
bez względu na twoją rolę ten certyfikat
obejmie wiedzę ogólną tj
trzeba wiedzieć, jak zacząć korzystać z Google
chmura i usługi w niej zawarte, które
dlatego oznaczyłem to tutaj jako
kurs na poziomie podstawowym I również
potraktuj to jako krok milowy
na jakikolwiek inny poziom zawodowy
certyfikaty, które również się zdarzają
zalecana ścieżka przez google z a
świetny kurs i trochę poświęcenia, naprawdę
uwierz, że każdy, kto ma nawet podstawy
poziom umiejętności w nim powinien być w stanie
osiągnąć ten poziom współpracownika
certyfikacja teraz jest zalecana od
Google sami, że przed podjęciem
ten egzamin, który powinieneś mieć powyżej sześciu
miesiące doświadczenia w budowaniu w Google
chmura dla tych z was, którzy mają więcej
zaawansowane tło w chmurze google lub
nawet inne chmury publiczne to
certyfikacja powinna być łatwa do przejścia, ponieważ
obejmuje podstawy, którymi powinieneś być
zaznajomiony z dodawaniem zwrotu Google do
to w czasie tej lekcji ten egzamin
trwa dwie godziny, a koszt to 125 nas
dolarów egzamin jest w sumie 50
pytania, które składają się z obu
wielokrotnego wyboru i wielu odpowiedzi
pytania, które zawiera każde z pytań
pytania z trzech do czterech linii z pojedynczym
linia odpowiada, że ​​zanim skończysz
ten kurs powinieneś mieć
pewności w identyfikacji błędnych
odpowiedzi
i umieć wybrać właściwe odpowiedzi
bez problemu wsiadając do
tam certyfikaty na poziomie profesjonalnym
to siedem certyfikatów obejmujących a
różne obszary specjalizacji w zależności
w swojej roli, którą możesz chcieć przyjąć
a może kilka z tych certyfikatów
aby pomóc Ci zdobyć więcej wiedzy nt
google cloud lub jeśli lubisz edukować
siebie i naprawdę kochasz swoje
podróż w gcp prawdopodobnie będziesz chciał
rozważ ściganie ich wszystkich w moim
osobista opinia jest najlepszym punktem wyjścia
do poziomu zawodowego byłoby
Cloud Architect to naturalny krok naprzód
od współpracownika inżyniera chmury i to
opiera się na tym, czego się nauczyliśmy
to zaświadczenie z bardziej szczegółowym
i dokładniejsze zrozumienie chmury
architektura potrzebna każdemu
inne certyfikaty istnieją
pokrywają się z inżynierem chmury, który jest
dlaczego moim zdaniem to robi
certyfikacja zaraz po ma sens
niesie ze sobą również umiejętność
projektowanie, opracowywanie i zarządzanie bezpieczne
skalowalna i wysoce dostępna dynamika
rozwiązań jest to znacznie trudniejszy egzamin i
zagłębia się w usługi
dostępna profesjonalna chmura
architekt jest świetnym podkładem dla każdego
inny certyfikat poziomu zawodowego
i może być naprawdę pomocny w utrwaleniu
nauka, która jest potrzebna w każdym innym
rola techniczna, którą uważam za najczęstszą
ścieżka, którą podąża wielu, którzy chcą się uczyć
Google Cloud, dlatego ja osobiście
polecam im to iw czasie
ta lekcja jest również najwyższa
zwrot z inwestycji
ze względu na najwyższą średnią płacę ze wszystkich
inne aktualne certyfikaty chmurowe w
market google zaleca ponad trzy
wieloletnie doświadczenie w branży m.in
rok wcześniej w Google Cloud
przystąpienie do tych egzaminów w odniesieniu do
egzaminy na poziomie zawodowym im
są znacznie trudniejsze niż poziom stowarzyszony
a w czasie tego kursu jest dwa
godzin, a koszt to 200 nas
dolarów te egzaminy są w sumie 50
pytania, które składają się z obu
wielokrotnego wyboru i wielu odpowiedzi
pytania to ta sama ilość
pytania z taką samą ilością czasu
ale każdy z nich jest znacznie trudniejszy
pytania zawierają od czterech do pięciu linii
pytania z jedną do trzech linii odpowiedzi
zdecydowanie nie jest to spacer po parku
i zajmie trochę dobrej koncentracji
i szczegółową wiedzę na temat chmury Google
utrwalić podanie po ukończeniu
certyfikacja architekta chmury w zależności
na twoją rolę, moja sugestia byłaby taka
podążaj w obszarach, które Cię interesują
najbardziej, aby Twoja podróż była przyjemniejsza
dla mnie w momencie, gdy wziąłem zabezpieczenie
inżyniera, którego jestem wielkim fanem
bezpieczeństwa i wiedziałem, że naprawdę
cieszyć się nauką i uczynić ją bardziej zabawną
dla mnie to też super
Certyfikat dla tych, którzy szukają
doskonalić swoją wiedzę na temat bezpieczeństwa w chmurze
nad wszelkimi innymi zabezpieczeniami
certyfikaty, takie jak bezpieczeństwo plus
lub cissp
teraz inni mogą być wielkimi fanami
networking lub utrzymywanie innych networkingów
certyfikaty, takie jak ccna i tak dalej
uzyskanie inżyniera sieci
certyfikacja może bardziej zależeć od ciebie
zaułek i dać ci lepsze
zrozumienie w sieciach w chmurze teraz, jeśli
jesteś w przestrzeni danych, której możesz potrzebować
przystąpić do egzaminu na inżyniera danych jako
jak również biorąc pod uwagę uczenie maszynowe
egzamin inżyniera, aby naprawdę wejść głębiej
wiedza z zakresu big data
uczenie maszynowe i sztuczne
inteligencja w chmurze Google, teraz już wiem
że jest wielu, którzy kochają mnie
będąc jednym z nich i naprawdę chcę kopać
głębiej i zrozumieć sre i tak oni
skończyć z deweloperem chmury i
certyfikaty inżynierów cloud devops, więc
Najważniejsze jest to, co cię przynosi
radość w wybranym przez siebie miejscu startu
z tym i przejdź do reszty
certyfikaty zawodowe są
cenne, ale pamiętaj, że są
trudne i wymagają przygotowania do nauki na końcu
ale nie mniej ważna jest współpraca
certyfikat inżyniera i to
certyfikacja koncentruje się na rdzeniu Google
narzędzia do współpracy w chmurze, które są
dostępne w G Suite lub tym, co jest teraz
znane jako przestrzenie robocze Google, takie jak Gmail
Dokumenty i arkusze Hangouts Drive teraz
współpraca na profesjonalnym poziomie
certyfikacja inżynierów to więcej
zaawansowane obszary G Suite, takie jak poczta
zarządzanie tożsamością routingu i
zautomatyzować to wszystko za pomocą narzędzi
skrypty i API
ten certyfikat jest dla nich świetny
chcą zbudować swój zestaw umiejętności jako
administrator tych narzędzi, ale daje
bardzo mała znajomość chmury Google
sam, więc zanim przejdę dalej, jest jeden
więcej certyfikatów, które chciałem
okładka, która nie mieści się w
certyfikat stowarzyszony lub zawodowy
poziomy i to jest chmura Google
certyfikowany program partnerski
teraz to zdecydowanie
jeden z najtrudniejszych certyfikatów
uzyskać, ponieważ jest bardzo mało certyfikowanych
koledzy w czasie nagrywania tego
lekcja jest jeszcze trudniejsza niż
certyfikaty poziomu zawodowego i
wynika to z czystego poziomu
kompetencje w zakresie hybrydowego środowiska wielu chmur
architektury korzystające z Google Cloud Anthos
zalecane doświadczenie Google
ma ponad 10 lat z rokiem
projektowanie rozwiązań dla przedsiębiorstw z
anthos rozpoczyna się czteroetapowy proces
pierwszym krokiem jest otrzymanie certyfikatu
kolega zaproszenie od Google i raz
otrzymałeś to zaproszenie, a potem ty
trzeba złożyć wniosek z niektórymi
próbki pracy, które wykonałeś
pokazując Google swoje kompetencje w hybrydach
multi-cloud, gdy jest to zrobione trzeci
step to seria praktycznych ćwiczeń technicznych
laboratoria, które należy wypełnić i jest
ocena kwalifikacyjna, która musi być
przeszedł, aby kontynuować i po
wszystko to, że ostatnim krokiem jest panel
wywiad przeprowadzony z ekspertami Google ds
w celu oceny Twoich kompetencji
projektowanie rozwiązań hybrydowych i wielochmurowych
rozwiązania z anthosem, jak widać
tutaj jest to bardzo trudne i wysoce
zaangażowany proces certyfikacji
do uzyskania tytułu stypendysty
to zdecydowanie nie jest dla słabych
serce, ale może wyróżnić się jako
lider techniczny w Anthos i hybrydzie
ekspertem od wielu chmur w Twojej branży
wiele razy jestem pytany czy
certyfikaty mają jakąkolwiek wartość
łatwe do zdobycia, czy są warte więcej niż
dokumenty, na których są wydrukowane, i
czy to pokazuje, że ludzie naprawdę wiedzą jak
korzystać z chmury Google, a moja odpowiedź brzmi
zawsze tak, jak utrzymują certyfikaty
korzyści wykraczające poza samą certyfikację
i oto dlaczego celujesz w siebie
za certyfikat daje
kamień milowy w nauce czegoś nowego
dzięki temu nowemu kamieniowi milowemu na to pozwala
ułożyć plan nauki, aby
zdobyć niezbędną wiedzę
nie tylko zdać egzamin, ale także zdobyć umiejętności
potrzebne, aby robić postępy w codziennym życiu
techniczną rolę pomaga ta nowa wiedza
dlatego aktualizuj swoje umiejętności
czyniąc cię aktualnym, zamiast stać się
relikt mający teraz te aktualne umiejętności
pomoże również w rozwoju Twojej kariery
przez całą moją karierę w chmurze
zawsze udawało mi się postawić stopę w
drzwi z różnymi wywiadami z powodu mojego
certyfikaty, które mi dał
możliwość zabłyśnięcia przed
wywiad, będąc w stanie
pewnie pokazać swoje umiejętności w chmurze
pozwoliło mi to również na znalezienie pracy
szukałem i wyrzeźbiłem
ścieżka kariery, którą naprawdę chciałem być na szczycie
lądowania na stanowiskach, na których mi zależało
w stanie osiągnąć wyższą pensję dzięki
certyfikaty, które posiadałem, podwoiły się
i potroiłem moją pensję od pierwszego razu
zaczęło się w chmurze, wszystko z powodu mojego
certyfikaty i znam innych
które uzyskały aż pięć razy
ich pensje z powodu ich
certyfikaty teraz to nie było tylko
od uzyskania certyfikatu do wprowadzenia
w moim CV i w mediach społecznościowych, ale
z wiedzy zdobytej przez
proces i oczywiście ja osobiście czuję
że stale podnosisz swoje umiejętności
data
rozwijać swoją karierę i zdobywać
wynagrodzenie, które chcesz, motywuje
nie tylko uzyskać więcej certyfikatów, ale
kontynuować proces uczenia się jestem i
zawsze byli wielkimi zwolennikami
uczenie się przez całe życie i jak zawsze powtarzam
kiedy kontynuujesz naukę, kontynuujesz
rozwijać się tak w skrócie Google Cloud
Certyfikaty to świetny sposób na rozwój
i tak to o obejmuje wszystko, co
chciałem omówić w tej lekcji tak
możesz teraz oznaczyć tę lekcję jako zakończoną
i do zobaczenia w następnym
[Muzyka]
Witamy spowrotem
i na tej lekcji będę
mówić o fikcji
organizacja o nazwie muszka inc, która i
będzie używany przez cały kurs
teraz przechodząc przez
architektury i demonstracje w tym kursie
razem chciałem związać je z prawdziwym
sytuacja na świecie
tak, że teoria i praktyka
przykłady są łatwe do zrozumienia
powiązanie go ze scenariuszem jest łatwym sposobem
zrób to i to dużo daje
więcej zabawy
więc znowu scenariusz
którego będę używać opiera się na muszce
atrament
więc zanim zaczniemy kurs
chciałbym szybko przejść przez
scenariusz
i nie martw się, będzie bardzo
wysoki poziom i będę trzymał to krótko
więc atrament z muszką jest muszką
firma produkcyjna, która projektuje i
produkuje muszki we własnym zakresie
fabryki
posiadają również kilka punktów sprzedaży detalicznej
gdzie sprzedają również swoje muszki
jak sprzedaż hurtowa do innych tajskich i męskich
butiki i domy towarowe
na całym świecie
będąc w branży modowej
zajmują się głównie bezpieczeństwem handlu
i duże zbiory danych
muszka inc jest firmą globalną i oni
mają siedzibę w Montrealu w Kanadzie
zatrudniają około 300 osób na całym świecie
z setką z nich w sprzedaży
sam, aby wspierać zarówno cegłę, jak i
sklepy z moździerzami i hurtownie
istnieje wiele różnych działów
firma, która sprawia, że ​​​​działa, np
personel sklepu
To
marketingu zarówno w sklepie stacjonarnym, jak i internetowym
obroty
finanse produkcji i nie tylko
rodzaje pracowników, którzy pracują w ukłonie
tie inc różnią się znacznie ze względu na różne
działów i składa się z wielu osób
takich jak sprzedaż zarówno w sklepie, jak i
kierowników hurtowni prowadzących sklepy
i kanalizacji, które działają w
Zakład produkcyjny
i wiele innych, które działają w tych różnych
działy
firma ma oba biura
i sklepy stacjonarne
w Montrealu
Londyn i Los Angeles
teraz ze względu na oszczędny sposób myślenia
zarządzanie koncentrując wszystkie swoje
wysiłków na rzecz handlu i prawie żadnych
spowodowała infrastruktura techniczna
wieloletni dług techniczny
i obecnie jest kompletną katastrofą
w miejscu murowanym
zawiera dwa stojaki z kilkoma
serwery i niektóre urządzenia sieciowe
światowy wykaz muszek są
aktualizowane po sprzedaży w obu sklepach
i hurtowych, jak również nowych zapasów
został wyprodukowany z fabryki
w każdym są systemy punktów sprzedaży
lokalizacja sklepu lub biura
wszystkie te systemy są ze sobą połączone
inne przez połączenie VPN, aby
zachować aktualizacje inwentarza świeże
cała infrastruktura biurowa i sklepowa
połączone ze sobą i montrealem
siedziba
oraz systemy punktów sprzedaży i kiosk
kopie zapasowe systemów są tworzone na taśmie w formacie
siedziba w Montrealu i podobnie jak ja
powiedział wcześniej
zarządzanie jest niezwykle oszczędne, ale oni
wreszcie doszli do wniosku
że muszą zacząć wydawać pieniądze
o porządek w infrastrukturze technicznej
skalować, aby przejść do szybkiego przeglądu
dokładnie tego, jak wygląda architektura
jak siedziba główna znajduje się w
Montreal Kanada
ma swoją główną bazę danych dla CRM i
systemy punktów sprzedaży
jak również ponosi odpowiedzialność
obudowa sprzętu do taśmy
kopii zapasowych, taśmy są następnie usuwane
witryny w Montrealu przez osobę trzecią
firma do przechowywania
firma posiada dwa główne biura w jednym
londyn obejmujący ue
a drugi na zachodnim wybrzeżu nas
w Los Angeles te główne biura
to także punkty sprzedaży detalicznej, które konsumują
obsługuje z centrali w
Montreal znów jest w modzie
Business Bowtie Inc zatrudnia dużą
ilość sprzedawców i kierowników
które ich wspierają
ci pracownicy obsługują
systemy punktów sprzedaży, więc jesteśmy
stale poszukuje strony internetowej
sprzedaży i zapasów aktualizowane w ogóle
razy każdy sprzedawca ma dostęp
e-mail i pliki do zaktualizowanych prognoz na temat
różne nowe wzory muszek
większość sprzedawców komunikuje się przez a
Voice over IP Phone i programy do czatu
przez telefon komórkowy menedżerów
również ręcznie przeglądaj zapasy na
co zostało sprzedane
w porównaniu z tym, co jest w magazynie
prognozować sprzedaż dla sklepów w
nadchodzące tygodnie
to da produkcji głowę
zacznij robić więcej muszek na przyszłość
obroty
teraz niezależnie od implementacji, które my
omawiać przez cały kurs
będziemy musieli wspierać na co dzień
działania handlowców i
menedżerowie
oraz ze względu na różne strefy czasowe
w grze
infrastruktura zaplecza musi być
dostępny
24 godziny na dobę siedem dni w tygodniu
wszelkie przestoje będą miały wpływ na aktualizację
zapasy zarówno dla sprzedaży internetowej, jak i
jako sprzedaż w sklepie w dowolnym momencie
teraz porozmawiajmy o prądzie
problemów, z jakimi boryka się firma
większość lokalizacji posiada sprzęt lokalny
to jest nieaktualne, a także nieaktualne
Gwarancja
firma rozważała rozszerzenie tego
gwarancji, ale stał się również bardzo kosztowny
kierownictwo zastanawia się, czy
kupić nowy sprzęt lokalny lub po prostu
przenieść się do chmury, tak im powiedziano
Chmura google to dobry sposób, aby to zrobić
przychodzi do powierzchni handlowej i tak jest
otwarty na sugestie
ale wciąż bardzo zmęczony teraz, kiedy to przychodzi
do wydajności wydaje się być głównym
opóźnienie z połączenia VPN ze sklepu
przechować
jak również siedziba główna
odpowiedzialność za prawidłowy stan magazynowy
spowalniając w ten sposób punkt sprzedaży
systemów i do tego wszystkiego
kopie zapasowe zajmują wygórowaną ilość
czas
zużywa dużo przepustowości
obecne połączenie VPN teraz Bowtie Inc
zawsze borykał się z brakiem
wysoka dostępność systemów i skalowalność
ze względu na koszt nowego sprzętu tak jest
powodując ekstremalny stres w Internecie
e-commerce, gdy nowy marketing
rusza kampania
ponieważ systemy nie nadążają
z popytem
patrząc na prognozę na następne dwa
kwartałów firma zamierza otworzyć
więcej sklepów w ue
jak i w nas
i przy aktualnej bazie danych
dostarczanie bardzo nieefektywnego haju
dostępność lub skalowalność
istnieje poważne zagrożenie ze strony głównej
baza danych spada
teraz jeśli chodzi o ocenę
kopii zapasowych, jakimi stały się kopie taśmowe
bardzo wolno, zwłaszcza tworzenie kopii zapasowych z
Londyn i koszty przechowywania poza terenem zakładu
stale idą w górę każdego roku
kopie zapasowe pochłaniają dużo
przepustowości i zaczynają stawać się
główny punkt bólu
w przypadku problemów z połączeniem między lokalizacjami
na szczycie wszystkich tych problemów małe to
zatrudniony personel jest przestarzały
umiejętności, więc jest dużo instrukcji
interwencję, którą należy wykonać
żeby zwieńczyć to całe bieganie
jest to konieczne, aby zachować przestarzałe
infrastruktura żyje
kierownictwo również teraz naciska na otwarcie
nowe sklepy dostarczające muszki na całym świecie
biorąc pod uwagę stale rosnące zapotrzebowanie
a także jest w stanie dostarczyć
popyt na muszki online za pośrednictwem ich
sklep internetowy
teraz są to realistyczne, ale powszechne
scenariusze, które pojawiają się w rzeczywistości dla a
wiele firm, które nie korzystają
Chmura obliczeniowa
i przez cały kurs będziemy nurkować
o tym, jak Google Cloud może pomóc złagodzić
ból
z tych bieżących bieżących problemów
teraz na wysokim poziomie z czym
biznes chce osiągnąć i co
korzystne wyniki są
wszystkie są ze sobą powiązane, więc
Bowtie Inc wymaga niezawodnego i
stabilne połączenie między wszystkimi
lokalizacji sklepów i biur
więc sprzedaż
systemy inwentaryzacji i punkty sprzedaży
szybko i zawsze na bieżąco
umożliwi to również wszystkim pracownikom w nich
lokalizacjach, aby pracować o wiele wydajniej
ze stabilnym i niezawodnym łączem w
miejsce
kopie zapasowe powinny działać płynnie
a także wyeliminować koszty związane z wyjazdem na miejsce
kopia zapasowa
nie wspominając o sile roboczej i
infrastruktury potrzebnej do zdobycia pracy
zrobione
jednocześnie powiększając biura i sklepy
aby zwiększyć popyt
firma powinna być w stanie wdrożyć
sklepy w nowych regionach, korzystając z opcji płatności zgodnie z Twoimi preferencjami
przejdź do rozliczeń, jednocześnie spełniając
wymagania i przepisy, kiedy to
chodzi o gpdr i pci
dałoby to również biznesowi
elastyczność w przypadku katastrofy
wdrożona strategia naprawy
w przypadku awarii głównego
baza danych w Montrealu teraz, jak wspomniano
zanim biznes jest wyjątkowo oszczędny
zwłaszcza jeśli chodzi o wydatki na to
infrastruktura
a więc celem jest, aby koszty były jak
możliwie niski, ale mający
elastyczność skalowania w razie potrzeby
zwłaszcza przy nowych kampaniach marketingowych
są uruchamiane podczas wyprzedaży o dużym popycie
okresy
to również dałoby muszkę inc
elastyczność analizy sprzedaży z wyprzedzeniem
czas
za pomocą analityki w czasie rzeczywistym i cateringu
do tego, kim dokładnie jest klient
wymagający
dzięki czemu inwentarz jest znacznie większy
dokładne i redukujące koszty w
wytwarzanie przedmiotów, które ostatecznie trwają
sprzedaż i kosztowanie firmy pieniędzy
koniec
wreszcie, jeśli chodzi o ludzi
wspieranie automatyzacji infrastruktury
klucz
usuwanie czynności ręcznych i wiele innych
procesy mogą zmniejszyć ilość
siły roboczej potrzebnej do utrzymania
infrastruktura żyje
a zwłaszcza zmniejszy przestoje, gdy
powstaje katastrofa
wprowadzenie automatyzacji również
zmniejszyć liczbę żmudnych zadań, które
wszystkie wydziały mają na swoim talerzu
aby mogli skupić się na ważniejszych
potrzeby biznesowe
teraz to jest scenariusz na wysokim poziomie
chciałem to naprawdę podkreślić
to typowy typ scenariusza, który ty
zmierzy się jako inżynier chmury i
architekt chmury
kluczem do tego scenariusza jest fakt
że są obszary, których brakuje
Szczegół
i obszary, które są w pełni zrozumiałe
a to uruchomi wiedzę kiedy i
gdzie zadać odpowiednie pytania
zwłaszcza w Twojej codziennej roli jako
inżynier
pozwoli Ci to wypełnić luki tzw
że jesteś w stanie dowiedzieć się, co
usług, których będziesz potrzebować i jakiego rodzaju
architektura do wykorzystania
jest to również niezwykle pomocne, gdy
przychodzi na egzamin
jak na egzaminie, z którym przyjdzie ci się zmierzyć
pytania odnoszące się do prawdziwego życia
scenariusze, które przetestują Cię w
podobny sposób wiedząc, jakie usługi i
architektura do użycia w oparciu o
podane informacje
zawsze da ci klucze do
drzwi z właściwą odpowiedzią i na koniec
jeśli chodzi o dema
ten scenariusz był używany przez cały kurs
pomoże spojrzeć na sprawę z perspektywy
jak przyjdziemy, aby rozwiązać wiele
te wspólne problemy
realistyczne scenariusze mogą dać ci
lepszą perspektywę na naukę taką, jaka jest
przywiązany do czegoś, co ułatwia
zrozumieć
i znowu muszka inc to scenariusz
z którego będę korzystać przez cały
kurs, który pomoże ci zrozumieć te pojęcia
więc to wszystko co mam do omówienia
scenariusz, abyś mógł teraz zaznaczyć tę lekcję
jako kompletne i przejdźmy do
Następna
[Muzyka]
hej, tu anthony cevallos i co ja
chciałem ci pokazać, gdzie możesz
dostęp do egzaminu praktycznego na egzaminie pro
platforma
więc po zapisaniu się na swoje
konto, na które możesz przejść
kurs
i możesz przewinąć w dół do dołu
listę programów i zobaczysz
egzaminy praktyczne tutaj na dole
teraz tylko jako szybka notatka
ogólnie nie powinieneś próbować
egzamin praktyczny, chyba że go ukończyłeś
cała treść wykładu, w tym m.in
postępuj zgodnie ze wskazówkami, jak tylko zaczniesz widzieć
na te pytania będziesz miał ochotę
zacznij zapamiętywać te pytania
i dlatego zawsze zalecam korzystanie z
egzamin próbny jako poważną próbę
a nie tylko droga do finału
egzamin w szybszym tempie, nie spiesząc się
z kursem
pozwoli ci naprawdę zwyciężyć
te egzaminy praktyczne i pozwalają na
znacznie lepszą zdawalność egzaminu końcowego
patrząc tutaj widzimy dwie praktyki
egzaminy z 50 pytaniami każdy i tak ja
chciałem poświęcić tutaj chwilę i zanurkować
do egzaminu praktycznego
i pokazać, co niektóre z nich
pytania będą wyglądać i tak klikać
do jednego z tych egzaminów, który możemy zdać dobrze
w to i tak jak widać ja
już rozpoczęty na egzaminie praktycznym 1 i
więc zamierzam kliknąć to po prawej stronie
teraz i jak widać egzamin jest
zawsze na czasie i w tym przypadku będzie
120 minut na ten konkretny egzamin
to 50 pytań do tego egzaminu praktycznego
i zobaczysz podział w
początek
rodzajów pytań, które będziesz mieć
poprosił teraz o egzaminy Google Cloud o godz
poziom współpracownika, na którym zwykle są
ustrukturyzowane we wspólnym formacie
zazwyczaj zaczynają się od jednego lub dwóch
linie zdań, które zazwyczaj
reprezentują scenariusz, po którym następuje
zadaje sobie to pytanie
mów krótko i od razu na temat
następnie zostaniesz przedstawiony
z kilkoma odpowiedziami
zwykle cztery lub pięć z natury i może
czasami są bardzo bardzo techniczne, jak oni
są przeznaczone dla inżynierów, takich jak pytanie
o tym, jakich poleceń gcloud użyć
wykonać w danym scenariuszu, jak również
teoretyczne pytania, z którymi można sobie poradzić
powiedzmy najlepsze praktyki lub pytania
o samych usługach
teraz te odpowiedzi przyjdą w dwóch
różne style wielokrotnego wyboru lub
wielokrotny wybór to zazwyczaj wielokrotny wybór
o wskazanie poprawnej odpowiedzi
z grupy błędnych lub mniej
poprawne odpowiedzi, podczas gdy wielokrotny wybór
będzie o wybranie wielu poprawnych
rozwiązania, aby zidentyfikować odpowiedź, jak również
dla tego egzaminu stowarzyszonego ogólny
struktura jest dość prosta z natury i
zwykle będzie albo słuszna, albo niewłaściwa
teraz czasami te pytania mogą się pojawić
trudne, gdy istnieje wiele możliwych
odpowiedzi
i będziesz musiał wybrać najwięcej
odpowiednie
teraz chociaż większość tego typu
pytania
zwykle pojawiają się na egzaminie zawodowym
czasami mogą zajrzeć do środka
współpracownik, a więc świetna taktyka
zawsze lubię używać jest natychmiast
określ, co jest ważne w pytaniu
samo
a następnie zacząć wykluczać którekolwiek z nich
odpowiedzi, które są błędne i tak będzie
pozwoli Ci odpowiedzieć na wiele pytań
szybciej i wydajniej, jak będzie
podaj bardziej poprawną odpowiedź
powierzchni, a także udzielając odpowiedzi a
dużo bardziej oczywiste
i zmniejszając całe pytanie
skomplikowane, więc na przykład z this
pytanie tutaj jest natychmiast zadawane
o zalecanych praktykach Google
jeśli chodzi o korzystanie z pamięci w chmurze jako
kopia zapasowa do odzyskiwania po awarii i to
byłoby dla określonego typu magazynu i
tak szybko patrząc na odpowiedzi
widać, że standardowe przechowywanie i blisko
pamięć liniowa nie będzie częścią
odpowiedź, a więc opuści zimną linię
przechowywanie lub przechowywanie archiwum jako dwa
możliwe wybory
za odpowiedź na to pytanie i tak dalej
są to typowe techniki, które ja
zawsze lubię używać
do tych egzaminów i tak pod warunkiem, że
przeszedłeś cały kurs
treści będziesz w stanie na nie odpowiedzieć
pytania techniczne z łatwością i
stosując techniki, które właśnie podałem
i stosując je do każdego pytania
naprawdę może Ci pomóc nie tylko w tym
egzamin praktyczny, ale do egzaminu końcowego
dając ci ocenę pozytywną, zdobywając cię
atestowany
[Muzyka]
witaj z powrotem iw tej sekcji i
chciałem naprawdę dopracować podstawy
charakterystyki przetwarzania w chmurze
sprawiają, że jest tym, czym jest
różne rodzaje komputerów
i jak różnią się od siebie jako
jak również rodzaje modeli usług obecnie
w tej lekcji chciałem zagłębić się w
definicja przetwarzania w chmurze i
podstawowe cechy, które ją definiują
teraz dla niektórych zaawansowanych ludzi, którzy to oglądają
to może być recenzja
i dla innych
może to zapewnić lepsze zrozumienie
na temat tego, co jest teraz chmurą, chmura jest terminem
które jest często rzucane w dzisiejszych czasach
posiada jeszcze inną definicję lub
wyrozumiałość dla każdego
indywidualny
prawdopodobnie mógłbyś zaprosić 10 osób dalej
ich definicję chmury i szans
Czy
każdy miałby na to swoje zdanie
wielu postrzega chmurę jako tę abstrakcyjną rzecz
niebo
gdzie przechowywane są pliki i wiadomości e-mail, ale
to o wiele więcej
teraz można podać jego prawdziwą definicję
w bardzo prostych słowach
i może być zastosowany do dowolnej chmury publicznej
być chmurą Google
aws
i lazurowy
przechodząc do definicji
przetwarzanie w chmurze to dostarczanie
wspólna pula obliczeń na żądanie
usługi w ogólnodostępnym internecie
które można szybko dostarczyć
i zwolniony
przy minimalnym wysiłku zarządzania lub
interakcji usługodawcy
te usługi komputerowe
składają się z rzeczy takich jak serwery
składowanie
sieci i bazy danych, jakie mogą być
szybko udostępniane i dostępne z
Twój lokalny komputer
przez połączenie internetowe, które jest teraz połączone
z tą definicją jest pięć zasadniczych
cechy definiujące chmurę
model, z którym chciałbym się zapoznać
Ty i ja wierzymy, że to się utrzyma
ogromne korzyści dla zrozumienia kiedy
rozmawiając z chmurą, te informacje mogą
można znaleźć w białej księdze opublikowanej przez
narodowy instytut norm i
technologii, dołączę link do tego
publikacja w notatkach do lekcji dla Ciebie
przejrzyj teraz te niezbędne
cechy są następujące pierwsze
jeden
jest samoobsługą na żądanie
i można to określić jako zdolność
udostępniać zasoby automatycznie
bez konieczności interakcji człowieka
koniec dostawcy
więc w końcu nigdy nie będziesz musiał
zadzwonić lub wejść w interakcję z usługą
dostawcy w celu uzyskania zasobów
przygotowane dla Ciebie
jak również masz elastyczność
możliwość udostępniania i anulowania udostępniania
te zasoby
kiedy ich potrzebujesz i w dowolnym momencie
pora dnia
druga cecha jest szeroka
dostęp do sieci
teraz oznacza to po prostu tę chmurę
zasoby obliczeniowe są dostępne ponad
sieci i jest dostępny dla wielu
różne platformy klienckie, np
telefony komórkowe
tablety czy komputery
innymi słowy
usługi w chmurze są dostępne przez ok
sieć przenosi się do trzeciego
jest łączenie zasobów
więc zasoby obliczeniowe dostawcy
są łączone razem, aby wspierać a
model wielu najemców, który pozwala na wiele
klientom udostępniać te same aplikacje
lub tę samą infrastrukturę fizyczną
przy zachowaniu prywatności i bezpieczeństwa
nad ich informacjami
obejmuje to takie rzeczy jak przetwarzanie
moc
przechowywanie w pamięci i sieci
jest podobny do ludzi żyjących w
budynek mieszkalny dzielący to samo
infrastruktury budowlanej, takiej jak zasilanie i
wody, ale wciąż mają swoje
apartamenty i prywatność w tym zakresie
infrastruktura
to również stwarza poczucie lokalizacji
niezależność w tym klienta
generalnie nie ma kontroli ani wiedzy
nad dokładną lokalizacją dostarczonego
zasoby
ale mogą być w stanie określić lokalizację
na wyższym poziomie abstrakcji tzw
koniec klient tak naprawdę nie
mieć możliwość wyboru dokładnie
który serwer szafa serwerowa lub centrum danych
z tego powodu
od tego, gdzie znajdują się dostarczone zasoby
pochodzi z
będą mogli mieć tylko tzw
możliwość wyboru takich rzeczy jak regiony lub
sekcje w tym regionie
czwarta podstawowa cecha to
szybka elastyczność
to dla mnie
jest kluczowym czynnikiem tworzącym chmurę
komputery tak świetne i tak zwinne
możliwości mogą być elastyczne
zaopatrzony i wydany
w niektórych przypadkach automatycznie do skalowania
szybko na zewnątrz i do wewnątrz w odpowiedzi
z popytem
konsumentowi możliwości
często pojawiają się dostępne do udostępnienia
być nieograniczony
i może być dostarczany w dowolnej ilości
w dowolnym momencie i dotykając piątego
i ostatnie charakterystyczne systemy chmurowe
automatycznie kontrolować i optymalizować
wykorzystanie zasobów poprzez wykorzystanie pomiaru
zdolność
wykorzystanie zasobów może być monitorowane
kontrolowane i zgłaszane dostarczanie
przejrzystość zarówno dla dostawcy, jak i
konsument usługi
teraz oznacza to, że jest to chmura
zużycie zasobów obliczeniowych jest mierzone i
możesz odpowiednio zapłacić za to, co masz
używany
utylizacja zasobów
można zoptymalizować za pomocą dźwigni
możliwości płatności za użycie
a to oznacza, że ​​wykorzystanie zasobów w chmurze
czy są to przypadki, które są
działanie
przechowywanie w chmurze lub przepustowość to wszystko
monitorowane mierzone i zgłaszane przez
dostawca usług w chmurze jest modelem kosztów
oparte na
płać za to, czego używasz, a więc za płatność
opiera się na faktycznym zużyciu
przez klienta
więc znając te kluczowe cechy
cloud computing wraz z nimi
korzyści
osobiście uważam, że naprawdę może ci dać
noga na egzaminie
jak również rozmawiać z innymi w swoim
codzienna rola
ponieważ coraz więcej firm zaczyna się przenosić
do chmury, mam nadzieję, że ta lekcja ma
wyjaśnił ci, czym jest chmura
komputera i korzyści, jakie zapewnia
więc to wszystko, co mam na tę lekcję
więc możesz teraz oznaczyć tę lekcję jako
zakończyć i przejść do następnego
jeden
Witamy spowrotem
w tej lekcji chciałem przejść przez
cztery popularne modele wdrażania w chmurze i
rozróżnić różnice między
chmura publiczna
wiele chmur
chmura prywatna i chmura hybrydowa
modele wdrażania
jest to częsty temat, który pojawia się
uczciwa kwota na egzaminie
a także wspólny motyw w każdym
organizacja przechodzi do chmury, znając
różnice między nimi mogą być
krytyczne dla typów architektury
i usługi, z których skorzystałbyś dla
konkretny scenariusz, który otrzymałeś
a także możliwość rozmowy z
różne typy modeli wdrażania, jak
inżynier w terenie wraca do
zacznijmy od modeli wdrażania
modelu chmury publicznej, którego dotknęliśmy
trochę na naszej ostatniej lekcji
teraz chmura publiczna jest zdefiniowana jako
usługi komputerowe oferowane przez
dostawcy zewnętrzni
przez publiczny internet
udostępnienie ich każdemu, kto
chce ich używać lub kupować, więc to
oznacza, że ​​Google Cloud upadnie
tę kategorię jako chmurę publiczną
są też inni sprzedawcy, którzy upadają
w ramach tej kategorii, takich jak aws i
lazur
więc znowu chmura publiczna to chmura
oferowanych przez publiczny Internet
teraz można również łączyć chmury publiczne
i używane razem w jednym
środowisko dla różnych przypadków użycia
nazywa się ten model wdrażania w chmurze
wiele chmur
teraz może być implementacja wielu chmur
niezwykle skuteczny, jeśli jest zaprojektowany w
właściwy sposób
jedna implementacja, która jest skuteczna
korzystanie z wielu chmur ma miejsce, gdy jest używane
w przypadku odzyskiwania po awarii to miejsce, w którym
architektura byłaby powielana w poprzek
różne chmury publiczne w jednym przypadku
miały zejść
inny mógłby podnieść luz co
napędza wiele przypadków wielu chmur
zastosowanie
jest zapobieganie blokadzie sprzedawcy tam, gdzie ty
są zamknięci w określonej chmurze
infrastruktury dostawcy i nie jest w stanie
przenieść ze względu na funkcję specyficzną dla dostawcy
ustaw główny upadek na tego typu
architektura to infrastruktura
chmury publicznej, z której korzystasz
nie może być w pełni wykorzystany
ponieważ każdy dostawca chmury ma swoje własne
zastrzeżonych zasobów, które będą tylko
pracować w swojej specyficznej infrastrukturze w
innymi słowy
w celu replikacji środowiska
musi być taki sam w każdej chmurze
usuwa to unikatowość każdej chmury
cechy, które czynią je takimi
wyjątkowy, a zasoby tak przekonujące
więc czasami znalezienie właściwej strategii
może być trudne w zależności od scenariusza
teraz następny model wdrażania, którego chciałem
dotknąć, to prywatna chmura prywatna
cloud odnosi się do twojej architektury, która
istnieje na miejscu
i ogranicza się do samej działalności
bez publicznego dostępu
ale wciąż ma tę samą piątkę
cechy, o których rozmawialiśmy
w odniesieniu do tego, co definiuje chmurę każdego z nich
przedstawieni tutaj główni dostawcy usług w chmurze
wszystkie mają swój własny smak prywatności
chmura, którą można wdrożyć na miejscu
chmura google ma anthos
aws
posiada posterunki aws
a azures to stos lazurowy
wykazują tę samą cechę
i wykorzystać podobne technologie, które
można znaleźć w publicznym miejscu dostawcy
cloud jeszcze można zainstalować samodzielnie
proszę o infrastrukturę lokalną
świadomy
każda organizacja może mieć vmware
implementacja, która przypomina chmurę
funkcje, ale nie jest to uważane za
prywatna chmura
prawdziwa chmura prywatna zawsze spełni wymagania
cechy, które obecnie składają się na chmurę
możliwe jest korzystanie z chmury prywatnej
chmura publiczna
a ta implementacja nazywa się hybrydą
Chmura
więc chmura hybrydowa jest wtedy, gdy używasz
chmura publiczna w połączeniu z prywatną
chmura jako jeden wspólny system
zastosowana architektura wynika ze zgodności
gdzie jedna chmura może pomóc organizacjom
osiągnąć określone zarządzanie
zarządzanie ryzykiem i zgodność
przepisów, podczas gdy druga chmura mogła
przejąć resztę
teraz naprawdę chciałbym zrobić coś ważnego
tutaj rozróżnienie
jeśli Twoja infrastruktura lokalna jest
podłączony do chmury publicznej tak nie jest
uważana za chmurę hybrydową, to jest to
znane jako środowisko hybrydowe lub hybryda
sieć jako lokalna
infrastruktura nie posiada prywatnej chmury
cechy, na które pozwala prawdziwa chmura hybrydowa
możesz używać dokładnie tego samego interfejsu i
oprzyrządowanie, jakie jest dostępne w
chmura publiczna, więc świadomość tego może
uniknąć wielu nieporozumień na drodze
więc podsumowując wszystko, co my
dyskutowane, jeśli chodzi o chmurę publiczną
dzieje się tak, gdy jedna chmura jest dostarczana przez jedną
sprzedawca, który jest dostępny publicznie
Internet
multi-cloud to dwie lub więcej chmur publicznych
które są ze sobą połączone w celu użycia
jako pojedynczy system prywatna chmura
jest uważana za chmurę lokalną, która
podąża za pięcioma cechami
Chmura
i ogranicza się do jednego
organizacja bez dostępu do
chmura publiczna i wreszcie hybrydowa
to prywatna chmura połączona z publiczną
Chmura
i jest używany jako pojedyncze środowisko
ponownie jako uwaga
połączona z architekturą lokalną
chmura publiczna jest uważana za hybrydę
środowisko, a nie chmura hybrydowa
rozróżnienie między nimi
są bardzo różne i powinny być
uważnie obserwowane, ponieważ mogą pojawić się kłopoty
na obu egzaminach
iw twojej roli inżyniera, więc te
to różne wdrożenia w chmurze
modele, które pomogą Ci się wyróżnić
na jakim typie architektury będziesz
używając w dowolnym scenariuszu, który ci podano
i to jest wszystko, co chciałem omówić
jeśli chodzi o modele wdrażania w chmurze
więc możesz teraz oznaczyć tę lekcję jako
kompletny
i przejdźmy do następnego
Witamy spowrotem
więc, aby dokończyć definicję nista
przetwarzanie w chmurze, które chciałem poruszyć
modele usług w chmurze, które są powszechnie stosowane
określany jako zas
teraz ten model jest zwykle nazywany zas lub
xaas
stojący za czymkolwiek jako usługą
obejmuje wszystkie usługi w chmurze
które klienci mogą konsumować i x może być
zmieniono, aby powiązać z konkretnym
praca
tak, aby opisać chmurę
modele usług, których musiałem dotknąć
pojęcia, którymi możesz być lub nie
zaznajomiony z tym sprawi
zrozumienie modeli usług a
trochę łatwiej, gdy przechodzę przez
kurs i opisz usługi
dostępne i jak odnoszą się do
wzór, ta lekcja przyniesie tak wiele
sens do końca
ułatwi usługi w chmurze
zarówno opisać, jak i zdefiniować
teraz, jeśli chodzi o wdrażanie
aplikacja, w której są wdrażane
stos infrastruktury
jak ten, który tu widzisz
teraz stos jest zbiorem potrzebnych
infrastruktury, w której znajduje się aplikacja
musi działać na nim jest warstwowy i każdy
warstwa jest nałożona na poprzednią
do niego, aby stworzyć to, co widzisz
tutaj teraz, jak widać na górze to
jest tradycyjnym lokalem
stos infrastruktury, który był typowy
używany teraz przed chmurą w tym tradycyjnym
Model
wszystkie komponenty są zarządzane przez
klientowi zakup danych
centrum oraz całą sieć i pamięć masową
zaangażowane serwery fizyczne
wirtualizacja licencji na
systemy operacyjne to personel
trzeba było to wszystko złożyć
w tym okablowanie do układania w stosy
bezpieczeństwo fizyczne też było czymś
to trzeba było wziąć pod uwagę
innymi słowy rozważenie dla
organizacja, która ma to połączyć
sami patrzyli na ogromne
koszty
teraz zaletą tego jest to, że to
pozwolił na znaczną elastyczność, ponieważ
organizacja jest w stanie dostroić to dowolne
sposób, w jaki chcą spełnić wniosek
standardy zgodności
w zasadzie wszystko, czego teraz chcieli
gdy mówimy o usłudze w chmurze
koncepcje wzorcowe
części są zawsze zarządzane przez Ciebie i
części są teraz zarządzane przez dostawcę
inną koncepcją, którą chciałem poruszyć, jest
tą jednostką konsumpcji jest sposób, w jaki
ceny dostawcy tego, do czego służą
ich klient teraz tuż przed chmurą
stał się duży na rynku było
modelu, w którym znajdowało się centrum danych
dla ciebie, aby sprzedawca przyszedł i
wszystkim by się zajęli
w odniesieniu do centrum danych
stojaki
zasilanie do stojaków powietrze
kondycjonowanie
kable sieciowe z
budynek, a nawet ochrona fizyczna
więc jednostka zużycia była tutaj
miejsca w szafie serwerowej w centrum danych tzw
sprzedawca pobierałby opłatę za stojak
przestrzeń, a oni z kolei by się tym zajęli
wszystkich potrzebnych danych
centrum teraz jest to mniej elastyczne niż
tradycyjny model lokalny, ale
centrum danych jest dla ciebie abstrakcyjne
przez całą lekcję chciałem
przedstawić koncepcję, która może sprawić, że
rzeczy łatwiejsze do uchwycenia, które jest
pizza jako usługa, więc teraz
tradycyjny model lokalny
to miejsce, w którym kupiłbyś wszystko i
zrobić pizzę w domu
teraz, gdy kontynuujemy lekcję
dostępna będzie mniejsza elastyczność
ponieważ więcej warstw zostanie wyabstrahowanych
więc następny model usługi, który chciałem
wprowadzić jest infrastruktura jako
praca
lub ja w skrócie, to jest miejsce, w którym wszystkie
warstw od centrum danych do
wirtualizacją zajmuje się m.in
sprzedawca jest to najbardziej podstawowy model
który jest zasadniczo twoim wirtualnym
maszyn w centrum danych w chmurze
konfigurujesz konfigurację
i zarządzać instancjami działającymi w środowisku
infrastruktury centrum danych i umieścić
co chcesz na nich w google
silnik obliczeniowy Google w chmurze by to zrobił
spełniają ten model, a więc jednostkę
Zużycie tutaj byłoby operacyjne
system tak, jak zarządzałbyś wszystkimi
aktualizacje systemu operacyjnego i wszystko
które zdecydujesz się umieścić w tej instancji
ale jak widzisz tutaj nadal jesteś
odpowiedzialny za przebieg kontenera
czas dane i warstwy aplikacji
teraz przynosząc pizzę jako usługę
modelem byłoby, gdybyś odebrał
pizzę i gotujesz ją w domu w ruchu
na platformie jako usługa lub paz dla
Krótko mówiąc, jest to model, który jest ukierunkowany
bardziej w kierunku deweloperów iz przepustką
dostawca chmury zapewnia przetwarzanie
platforma typowo
łącznie z systemem operacyjnym
wykonanie języka programowania
środowisko bazy danych i sieci
serwer teraz zazwyczaj z pass you never
trzeba się martwić o system operacyjny
aktualizacje lub zarządzanie środowiskiem wykonawczym i
oprogramowanie pośrednie, a więc jednostka
zużycie tutaj byłoby czasem wykonywania
teraz warstwa środowiska wykonawczego byłaby warstwą
konsumowałbyś tak, jakbyś był
uruchamiając swój kod w dostarczonym
środowisko uruchomieniowe, które jest chmurą
dostawca zapewnia dla ciebie dostawcę
zarządza sprzętem i oprogramowaniem
infrastruktury i po prostu używasz
usługi jest to zwykle warstwa na wierzchu
z jest i tak wszystkie warstwy między
dba się o centrum danych i czas pracy
sprzedawca jest tego doskonałym przykładem
dla Google Cloud to silnik aplikacji Google
w którym będziemy trochę nurkować
trochę później wracając do pizzy jako
model usługowy
przepustka mieściłaby się pod istotą pizzy
dostarczane prosto do twoich drzwi
teraz z wyjaśnieniem poprzedniego modelu, którego chcę
przejść do ostatniego modelu, którym jest sas
co oznacza oprogramowanie jako usługę
teraz z sas wszystkie warstwy są zajęte
pod opieką dostawcy, więc użytkownicy są
zapewnił dostęp do oprogramowania aplikacyjnego
i dostawcy chmury zarządzają
działającej infrastruktury i platform
aplikacje G Suite i Microsoft
Office 365 jest tego doskonałym przykładem
model teraz sas nie oferuje zbyt wiele
elastyczność, ale kompromis jest taki
sprzedawca faktycznie dba o wszystko
te warstwy, więc znowu jednostka
zużycie tutaj jest aplikacja
i oczywiście dotarcie do
model pizzy jako usługi sas
jest prawie jadalnia w restauracji
ciesz się teraz swoją pizzą, aby podsumować
gdy masz centrum danych na miejscu
zarządzać wszystkim
gdy jest to infrastruktura jako usługa
część tego stosu jest wyodrębniana przez
dostawca chmury z platformą jako usługą
jesteś odpowiedzialny za aplikację
i dane
wszystko inne jest abstrahowane przez
dostawcy z oprogramowaniem jako usługą
używając pizzy jako analogii do usługi
założenie, że kupujesz wszystko i robisz
pizza w domowej infrastrukturze jako
praca
odbierasz pizzę i gotujesz ją w
domu, jeśli chodzi o platformę jako
obsługa pizza jest dostarczana
i oczywiście oprogramowanie jako usługa
jadalnia w restauracji teraz nie będzie
nadchodzą inne modele usług
w tym kursie, takie jak funkcja jako a
usługa i kontenery jako usługa i
nie martw się, wchodzę w to
później, ale chciałem ci tylko dać
głowa do góry, więc teraz dla niektórych z was może to być
było wiele informacji do wzięcia
ale zaufaj mi
Znajomość tych modeli da ci
lepsze zrozumienie usług
udostępniane w chmurze Google, jak również dowolne
inny dostawca chmury, więc to wszystko
chciałem omówić w tej lekcji, więc ty
może teraz oznaczyć tę lekcję jako ukończoną i
przejdźmy do następnego
witaj z powrotem na tej lekcji, którą chciałem
omówić globalną chmurę Google
infrastruktury, jakie są centra danych
połączone, jak przepływa ruch, gdy a
prośba jest wykonana
wraz z ogólną strukturą tego, jak
lokalizacje geograficzne Google Cloud są
podzielone dla lepszej dostępności
trwałość i latencja
teraz Google posiada wysoce zabezpieczone
sieć o niskim opóźnieniu, w której odbywa się ruch
pozostaje w prywatnym szkielecie Google przez
większość swojej podróży zapewniając wysoką
wydajność i wrażenia użytkownika
jest zawsze powyżej normy Google Cloud
został zaprojektowany, aby służyć wszystkim użytkownikom
na całym świecie, projektując swoje
infrastruktura z nadmiarową chmurą
regiony połączone dużą przepustowością
kable światłowodowe oraz kable podmorskie
łącząc różne kontynenty
obecnie Google zainwestował w 13
łączące je kable podmorskie
kontynenty w punktach obecności jak ty
zobacz tutaj na tym diagramie setki
tysiące kilometrów światłowodów
położono również, aby połączyć punkty
obecność zapewniająca bezpośrednią łączność
prywatność i mniejsze opóźnienia
tylko po to, żeby dać ci wyobrażenie o tym, co
podmorski przebieg kabla może wyglądać tak, jak ja
zawiera schemat, w jaki sposób poświęcony
Google jest dla swoich klientów takie, jakie jest
tak wiele idzie w ich prowadzenie
kable, które łączą kontynenty tak jak Ty
tutaj widać, że to północna Wirginia
Region połączony z Belgią
region od usa do europy a
kabel jest prowadzony z północnej Wirginii
centrum danych, a także o punkt
obecność na miejscu
przejeżdżając wcześniej przez stację lądowania
schodząc w głąb morza z drugiej strony
stronie stacji lądowania po francusku
Zachodnie Wybrzeże
podnosi drugą stronę kabla i
przenosi go do centrum danych w
region belgijski i jest to typowe
kabel podmorski prowadzony dla google tak
kontynenty są połączone maksymalnie
globalna łączność
teraz w momencie nagrywania tego filmu
Ślad Google Cloud obejmuje 24 regiony
73 strefy i więcej
144 punktów obecności w ponad
200 krajów i terytoriów na całym świecie
i jak widać tutaj białe kropki
na mapie są regiony, które są
obecnie budowane w celu rozszerzenia ich
sieć dla szerszej łączności teraz do
pokazać, w jaki sposób żądanie jest kierowane
sieć google, myślałem, że tak
zademonstruj to, używając muszki Tony'ego
teraz Tony wysyła zapytanie do swojej bazy danych
w chmurze Google, a Google odpowiada
prośba Tony'ego
z popowej lub krawędziowej lokalizacji sieciowej, która
zapewni najniższe opóźnienie
punkt obecności to miejsce, w którym dostawcy usług internetowych mogą
połącz się z siecią google google
Edge Network otrzymuje prośbę Tony'ego i
przekazuje go do najbliższych danych Google
centrum w swojej prywatnej sieci światłowodowej
centrum danych generuje odpowiedź
który jest zoptymalizowany, aby zapewnić to, co najlepsze
doświadczenie dla Tony'ego w danym momencie
w czasie aplikacja lub przeglądarka, którą jest tony
using pobiera żądaną zawartość
z odpowiedzią z różnych google
lokalizacje, w tym dane Google
wyśrodkowuje wyskakujące krawędzie i węzły krawędzi
w zależności od tego, która zapewnia najniższą
opóźnienie ta ścieżka danych dzieje się w
kwestia sekund i ze względu na google
globalnej infrastruktury, po której podróżuje
bezpiecznie i przy jak najmniejszej ilości
możliwe opóźnienie
bez względu na położenie geograficzne
pochodzi prośba
teraz chciałem zrobić sobie chwilę przerwy
w jaki sposób podzielone są obszary geograficzne
na zewnątrz i uporządkowane w chmurze Google
zaczynamy od geografii
lokalizacji, takich jak stany zjednoczone
ameryka i dzieli się na
z wielu regionów na regiony i wreszcie
strefy i tak na początek chciałem
mówić o strefach, teraz strefa to a
obszar wdrażania dla chmury Google
zasobów w regionie, w którym znajduje się strefa
najmniejszy podmiot w globalnym Google
sieć, możesz myśleć o tym jako o singlu
domena awarii w regionie teraz jako a
zasoby najlepszych praktyk powinny zawsze istnieć
rozmieszczony
w strefach najbliższych Twoim użytkownikom
dla optymalnego opóźnienia
teraz następny w górę mamy region
a regiony są niezależne geograficznie
obszary podzielone na strefy tzw
możesz myśleć o regionie jako o
zbiór stref i posiadanie regionu
z wieloma strefami jest przeznaczony dla
odporność na awarie i wysoka dostępność
komunikację między strefami
w regionie wynosi mniej niż pięć
milisekund, więc bądź pewny, że twój
dane zawsze podróżują optymalnie
prędkości
teraz przechodzimy do multiregionu
teraz multi-regiony są duże geograficznie
obszary, które zawierają dwa lub więcej regionów
a to umożliwia usługom Google
zmaksymalizować redundancję i dystrybucję
w obrębie regionów i między nimi
i to jest dla nadmiarowości Google lub
wysoka dostępność posiadania Twoich danych
rozłożone na wiele regionów
zawsze zapewnia, że ​​Twoje dane są
stale dostępne
i to obejmuje wszystkie koncepcje, które
Chciałem przejść, jeśli chodzi o
geografia i regiony w google
Chmura
pamiętaj, że geografia i regiony
pojęcia są fundamentalne nie tylko dla
egzaminu, ale za twoją codzienną rolę
chmura google
więc tak dla przypomnienia, strefa to a
obszar wdrażania dla chmury Google
zasobów w regionie, w którym znajduje się strefa
najmniejszy podmiot globalny Google
infrastruktura teraz region jest
niezależnego obszaru geograficznego, tj
podzielone na strefy i wreszcie kiedy
chodzi o multiregion
multiregiony to duże obszary geograficzne
który zawiera dwa lub więcej regionów
Ponownie
są to wszystkie podstawowe pojęcia, które
powinieneś wiedzieć na egzamin i na
Twoja codzienna rola w Google Cloud i
więc to wszystko, co miałem na tę lekcję
możesz teraz oznaczyć tę lekcję jako zakończoną
i przejdźmy do następnego
[Muzyka]
Witamy spowrotem
ta lekcja będzie miała charakter ogólny
spośród wszystkich opcji usług obliczeniowych, które
są dostępne w chmurze Google
jak się od siebie różnią
i gdzie wpadają pod chmurę
model usług ponownie ta lekcja jest po prostu
przegląd opcji obliczeniowych jako we
będzie nurkować głębiej w każdym komputerze
opcja
później w tym kursie, więc Google Cloud
daje tak wiele opcji, jeśli chodzi
do obliczania usług, które oferują
pełna kontrola i elastyczność inne
które oferują elastyczną technologię kontenerową
zarządzana platforma aplikacji i
środowiskach bezserwerowych, więc kiedy my
weź wszystkie te opcje obliczeniowe i my
spójrz na to z modelu usługowego
perspektywy widać, że tak
duża elastyczność, zaczynając tutaj na
pozostawiono z infrastrukturą jako usługą
zapewniając najbardziej optymalną elastyczność
przesuwając się całkowicie w prawo
gdzie pełnimy funkcję usługi
oferując mniejszą elastyczność, ale plus
będąc mniej, że musisz zarządzać i
będziemy przeglądać te obliczenia
opcje zaczynające się od lewej tutaj z
infrastruktura jako usługa, którą mamy
silnik obliczeniowy jest teraz silnikiem obliczeniowym
Podstawowa infrastruktura Google
produkt usługowy, który oferuje wirtualne
maszyny lub maszyny wirtualne nazywane instancjami te
instancje można wdrożyć w dowolnym regionie
lub strefę, którą wybierzesz, również masz
możliwość decydowania jakie działanie
system, który chcesz na nim, jak również
oprogramowanie, więc masz możliwość
instalowanie różnych rodzajów smaków
Linux lub Windows i oprogramowanie do pracy
z tym Google daje również
opcje tworzenia tych instancji
przy użyciu obrazów publicznych lub prywatnych
więc jeśli Ty lub Twoja firma macie prywatny
obraz, którego chcesz użyć, możesz użyć
to, aby utworzyć instancje google
daje również możliwość korzystania z publicznych
obrazy do tworzenia instancji i are
dostępne po uruchomieniu silnika obliczeniowego
jak również istnieją również wstępnie skonfigurowane
dostępne obrazy i pakiety oprogramowania
na rynku Google Cloud i my
będzie nurkować trochę głębiej
rynek Google Cloud w innym
lekcja po prostu wiedz, że jest ich mnóstwo
dostępnych obrazów
tworzyć instancje dające ci łatwość
wdrożyć teraz, jeśli chodzi o obliczenia
engine i zarządzasz wieloma
instancjach są one wykonywane przy użyciu instance
grupy
i kiedy patrzysz na dodanie lub
usuwanie pojemności dla tych obliczeń
instancje silnika automatycznie
użyj automatycznego skalowania w połączeniu z
silnik obliczeniowy tych grup instancji
daje również możliwość dołączenia
i odłączanie dysków tak, jak ich potrzebujesz
dobrze można używać pamięci masowej Google Cloud
w połączeniu z silnikiem obliczeniowym jako
inna opcja przechowywania i kiedy
bezpośrednie połączenie z silnikiem obliczeniowym
google daje ci możliwość użycia ssh
aby bezpiecznie się z nim połączyć, więc przejdź dalej
do następnej opcji usługi obliczeniowej
mamy również silnik google kubernetes
znany jako gk
teraz gk
to flagowy kontener Google
system orkiestracji
do automatyzacji
wdrażanie
skalowanie i zarządzanie kontenerami
gke jest również zbudowany na tym samym open
source kubernetes projekt, który był
wprowadzony przez Google do wiadomości publicznej z powrotem
w 2014
teraz, zanim Google stworzył kubernetes a
usług zarządzanych było ich wiele
zdecydowałem się zbudować kubernetes na założeniu
w swoich centrach danych i dlatego, że tak jest
zbudowany na tej samej platformie
gke
oferuje elastyczność integracji
z tymi lokalnymi Kubernetes
wdrożenia są teraz pod maską, których używa gke
instancje silnika obliczeniowego jako węzły w pliku a
klaster i jako krótka uwaga, klaster jest
grupa węzłów lub silnik obliczeniowy
przypadkach i znowu będziemy przechodzić
wszystko to o wiele bardziej szczegółowo w a
inna lekcja, więc jeśli nie
już to rozgryzłem google kubernetes
silnik jest uważany za kontener jako a
service teraz następna usługa obliczeniowa
opcja, którą chciałem przejść
która wchodzi w zakres platformy jako usługi
jest silnikiem aplikacji
teraz silnik aplikacji jest w pełni zarządzany
bezserwerowa platforma do tworzenia i
hosting aplikacji internetowych na dużą skalę
dzięki silnikowi aplikacji Google obsługuje większość
zarządzanie zasobami dla Ciebie
na przykład, jeśli wymaga tego Twoja aplikacja
więcej zasobów obliczeniowych, ponieważ ruch
do Twojej witryny zwiększa google
automatycznie skaluje system do
udostępnij te zasoby, jeśli system
oprogramowanie wymaga również aktualizacji zabezpieczeń
to jest obsługiwane również dla ciebie i tak dalej
o które naprawdę musisz dbać, jest twoje
aplikacja
i możesz zbudować swoją aplikację w
Twój ulubiony język to java.net i
wiele innych
i możesz użyć obu wstępnie skonfigurowanych
środowiska wykonawcze lub użyj niestandardowych środowisk wykonawczych, aby zezwolić
napisanie kodu w dowolnym języku
silnik aplikacji umożliwia również łączenie
z produktami do przechowywania w chmurze Google i
bazy danych bezproblemowo również silnik aplikacji
zapewnia elastyczność łączenia
z zewnętrznymi bazami danych, jak również
inni dostawcy usług w chmurze i osoby trzecie
Silnik aplikacji dostawców również integruje się z
dobrze znany produkt zabezpieczający w google
chmura o nazwie Web Security Scanner co do
zidentyfikować luki w zabezpieczeniach i tak dalej
który w skrócie obejmuje silnik aplikacji
przejście do następnej usługi obliczeniowej
opcja
mamy funkcje chmury i chmurę
funkcje podpadają pod funkcję jako a
service jest to wykonanie bezserwerowe
środowisko
do budowania i łączenia chmury
usługi z funkcjami chmury, które piszesz
proste funkcje jednego celu, które są
dołączone do wydarzeń
które są produkowane z twojego
infrastruktura i usługi w google
cloud twoja funkcja jest wyzwalana, gdy an
obserwowane zdarzenie uruchamia twój kod
następnie wykonuje się w pełni zarządzany
środowisku nie ma takiej potrzeby
zapewnić jakąkolwiek infrastrukturę lub martwić się
o zarządzaniu dowolnymi serwerami i chmurą
funkcje można pisać za pomocą
javascript python 3
go lub środowisko uruchomieniowe java, abyś mógł zabrać swoje
funkcję i uruchom ją w dowolnym z nich
standardowe środowiska, które to czynią
niezwykle przenośne teraz funkcje chmury
są dobrym wyborem dla takich przypadków użycia
zawierać następujące
przetwarzanie danych lub operacje etl, takie jak
jak transkodowanie wideo i przesyłanie strumieniowe IOT
haków sieciowych danych, które odpowiadają na http
wyzwalacze
lekkie api, które komponują się luźno
logika połączona z aplikacjami
jako mobilne funkcje zaplecza
ponownie brane są pod uwagę funkcje chmury
funkcjonować jako usługa i tak to obejmuje
funkcje chmury
teraz przesuwa się w skrajną prawą stronę
ekran po drugiej stronie strzałki my
mają naszą ostatnią opcję usługi obliczeniowej
który jest uruchamiany w chmurze, teraz uruchamiany w chmurze to a
w pełni zarządzana platforma obliczeniowa dla
wdrażanie i skalowanie kontenerów
aplikacje szybko i bezpiecznie
cloudrun został zbudowany w oparciu o otwarty standard
o nazwie k native, co umożliwiło
przenośność wszelkich aplikacji, które
zbudowano na nim cloudrun również streszczenia
z dala od całego zarządzania infrastrukturą
poprzez automatyczne skalowanie w górę i w dół
niemal natychmiast w zależności od
ruch teraz w chmurze należał do Google
odpowiedź na abstrakcję wszystkich
infrastrukturę, która została zaprojektowana do działania
pojemniki i tak to jest znane jako
serverless dla kontenerów, które ma cloudrun
ogromna elastyczność, jak możesz to napisać
w dowolnym języku
dowolna biblioteka używająca dowolnego pliku binarnego this
usługa obliczeniowa jest uważana za funkcję
jako usługa teraz w czasie
nagrywając ten film, o którym nie słyszałem
cloudrun jest na egzaminie, ale
ponieważ jest to opcja usługi obliczeniowej, tj
poczuł potrzebę posiadania przez cloudrun
wyróżnienie i to wszystko
dostępne opcje usług obliczeniowych
dostępne w chmurze Google i będziemy
zagłębiając się w każdy z nich
później w tym kursie
znowu jest to tylko przegląd wszystkich
dostępne opcje usług obliczeniowych
dostępne na platformie Google Cloud
i to wszystko, co chciałem pokryć
ta lekcja
więc możesz teraz oznaczyć tę lekcję jako
zakończyć i przejść do następnego
jeden
[Muzyka]
Witamy spowrotem
teraz w ostatniej lekcji omówiłem wszystkie
różne opcje usług obliczeniowych
w tej lekcji omówimy
opcje, które są dostępne dla tej pary
dobrze z tymi usługami obliczeniowymi według
nurkowanie głębiej w różnych magazynach
typów i różnych baz danych
ponownie dostępne w chmurze Google, to jest
ściśle przegląd, ponieważ będę nurkować
głębiej w te usługi później w
kurs
teraz, jeśli chodzi o opcje przechowywania
są trzy usługi
łatwo dostępne w chmurze Google
każdy z nich ma swoje specyficzne zastosowanie
przypadku, w którym będę nurkować w just
sekunda
pierwszym, do którego chciałem przejść, jest
magazyn w chmurze
teraz z przechowywaniem w chmurze to jest Google
spójne skalowalne
duża pojemność i bardzo trwały przedmiot
składowanie
więc kiedy odwołuję się do przechowywania obiektów this
nie jest typem magazynu, który ty
dołączy do Twojej instancji i sklepu
Twój system operacyjny włączony, mówię
o zarządzaniu danymi jako obiektami, takimi jak
dokumenty lub zdjęcia, a nie powinny
mylić z pamięcią blokową, która
zarządza danymi na bardziej szczegółowym poziomie
takich jak system operacyjny, aby się nie martwić
jeśli w pełni nie rozumiesz koncepcji
obiektowa pamięć masowa, do której będę się odnosić
więcej szczegółów z tym
później w lekcji dotyczącej przechowywania w chmurze
przechowywanie w chmurze ma trwałość 11 9 i
co mam na myśli przez trwałość jest w zasadzie
utrata plików, więc po prostu dam ci
lepszy obraz w chmurze
trwałość, jeśli przechowujesz 1 milion plików
statystycznie google straci jeden plik
co 659
000 lat, a ty masz ponad 400 lat
razy większe prawdopodobieństwo trafienia przez meteor
niż faktycznie stracić plik, tak jak ty
widzę, że przechowywanie w chmurze jest bardzo dobre
inne miejsce do przechowywania plików
świetną funkcją przechowywania w chmurze jest
nieograniczone miejsce do przechowywania, które ma bez
minimalny rozmiar obiektu, więc nie krępuj się
ciągłe umieszczanie plików w chmurze
teraz, jeśli chodzi o chmurę przypadków użycia
przechowywanie jest fantastyczne dla zawartości
dostarczanie jezior danych i kopii zapasowych oraz do
uczynić przechowywanie w chmurze jeszcze bardziej elastycznym
jest dostępny w innym magazynie
zajęcia i dostępność, którą będę
przechodząc w ciągu zaledwie sekundy teraz, kiedy to
chodzi o te różne klasy pamięci
istnieją cztery różne klasy
możesz wybrać z pierwszego z nich
standardowa klasa pamięci masowej i ta pamięć masowa
klasa oferuje maksymalną dostępność
z twoimi danymi absolutnie nie
ograniczenia, to świetnie nadaje się do przechowywania
że masz dostęp cały czas następny
klasa przechowywania jest bliska linii i tak jest
tanie przechowywanie archiwów, więc to
klasa przechowywania jest tańsza niż standardowa
i jest przeznaczony wyłącznie do przechowywania
musi być dostępny rzadziej niż raz na
miesiąc i jeśli szukasz wyrównania
bardziej opłacalne rozwiązanie chmurowe
storage ma klasę przechowywania na linii zimnej
co jest jeszcze tańszym archiwum
rozwiązaniem pamięci masowej jest ta klasa pamięci masowej
przeznaczony do przechowywania, które tylko tego potrzebuje
być dostępne rzadziej niż raz na kwartał
i właśnie wtedy, gdy myślałeś, że
ceny nie mogły być niższe niż linia zimna
przechowywanie w chmurze zaoferowało inne
klasa pamięci o nazwie Archive i to jest to
najtańszy magazyn archiwalny, który
oferuje przechowywanie za ułamek grosza
na gigabajt, ale jest przeznaczony dla
korzystanie z archiwum lub kopii zapasowej, do którego uzyskuje się dostęp
rzadziej niż raz w roku, kiedy to przychodzi
do dostępności pamięci masowej w chmurze są
dostępne trzy opcje
istnieje region podwójny region i
region wieloregionowy jest przeznaczony do przechowywania
Twoje dane w jednym pojedynczym regionie podwójnym
region jest dokładnie taki, jak brzmi
para regionów teraz w multiregionie
przechowywanie w chmurze przechowuje twoje dane w
duży obszar geograficzny składający się z wielu
różne regiony w tym samym
wybrany obszar geograficzny i tak dalej
about obejmuje przechowywanie w chmurze jako miejsce do przechowywania
opcja następna opcja przechowywania, którą ja
o którym chciałem porozmawiać, to magazyn plików
teraz magazyn plików jest w pełni zarządzanym nfs
czyli serwer plików z chmury Google
zgodny z nfs w wersji 3, który możesz przechowywać
dane z uruchomionych aplikacji z
wiele instancji maszyn wirtualnych i kubernetes
klastry
dostęp do danych w tym samym czasie pliku
store to świetna opcja, gdy jesteś
myśląc o dostępie do danych z let's
powiedz grupę instancji i potrzebujesz
wiele instancji, aby uzyskać dostęp do tego samego
danych i przejście do ostatniej pamięci
opcja mamy dyski trwałe
teraz z dyskami trwałymi tak jest
Trwała blokowa pamięć masowa na przykład teraz
jak wyjaśniłem przed przechowywaniem bloków
inaczej niż pamięć obiektowa
jeśli pamiętasz, wcześniej wyjaśniłem
obiektowa pamięć masowa jest przeznaczona do przechowywania
obiektów, takich jak dane, zdjęcia lub filmy
podczas gdy pamięć blokowa jest pamięcią surową
pojemność używana w dyskach, które są
podłączony do systemu operacyjnego w tym
przypadku dyski trwałe robią to samo
że dyski trwałe występują w dwóch
opcje
pierwsza to opcja standardowa
co zapewnia regularne standardowe przechowywanie
za rozsądną cenę i inne
opcja to półprzewodnikowy lub ssd
co zapewnia mniejsze opóźnienie
wyższe iops i jest po prostu dookoła
szybciej niż twój standardowy trwały
disk obie te opcje są dostępne
w opcjach strefowych i regionalnych w zależności
na temat tego, czego potrzebujesz do swojego konkretnego
obciążenie pracą, więc teraz, gdy omówiłem wszystko
trzy opcje przechowywania, które chciałem dotknąć
do opcji bazy danych, które są
dostępne w chmurze Google te bazy danych
opcje są dostępne zarówno w sql, jak i nosql
smaki w zależności od przypadku użycia
wchodzenie w same opcje i
chciałem zacząć trochę wchodzić
trochę szczegółów z relacją sql
options, więc pierwszą opcją jest cloud sql
a chmura sql jest w pełni zarządzana
usługa bazy danych oferowana w
smaki serwera postgres mysql i sql
cloud sql ma również opcję bycia
wysoce dostępne w różnych strefach, które są obecnie w ruchu
do klucza do chmury jest to skalowalny
usługa relacyjnej bazy danych, tj
wysoce dostępne nie tylko w różnych strefach
ale między regionami iw razie potrzeby
dostępny globalnie klucz do chmury to
zaprojektowany, aby wspierać silne transakcje
spójność i replikacja synchroniczna
przejście do dostępnych opcji nosql
cztery dostępne usługi, które google
oferty chmurowe przechodzą do pierwszej
jest bigtable
a bigtable to w pełni zarządzane skalowalne rozwiązanie
baza danych nosql, która ma wysoką przepustowość
i jest również wyposażony w bigtable o niskim opóźnieniu
elastyczność tworzenia klastrów
zmiana rozmiaru bez przestojów w następnym
dostępna opcja nosql to datastore i
to jest w pełni szybka chmura Google
zarządzany
bez serwera
magazyn danych bazy danych dokumentów nosql to
przeznaczony do internetu mobilnego
i aplikacji internetu rzeczy
datastore ma możliwości robienia
replikacja wieloregionowa
a także kwaśne transakcje dla nich
z was, którzy nie wiedzą, że będę kryć
kwaśne transakcje w następnej lekcji
dla opcji nosql jest firestore i
to jest baza danych czasu rzeczywistego nosql
i jest zoptymalizowany do użytku w trybie offline, jeśli
szukasz do przechowywania danych w
baza danych w czasie rzeczywistym firestore jest twoja
opcja i podobnie jak bigtable możesz zmienić rozmiar
klaster w firestore bez żadnego
przestoju, a ostatnią opcją nosql jest
memorystore, a to jest chmura Google
wysoce dostępne
w usłudze pamięci dla redis i
memcached to jest w pełni zarządzany
usługi, więc Google Cloud dba o to
wszystkiego dla ciebie teraz to wiem
była krótka lekcja na temat przechowywania i
opcje bazy danych, ale konieczne
przegląd tego, co ma nadejść
i to jest wszystko, co chciałem
okładka w tej lekcji, abyś mógł teraz zaznaczyć
tę lekcję za zakończoną i ruszamy
Przechodząc do następnego
[Muzyka]
witaj z powrotem teraz, póki jest ich trochę
usługi w gcp, którymi się opiekują
sieci dla Ciebie
są jeszcze inne, takie jak obliczenia
silnik, który daje ci trochę więcej
elastyczność w rodzaju sieci
chciałbyś założyć
ta lekcja omówi je
usługi sieciowe na wysokim poziomie i
zapewnić Państwu ścisły przegląd do
dać ci pomysł na to, co jest dostępne
dowolny konkretny rodzaj scenariusza, kiedy to
chodzi o łączenie i skalowanie
ruch sieciowy, do którego będę się odnosił
dalsze szczegóły
o tych usługach sieciowych później
lekcje, od których chciałem zacząć
niektóre podstawowe funkcje sieciowe
zasoby i jak zarządzać określonymi
ruch drogowy
podróżowanie do iz twojej sieci to
to miejsce, w którym znajdują się zapory sieciowe i trasy
wejść do gry, więc najpierw chciałem
zacznij od wirtualnej chmury prywatnej
znany również jako vpc teraz vpc
zarządza funkcjami sieciowymi dla
Twoje zasoby w chmurze Google
jest to zwirtualizowana sieć wewnątrz
Google Cloud, abyś mógł to sobie wyobrazić
twój zwirtualizowany vpc centrum danych to a
podstawową usługę sieciową
i jest również globalnym zasobem, który obejmuje
we wszystkich różnych regionach
dostępne w chmurze Google dla każdego vpc
zawiera również domyślną sieć
można tworzyć dodatkowe sieci
twój projekt, ale sieci nie mogą
współdzielone między projektami
i będę zagłębiać się dalej
vpc w późniejszej lekcji, więc teraz już to zrobiliśmy
objęte vpc, do którego chciałem się dostać
reguły i trasy zapory teraz zapora
reguły segmentują twoje sieci za pomocą a
globalna zapora dystrybucyjna do ograniczenia
dostęp do zasobów, więc to rządzi
ruch przychodzący do instancji na a
sieć każda domyślna sieć ma
domyślny zestaw reguł zapory, które mają
już ustalone, ale nie martw się
możesz tworzyć własne reguły i ustawiać
je odpowiednio w zależności od
obciążenie pracą teraz, jeśli chodzi o trasy
określa, jaki powinien być ruch
kierowane w twoim vpc, aby uzyskać trochę
nieco bardziej szczegółowe trasy określają sposób
powinny być pakiety opuszczające instancję
skierowany, więc jest to podstawowy sposób definiowania
w którą stronę zmierza Twój ruch
podróżować przechodząc do następnej koncepcji i
chciałem zakryć trochę o niskim
równoważenie i sposób dystrybucji
obciążenia w wielu instancjach
teraz mamy dwa różne rodzaje obciążenia
równoważenia i obu tych rodzajów obciążenia
równoważenie można rozbić na nawet a
bardziej szczegółowy poziom teraz, jeśli chodzi o
Niskie równoważenie http lub https to jest to
rodzaj równoważenia obciążenia, które obejmuje
automatyczne skalowanie i ładowanie na całym świecie
równoważenie w wielu regionach lub nawet
jeden region na jednym globalnym IP
Równoważenie obciążenia https rozdziela ruch
w różnych regionach i upewnij się
że ruch kierowany jest do ul
najbliższy region lub w przypadku, gdy jest
awarie między instancjami lub w
przypadki bombardowania ruchem
Równoważenie obciążenia HTTP i https może kierować
ruch do zdrowej instancji w
następny najbliższy region kolejny świetny
Cechą tego równoważenia obciążenia jest to
może dystrybuować ruch w oparciu o
rodzaj treści teraz, jeśli chodzi o
równoważenie obciążenia sieciowego to jest
regionalny moduł równoważenia obciążenia i obsługuje dowolny
i wszystkie porty
rozprowadza ruch między serwerami
instancji w tym samym regionie
na podstawie przychodzących danych protokołu IP, takich jak
jako port adresowy i protokół teraz, kiedy to
przychodzi do sieci
dns odgrywa dużą rolę, a ponieważ dns
odgrywa dużą rolę w tworzeniu sieci Google
udostępnił tę usługę 100
oprócz podania jakichkolwiek zapytań dns
absolutnie najniższe opóźnienie z Google
dns w chmurze, które możesz publikować i utrzymywać
dns rekordy przy użyciu tego samego
infrastruktura, z której korzysta Google i Ty
może współpracować ze strefami zarządzanymi i DNS
rekordy, takie jak rekordy mx rekordy podatkowe
rekordy cname i rekordy i możesz
zrób to wszystko przez cli
API
lub sdk teraz niektóre z zaawansowanych
dostępne opcje połączeń
w chmurze Google są cloudvpn i direct
połącz teraz cloudvpn łączy twoje
istniejącej sieci, czy to jest
na miejscu lub w innym miejscu
do twojej sieci vbc przez ipsec
połączenie
ruch jest szyfrowany i podróżuje
między dwiema sieciami w przestrzeni publicznej
Internet teraz, jeśli chodzi o bezpośrednie
połączyć tę opcję połączenia
pozwala na podłączenie istniejącego
network do swojej sieci vpc za pomocą
wysoce dostępne
połączenie o niskim opóźnieniu ta łączność
opcja nie przechodzi do wiadomości publicznej
internet i łączy się jedynie z Google
kręgosłup i to właśnie mu to daje
wysoce dostępne połączenie o niskim opóźnieniu
kilka innych zaawansowanych połączeń
dostępne są opcje bezpośrednie i peering przez przewoźnika
te połączenia przepuszczają Twój ruch
przepływać przez sieć brzegową Google
lokalizacje i parowanie można wykonać
bezpośrednio lub można to zrobić przez a
przewoźnik zewnętrzny i tak chociaż this
to bardzo krótka lekcja, na którą pójdę
do głębszej analizy wszystkich tych pojęć
na późniejszych lekcjach kursu, więc to jest to
wszystko, co musiałem pokryć na tę lekcję, więc
możesz teraz oznaczyć tę lekcję jako zakończoną
i przejdźmy do następnego
witaj z powrotem na tej lekcji, na którą idziemy
dowiedzieć się, w jaki sposób zasoby i
podmioty
są zorganizowane w chmurze Google i
w jaki sposób uprawnienia są dziedziczone przez
to podejście, znając tę ​​strukturę
jest podstawową koncepcją, którą powinieneś
wiedzieć podczas pracy w gcp w dowolnym
pojemność, więc przed zdefiniowaniem, co
hierarchia zasobów to chciałbym wziąć
trochę czasu, aby zdefiniować, co to jest
zasób teraz w kontekście google
cloud zasób może odnosić się do
zasobów poziomu usług, do których są przyzwyczajeni
przetwarzać obciążenia, takie jak obliczenia
instancja vms
zasobniki do przechowywania w chmurze
a nawet bazy danych sql w chmurze
zasoby na poziomie konta, które siedzą
nad usługami
jak sama organizacja
foldery
i oczywiście projekty, które będziemy realizować
wejść trochę głębiej
tylko minuta
hierarchia zasobów jest sposobem Google
skonfigurować i przyznać dostęp
do różnych zasobów w chmurze dla Twojego
firma w chmurze Google zarówno w
poziom usług
i na poziomie konta
hierarchia zasobów w chmurze Google
może naprawdę zdefiniować ziarnistość
uprawnienia potrzebne, kiedy zajdzie taka potrzeba
skonfiguruj uprawnienia dla wszystkich w
organizacji, która faktycznie ma sens
więc teraz, gdy omówiliśmy, czym jest a
zasób, w którym chciałem zacząć kopać
hierarchia i struktura zasobów
teraz zasoby Google Cloud są
zorganizowane hierarchicznie za pomocą a
relacji rodzic-dziecko tej hierarchii
jest przeznaczony do mapowania organizacji
strukturę operacyjną do chmury Google
oraz do zarządzania kontrolą dostępu i
uprawnienia dla grup pokrewnych
zasoby
tak ogólnie
zapewni hierarchia zasobów
organizacji lepsze zarządzanie
uprawnienia i kontrola dostępu
dostępność tych zasobów lub
zasady są kontrolowane przez tożsamość i
zarządzanie dostępem, znane również jako iam a
duży składnik gcp, którym będziemy
zagłębiając się nieco później
ten kurs, a więc kiedy jest polityka iam
ustawiony na rodzica, który dziecko odziedziczy
niniejszą politykę odpowiednio kontroli dostępu
polityki i ustawienia konfiguracyjne na a
zasób nadrzędny
są zawsze dziedziczone również przez dziecko
należy pamiętać, że każdy obiekt podrzędny może
mieć dokładnie jednego rodzica
i że te zasady są znowu
kontrolowany przez iam, więc teraz rozumiem a
trochę więcej o tym, jak gcp
działa hierarchia zasobów
chciałem zagłębić się w te warstwy
wspierać tę hierarchię
więc to jest schemat dokładnie tego, co
hierarchia zasobów wygląda jak we wszystkich
jego wspaniałość
w tym konto rozliczeniowe wraz z
profilu płatności, ale nie idziemy
aby dostać się do tego w tej chwili, właściwie to zrobię
omówimy to w późniejszej lekcji, więc
więcej o tym później
więc budowanie konstrukcji od góry
zaczynamy od domeny lub
poziom chmur i jak widać tutaj
domena bowtieinc.co
jest na górze
to jest twoja podstawowa tożsamość
jest to organizacja na poziomie domeny
gdzie zarządzasz użytkownikami w swoim
organizacje
więc zasady użytkowników i te są ze sobą powiązane
do kont G Suite lub Cloud Identity
teraz poniżej poziomu domeny, który mamy
poziom organizacji i tyle
bardzo ściśle zintegrowany z domeną
więc z poziomem organizacji to
reprezentuje organizację i jest
węzeł główny hierarchii zasobów gcp
jest powiązany dokładnie z jedną domeną
tutaj mamy domenę ustawioną jako muszka
inc
wszystkie podmioty lub zasoby
należą do i są zgrupowane pod
organizacja
wszystkie kontrolowane zasady miały zastosowanie do
organizacja
są dziedziczone przez wszystkie inne podmioty i
zasoby pod nim, więc wszystkie foldery
projekty lub zasoby je otrzymają
zasady, które są stosowane od
warstwa organizacyjna teraz wiem, że my
jeszcze nie zagłębiał się w role
ale jedna rzecz, którą chciałem
podkreślić, że kiedy organizacja
jest tworzone
tworzona jest rola administratora organizacji
a to ma na celu umożliwienie pełnego dostępu do edycji
dowolne lub wszystkie zasoby
teraz przechodzimy do warstwy folderów
jest dodatkowym mechanizmem grupowania i
granica izolacji między każdym projektem
w istocie
to grupa innych folderów
projekty i zasoby, więc jeśli masz
różne działy i zespoły w ramach a
firma
jest to świetny sposób na zorganizowanie go teraz a
kilka zastrzeżeń, jeśli chodzi o
lornetka składana
po pierwsze musisz mieć
węzeł organizacji, a drugi to
podczas gdy folder może zawierać wiele
foldery lub zasoby
folder lub zasób może mieć dokładnie
jeden rodzic
teraz przechodzę do warstwy projektów this
jest podstawowym elementem organizacyjnym
Google Cloud, ponieważ projekty są do tego wymagane
korzystać z zasobów poziomu usług
te projekty to poziom bazowy
jednostka organizacyjna w gcp
i nadrzędnie nad wszystkimi zasobami poziomu usługi
tylko jako notatka
dowolny zasób może istnieć tylko w jednym
projekt, a nie wiele projektów w
w tym samym czasie i przechodzimy do ostatniego
warstwa mamy warstwę zasobów i
to jest dowolny zasób poziomu usługi
utworzone w chmurze Google
wszystko z instancji silnika obliczeniowego
do zasobników pamięci masowej w chmurze do sql w chmurze
użytkowników apis baz danych
wszystkie te zasoby poziomu usług, które
tworzymy w google cloud spadają
ta warstwa daje teraz hierarchii a
trochę więcej kontekstu, którego chcę dotknąć
na etykietach tylko przez sekundę
etykiety pomagają kategoryzować zasoby według
używając pary klucz-wartość i możesz
dołącz je do dowolnego zasobu
więc to, co pomagają etykiety, to zrobić
rozkładać i organizować koszty, kiedy to nastąpi
przychodzi teraz do rozliczeń, aby dać ci trochę
więcej struktury w odniesieniu do
hierarchia
poniżej poziomu domeny
wszystko pod tym jest brane pod uwagę
zasób
i jeszcze bardziej rozbić
wszystko, co widzisz z organizacji
warstwa do warstwy projektów jest
uważane za zasób na poziomie konta
wszystko w warstwie zasobów jest
uważane za zasób na poziomie usług i
więc tak wygląda zasób Google Cloud
hierarchia jest podzielona i zorganizowana i
więc zanim skończę tę lekcję i
chciałem dać ci szybki przegląd
o tym, jak zasady mogą być stosowane w
poziom hierarchiczny
więc pomyślałem, że przyniosę muszkę Tony'ego
na szybkie demo
więc podam tylko przykład
Tony Bowtie jest częścią działu B i
skowronek menedżera Tony'ego
decyduje się na ustawienie polityki w dziale
b, a ta zasada obowiązuje
rola właściciela projektu dla tony at
bowtieinc.co, więc Tony będzie miał
rola właściciela projektu dla projektu x i dla
projekt y w tym samym czasie
Lark przypisuje Laurę na stronie bowtieinc.co
rola administratora magazynu w chmurze w projekcie x
i tak będzie mogła tylko zarządzać
zasobniki do przechowywania w chmurze w tym projekcie
tę hierarchię i pozwolenie
dziedziczenie pojawia się całkiem nie
tylko na egzaminie, ale coś w tym jest
należy dokładnie zbadać, kiedy
stosowania uprawnień
w dowolnym miejscu w hierarchii w twoim
na co dzień jako inżynier
stosowanie uprawnień lub zasad do
zasoby
z istniejącymi politykami
może nie skończyć się uzyskaniem pożądanego
wyniki, których szukasz i które możesz mieć
mam nadzieję, że teraz mam szansę zostać przeoczonym
te diagramy dały ci trochę dobrego
kontakty w odniesieniu do zasobów
hierarchia jego struktura i
uprawnienia są teraz stosowane w łańcuchu
to wszystko, co mam na temat tej lekcji
hierarchię zasobów, dzięki czemu możesz teraz oznaczać
tę lekcję za zakończoną i ruszamy
Przechodząc do następnego
[Muzyka]
Witamy spowrotem
w tej lekcji omówię kilka
różne tematy, które poruszę
podczas tworzenia nowego konta Google Cloud
będę opisywał przechodzenie za darmo
poziom i zawsze darmowe opcje
różnice między nimi a wersją demonstracyjną
pokazując, jak możesz stworzyć swój własny darmowy
Konto poziomu, jak również, też się wybieram
w to, czego będziesz potrzebować, aby to zrobić
wypełnij to demo, więc przez resztę
tego kursu uruchomione zostaną wszystkie wersje demonstracyjne
pod darmowym poziomem teraz, kiedy budowałem
ten kurs zbudowałem go z budżetem
umysł i po obejrzeniu sposobów, w których ja
może utrzymać cenę na minimalnym poziomie
wciąż utrzymując, że wersje demonstracyjne są niezwykle przydatne
i tak bezpłatny poziom mieści się we wszystkich
te wskazówki i pomogą ci się uczyć
bez wysokiej ceny biletu i tak dalej
szybkie zapoznanie się z
różnice między darmowym poziomem a
zawsze bezpłatna opcja, którą zepsułem
ich tutaj z ich najbardziej
znaczne różnice w warstwie bezpłatnej
Google Cloud oferuje 12 miesięcy za darmo
Próba z 300
nam kredyt kończy się na tym typie konta
kiedy kredyt jest wykorzystany lub po 12
miesięcy, w zależności od tego, co nastąpi wcześniej i tak dalej
dla tych z was, którzy patrzą
wykorzystując to w biznesie
poziom niestety tylko darmowy poziom
dotyczy konta osobistego i nie może
dołącz teraz do konta firmowego
przejście do opcji zawsze bezpłatnej
opcja zawsze bezpłatna nie jest niczym szczególnym
program, ale jest to stała część twojego
konto w chmurze Google, które ci zapewnia
ograniczony dostęp do wielu google
zasobów w chmurze bezpłatnie i jednorazowo
te granice zostały przekroczone
wtedy opłata jest naliczana według zwykłej opłaty za
druga stawka rozliczeniowa
i pokażę ci trochę później
jak monitorować te kredyty, aby
nie przesadzaj z używaniem tego w połączeniu
z darmowym kontem nie jest
możliwe, że musisz mieć uaktualniony
konto rozliczeniowe, które może również zawierać a
konto firmowe, teraz jest ich kilka
więcej postanowień w tym programie oraz i
będzie zawierać link do obu z nich w
tekst lekcji poniżej do późniejszego wglądu
kiedy będzie Ci wygodnie
teraz na koniec, zanim przejdziemy do wersji demonstracyjnej
chciałem szybko przejść
przejrzenie dokładnie tego, co jest potrzebne
otwórz swoje bezpłatne konto poziomu
więc zaczniemy od świeżego
nowy adres gmail, aby tak nie było
konflikt z jakimkolwiek aktualnym adresem Gmail
że możesz mieć, będziesz potrzebować
karta kredytowa do weryfikacji i to jest to
aby Google upewnił się, że jesteś
rzeczywista istota ludzka, a nie robot i
nie zostaniesz obciążony, chyba że przejdziesz powyżej
limit kredytowy 300 i bardzo
polecam przejść do prywatnego przeglądania
session, więc niezależnie od tego, czy używasz chrome
użyłbyś sesji incognito, gdyby
używasz firefoxa, którego byś użył
przeglądanie prywatne i Microsoft Edge
używałbyś trybu prywatnego
i tak aby zacząć od tego za darmo
wersję próbną możesz przejść do adresu URL
wymienione tutaj i dołączę to również
w tekście lekcji, więc przejdź do
ten adres URL i do zobaczenia za chwilę
sekunda
dobrze, więc jesteśmy na bezpłatnej wersji próbnej
url jestem tutaj w google chrome w
sesja incognito i tak nie idziemy
aby się zarejestrować, przejdziemy tutaj
aby utworzyć konto, wystarczy kliknąć
Utwórz konto
dla siebie, bo jak wspomniałem
wcześniej nie możesz utworzyć darmowego
konto próbne w Twojej firmie
więc sam klikam
i przeniesie Cię na tę stronę
gdzie jest napisane, że utwórz swoje konto Google
i zamierzasz przejść do tworzenia nowego
Zamiast tego adres gmail
a teraz masz zamiar wypełnić wszystkie
niezbędne informacje, które są potrzebne w
aby otworzyć to nowe konto Gmail
kiedy skończysz wpisywać swój
hasło, które możesz nacisnąć dalej
a teraz zostałem poproszony o podanie sześciu cyfr
kod weryfikacyjny, który muszę wprowadzić
ale aby to zrobić, Google potrzebuje my
numer telefonu, więc go wpiszę
teraz i tylko po to, żeby Cię o tym poinformować
weryfikacja ma na celu poinformowanie Google
że nie jesteś botem i jesteś prawdziwy
human i Google właśnie przesłali mi wiadomość
kod weryfikacyjny
i jest to jednorazowy kod weryfikacyjny
że się podłączę
i zamierzam nacisnąć weryfikację
i możesz podłączyć niezbędne
tutaj informacje dotyczące pomocniczego adresu e-mail
zaadresuj swoje urodziny i płeć oraz
ma to na celu umożliwienie uwierzytelnienia przez Google
na wypadek, gdybyś przypadkowo zgubił miejsce
Twoje hasło
a następnie po prostu naciśnij następny i tutaj google
daje trochę więcej informacji
o tym, do czego może być używany Twój numer i
więc idę dalej i omijam to
i oczywiście będziemy czytać
poprzez warunki korzystania z usługi i
Polityka prywatności
kliknij zgadzam się
i jak widać jesteśmy już prawie na miejscu
pokazuje, że jesteśmy
rejestracja na bezpłatny okres próbny, w którym biorę udział
kanada tak
w zależności od kraju może to być
zmiana oczywiście przeczytałem warunki
usługi i mam zamiar zgodzić się na to i
tak naprawdę nie chcę żadnych aktualizacji, więc ty
prawdopodobnie można to pominąć i po prostu uderzyć
Kontynuować
i to jest wszystko, co konieczne
informacje, które należy uzupełnić
do rozliczeń i tak tutaj pod kontem
wpisz pamiętaj, aby kliknąć na osobę jako
w przeciwieństwie do biznesu i ponownie wypełnij
wszystkie niezbędne informacje z
w odniesieniu do twojego adresu i twojego kredytu
dane karty i po ich wypełnieniu
możesz kliknąć rozpocznij mój bezpłatny okres próbny
a kiedy już w to wszystko wszedłeś
informacje, do których powinieneś zostać doprowadzony
tę stronę z monitem
pytając dokładnie, czego potrzebujesz
w odniesieniu do chmury Google i możesz po prostu
kliknij pomiń tutaj
i zamierzam powiększyć tutaj, po prostu zobacz
trochę lepiej i tak tu jesteś
z listą kontrolną, dokąd możesz się udać
przez wszystkie różne zasoby i
daje nawet listę kontrolną do zrobienia
przez, ale poza tym jesteśmy w środku
i tak tylko po to, by zweryfikować, czy jesteśmy podpisani
się na bezpłatne konto poziomu, na które zamierzam
przejdź do rozliczeń, a ja zobaczę
tutaj mam mój darmowy kredyt próbny
i mówi 411 dolarów i ze względu na
Fakt, że moja waluta jest w Kanadzie
dolarów zostało przeliczone z nas
dolarów i tak będziemy przechodzić
rozliczanie w późniejszej lekcji
ale teraz jesteśmy faktycznie zalogowani
i to wszystko, co chciałem pokryć
tę lekcję, jak zarejestrować się w
bezpłatne konto próbne
więc możesz teraz oznaczyć tę lekcję jako
ukończone i możesz dołączyć do mnie w następnym
jeden
gdzie zabezpieczymy konto
stosując metodę zwaną dwuetapową
weryfikacja
[Muzyka]
Witamy spowrotem
więc na ostatniej lekcji poszliśmy do przodu i
utworzył w tym zupełnie nowe konto gcp
lekcja, o której będziemy rozmawiać, jak się zabezpieczać
to konto gcp, postępując zgodnie z najlepszymi
praktyki
za każdym razem, gdy zostanie utworzone konto w
Google Cloud i można to zastosować
w odniesieniu do kont osobistych jako
jak również konto superadministratora
zawsze dobrze jest zachować bezpieczeństwo jako priorytet
ta lekcja może być dla nich odświeżeniem
którzy są nieco bardziej zaawansowani
wszyscy inni, te kroki mogą ci pomóc
od ataku na twoje konto, najpierw
chciałbym przeprowadzić cię przez scenariusz
wynik zarówno bezpieczny, jak i
niezabezpieczone konta
jak również różne opcje, które
przebywać w chmurze Google
jeśli chodzi o zablokowanie twojego
konto, a następnie przejdę przez praktyczne
demo w konsoli
aby pokazać, jak możesz go zastosować
się
więc w tym konkretnym scenariuszu nazwa użytkownika
i hasło służy do zabezpieczenia
konto
tutaj skowronek powoduje kłopoty menedżera
zagląda przez ramię tony muszce
podczas gdy on podłącza swoją nazwę użytkownika i
hasło
aby mógł później uzyskać dostęp do swojego konta
siać spustoszenie w reputacji Tony'ego jako
Tony wychodzi na kawę
skowronek postanawia się zalogować i wysłać wiadomość
e-mail obejmujący całą firmę z konta Tony'ego
zmienić już podjętą decyzję dot
otwarcie sklepu w przyszłym sezonie w Rzymie
Włochy, to nie wyglądałoby dobrze dla Tony'ego
skowronkowi tak łatwo było ukraść
hasło Tony'ego iw prawdziwym życiu
scenariusz, dla którego byłoby to takie łatwe
ktoś, kto ukradnie twoje hasło teraz, kiedy
ktoś może ukraść twoje hasło
robić jeszcze bardziej przebiegłe rzeczy niż co
skowronek nie tylko wysyłał szkodliwe
e-maile, które mogą cię zablokować
konto, a nawet usuwać wiadomości e-mail lub
dokumenty to jest dwuetapowy
przychodzi weryfikacja, która może pomóc w utrzymaniu
źli ludzie na zewnątrz
nawet jeśli mają twoje hasło dwuetapowe
weryfikacja to dodatkowa warstwa
bezpieczeństwa większość ludzi ma tylko jedną warstwę
aby chronić swoje konto, które jest ich
hasło z weryfikacją dwuetapową
jeśli zła osoba włamie się do twojego
hasło, nadal będą potrzebować Twojego telefonu
lub klucz bezpieczeństwa, aby uzyskać dostęp do konta
tak działa weryfikacja dwuetapowa
że logowanie będzie wymagać czegoś od Ciebie
wiedzieć
i coś, co masz
pierwszy to ochrona twojego konta
z czymś, co wiesz, co będzie
twoje hasło, a drugie to
coś, co masz
jaki jest Twój telefon lub klucz bezpieczeństwa
więc za każdym razem, gdy zalogujesz się do Google, będziesz
wprowadź swoje hasło jak zwykle
następnie kod zostanie wysłany na Twój telefon
za pośrednictwem tekstu
połączenie głosowe lub aplikacja mobilna Google lub if
masz klucz bezpieczeństwa, który możesz włożyć
go do portu USB komputera
kody można wysłać w wiadomości sms lub
poprzez połączenie głosowe w zależności od
ustawienie, które wybierzesz
możesz skonfigurować Google Authenticator lub
kolejna aplikacja, która tworzy jednorazową
kod weryfikacyjny, który jest świetny dla
kiedy jesteś offline, wszedłbyś
kod weryfikacyjny przy logowaniu
ekran, aby potwierdzić, że to Ty
innym sposobem weryfikacji jest użycie
podpowiedzi Google, a to może pomóc w ochronie
na zamianę karty SIM lub inny numer telefonu
oparte na hackach podpowiedzi Google są push
powiadomienia, które będziesz otrzymywać na Androida
telefony, które są zalogowane w Google
konto lub telefony iPhone z aplikacją Gmail lub
aplikacja Google, która jest zalogowana do Twojego
konto Google teraz możesz faktycznie pominąć
drugi krok na zaufanych urządzeniach
jeśli nie chcesz zapewnić drugiego
etap weryfikacji przy każdym logowaniu
na komputerze lub telefonie możesz
zaznacz pole obok opcji nie pytaj ponownie
ten komputer i to jest świetny dodatek
tę funkcję, jeśli jesteś jej jedynym użytkownikiem
urządzenie
ta funkcja nie jest zalecana, jeśli to
urządzenie jest używane przez wielu użytkowników
klucze bezpieczeństwa to kolejny sposób pomocy
chroń swoje konto Google przed
ataki phishingowe, gdy próbuje to zrobić haker
oszukać Cię, abyś podał im swoje hasło
lub inne dane osobowe teraz a
fizyczny klucz bezpieczeństwa to małe urządzenie
które możesz kupić, aby udowodnić, że to ty
logowanie, gdy Google musi to zrobić
pewien, że to ty
możesz po prostu podłączyć swój klucz do swojego
komputer i sprawdź, czy to Ty i
gdy nie masz innego sposobu na weryfikację
Twoje konto, które masz do wyboru
za pomocą kodów zapasowych i są to
jednorazowe kody, które można wydrukować lub
download i jest to wiele zestawów
ośmiocyfrowe kody, które można przechowywać w
bezpieczne miejsce na wypadek, gdybyś nie miał innego
opcje weryfikacji ja osobiście
znalazły zastosowanie w korzystaniu z tych kopii zapasowych
kody, ponieważ używałem ich w przeszłości, kiedy
mój telefon umarł
więc od ostatniego e-maila Larka
tony nie tylko zmienił hasło
ale dodał do swojego dwuetapową weryfikację
konto, aby tylko on je miał
dostęp i nigdy nie musiałbym się martwić
znowu o innych patrzących na jego
ramię, aby uzyskać dostęp do swojego konta
gdy Tony wychodzi na kawę
Lark próbuje się ponownie zalogować, ale jest
nieudany ze względu na dwuetapowość
weryfikacja, którą tony ma wyraźnie
przechytrzył złego człowieka w tym scenariuszu
a skowronek będzie musiał szukać innego
sposób, aby udaremnić plan Tony'ego
wielkość muszki na całym świecie
i to jest pewna różnica między
posiadanie bezpiecznego konta i nie tak
bezpieczne konto i tak teraz, kiedy już poszedłem
poprzez teorię dwuetapową
proces weryfikacji zamierzam nurkować
do konsoli i zaimplementuj go za pomocą
praktyczne demo, po prostu pamiętaj, że ty
można to również zrobić przez gmail
konsoli, ale zamierzamy iść dalej i
zrób to za pomocą konsoli Google Cloud
używając adresu URL, który widzisz tutaj, więc zawsze
jesteś gotowy, dołącz do mnie w
konsola
i tak oto jesteśmy z powrotem w konsoli
i tutaj w prawym górnym rogu
rogu znajdziesz ikonę użytkownika i siebie
można go po prostu kliknąć
i kliknij na swoje konto Google
teraz po prostu powiększę dla lepszego
oglądanie
i tak w celu umożliwienia dwuetapowego
weryfikacja, do której tu pójdziemy
menu po lewej stronie i kliknij
security i pod logowaniem do google
znajdziesz weryfikację dwuetapową
obecnie jest wyłączony, a także używa mojego
telefon do logowania jest wyłączony, więc ja to zrobię
kliknij ten pasek tutaj, aby przejść do dwóch kroków
weryfikacja
i zdecydowanie chcę dodać dodatkowe
warstwę bezpieczeństwa i zdecydowanie chcę
aby trzymać złych facetów z dala, więc zamierzam to zrobić
Śmiało i kliknij na rozpoczęcie
przycisk
poprosi mnie o hasło
i ponieważ wpisałem swój numer telefonu
kiedy po raz pierwszy założyłem konto
faktycznie pojawia się tutaj, to jest ja
antony, który jest moim iphonem, więc teraz ja
można uzyskać weryfikację dwuetapową tutaj
mój iPhone i znowu to będzie
monit google, jak to pokazuje tutaj, ale jeśli
chciałem to zmienić na coś innego
mogę po prostu kliknąć pokaż więcej opcji
i tutaj mamy również klucz bezpieczeństwa
jako wiadomość tekstową lub połączenie głosowe i bardzo
polecam zachętę google taką, jaka jest
super łatwy w użyciu z absolutnie nie
zamieszanie i tak jak zawsze lubię weryfikować
co zrobiłem, kliknę
ten przycisk wypróbuj teraz, a więc ponieważ ja
chciałem wam dokładnie pokazać, co to jest na żywo
zachęta google wygląda na to, że zamierzam
przywołaj mój telefon tutaj na ekranie, więc
że możesz rzucić okiem
i faktycznie wysłał mi monit Google
do mojego telefonu i po prostu idę
naprzód i otwórz moją aplikację Gmail, abym mógł
zweryfikować, czy to rzeczywiście ja tego chcę
aby się zalogować, które zaakceptuję
i tak po zaakceptowaniu Google
monit pojawi się kolejne okno z pytaniem
mnie o opcji kopii zapasowej, więc to zrobię
wystarczy mój numer telefonu
i mogę otrzymać wiadomość tekstową lub wiadomość
telefon i znowu masz inne
opcje, więc możesz użyć
jednorazowe kody zapasowe, o których rozmawialiśmy
wcześniej i możesz wydrukować lub pobrać
je, ale zwykle lubię używać tekstu
wiadomość, więc zamierzam to wykorzystać
wyślę to na mój telefon
i tak tylko po to, żeby to zweryfikować
teraz podłączę kod jednorazowy
który został do mnie wysłany
a potem po prostu naciśnij następny
więc drugim krokiem jest monit google
to moje domyślne i moje opcje zapasowe, jeśli
nie mogę uzyskać potwierdzenia od google to głos lub
SMS i znowu to dla mnie
konto antony gcloud ace na gmail.com
wysyłanie go do mojego urządzenia i antony, więc włącz
absolutnie na weryfikacji dwuetapowej
i tak tam masz to jest
włączona weryfikacja dwuetapowa i jeśli i
chciałem zmienić dostępne kroki i
mogę to zrobić tutaj, mogę to również edytować
edytuj mój numer telefonu i mogę również ustawić
przygotować kody zapasowe na wypadek, gdyby były potrzebne
moja osobista opinia dwuetapowa
weryfikacja
jest koniecznością pod każdym względem
praktyką jest zawsze robić to dla siebie
konto superadministratora, które byłoby moim
konto gmail, na którym jestem obecnie podpisany
się z, ale uważam, że jest koniecznością
innych użytkowników i zawsze rób z tego a
polityka dla ludzi, aby dodać dwa kroki
weryfikacja ich kont i bardzo
polecam zrobić to jak najlepiej
przećwicz robienie tego w swojej roli jako
inżynier w dowolnym środowisku w dowolnym momencie
organizacja ponownie dwuetapowa weryfikacja
pozwoli zapewnić bezpieczeństwo użytkownikom
bezpieczne, a twoje środowisko bezpieczne przed jakimkolwiek
złośliwych działań, które mogą się zdarzyć
w dowolnym momencie i to wszystko, co mam
tę lekcję dotyczącą weryfikacji dwuetapowej i
zabezpieczenie konta
więc możesz teraz oznaczyć tę lekcję jako
zakończyć i przejść do następnego
jeden
[Muzyka]
Witamy spowrotem
teraz istnieje wiele różnych sposobów
z którymi możesz wchodzić w interakcje z Google Cloud
usługi i zasoby ta lekcja jest
omówienie konsoli gcp i sposobu, w jaki ty
może wchodzić z nim w interakcję za pomocą grafiki
interfejs użytkownika i tak dalej
próbny
będę zagłębiać się w sposób nawigacji
przez konsolę gcp i wskaż
niektóre funkcje i funkcje, które możesz
znaleźć pomocne, więc powiedziano
zanurzmy się
i tak oto jesteśmy z powrotem w konsoli
tutaj możesz zobaczyć bezpłatną wersję próbną
status, a następnie nadal mam 410 kredytów
znowu to są dolary kanadyjskie, więc ja
chyba uznają mnie za szczęściarza, więc zamierzam
idź tutaj i odrzuć to
nie aktywuj go, bo inaczej to
zabije twój status bezpłatnej wersji próbnej i ciebie
Nie chcę tego robić, więc po prostu idę
uderzyć odrzucić, więc tutaj na głównej
strona masz tutaj kilka kart
nada ci status twojego
środowiska, jak również status
co dzieje się w chmurze Google
za pomocą tych kart możesz je dostosować
naciskając ten przycisk tutaj
dostosować i możesz je włączyć lub
wyłączone i możesz śmiało je przenieść
w okolicy, jeśli chcesz
i zamierzam umieścić to tutaj jako
więc zamierzam włączyć rozliczanie
mogę śledzić dokładnie to, co mój
wydać, tak naprawdę nie potrzebuję mojego geta
karta startowa, więc ją odwrócę
off, a także dokumentację, którą posiadam
też to wyłączę
a api jest zawsze miło mieć
jak również tutaj w informacjach o projekcie this
odzwierciedla obecny projekt, który jest moim
pierwszy projekt
a nazwa projektu tutaj jest taka sama
wyświetlany jest identyfikator projektu i
numer projektu i idę nurkować
głębiej w to również w innej lekcji
pamiętaj, że twoje karty będą odzwierciedlać
dokładnie to, czym jesteś
wchodzić w interakcje i tym bardziej
zasobów, które zanurzasz w kartach
w końcu pojawi się tutaj
i możesz je dodawać i wyłączać
do woli, więc idę tutaj i
kliknij gotowe, bo jestem zadowolony
sposób, w jaki rzeczy wyglądają
tutaj na mojej stronie głównej i tutaj do
Twoja lewa strona, na której chciałem się skupić
wszystkie usługi dostępne w
ich własne specyficzne tematy, więc dla
instancja wszystkich obliczeń
znajdziesz silnik obliczeniowy silnika aplikacji
kubernetes i tak dalej, więc zauważ to
znajdziesz wszystko, co jest związane z obliczeniami
wszystkie one zgrupowane razem także inny
świetną cechą jest to, że możesz przypiąć
dokładnie to, czego często używasz
jeśli jestem dużym użytkownikiem silnika aplikacji, mogę
przypnij to, a przesunie się do
góry w ten sposób oszczędzam czas
od konieczności chodzenia i szukania go każdego dnia
czas, kiedy go potrzebuję i czy go używam
ciągle dobrze jest mieć skrót
aby go odpiąć, po prostu wracam do pinezki
i kliknij go ponownie, gdybym chciał
jak przenieść menu z drogi do
uzyskać więcej nieruchomości ekranowych, które mogę po prostu
kliknij ten przycisk hamburgera tutaj
i sprawić, że zniknie i przynieść
z powrotem mogę po prostu kliknąć na to ponownie i
Przyniosę to z powrotem, teraz to wiem
jest tu wiele zasobów do wykorzystania
przez więc jeśli szukasz
coś konkretnego, zawsze możesz iść w górę
do paska wyszukiwania tutaj
i po prostu wpisz go, więc jeśli szukam
powiedzmy, że cloud sql mogę po prostu
wpisz sql
i mogę go znaleźć tutaj
mogę znaleźć api i jeśli cokolwiek
związane ze słowem sql, jeśli jestem
szukam cloud sql konkretnie mogę
po prostu wpisz
chmura sql
i oto jest
należy zauważyć, że jeśli ty
chcesz wrócić do swojej strony głównej, możesz
po prostu przejdź do lewego rogu
tutaj i kliknij chmurę Google
logo platformy, a naprowadzi cię na właściwe tory
z powrotem i tutaj pod google
logo platformy w chmurze zobaczysz inne
zestaw kart mamy również deskę rozdzielczą
mieć aktywność, a to pokaże wszystkie
ostatnio wykonana czynność
i ponieważ jest to zupełnie nowe konto
Nie mam tu teraz zbyt wiele, ponieważ to
jest to mój pierwszy raz w działalności
indeksowanie zajmie trochę czasu
a w międzyczasie chciałem ci pokazać
filtry
gdyby to była długa lista do przejrzenia
gdzie odbywa się aktywność
miesięcy mogę je przefiltrować
działania przez użytkownika lub przez
kategorii lub według typu zasobu
jako datę mogę je również połączyć
wyszukaj coś naprawdę szczegółowego i
obok zakładki aktywności mamy
rekomendacje oparte na tzw
usługi rekomendacji i tej usługi
dostarcza rekomendacji i spostrzeżeń
za korzystanie z zasobów w chmurze Google
te zalecenia i spostrzeżenia są
na podstawie produktu lub usługi
i opierają się na uczeniu maszynowym
a bieżące wykorzystanie zasobów jest świetne
przykładem zalecenia jest vm
odpowiedni rozmiar instancji, więc jeśli
usługa rekomendująca wykryje, że plik vm
instancja nie jest w pełni wykorzystana, tak będzie
zalecamy zmianę rozmiaru maszyny tzw
że mogę zaoszczędzić trochę pieniędzy i ponieważ
to jest świeże nowe konto i ja
nie użyłem żadnych zasobów, dlatego
nie ma dla mnie takiej rekomendacji
powrót do strony głównej
chcę dotknąć tego menu projektów
na sekundę i jak widać tutaj ja
mogę teraz wybrać projekt, gdybym miał ich wiele
różne projekty, które mogę po prostu wyszukać
od każdego innego i tak do pokrycia
ostatnia część konsoli, którą chciałem
dotknij tego menu w prawym górnym rogu
rogu tutaj, więc kliknij ten prezent
ikona pokaże mój status bezpłatnej wersji próbnej
które odrzuciłem wcześniej obok
obecnie mamy ikonę powłoki chmurowej i
tutaj możesz aktywować i przynieść
w górę skorupy chmur, którą będę
nurkowanie głębiej w późniejszej lekcji i
tuż obok znajduje się przycisk pomocy
jeśli potrzebujesz skrótu do dowolnego
dokumentacje lub samouczki, a także niektóre
Skróty klawiszowe
może pomóc ci być trochę więcej
wydajny i zawsze możesz kliknąć
to, a pokaże ci dokładnie, o co ci chodzi
muszę wiedzieć, więc zamykam
Ten
i przejść do następnej części w
menu to są powiadomienia więc dowolne
działania, które się zdarzają, będziesz
powiadomiony tutaj i możesz po prostu kliknąć
na dzwonek, a pokaże ci kilka
różnych powiadomień dla każdego z nich
tworzonych zasobów lub jakichkolwiek innych
czynności, które mogły mieć miejsce teraz
przejść dalej
trzy przyciski tutaj to ustawienia
i narzędzia
a tutaj znajdziesz tzw
preferencje
a pod komunikacją znajdziesz
powiadomienia o produktach i aktualizacje oraz
oferty i możesz je wyłączyć lub włączyć
w zależności od tego, czy chcesz
otrzymywać te powiadomienia również Ty
mieć swój język i region oraz Ciebie
może spersonalizować konsolę w chmurze
czy chcesz zezwolić Google
śledzić Twoją aktywność i to jest świetne
bo kiedy chcesz rekomendacji, więc ja
zamierzam zachować to zaznaczone
z powrotem do kilku innych opcji, które znajdziesz
link do plików do pobrania oraz chmury
partnerzy i warunki korzystania z usługi
ustawienia prywatności i projektu itp
omówić ostatni temat, który chciałem poruszyć
on jest faktycznym przyciskiem konta Google
i tutaj możesz dodać inne konta użytkowników
gdy logujesz się do konsoli za pomocą a
innego użytkownika, a także przejść bezpośrednio do
Twoje konto Google i oczywiście jeśli
korzystasz z komputera używanego przez
wielu użytkowników, jako których możesz się tutaj wylogować
dobrze, więc to tylko szybkie
przebieg konsoli i tak się czuje
swobodnie się rozglądać i poznawać
z dokładnie tym, co jest dostępne w
konsoli, dzięki czemu jest to o wiele łatwiejsze
możesz użyć i pozwolić ci stać się kimś więcej
wydajny i to wszystko co mam
tę lekcję, abyś mógł teraz to zaznaczyć
lekcję za zakończoną i przejdźmy dalej
Następny
Witamy spowrotem
w tej lekcji zamierzam iść
poprzez podział rozliczeń w chmurze i
przegląd różnych zasobów
jest to związane z rozliczeniami
ważne, aby wiedzieć
i zagłębię się w koncepcje
wokół rozliczeń i interakcji rozliczeniowych
przez kilka następnych lekcji
jak również będę wsiadać do innego
demo przeglądające szczegóły, jak to zrobić
tworzyć
edytować
i usuń konto rozliczeniowe w chmurze
teraz wcześniej w trakcie przeszedłem
hierarchia zasobów i jak google
zasoby w chmurze są rozbijane od początku
od poziomu domeny do ich
poziom zasobów
ta lekcja skupi się ściśle na
konto rozliczeniowe
i profilu płatności
a podział to pojęcia, które są
w nich zawartych
więc przechodząc od razu do rzeczy, zacznijmy
z kontem rozliczeniowym w chmurze chmura
konto rozliczeniowe to poziom chmury
zasób zarządzany w konsoli chmury
określa to, kto płaci za dany zestaw
ścieżki rozliczeń zasobów Google Cloud
wszystkie koszty poniesione przez Google
korzystanie z chmury jest również połączone z a
profil płatności Google, który zawiera m.in
metoda płatności określająca, w jaki sposób płacisz
dla Twoich opłat konto rozliczeniowe w chmurze
może być powiązany z jednym lub kilkoma projektami
a nie do konkretnego projektu
rozliczenia w chmurze są również specyficzne dla rozliczeń
role i uprawnienia do kontrolowania
uzyskiwanie dostępu i modyfikowanie związanych z rozliczeniami
funkcje ustanowione przez
chmura zarządzania tożsamością i dostępem
rozliczenia oferowane są w dwóch różnych
typów kont istnieje samoobsługa
lub konto online lub możesz też wybrać
z płatności zafakturowanych lub offline
jeśli chodzi o opcję samoobsługową
metodą płatności jest zwykle kredyt
lub kartą debetową i pobierane są koszty
automatycznie do określonej płatności
metoda połączona z rozliczeniami w chmurze
konto i kiedy potrzebujesz dostępu do swojego
faktury możesz po prostu przejść do chmury
konsoli i przeglądać je online teraz, kiedy to
przychodzi na konto faktury jako pierwszy ty
musi kwalifikować się do wystawiania faktur
gdy kwalifikujesz się do płatności
zastosowaną metodą może być czek lub drut
przelew Twoje faktury są wysyłane pocztą
lub elektronicznie, jak również są
dostępne również w konsoli w chmurze
jako dowody wpłaty
teraz kolejna fajna funkcja rozliczeń
konto to subkonta i takie są
przeznaczone dla sprzedawców, więc jeśli jesteś
sprzedawcy, do którego możesz używać subkont
reprezentuj swoich klientów i zrób to
łatwe rozliczanie obciążeń zwrotnych w chmurze
subkonta umożliwiają grupowanie opłat
z projektów razem na osobnej
część faktury i jest połączona
z powrotem do głównego konta rozliczeniowego w chmurze
na którym pojawiają się Twoje opłaty
subkonta są zaprojektowane tak, aby umożliwić
separacja klientów i zarządzanie tzw
jeśli chodzi o posiadanie chmury
konto rozliczeniowe jest ograniczone do a
pojedyncza organizacja
jest to jednak możliwe dla chmury
konto rozliczeniowe do płacenia za projekty, które
należy do organizacji tj
inna niż ta organizacja
jest właścicielem konta rozliczeniowego w chmurze teraz jeden
należy zauważyć, że jeśli masz
projekt, który nie jest powiązany z fakturowaniem
konto, z którego będziesz mieć ograniczone możliwości korzystania
produktów i usług dostępnych dla Ciebie
projekt, który jest projektem, który nie jest
połączone z kontem rozliczeniowym nie mogą być używane
Google Cloud Services, które nie są darmowe
a więc teraz, kiedy przeszliśmy przez
przegląd konta rozliczeniowego
zrób szybki krok do płatności
profil, teraz profil płatności to a
zarządzany zasób na poziomie Google pod adresem
płatności.google.com
profil płatności
przetwarza płatności dla wszystkich usług Google
usług, a nie tylko dla Google Cloud
łączy się ze wszystkimi Twoimi usługami Google
usługi, takie jak reklamy Google, jak również
Google Cloud przechowuje takie informacje jak
twoje imię i nazwisko adres i kto jest odpowiedzialny
dla profilu, w którym przechowuje różne
metody płatności, takie jak debetowanie kart kredytowych
karty i konta bankowe płatności
profil
działa jak pojedyncza tafla szkła
gdzie można przeglądać płatności za faktury
historia i tak dalej, kontroluje również, kto
może przeglądać i odbierać faktury za Twoje
różne konta rozliczeniowe w chmurze i
produkty
teraz jedna rzecz do zapamiętania na temat płatności
profil jest taki, że są dwa różne
rodzaje profili płatności pierwszy
jest indywidualna i wtedy jesteś
używanie konta do własnych celów osobistych
płatności, jeśli zarejestrujesz swoje płatności
profil jako osoba fizyczna, to tylko ty
możesz zarządzać profilem, którego ty nie będziesz mógł
dodawać lub usuwać użytkowników lub zmieniać
uprawnienia w profilu teraz, jeśli ty
wybierz typ profilu biznesowego, którym jesteś
płacąc w imieniu firmy lub
organizacji, jaką daje profil biznesowy
elastyczność dodawania innych użytkowników
do profilu płatności Google
zarządzać tak, aby więcej niż jedna osoba mogła
uzyskiwać dostęp do profilu płatności lub zarządzać nim
użytkowników dodanych do profilu biznesowego
można wtedy zobaczyć informacje o płatności na
ten profil to kolejna rzecz, na którą należy zwrócić uwagę
że kiedyś był to typ profilu
wybrana, nie można jej później zmienić
i tak teraz, gdy szybko poszliśmy
poprzez przegląd wszystkich pojęć
jeśli chodzi o rozliczenia, teraz idę
przeprowadzić krótkie demo, gdzie to zrobię
utwórz nowe konto rozliczeniowe edytuj to
konto rozliczeniowe i pokazać, jak to zrobić
zamknij konto rozliczeniowe, więc kiedy tylko
jesteś gotowy, dołącz do mnie w konsoli i
więc jestem z powrotem w konsoli i tak dalej
pierwszą rzeczą, którą chcę zrobić, to chcieć
aby upewnić się, że mam odpowiedni
uprawnień w celu tworzenia i edytowania
nowe konto rozliczeniowe, więc do czego zmierzam
zrobić, to pójść tutaj do hamburgera
menu tutaj, w lewym górnym rogu
i kliknij na to
i przejdź do Jestem administratorem i przejdź do
Ja jestem
teraz nie martw się, nie dostanę
naprawdę głęboko w to pójdę
nad tym w późniejszej sekcji, w której to zrobię
przejść przez iam i role, ale chciałem
dać ci poczucie tego, czym dokładnie jesteś
potrzeba w odniesieniu do uprawnień tak teraz
że jestem tutaj i będę szukać
na stanowisko związane z rozliczeniami
więc po prostu przejdę tutaj
menu po lewej stronie i kliknij role
i będziesz miał mnóstwo ról nadchodzących
w górę
a co możesz zrobić, to przefiltrować
je po prostu wpisując billing
do tabeli filtrów tutaj na górze
i jak widać tutaj
jest administrator konta rozliczeniowego
twórca konta rozliczeniowego i tak dalej i tak dalej
dalej i tylko po to, żeby dać ci szybki
przegląd tych ról i tak dla
administrator konta rozliczeniowego to jest
rola, która pozwala zarządzać rozliczeniami
kont, ale ich nie tworzyć, więc jeśli ty
musisz ustawić alerty budżetowe lub zarządzać
metody płatności możesz użyć tej roli
na co pozwala twórca konta rozliczeniowego
stworzyć nowe samoobsługowe rozliczenia online
konta, na które zezwala użytkownik konta rozliczeniowego
do łączenia projektów z kontami rozliczeniowymi
pozwala na to przeglądarka kont rozliczeniowych
wyświetlić informacje o kosztach konta rozliczeniowego
i transakcji, a wreszcie projektu
Menedżer rozliczeń umożliwia połączenie lub
odłączyć projekt od rozliczenia
konto, aby móc zobaczyć te role
pozwalają uzyskać dość ziarnisty, kiedy to
przychodzi do rozliczeń, więc zamierzam wrócić
przejdź do menu po lewej stronie na stronie iam
i kliknij tam i chcę być w stanie
sprawdzić moją konkretną rolę i jaką
uprawnienia, które posiadam lub będę potrzebować
w celu utworzenia nowego konta rozliczeniowego
więc jeśli kliknę na ten ołówek, to się pojawi
pokaż dokładnie
jaka jest moja rola i co robi i jak
tu jest napisane, że mam pełny dostęp do wszystkich
zasobów, co oznacza, że ​​jestem ładna
dużo dobrego, więc zamierzam anulować
tu
i zamierzam wyjść Jestem administratorem
więc klikam w nawigację
menu
i przejdź do rozliczeń
więc to konto rozliczeniowe jest powiązane
bieżący projekt i ponieważ jest to
jedyne konto rozliczeniowe to to
pojawia się, więc to, co chcę zrobić, to ja
chcesz dowiedzieć się trochę więcej
informacje dotyczące tego rozliczenia
konto, więc zamierzam przejść w dół
menu i kliknij zarządzanie kontem
tutaj widzę konto rozliczeniowe, które
to moje konto rozliczeniowe, jeśli mogę zmienić jego nazwę
chciałbym
i widzę też projekty, które są
połączone z tym kontem rozliczeniowym, więc teraz
że przejrzeliśmy wszystkie informacje
w odniesieniu do mojego konta rozliczeniowego
zamierzam po prostu kliknąć to menu
tutaj
i kliknij strzałkę i przejdź do zarządzania
konta rozliczeniowe i tutaj przyniesie
mnie do wszystkich moich kont rozliczeniowych i
ponieważ mam tylko jeden jest pokazany tutaj mój
konto rozliczeniowe, ale gdybym miał więcej niż
taki, który pojawiliby się tutaj i tak teraz
abym mógł stworzyć to nowe
konto rozliczeniowe mam zamiar po prostu
kliknij utwórz konto
i zostanę poproszony o nazwę a
kraj i waluta dla mojego nowego
konto rozliczeniowe i faktycznie jadę
zmienić nazwę tego konta rozliczeniowego i jestem
zamierzam zmienić jego nazwę na gcloud
as
rozliczenie kreskowe
zamierzam opuścić mój kraj jako Kanadę
a moja waluta w dolarach kanadyjskich i
po prostu wcisnę Kontynuuj
i daje mi wybór w moim
profil płatności
i ponieważ chcę użyć tego samego
profil płatności, który właśnie zamierzam otworzyć
po prostu zostaw wszystko tak, jak jest, ale dla
celach demonstracyjnych
tutaj możesz kliknąć płatności
profil
i mała strzałka tuż obok
obecny profil da mi taką możliwość
aby utworzyć nowy profil płatności
i zostawimy to tak jak jest
w informacji o kliencie mam możliwość
zmieniam adres i mogę kliknąć
tę ikonę ołówka i również ją zmień
możesz przejść do metod płatności i kliknąć
obecną metodę płatności z tym
mała strzałka
i dodaj nową kartę kredytową lub debetową oraz
jak powiedziałem wcześniej, będziemy trzymać
rzeczy takimi, jakimi są i po prostu uderzają
przesłać i włączyć rozliczenia
teraz, jak widać tutaj, dostałem monit
mówiąc, że e-mail z potwierdzeniem będzie
wysłane w ciągu 48 godzin teraz zwykle kiedy
konfigurujesz zupełnie nowe rozliczenia
profil z już utworzonymi płatnościami
profil, na pewno dostaniesz
wiadomość e-mail z potwierdzeniem w ciągu mniej niż 48 godzin
teraz, abym mógł to dokończyć
demo, poczekam do nowego
pojawi się konto rozliczeniowe i będzie kontynuować
z wersją demonstracyjną od tego czasu i oto jestem
z powrotem w konsoli rozliczeniowej i tylko to
zajęło około 20 minut, a gcloud ace
pojawiło się konto rozliczeniowe i tak dalej
część tego demo, co chciałem pokazać
jest jak możesz wziąć projekt i dołączyć
na inne konto rozliczeniowe i tak dalej
obecnie mój jedyny projekt jest dołączony do
moje konto rozliczeniowe, więc teraz, jeśli i
chciałem zmienić mój pierwszy projekt na mój
konto rozliczeniowe gcloud ace dash
mogę po prostu przejść tutaj do działań
kliknij menu hamburgerów
i przejdź do zmiany rozliczeń
tutaj zostanę poproszony o wybranie
konto rozliczeniowe i mogę wybrać chmurę g
rozliczenie skrytki
a następnie kliknij na ustaw konto
i oto jest mój pierwszy projekt
połączone z g cloud rozliczeniem skrytki, więc jeśli
wracam do moich kont rozliczeniowych
widać tutaj, że moje konto rozliczeniowe
obecnie ma zero projektów i chmurę g
rozliczenie skrytki ma teraz tylko jeden projekt
jako szybka notatka i naprawdę chcę
podkreślić to
jest to, że jeśli zmieniasz rozliczenia
rozliczyć projekt
i jesteś zwykłym użytkownikiem
będziesz potrzebować roli rozliczeń
administrator konta
a także rolę właściciela projektu
więc te dwa razem pozwolą a
zwykłego użytkownika do zmiany konta rozliczeniowego
dla projektu
więc teraz to, co chcę zrobić, to chcę
wziąć gcloud za skrytkę rozliczeniową i
chcesz zamknąć to konto
ale zanim to zrobię, muszę się rozłączyć
ten projekt i przynieś go z powrotem
inne konto rozliczeniowe, które w tym
przypadek byłby moim kontem rozliczeniowym, więc jestem
zamierzam wrócić tutaj do menu
kliknij na moje projekty i idziemy
zrobić dokładnie to samo, co my
zanim
pod działaniami zamierzam kliknąć na
menu hamburgerów i zmień rozliczenia
ponownie otrzymam monit i
pod kontem rozliczeniowym, do którego zamierzam
wybierz moje konto rozliczeniowe, a następnie kliknij
na ustalonym koncie
więc jak widać projekt został
przeniesiony na inne konto rozliczeniowe
wracam do moich kont rozliczeniowych
i jak widać tutaj projekt jest
z powrotem na moje konto rozliczeniowe i tak teraz
że projekt jest odłączony od
gcloud konto rozliczeniowe, które mogę teraz
Śmiało i zamknij to konto teraz
w tym celu klikam
na gcloud zamierzam rozliczyć skrytkę
zejść tutaj w menu strony wszystkie
droga na sam dół do zarządzania kontem
kliknij tam i na górze tutaj ty
zobaczę zamknięcie konta rozliczeniowego, do którego idę
po prostu kliknij na to, a dostanę
podpowiedź, że wydałem zero dolarów i
jest powiązany z zerowymi projektami
teraz, gdybym miał projekt, który byłby
połączone z tym kontem rozliczeniowym
muszę odłączyć projekt, zanim to zrobiłem
w stanie zamknąć to konto rozliczeniowe, tak aby
a failsafe Jestem proszony o wpisanie blisko
w celu zamknięcia tego konta rozliczeniowego
więc pójdę dalej i zrobię to teraz
i kliknij tylko zamknij konto rozliczeniowe
jako uwaga google daje mi taką opcję
otwórz ponownie to konto rozliczeniowe w przypadku i
Zrobiłem to przez pomyłkę i naprawdę potrzebowałem
To
mogę ponownie otworzyć to konto rozliczeniowe, więc teraz
zobaczysz, jak wrócisz do rozliczeń
Tutaj
że zostaję z moim pojedynczym rachunkiem
konto o nazwie moje konto rozliczeniowe
jeden projekt, który jest z nim połączony i
więc to obejmuje moje demo na temat tworzenia
edycja i zamknięcie nowego rozliczenia
konta, jak również łączenie i rozłączanie
projekt do iz innego
konto rozliczeniowe, więc mam nadzieję, że to znalazłeś
użyteczne
i możesz teraz oznaczyć tę lekcję jako
zakończyć i przejść do następnego
jeden
[Muzyka]
Witamy spowrotem
w tej lekcji zamierzam iść
nad kontrolowaniem kosztów w chmurze Google
wraz z alertami budżetowymi
Dotknę wszystkich dostępnych
dyskontuje liczbę sposobów kontroli
koszty
i przejrzyj alerty dotyczące budżetu, aby uzyskać więcej
podejście granularne i programowe tzw
zaczynając, chciałem dotknąć
zadeklarowane rabaty za użytkowanie są teraz zatwierdzone
korzystaj ze zniżek zapewniaj obniżone ceny
w zamian za zobowiązanie do korzystania z
minimalny poziom środków na a
określony termin rabaty są
elastyczne pokrycie szerokiego zakresu zasobów
i są idealne do obciążeń roboczych
przewidywalne potrzeby w zakresie zasobów, gdy ty
kup zobowiązanie do korzystania z Google Cloud
rabaty, które zobowiązujesz się do stałego
zużycie przez rok lub trzy lata
okresie istnieją dwa rodzaje zobowiązań
dostępny
i jak widać tutaj są wydawane
zaangażowanie oparte i oparte na zasobach
typy
iw przeciwieństwie do większości innych dostawców
opłata za zaangażowanie jest rozliczana co miesiąc tzw
omawiając poszczególne rodzaje zobowiązań
chciałem zacząć od wydatków opartych na wydatkach
zobowiązanie teraz na podstawie wydatków
zobowiązanie, które zobowiązujesz się do konsekwentnego
ilość zużycia mierzona w dolarach na
godzina
równowartości wydatków na żądanie za jeden
lub trzyletnia kadencja w zamian za ciebie
otrzymać zniżkę na
odpowiednie wykorzystanie, które obejmuje Twoje zobowiązanie
więc możesz kupić zobowiązanie do użycia
rabaty z dowolnego konta rozliczeniowego w chmurze
a zniżka dotyczy wszystkich kwalifikujących się
wykorzystania w projektach opłacanych przez tę chmurę
konto rozliczeniowe jest obciążane wszelkimi nadwyżkami
według stawki na żądanie opartej na wydatkach
zobowiązania mogą dać ci 25 rabatów
zniżki na ceny na żądanie przez jeden rok
zobowiązanie i do 52 zniżki
cen na żądanie przez trzy lata
zobowiązanie, teraz zobowiązania oparte na wydatkach
są ograniczone do określonych zasobów
czyli instancje bazy danych cloud sql
i silnik Google Cloud vmware
i to zaangażowanie
dotyczy użycia procesora i pamięci dla
te dostępne zasoby teraz inne
zniżka za świadome użytkowanie wynosi
zaangażowanie oparte na zasobach
więc ta zniżka dotyczy zobowiązania
wydać minimalną kwotę na obliczenia
zasobów silnika w określonym regionie
zobowiązania oparte na zasobach są idealne
przewidywalne obciążenia pracą
Twoje vms
przy zakupie zobowiązania
w ramach umowy kupujesz zasoby obliczeniowe
jak vcpus
pamięć
GPU
i lokalne dyski ssd, które kupujesz pod adresem
w zamian obniżona cena
zobowiązując się do płacenia za te zasoby
przez rok lub trzy lata zniżka jest
do 57 procent dla większości zasobów, takich jak
typy maszyn lub procesory graficzne, rabat jest wyższy
do 70 procent w celu zoptymalizowania pamięci
typy maszyn i możesz kupić
umowa o zobowiązanie do korzystania z jednego
projektuj lub kupuj wiele kontraktów
które możesz udostępniać w wielu projektach
poprzez umożliwienie wspólnych rabatów i udostępnianie
rabaty za zaplanowane użytkowanie we wszystkich
Twoje projekty zmniejszają koszty ogólne
zarządzanie rabatami na projekt
podstawa
i maksymalizuje oszczędności poprzez łączenie
wszystkie Twoje rabaty w całym
wykorzystanie zasobów projektu, jeśli masz
wiele projektów, które dzielą to samo
konto rozliczeniowe w chmurze, które możesz włączyć
zobowiązała się do dzielenia się zniżkami, więc wszyscy
Twoje projekty w ramach rozliczeń w chmurze
konto udostępnia całe twoje zobowiązanie do użycia
umowy ze zniżkami, a więc Twoje trwałe
zniżki na korzystanie są również łączone w
jednocześnie tak dotykając trwałego użytkowania
zniżki
są to automatyczne rabaty dla
uruchamianie określonego silnika obliczeniowego
zasobów znaczną część
miesiąc rozliczeniowy
obowiązują zniżki za ciągłe użytkowanie
ogólny cel
maszyna do optymalizacji obliczeń i pamięci
typy, a także jedyne węzły dzierżawy i
gpus znowu są zniżki na przedłużone użytkowanie
stosowane automatycznie do użycia w ciągu a
projekt oddzielnie dla każdego regionu tzw
nie jest wymagane żadne działanie z Twojej strony
aby włączyć te rabaty, więc np
kiedy prowadzisz jeden z nich
środków na więcej niż powiedzmy 25
procent miesiąca
Compute Engine automatycznie daje
rabat za każdą kolejną minutę
którego teraz używasz w tej instancji
automatycznie rabaty za przedłużone użytkowanie
stosuje się do maszyn wirtualnych utworzonych zarówno przez google
silnik kubernetes i silnik obliczeniowy, ale
niestety nie dotyczą vms
stworzony przy użyciu elastycznego silnika aplikacji
środowisko oraz przepływ danych i e2
typy maszyn
teraz, aby skorzystać z pełni
zniżka, którą stworzyłbyś swoją maszynę wirtualną
przypadków pierwszego dnia miesiąca
ponieważ rabaty resetują się na początku
każdego miesiąca i tak poniższa tabela
pokazuje zniżkę, którą otrzymujesz przy każdym użyciu
poziom instancji vm te rabaty
stosuje się do wszystkich typów maszyn, ale nie
stosuje się do przypadków z możliwością wywłaszczenia i tak dalej
zniżki za przedłużone użytkowanie mogą zaoszczędzić
do maksymalnie 30 procent zniżki tzw
kolejny świetny sposób na obliczenie oszczędności
w Google Cloud jest przy użyciu gcp
kalkulator cen to szybki sposób
aby uzyskać oszacowanie zużycia
będzie kosztować w chmurze Google, więc gcp
kalkulator cen może pomóc w identyfikacji
ceny zasobów, które ty
planujesz użyć w swojej przyszłej architekturze
abyś mógł obliczyć jak
ile będzie cię kosztować twoja architektura
ten kalkulator zawiera ceny dla
prawie wszystkie zasoby zamknięte w środku
gcp, więc możesz uzyskać całkiem niezłe
wyobrażenie o tym, ile będzie kosztować twoja architektura
bez konieczności odkrywania trudnego
sposób ten kalkulator można znaleźć na stronie
url pokazany tutaj i dołączę to
w poniższym tekście lekcji teraz w ruchu
aż do budżetów rozliczeniowych w chmurze
budżety umożliwiają śledzenie rzeczywistych
wydawać
w stosunku do Twojego planu wydatków
po ustaleniu ustalonej kwoty budżetu
reguły progu alertu budżetowego, które są
używane do wyzwalania powiadomień e-mail i
e-maile z alertami budżetowymi pomogą Ci zostać
poinformowany o tym, jak wyglądają twoje wydatki
śledzenie tego w stosunku do budżetu
przykład tutaj jest diagramem budżetu
powiadomienie o alercie i jest ustawieniem domyślnym
funkcjonalność dla każdego alertu budżetowego
powiadomienia
teraz trochę bardziej szczegółowo
możesz określić zakres budżetu
więc na przykład możesz określić zakres budżetu
zastosować do wydatków całej chmury
konto rozliczeniowe lub uzyskać bardziej szczegółowe informacje
jeden lub więcej projektów
a nawet do konkretnego produktu
może ustawić kwotę budżetu na sumę
które określasz
lub oprzyj kwotę budżetu na
wydatków z poprzedniego miesiąca, gdy koszty przekraczają
procent twojego budżetu na podstawie
reguły, które ustawiłeś jako domyślny alert
e-maile są wysyłane na konto rozliczeniowe
administratorzy i użytkownicy kont rozliczeniowych
na docelowym koncie rozliczeniowym w chmurze i
znowu jest to domyślne zachowanie a
powiadomienie e-mail o budżecie
teraz, jak powiedziano przed zachowaniem domyślnym
budżetu jest wysyłanie e-maili z alertami na adres
administratorzy kont rozliczeniowych i
użytkowników konta rozliczeniowego w miejscu docelowym
konto rozliczeniowe w chmurze, gdy budżet
reguły progu alertu wyzwalają wiadomość e-mail
powiadomienie teraz tych odbiorców wiadomości e-mail
można dostosować za pomocą chmury
monitorowanie w celu określenia innych osób
swojej organizacji, aby je otrzymać
e-maile z alertami budżetowymi są doskonałym przykładem
byłby to kierownik projektu lub
dyrektor, wiedząc, ile wydano
wykorzystany w twoim budżecie i ostatni
koncepcja, którą chciałem dotknąć, kiedy to
chodzi o budżety rozliczeniowe w chmurze
możesz także użyć pub sub dla
automatyczne powiadomienia programistyczne
Twoja odpowiedź na kontrolę kosztów na podstawie
zawiadomienie o budżecie
możesz także użyć pub sub w połączeniu
z budżetami rozliczeniowymi w celu automatyzacji kosztów
zadań związanych z zarządzaniem, a to zapewni
status rozliczeń w chmurze w czasie rzeczywistym
budżet i pozwalają robić takie rzeczy jak
wysyłaj powiadomienia do Slack lub wyłącz
rozliczeń, aby zatrzymać korzystanie, jak również
selektywnie kontroluj użycie, gdy budżet
został spełniony, więc to wszystko
pojęcia, które chciałem omówić, kiedy to
przyszedł do budżetów rozliczeniowych w chmurze, teraz wiem
ta lekcja mogła być trochę sucha i
nie jest to najbardziej ekscytująca usługa do nurkowania
ale bardzo ważne jest, aby wiedzieć
oba na egzamin
i za twoją rolę jako inżyniera, kiedy to
chodzi o cięcie kosztów w środowiskach
tam, gdzie uznają to właściciele Twojej firmy
konieczne i to wszystko, co miałem
ta lekcja
więc możesz teraz oznaczyć tę lekcję jako
ukończ i dołącz do mnie w następnym
taki, w którym zanurzam się w konsoli i robię
kilka praktycznych demonstracji, jeśli chodzi o
rabaty za zobowiązane użytkowanie
alerty budżetowe i edycja alertów budżetowych
a także dodać trochę
automatyzacji w alertach budżetowania
[Muzyka]
Witam ponownie na ostatniej lekcji, na której byłem
nad kilkoma sposobami zarządzania kosztami
i zachowanie alertów budżetowych
w tej lekcji będę robić demo
pokazać rabaty za zobowiązane użytkowanie i
rezerwacje wraz ze sposobem ich tworzenia
alerty budżetowe
a także jak je edytować
to powiedziawszy, zanurzmy się, więc teraz jestem
zaczniemy od zaangażowanego użytkowania
zniżki, aby się tam dostać, jestem
zamierzam go znaleźć w silniku obliczeniowym, więc
zamierzam po prostu wejść tutaj na
lewy górny róg z powrotem do
Menu nawigacji
zejdę na dół do silnika obliczeniowego
i zamierzam się tu przejść
rabaty za zobowiązane użytkowanie
i jak omówiliśmy wcześniej te
zobowiązania dotyczące silnika obliczeniowego są
oparte na zasobach i jak widać tutaj
mamy zobowiązania sprzętowe i
rezerwacje teraz rezerwacje, które dostanę
w trochę później, ale z
jeśli chodzi o zobowiązania sprzętowe, jesteśmy
zaraz się tym zajmę i jak
oczekiwany nie mam żadnych bieżących zobowiązań
więc jadę na zakupy
zaangażowanie, więc muszę zacząć
z
znalezienie nazwy dla tego zobowiązania i
więc nazwę to zobowiązanie
zaangażowanie w demonstrację kreski
zapyta mnie o region, w którym jestem
zamiar zachować to w nas centralnej jeden z
rodzaj zobowiązania tutaj jest tam, gdzie mogę
wybierz typ maszyny, którą jestem
szukam, więc mogę przejść do ogólnego
cel oraz 1 i 2
i 2d e2 oraz optymalizacja pamięci
i zoptymalizowany pod kątem obliczeń, więc idę
aby zachować go w celu ogólnym i jeden
ponownie na okres jednego lub trzech lat
i przechodzimy do rdzeni, które mogę mieć jako
wiele vcpus, jak bym chciał
więc gdybym potrzebował 10, mogę to zrobić i zrobię to
wyskakujące okienko tutaj po prawej stronie
mi również szacunkową sumę miesięczną
jako stawka godzinowa dla tego konkretnego vm
z 10 rdzeniami mogę również wybrać
przez trzy lata i zgodnie z oczekiwaniami
Dostanę większe oszczędności, ponieważ jestem
dając większe zaangażowanie, więc przynieś to
cofnijmy się do jednego roku i postawmy
pamięć do 64 gigabajtów tutaj mogę dodać
gpus i mam całkiem sporo do wyboru
z lokalnych dysków ssd i tutaj z
lokalne ssds mogę wybrać tyle
dysków tak, jak chcę, o ile jest w środku
mój przydział i każdy rozmiar dysku będzie
być 375 gigabajtów, więc jeśli szukasz
do zniżek i użytkowania zadeklarowanego
lokalne ssds, proszę o tym pamiętać
ponownie rezerwację można dodać tutaj
i zajmę się tym za chwilę
po drugie, a teraz właściwie nie chcę
kupić, ale chciałem ci pokazać
dokładnie, co za zobowiązanie rabat za użytkowanie
wyglądałby i jak byś się zastosował
to znowu tutaj po prawej stronie to
pokazuje mi szczegóły oszacowania
suma miesięczna i stawka godzinowa, więc jestem
Podejdź tutaj i naciśnij anuluj
i gdybym miał to zastosować
zobowiązanie pojawi się tutaj w
tę tabelę i daj mi wszystkie określone
konfiguracje
tej instancji tutaj, teraz dotykającej
na rezerwacjach
bookings jest wtedy, gdy rezerwujesz vm
potrzebne instancje
więc kiedy rezerwacja została złożona
rezerwacja zapewnia, że ​​te
zasoby są zawsze dostępne dla Ciebie
jak niektórzy z was mogą wiedzieć, kiedy idziesz do
uruchom nową maszynę wirtualną silnika obliczeniowego
zwłaszcza jeśli chodzi o automatyczne skalowanie
grup instancji, które mogą wystąpić
czasami być opóźnione lub niedostępne teraz
rzeczą z zastrzeżeniami jest to, że vm
instancja może korzystać z rezerwacji tylko wtedy, gdy
jego właściwości dokładnie odpowiadają
właściwości rezerwacji, która jest
dlaczego to takie świetne połączenie
rabaty za zobowiązane użytkowanie
więc jeśli chcesz zrobić
zaangażowanie oparte na zasobach i zawsze
chcesz, aby Twoja instancja była dostępna, możesz
po prostu utwórz rezerwację, do której ją dołącz
zobowiązanie, którego nigdy nie będziesz miał
martwić się o zasoby
zaspokoić swoje obciążenie pracą tak, jak chcą
zawsze tam być, więc znowu wchodzę
utwórz rezerwację, pokaże mi się tutaj
nazwa opis mogę wybrać
skorzystać z rezerwacji automatycznie lub
wybierz konkretną rezerwację regionu
i strefa
liczba instancji i tutaj mogę
określ typ maszyny lub określ
szablon instancji i znowu to jest
inny przypadek użycia, jeśli potrzebujesz
instancje silnika obliczeniowego uruchomiły się z powodu
automatyczne skalowanie to miejsce, w którym dokonuje się rezerwacji
miałby zastosowanie, więc wracając do maszyny
typ, który mogę wybrać z vcpus
a także pamięć, którą mogę dostosować
mogę dodać tyle lokalnych dysków ssd, ile mam
przydziały pozwolą mi i mogę wybrać mój
typ interfejsu i zamierzam anulować
wynoś się stąd teraz, jeśli o to chodzi
zadeklarowane rabaty i rezerwacje
jeśli chodzi o egzamin
nie widziałem tego, ale ponieważ jest to
możliwość zaoszczędzenia pieniędzy, które chciałem zarobić
Jestem pewien, że uwzględniłem to w tej lekcji
ponieważ może to być świetna opcja do użycia
w twoim środowisku, więc teraz my
objęte zobowiązaniem użytkowanie oparte na zasobach
rabaty, które chciałem przenieść do wydatków
opartych na zobowiązaniach i tak gdzie byś chciał
okaże się, że skończyłoby się to na rozliczeniach
więc znowu idę do
menu nawigacyjne w lewym górnym rogu
róg i przejdź do rozliczeń
teraz myślisz, że go znajdziesz
tutaj w ramach zobowiązań, ale tylko wtedy, gdy ty
kupili zobowiązanie będzie to
właściwie się tu pojawiam ale jak widać
tutaj zachęca nas do pójścia do
strona przeglądu rozliczeń
więc wracając do strony przeglądu
znajdziesz to
tutaj, po prawej stronie, więc teraz mogę
zakup zobowiązania i jak my
omówione wcześniej
można wykorzystać zobowiązanie oparte na wydatkach
albo cloud sql, albo dla silnika vmware
wybieram moje konto rozliczeniowe
zobowiązanie określa również okres
rok lub trzy lata i to też
pokazuje mi zniżkę, która może pomóc
wpłynąć na moją decyzję, jak również na region
jak również godzinowe na żądanie
zaangażowanie, teraz pewnie się zastanawiasz
co to jest
i jak wyjaśniono tutaj, to zobowiązanie jest
w oparciu o cenę na żądanie
a kiedy to wszystko zostanie wypełnione,
podsumowanie zobowiązań zostanie wypełnione i
po zaakceptowaniu wszystkich warunków i
usługi, które możesz po prostu nacisnąć przycisk zakupu
ale zamierzam się stąd wycofać
i to jest przegląd wydatków
zobowiązanie oparte i znowu te
rabaty za zobowiązane użytkowanie, których nie widziałem
na egzaminie
ale myślę, że dobrze wiedzieć
dla Twojego codziennego środowiska, jeśli
szukasz, aby zaoszczędzić pieniądze i naprawdę
rozbić koszty
więc teraz, gdy omówiłem zaangażowane użycie
zniżki i rezerwacje
chciałem przejść do budżetów i
alerty dotyczące budżetu i dlatego, że już jestem włączony
na stronie rozliczeniowej wszystko, co muszę zrobić, to przejść
tutaj do menu po lewej stronie i
kliknij ustawienia budżetów i alertów teraz
ustalić budżet dla siebie na ten kurs
byłby świetnym pomysłem zwłaszcza dla
tych, którzy są świadomi kosztów, ile
wydajesz na swoje
korzystanie z chmury, więc mamy iść naprzód i
utwórz teraz nowy budżet, więc zróbmy to
idź tutaj na górę, aby utworzyć budżet
i zostanę przeniesiony do nowego
okno, w którym mogę umieścić nazwę
budżet i zamierzam to nazwać
as
budżet kreskowy i dlatego, że chcę
monitorować wszystkie projekty i wszystkie produkty
Zostawię to tak, jak jest, ale jeśli ty
miał wiele projektów, które możesz zdobyć
trochę bardziej ziarnisty i to samo
rzecz z produktami
więc pójdę dalej i zostawię to tak
jest i po prostu kliknij dalej teraz pod
rodzaj budżetu
mogę wybrać z określonego
kwotę lub wydatki z ostatniego miesiąca i tak dalej
dla tego demo zamierzam go zatrzymać
określona kwota
i dlatego, że chcę być naprawdę
Świadomość tego, ile na to wydaję
oczywiście dam 10
za moją kwotę docelową zamierzam
uwzględnij kredyty i koszt, a następnie
mam zamiar kliknąć na następny teraz te
reguły progowe są tam, gdzie rozliczenia
administratorzy otrzymają wiadomość e-mail, gdy a
trafiony zostanie określony procent budżetu
więc jeśli moje wydatki przekroczą pięć
dolarów
ponieważ jestem administratorem ds. rozliczeń, tj
zostanie wysłany e-mail z informacją, że my
wydatki osiągnęły pięć dolarów, które też mam
możliwość zmiany tych wartości procentowych
więc gdybym zdecydował się zmienić na czterdzieści
procent
teraz moja kwota idzie do czterech dolarów i
odbywa się to automatycznie, więc nie ma takiej potrzeby
wykonać jakiekolwiek obliczenia
ale zatrzymam to tutaj na 50
procent
i odwrotnie, gdybym chciał zmienić
kwota
procent budżetu będzie faktycznie
zmień teraz za pomocą wyzwalacza i faktycznie
mieć możliwość wyboru prognozy
lub rzeczywiste, więc zamierzam to kontynuować
rzeczywiste i jeśli chcę, mogę dodać więcej
reguły progowe, teraz wyjeżdżam
wszystko tak jak jest i po prostu kliknij
skończyć
a teraz jak widać tutaj mam
nazwa budżetu asa budżet teraz, ponieważ
nazwa budżetu nie musi być
globalnie unikalny w twoim środowisku ty
możesz nazwać swój budżet dokładnie tak samo
i znowu poda mi wszystkie szczegóły
konfiguracje, które wypełniłem, pokazują
mi, ile kredytów wykorzystałem i to wszystko
i w ten sposób stworzyłbyś plik
alert budżetowy teraz, gdybym musiał go edytować
Zawsze mogę wrócić do budżetu asa i
tutaj mogę to edytować, ale nie zamierzam
dotknij go, a ja po prostu uderzę
anulować
i tak ostatnia rzecz, którą chciałem pokazać
zanim zakończymy tę lekcję, jest jak to zrobić
stworzyć inny budżet, ale być w stanie
wyślij e-maile z alertami wyzwalającymi do
różnych użytkowników
więc w tym celu zamierzam to zrobić
wróć tutaj, aby utworzyć budżet
zamierzam nazwać to Ace Dash
budżet
kropla
użytkowników, resztę zostawię bez zmian
mam zamiar kliknąć na następny ponownie jestem
zamierzam zostawić typ budżetu
jest to kwota docelowa, którą zamierzam umieścić
dziesięć dolarów
zostaw uwzględnienie kredytów i kosztów oraz
po prostu kliknij dalej
i tak tutaj zamierzam zostawić
progi rządzą tak, jak są i
tutaj, pod zarządzaniem powiadomieniami
wyłączę monitorowanie linków
do tego kanały powiadomień e-mail
budżet teraz, ponieważ e-mail
kanał powiadomień potrzebuje chmury
monitorowanie w celu pracy jestem
pojawi się monit o wybranie obszaru roboczego
co jest potrzebne do monitorowania chmury tzw
bo nie mam idę
naprzód i utwórz jeden, a następnie kliknij
zarządzanie obszarami roboczymi monitorowania
doprowadzić cię do dokumentacji, ale w
zamów mi utworzenie obszaru roboczego
muszę teraz przejść do monitorowania chmury
workspace to kontener najwyższego poziomu
który służy do organizowania i kontrolowania
dostęp do Twojego powiadomienia monitorującego
kanały w celu otrzymania powiadomienia
kanały do ​​pracy muszą należeć do a
monitorowanie obszaru roboczego, więc musisz
utwórz wcześniej co najmniej jeden obszar roboczy
dodanie monitoringu
kanały powiadomień i nie martw się
będziemy wchodzić w większą głębię
w odniesieniu do monitorowania w dalszej części
w tym kursie, więc zamierzam iść naprzód
i anuluj to
i zamierzam przejść do nawigacji
menu
kliknij tam
i przewiń w dół do monitorowania
a następnie przegląd i może to zająć
minutę na uruchomienie
ponieważ interfejsy API są włączane, a plik
domyślny obszar roboczy do monitorowania chmury
jest budowany
w porządku, a teraz, gdy interfejs API monitorowania ma
została włączona, jesteśmy teraz w trakcie monitorowania
utworzony obszar roboczy to my
pierwszy projekt, więc teraz, kiedy mamy nasz
utworzony obszar roboczy monitorowania, którego potrzebuję
dodaj e-maile do użytkowników, których chcę
alerty do wysłania i dodane
do kanału powiadomień tak po kolei
aby to zrobić, pójdę tutaj
ostrzegam i jestem tutaj na szczycie
zamierza kliknąć edytuj powiadomienie
kanały
a tutaj, jak widać, jest ich wiele
kanały powiadomień, które możesz
włączyć, klikając po prostu dodaj nowy
tutaj po prawej, więc teraz kim jestem
szukam jest pod adresem e-mail, do którego zamierzam
kliknij dodaj nowy teraz tutaj mogę dodać
nowy adres e-mail i tak dla mnie jestem
dodam antoniego
na antonyt.com
i możesz dodać dowolny adres e-mail
polubiłbyś
i pod wyświetlaną nazwą zamierzam dodać
administrator rozliczeń
powiadomienie
i po prostu kliknij Zapisz
i jak widać mój e-mail był
dodane do kanału powiadomień i tak
to wszystko, co musiałem zrobić, aby to zrobić
przejdź do następnego kroku i tak teraz
omówiłem tworzenie mojego monitoringu
obszar roboczy, a także dodanie kolejnego
e-mail do moich kanałów powiadomień e-mail
mogę teraz wrócić do rozliczeń i zakończyć
poza moim alertem budżetowym
przejdźmy tutaj do budżetów i alertów
stworzyć budżet
i przejdziemy przez to samo
kroki
nazwij to rozliczeniem
alarm
użytkownicy
pozostaw wszystko inne tak, jak jest i kliknij
Następny
Po prostu zmienię cel
wynieść 10
kliknij dalej
zostawię tu wszystko tak jak jest
i wracam do klikania
powiadomienie e-mail dotyczące monitorowania łącza
kanałów do tego budżetu teraz, jeśli ty
zauważ, kiedy klikam wybrany obszar roboczy
pojawił się mój pierwszy projekt i oto on
poprosi mnie o moje kanały powiadomień
a ponieważ już to skonfigurowałem, mogę
po prostu kliknij na to, a zobaczysz
kanał powiadomień administratora rozliczeń
więc gdybym nie miał tego skonfigurowanego, ja
zawsze możesz przejść do zarządzania powiadomieniami
kanały i przeniesie mnie z powrotem do
ekran, który widziałeś wcześniej
więc teraz, kiedy to jest skonfigurowane, mogę
po prostu kliknij Zakończ
a więc teraz, gdy mam
regularny alert budżetowy, mam też inny
alert budżetowy, który może przejść do innego
e-mail, więc jeśli masz kierownika projektu
lub reżysera, którego chcesz wysłać
alerty dotyczące budżetu w ten sposób
zrób to i tak mniej więcej obejmuje to demo
na zarezerwowane rabaty za użytkowanie zobowiązaniowe
budżety i alerty budżetowe i tyle
wszystko, co chciałem omówić na tej lekcji
więc możesz teraz oznaczyć tę lekcję jako
kompletny
i przejdźmy do następnego
[Muzyka]
Witamy spowrotem
w tej krótkiej lekcji będę omawiać
eksportu danych rozliczeniowych tzw
że jesteś w stanie przeanalizować te dane
i zrozum swoje wydatki na więcej
poziom granularny
ja też będę przechodzić przez skrót
demo, w którym pokażę ci, jak włączyć
funkcję rozliczeń eksportowych i przynieś ją
do BigQuery do analizy
teraz eksport rozliczeń w chmurze do bigquery
umożliwia eksportowanie szczegółowych plików google
dane rozliczeniowe w chmurze, takie jak wykorzystanie
szczegóły dotyczące kosztów i dane dotyczące cen
automatycznie do zbioru danych BigQuery
które określisz, możesz uzyskać dostęp
Twoje dane rozliczeniowe w chmurze z bigquery
do szczegółowej analizy
lub użyj narzędzia takiego jak studio danych
zwizualizuj swoje dane, tylko krótka notatka
tutaj eksport rozliczeń nie jest
działa wstecz i należy to przyjąć
pod uwagę przy planowaniu
analizy tych danych i tak jest
dwa rodzaje danych rozliczeniowych w chmurze
może eksportować
są dzienne dane dotyczące szczegółowych kosztów
oraz dane cenowe i takie mogą być
wybrany bezpośrednio w konsoli
w zależności od przypadku użycia i tak teraz
że przeszliśmy dokładnie przez co
eksport rozliczeń to chciałem dostać się do
demo i pokaż, jak wyeksportować swój plik
dane rozliczeniowe w chmurze do bigquery i gotowe
przez wszystkie niezbędne kroki, aby uzyskać
to umożliwiło, więc kiedy będziesz gotowy, dołącz do mnie
w konsoli i oto jesteśmy z powrotem
w konsoli i tak, aby włączyć
eksport rozliczeń, do którego zamierzam się udać
na stronie rozliczeniowej, więc przejdę wyżej
w lewy górny róg do
Menu nawigacji
i kliknij rozliczenia
tutaj w menu po lewej stronie zobaczysz
eksport rozliczeń i możesz po prostu kliknąć
Tam
i tak dla tych, którzy dopiero przychodzą do rozliczeń
export po raz pierwszy jest
szybkie podsumowanie tego, co dokładnie
Eksport bigquery jest używany dla i jako my
omówione wcześniej istnieje opcja dla
szczegóły dziennego kosztu i ceny
i zamierzam użyć dziennego kosztu
szczegóły w tym demo i wyeksportuj te dane
do bigquery, więc pierwszy krok idę
do zrobienia
jest kliknięcie na edytuj ustawienia i gotowe
zamierza przenieść mnie do nowej strony, gdzie to
poprosi mnie o mój projekt i to jest to
gdzie będą moje dane rozliczeniowe
przechowywane, ale jak widać tutaj jestem
pojawia się monit, który mówi, że musisz
najpierw utwórz zestaw danych bigquery, a teraz
zestaw danych bigquery, o który prosi is
gdzie będą znajdować się dane rozliczeniowe
przechowywane tak, aby przejść do przodu
mój eksport rozliczeń, do którego muszę przejść
bigquery i skonfigurować zestaw danych, więc jestem
po prostu kliknij ten przycisk
tutaj jest napisane idź do bigquery
i doprowadzi mnie do
strona bigquery, na której zostanie wyświetlony monit
z dużą notatką powitalną możesz po prostu
kliknij gotowe i tutaj po prawej
strona strony, gdzie jest napisane, że utwórz zestaw danych
po prostu tam kliknę i już
zamierzam utworzyć mój nowy zestaw danych i tak dalej
dla mojego identyfikatora zestawu danych, do którego zadzwonię
Ten
dane do faktury
eksport
i tylko jako notatkę z identyfikatorem zestawu danych
nie możesz używać żadnych znaków, takich jak
łączniki przecinki lub kropki i dlatego
piszę wielką literą b i e teraz z
lokalizację danych domyślną lokalizację
jest amerykańskim regionem, ale mogę po prostu
kliknij menu rozwijane i miej
możliwość przechowywania moich danych w innym
Lokalizacja
ale mam zamiar zachować to domyślnie i
mieć możliwość wygaśnięcia tej tabeli
za określoną liczbę dni lub do
nigdy nie wygasa tak dobrze, jeśli chodzi o
szyfrowanie, zostawię to bez zmian
klucz zarządzania google w przeciwieństwie do a
klucz zarządzania klientami, a ja się do niego dostanę
trochę szyfrowanie i zarządzanie kluczami
później w tym kursie mam zamiar iść
przed siebie i zejdź na sam dół
i kliknij utwórz zestaw danych
a teraz mój zestaw danych został utworzony i
można go teraz zobaczyć tutaj po lewej stronie
boczne menu, w którym subtelny poeta 28400
jest identyfikatorem mojego projektu, jeśli po prostu
kliknij strzałkę obok, to się pokaże
mój zestaw danych eksportu rozliczeniowego, ponieważ
nic w nim nie ma nic nie widać
a więc teraz, gdy zestaw danych jest skonfigurowany, tj
możesz teraz wrócić do eksportu rozliczeń
stronę i dokończ konfigurowanie rozliczeń
eksportuj, więc powiedziano mi, że idę
aby wrócić do menu nawigacji
przejdź do rozliczeń
i przejdź do eksportu rozliczeń w obszarze codziennie
szczegóły kosztów, które zamierzam kliknąć edytuj
settings i ponieważ mam zestaw danych
już skonfigurowany i ponieważ jest to jedyny
jeden został rozpropagowany w moim rozliczeniu
wyeksportuj pole zestawu danych, gdybym miał więcej danych
zestawów, wtedy będę mógł je wybrać
tutaj też, więc zostawiam
zestaw danych przy eksporcie rozliczeniowym
i po prostu kliknij Zapisz
i tak teraz, że eksport rozliczeń był
włączone, będę mógł sprawdzić moje
rozliczeń, które są aktualizowane każdego dnia
mówi tutaj i przejść od razu do danych
ustawić, mogę po prostu kliknąć ten gorący link
i przeniesie mnie prosto do bigquery i
więc jest jeszcze jeden ostatni krok
należy wykonać, aby umożliwić rozliczanie
eksport do pracy, a to jest umożliwienie
interfejs API usługi transferu danych bigquery, więc w
aby to zrobić, musimy do niego wrócić
menu nawigacji
przejdź do apis i usług
do deski rozdzielczej
a teraz idę szukać
usługa transferu danych bigquery i jestem
zamierza po prostu wejść tutaj na szczyt
pasek wyszukiwania
i po prostu wpisz bigquery
a tutaj jest transfer danych bigquery
api, po prostu to kliknę
i naciśnij włącz
a to może zająć minutę i możesz
zostać poproszony o utworzenie poświadczeń tutaj
w prawym górnym rogu i możesz po prostu
zignoruj ​​to, ponieważ obecnie nie są
potrzebne, a więc teraz dane bigquery
interfejs API usługi transferu został włączony
mogę teraz przejść do bigquery i
przyjrzyj się moim eksportowanym danym rozliczeniowym
bez żadnych problemów teraz będzie
trochę czasu na propagację, ale do czasu i
przyjdź tu jutro dane będą
w pełni propagowane i będę mógł
zapytaj o dane, które uznam za stosowne i tak dalej
chociaż jest to krótkie demo, to jest
wiedza niezbędna do egzaminu
jak również być inżynierem i szukać
zapytaj o swoje dane rozliczeniowe, które teraz wykonasz
mieć wiedzę, aby podjąć
niezbędne kroki, które pozwolą Ci to zrobić
zrób tak i tak, to wszystko, co mam na ten temat
lekcja i prezentacja na temat eksportu danych rozliczeniowych
więc możesz teraz oznaczyć tę lekcję jako
kompletny
i przejdźmy do następnego
Witamy spowrotem
w tym praktycznym demo mam zamiar iść
przez API w chmurze Google
teraz platforma Google Cloud jest ładna
dużo biegać po apisach
czy to w konsoli, czy w sdk
pod maską teraz uderza w apis
niektórzy z was mogą się zastanawiać, co to jest
interfejs API
cóż, jest to akronim oznaczający
interfejs programowania aplikacji i
to standard używany wśród
społeczność programistów w tym konkretnym
kontekstem jest interfejs programowania
dla usług w chmurze Google
i jak powiedziałem wcześniej, oba sdk w chmurze
a konsola używa apis pod
kaptur i zapewnia podobne
funkcjonalność teraz podczas korzystania z apis
bezpośrednio umożliwia włączenie
automatyzację przepływu pracy za pomocą
biblioteki oprogramowania, których używasz do
ulubiony język programowania teraz jako
widzialam na poprzednich lekcjach
korzystać z interfejsu API w chmurze
musisz go najpierw włączyć, więc jeśli poszedłem do
Compute Engine lub kiedy włączałem
monitorowanie
musiałem włączyć api, więc bez względu na
usługa, o którą prosisz tutaj w google
chmury, a niektóre z nich mogą być parzyste
połączone ze sobą zawsze musi być
włączone, aby użyć go teraz, otrzymując
trochę bardziej ziarnisty podczas używania
api musisz mieć projekt, więc kiedy
włączasz api, dla którego je włączasz
Twój projekt
korzystając z uprawnień do projektu i
uprawnienia do interfejsu API, aby włączyć je teraz
ponieważ jest to demo, chcę przejść
do menu nawigacyjnego i jedź prosto
w API i usługi
a oto pulpit nawigacyjny apis
i usług możesz zobaczyć ruch
tutaj błędy i opóźnienie z
w odniesieniu do tych apis również tutaj
ma ramy czasowe dla mediany latencji
które możesz wybrać dla bardziej szczegółowego
szukaj teraz, jeśli chodzi o to, co jest
włączone, możesz zobaczyć listę tutaj
apis, które są włączone i ponieważ my
nie zrobiłem wiele, jest tylko kilka
apis, które są teraz włączone w ten praktyczny sposób
demo nie ma na celu zagłębienia się w
apis, ale jest to tylko przegląd
rozumiesz, do czego używane są api
for w kontekście chmury Google if
chcesz zagłębić się w temat
pozdrowienia dla apis i ewentualnie get
poświadczone w nim świadectwo apogeum
z odpowiednimi lekcjami byłoby
świetny sposób, aby uzyskać trochę więcej
zrozumienie, ale dla tego demo jesteśmy
zamierzam trzymać się tego przeglądu i tak dalej
aby wyszukać więcej apis
muszą być włączone lub jeśli szukasz
na coś konkretnego
możesz przyjść tutaj, aby włączyć apis i
usługi
lub możesz przeprowadzić szybkie wyszukiwanie na stronie
pasek wyszukiwania u góry strony, ale
tak jak szybkie spojrzenie mam zamiar iść
aby włączyć apis i usługi, a więc ty
zostanie przeniesiony na nową stronę, na której
zobaczysz bibliotekę api po lewej stronie
zobaczy menu, w którym znajdują się api
skategoryzowane i wszystkie apis, które są
dostępne, jeśli chodzi o chmurę Google
i inne usługi Google, tak jak widziałeś
wcześniej, kiedy potrzebowałem włączyć api
dla bigquery
po prostu wpisałbym bigquery
i mogę przejść do api i od
api jest włączony, nie mam nic do tego
zrobić, ale gdybym musiał to włączyć, mógłbym
zrób to od razu i równie szybko
uwaga, kiedy idziesz do serwisu, który jest
dostępne w konsoli api
automatycznie włącza się, gdy idziesz
i użyć go po raz pierwszy i tak dalej
znowu jest to tylko krótki przegląd
apis i biblioteka api w odniesieniu do
google cloud krótkie, ale ważne demo
aby zrozumieć pod spodem działania
Cloud sdk i konsola tak po prostu
pamiętaj, że korzystając z jakiejkolwiek usługi w
chmura google
ponownie musisz włączyć interfejs API w kolejności
zacząć z niego korzystać i tyle
podsumowuje to demo dla Cloud API, więc ty
może teraz oznaczyć tę lekcję jako ukończoną i
przejdźmy do następnego
[Muzyka]
Witamy spowrotem
w tym demo będę tworzyć i
konfigurowanie nowego użytkownika Gmaila jako administratora
użytkownika do wykorzystania w tym kursie
a także podążanie za najlepszymi wynikami Google
praktyki potrzebujemy użytkownika, który ma mniej
uprawnienia niż konto użytkownika, które my
ustaw się wcześniej i jadę
przez pełne demo, aby pokazać, jak to zrobić
skonfiguruj to
teraz w konfiguracji Google Cloud, która używa a
konto G Suite lub Cloud Identity a
tworzone jest konto superadministratora
do administrowania domeną to super
konto administratora jest nieodwołalne
uprawnienia administracyjne
które nie powinny być używane na co dzień
administracji oznacza to, że nie
uprawnienia mogą zostać mu odebrane
konto i ma uprawnienia do udzielania
rola administratora organizacji
lub jakąkolwiek inną rolę w tej sprawie i
odzyskać konta na poziomie domeny
co czyni to konto niezwykle
potężny teraz, ponieważ nie mam
konfiguracja domeny lub korzystanie z pakietu ag lub chmury
konto tożsamości, nie muszę się martwić
o koncie superadministratora w tym
określone środowisko, takie jak konta Gmail
to samodzielne konta, które są przeznaczone
być osobistym i nie mieć organizacji
i zwykle rozpoczynają się na poziomie projektu
a więc aby wyjaśnić to nieco szerzej
Szczegół
mam tutaj diagram pokazujący te dwa
różnych kont, z których będę korzystać
i struktura za nim
teraz, jak omówiliśmy przed rozliczeniem
konta mają opcję zapłaty
projekty w innej organizacji tzw
podczas tworzenia nowych projektów przy użyciu tych dwóch
były różne konta Gmail
stworzony bez jakiejkolwiek organizacji i tak dalej
każde konto jest niezależne i może
tworzyć własne projekty teraz co sprawia
różnią się tym, że antony gcloud
konto ace jest właścicielem konta rozliczeniowego i
jest ustawione jako konto rozliczeniowe
administrator i as Tony'ego w muszce
account to użytkownik konta rozliczeniowego, który
jest w stanie powiązać projekty z tym rozliczeniem
konto, ale nie ma do niego pełnego dostępu
dane do faktury
więc w duchu trzymania się
zasada przywileju najmu
będę używał Tony Bowtie Ace
konto, które założyłem wcześniej
mniejsze uprawnienia w zakresie rozliczeń
nadal udzielaj mi wszystkich uprawnień, których potrzebuję
do tworzenia zasobów edycji i usuwania
bez wszystkich potężnych uprawnień
potrzebne do fakturowania, które przydzielę
temu nowemu użytkownikowi Gmaila konto rozliczeniowe
rolę użytkownika i pozwoli ci to zrobić
osiągnąć wszystko, czego potrzebujesz do budowania
pozostała część kursu
więc jako recenzję będę używać
nowe konto Google, które utworzyłem
lub jeśli chcesz, możesz użyć a
istniejące wcześniej konto Google i jako
zawsze zalecam włączenie dwuetapowego
weryfikacja na Twoim koncie
ponieważ ten użytkownik będzie posiadał potężną moc
uprawnienia dostępu do wielu różnych
zasoby w chmurze Google
więc skoro już omówiliśmy szczegóły
o tym, co i dlaczego należy skonfigurować
drugie konto przejdźmy do wersji demonstracyjnej
i zacznij wszystko, więc kiedy tylko
jesteś gotowy, dołącz do mnie w konsoli
więc jestem z powrotem w konsoli i
więc przed przejściem na mojego nowego użytkownika
Muszę przypisać określone role
będę potrzebować tego użytkownika, którym jest
rolę użytkownika konta rozliczeniowego, aby ją przypisać
tę rolę dla mojego nowego użytkownika, którym muszę kierować
do rozliczenia, więc wracam
tutaj do lewego rogu
i kliknij menu nawigacyjne
i przejdź do rozliczeń
ponownie w menu po lewej stronie zamierzam
przejdź do zarządzania kontem i
kliknij tam i tutaj pod moim
konto rozliczeniowe, które zobaczysz, że mam
uprawnienia przypisane jednemu członkowi
administrator konta rozliczeniowego
i zgodnie z oczekiwaniami spotykam się z anthonym g
as chmury
gmail.com, więc chcę dodać kolejny
członka do mojego konta rozliczeniowego, więc jestem
po prostu kliknij dodaj członków i
tutaj wprowadzę mojego nowego drugiego użytkownika
czyli Tony Bowtie Ace
gmail.com
i pod wybierz rolę, którą zamierzam pełnić
przejdź do rozliczeń i przejdź do rozliczeń
użytkownik konta i jak widać tutaj
tę rolę będzie pełnił użytkownik konta rozliczeniowego
zezwól na uprawnienia do powiązania projektów
z kontami rozliczeniowymi, czyli dokładnie
co chcę robić
więc po prostu na to kliknę
i po prostu kliknij Zapisz
a więc teraz, kiedy wyznaczyłem moją drugą
użytkownikowi odpowiednie uprawnienia, które ja
potrzebne, zamierzam się teraz wylogować
i zaloguj się jako mój nowy użytkownik po prostu
idąc do prawego rogu w
ikona klikając na ikonę i przechodząc do
dodaj konto, dodając konto, które zrobię
być w stanie przełączać się między nimi
różni użytkownicy i tylko ja
polecam to, jeśli jesteś jedynym użytkownikiem
komputera, jeśli korzystasz z
po prostu komputer, który ma wielu użytkowników
wyloguj się i zaloguj ponownie za pomocą
Twój inny użytkownik
i tutaj jestem proszony o e-mail, który
byłby Tony Bowtie Ace
gmail.com
Podłączę swoje hasło
i poprosi mnie o mój dwuetapowy krok
weryfikacja
zamierzam kliknąć tak
i powinienem być w
i ponieważ jest to moje pierwsze logowanie
do chmury Google z tym użytkownikiem otrzymuję
monit z prośbą o zgodę na warunki
usługi zamierzam się na nie zgodzić
i po prostu kliknij Zgadzam się i kontynuuj
i tak teraz zamierzam przenieść się z powrotem do
przegląd i jak widać tutaj nie
mieć uprawnienia do przeglądania kosztów dla
to konto rozliczeniowe i tak dalej
uprawnienia przypisane do rozliczeń
administrator konta, którym jest antony g
as chmur nie jest nakładany na muszkę Tony'ego
ace, a zatem rzeczy takie jak budżety
i ostrzega nawet eksport rozliczeniowy, którego nie robię
mieć dostęp do
więc posuwając się naprzód w kursie, jeśli ty
potrzebujesz dostępu do czegokolwiek w rozliczeniach
obecnie nie masz dostępu do polubień
budżety i alerty, które można po prostu przełączać
przejdź na inne konto i uważaj
o wszelkich niezbędnych zmianach, ale to, co robię
mieć dostęp do jest, jeśli pójdę tutaj do mojego
konto rozliczeniowe kliknij menu rozwijane
menu i kliknij Zarządzaj rozliczeniami
konta, ale jak widać tutaj, tak
mieć dostęp do przeglądania wszystkich rozliczeń
rachunki wraz z projektami, które
są teraz z nimi powiązane, ponieważ te
Konta gmail są kontami samodzielnymi
ten projekt tutaj, który jest własnością
antony gcloud ace nie mam dostępu
aby uzyskać dostęp do projektu i
musiałby mieć przypisane uprawnienia
bezpośrednio do mnie, żebym to zrobił
faktycznie zobaczyć projekt lub ewentualnie
tworzenie jakichkolwiek zasobów w tym zakresie
projekt teraz, jeśli wrócę do mojej strony głównej
widzę tutaj, że nie mam żadnych projektów
dostępne, a co za tym idzie brak środków
w moim środowisku i tak to kopać
off Idę utworzyć nowy projekt
i tak pod nazwą projektu zamierzam
nazwij to
projekt ton
i możesz nazwać swój projekt jakkolwiek
polubiłbyś
pod lokalizacją nie mam żadnych
organizacja
i dlatego po prostu kliknę
na tworzeniu
a to może zająć minutę
tworzyć i oto jesteśmy z moim pierwszym
projekt
nazwany projekt tony, jak również my
pojawiło się powiadomienie, że my
projekt został stworzony i tak teraz
ten projekt powstał, powinien
być powiązany z moim kontem rozliczeniowym, więc w
aby to zweryfikować, jadę
przejść do rozliczeń
i pod listą rozwijaną
zamierzam kliknąć zarządzanie rozliczeniami
konta
i jak widać tutaj liczba
projektów spadła z jednego do dwóch, a if
klikam menu tutaj pod moim
projekty, możesz zobaczyć ten projekt tony
to projekt powiązany z my
konto rozliczeniowe też mam
uprawnienia do wyłączenia rozliczeń lub
zmienić rozliczenia dla tego konkretnego projektu
jednak, aby zmienić rozliczenia, zrobię to
musisz mieć inne konto rozliczeniowe, ale
nie ma innych kont rozliczeniowych
dostępny
i tak idąc do przodu będę miał tylko
to jedno konto rozliczeniowe i tak dalej
projekty, które zdecyduję się stworzyć, będą
połączone z tym kontem rozliczeniowym itp
jest to doskonały przykład przycinania
uprawnienia potrzebne do różnych
użytkowników i chociaż nie jest to
konto należące do domeny, ale osobiste
konto, do którego zawsze jest to zalecane
praktykować zasadę najmu
przywilej za każdym razem, gdy się spotkasz
przypisywanie uprawnień do dowolnego użytkownika teraz jako
powiedziałem przed jakimikolwiek zadaniami związanymi z rozliczeniami
że zdecydujesz się iść naprzód
możesz po prostu przełączyć się na inny
użytkownika i dokonać niezbędnych zmian i tak dalej
to wszystko, co mam na tę lekcję
więc możesz teraz oznaczyć tę lekcję jako
kompletny
i przejdźmy do następnego
[Muzyka]
Witamy spowrotem
w tej krótkiej lekcji będę
obejmujące omówienie zestawu SDK w chmurze
i interfejs wiersza poleceń bez zmian
niezbędny element interakcji
z chmurą Google do egzaminu
trzeba zapoznać się z komendą
wiersz i polecenia potrzebne do tego
tworzyć
modyfikować i usuwać zasoby, to także
niezwykle cenne narzędzie dla twojego narzędzia
pas w świecie bycia chmurą
inżynier, jak stwierdziłem, że jest bardzo
powszechny i ​​łatwy sposób na wdrożenie małych
operacje w chmurze Google
jako automatyzację złożonych, co z tego
dokładnie jest sdk w chmurze
cóż, cloud sdk to zestaw poleceń
narzędzia linii
który pozwala zarządzać zasobami
przez terminal w chmurze Google i
zawiera polecenia takie jak gcloud
gsutil bq i cubectl używając tych
polecenia
pozwalają zarządzać zasobami, takimi jak
silnik obliczeniowy
przechowywanie w chmurze bigquery kubernetes i tak dalej
wiele innych zasobów, którymi mogą być te narzędzia
uruchamiać interaktywnie lub automatycznie
skrypty dające moc i
elastyczność, której potrzebujesz, aby dostać pracę
sporządzono pakiet sdk w chmurze jest tak potężny, że
możesz zrobić wszystko, co konsola
może zrobić, ale ma więcej opcji niż
konsola, do której możesz jej użyć
infrastruktura jako autouzupełnianie kodu
pomaga ukończyć wszystkie twoje polecenia
oświadczenia liniowe i dla tych z was, którzy
uruchom system Windows, który ma pakiet sdk w chmurze
objęte dostępnością dla powershell
teraz, aby uzyskać dostęp do chmury Google
platformę, którą zwykle będziesz musiał
autoryzuj narzędzia sdk Google Cloud, aby
nadaj autoryzację narzędziom cloud sdk
możesz użyć konta użytkownika lub
konto usługi, teraz konto użytkownika to a
konto Google, które umożliwia użytkownikom końcowym
uwierzytelnić bezpośrednio do twojego
aplikacja dla najczęstszych przypadków użycia na
jest pojedyncza maszyna korzystająca z konta użytkownika
najlepsza praktyka podąża teraz drogą a
konto usługi to jest konto Google
który jest powiązany z Twoim projektem gcp
a nie konkretnego użytkownika usługę
konta można używać, podając a
klucz konta usługi do Twojej aplikacji
i jest zalecany do tworzenia skryptów Cloud SDK
narzędzia do użytku na wielu maszynach
po zainstalowaniu sdk w chmurze przychodzi
z niektórymi wbudowanymi poleceniami, które pozwalają
możesz skonfigurować różne opcje za pomocą
gcloud init to inicjuje i
autoryzuje dostęp i wykonuje inne
typowe kroki konfiguracji pakietu sdk w chmurze przy użyciu some
polecenia opcjonalne
gcloud auth login autoryzuje Twój dostęp
dla gcloud z poświadczeniami użytkownika Google
i ustawia rachunek bieżący jako aktywny
konfiguracja gcloud
to kolejna opcjonalna konfiguracja, która
pozwala konfigurować konta i
projekty, a także komponenty gcloud
pozwalają zainstalować
aktualizować i usuwać
opcjonalne składniki sdk, które dają
Ci więcej elastyczności z różnymi
zasobów teraz po zainstalowaniu
cloud sdk prawie wszystkie polecenia gcloud
będzie działać zgodnie z określonym formatem pokazanym tutaj
jest przykładem tego formatu i jest
w podziale na komponent
podmiot
argumenty i flagi pozycyjne operacji
i przejdę przez jakieś konkretne
przykłady w demonstracji trochę
nieco później i to wszystko, czego chciałem
omówić w tym przeglądzie chmury
sdk i cli, abyś mógł teraz to zaznaczyć
lekcja za zakończona i możesz do mnie dołączyć
w następnym, gdzie idę naprzód i
zademonstruj instalację zestawu SDK w chmurze
[Muzyka]
z powrotem w tej demonstracji pokażę
jak pobrać zainstalować i
skonfiguruj sdk w chmurze i będę
korzystając ze skróconej instrukcji obsługi, która znajduje się w
przechowywana dokumentacja Cloud SDK
wszystkie kroki instalacji chmury
sdk w różnych systemach operacyjnych i i
z pewnością uwzględni to w
pojawi się tekst lekcji poniżej tego demo
jak zainstalować SDK w chmurze
na każdym z najczęstszych operacji
systemy
okna
mac os i ubuntu linux wszystko, czego potrzebujesz
zrobić, to postępować zgodnie z procesem na każdym z nich
strony i powinieneś być na dobrej drodze
więc biorąc to pod uwagę, weźmy to
demo rozpoczęło się i przenieś zestaw SDK do chmury
życie, instalując wszystko i
skonfigurowane dla konkretnego działania
system
tak jak wyjaśniłem przed wyjazdem
naprzód i zainstaluj pakiet SDK w chmurze
na każdym z trzech różnych operacji
systemy
Windows mac os i ubuntu linux i i
będzie go instalować z pomocą
przewodnik szybkiego startu, który widzisz tutaj
i jak powiedziałem wcześniej, będę w tym
ten link w tekście lekcji i tak dalej
Rozpocznij to demo, od którego chciałem zacząć
instalowanie zestawu SDK w chmurze w systemie Windows tak
przeniosę się do swoich okien
maszynę wirtualną i zamierzam ją otworzyć
przeglądarkę i zamierzam wkleić plik
link do przewodnika szybkiego startu
i możesz kliknąć dowolny link do
szybki start dla systemu Windows i każdy szybki
strona startowa da mi instrukcje
dokładnie tego, co muszę zrobić dla każdego
system operacyjny, więc teraz mówi, że my
trzeba mieć utworzony projekt, który i
zrobił na ostatniej lekcji, która jest projektem
tony, więc następnym razem pobiorę plik
instalator SDK w chmurze
więc tam klikam
i zobaczę monit w lewym dolnym rogu
zakątek dłoni, którym był instalator
pobrany, zamierzam go kliknąć
otwórz plik i będę
monit o przejście przez tego kreatora i
więc po prostu klikam dalej
Zgadzam się na warunki
Umówmy się, że to będzie tylko dla mnie
anthony i mój folder docelowy
zachowaj to tak, jak jest, a oto wszystko
komponenty, które zamierza zainstalować
zamierzam zachować polecenia beta
odznaczone, ponieważ tak naprawdę ich nie potrzebuję
a jeśli będę ich potrzebować później, to mogę
zainstaluj ten komponent dla tych, którzy są
bardziej doświadczeni lub nawet trochę ciekawi
możesz kliknąć polecenia beta i
zabierz go na jazdę próbną, ale ja jadę
aby to wyłączyć, a ja kliknę
zainstalować iw zależności od mocy
twoja maszyna
powinno zająć od dwóch do pięciu
minuty na instalację i chmurę Google
sdk został zainstalowany, więc jestem po prostu
zamierza kliknąć dalej i jak pokazano tutaj
w dokumentacji, którą chcesz wykonać
upewnij się, że masz wszystkie opcje
zaznaczone jest utworzenie menu startowego
skrót żądany skrót na pulpicie
uruchom powłokę Google Cloud SDK i
na koniec chcesz uruchomić gcloud init
w celu zainicjowania i skonfigurowania
cloud sdk, teraz zamierzam kliknąć
Zakończ, aby wyjść z konfiguracji i idę
aby uzyskać powłokę poleceń, która wyskakuje i
Po prostu powiększę, żeby było lepiej
oglądanie
i tak tu jest napisane mój prąd
konfiguracja została ustawiona na domyślną tak
jeśli chodzi o konfigurację to tak
wszystko o wyborze aktywnego konta
i tak jest z moim obecnym aktywnym kontem
zostanie ustawione jako konto domyślne
trzeba było też zrobić diagnostykę
tylko po to, aby upewnić się, że może się z nim połączyć
Internet, aby mógł to zweryfikować
konto i tak teraz pojawia się monit
mówiąc, że musisz się zalogować, aby kontynuować
lubisz się logować tak
możesz po prostu kliknąć y, a następnie wejść
i zaproponuje mi nowe
okno przeglądarki, w którym muszę się zalogować
używając mojego rachunku bieżącego, abym mógł
autoryzować sdk w chmurze, więc zamierzam to zrobić
zaloguj się na moje konto Tony Bowtie Ace
kliknij dalej
wpisz moje hasło
znowu poprosi mnie o moje
weryfikacja dwuetapowa
i dostanę szybką odpowiedź
że Google SDK chce uzyskać dostęp do my
konto Google
zamierzam kliknąć na zezwolenie
i sukces, jesteś teraz uwierzytelniony
z Google Cloud SDK
a jeśli wrócę do mojego terminala, jestem
monit o wprowadzenie pewnych wartości
abym mógł poprawnie skonfigurować
google cloud sdk, więc wybiorę
projekt w chmurze do użycia
i zamierzam użyć projektu tony, który i
utworzony wcześniej, więc wprowadzę 1
i naciśnij enter
i znowu, niezależnie od projektu, który masz
utworzone, użyj tego jako domyślnego
configuration i stwierdza tutaj, że my
bieżący projekt został ustawiony na projekt
tony i znowu taka konfiguracja
nazywany domyślnym
więc jeśli mam drugą konfigurację to
chciałem użyć, mogę to nazwać a
inna konfiguracja, ale inna niż
że mój Google Cloud SDK jest skonfigurowany
i gotowy do użycia, tak dla pewności
że to działa, zamierzam uruchomić
kilka poleceń, które zamierzam uruchomić
gcloud
pomoc
Komenda
i jak widać dał mi listę
z wielu różnych poleceń, które ja
można uruchomić i wyjść można po prostu uderzyć
ctrl c zamierzam uruchomić gcloud
lista konfiguracji
a to mi da
moje właściwości w mojej aktywnej konfiguracji
więc moje konto to Tony Bowtie Ace
gmail.com wyłączyłem raportowanie użytkowania
a mój projekt to projekt tony i mój
aktywna konfiguracja jest ustawiona jako domyślna
teraz nie martw się, będę cię kryć
wszystkie te polecenia w następnej lekcji
i zamierzam przejść do szczegółów
jak możesz skonfigurować i dodać inne
użytkownicy
w ramach konfiguracji sdk w chmurze, więc
gdy wchodzimy głębiej w kurs, jestem
będzie używał znacznie więcej poleceń
linii, abyś mógł się z nią zapoznać
składnię i stać się trochę więcej
wygodne z tym tak teraz, że mam
zainstalowałem SDK w chmurze w systemie Windows
proces będzie trochę inny
jeśli chodzi o instalację na
inne systemy operacyjne, ale będzie bardzo
podobnie jeśli chodzi o
konfiguracji, więc teraz przejdźmy do
mac os i zainstaluj tam pakiet Cloud SDK
i tak oto jesteśmy w mac os i tak
pierwszą rzeczą, którą chcę zrobić, jest to, że chcę
otwórz przeglądarkę internetową i chcę iść
do strony szybkiego startu SDK w chmurze, więc jestem
po prostu wkleję tutaj adres URL
i szukamy szybkiego startu
dla systemu Mac OS, więc możesz albo kliknąć
w menu z lewej strony lub
menu tutaj na stronie głównej
i tak jak mówiłem wcześniej
ta instalacja będzie
trochę inny niż ten, w którym był
windows, więc tutaj jest kilka kroków
do naśladowania i tak stawia nas pierwszy krok
jeśli mamy już utworzony projekt
co już zrobiliśmy i jest projektem
tony, więc następny krok nam to mówi
SDK w chmurze
wymaga Pythona, więc chcemy to sprawdzić
nasz system, aby sprawdzić, czy mamy obsługiwany
wersja, aby sprawdzić naszą wersję
użyjemy tutaj tego polecenia
python minus v
i mam zamiar skopiować to do mojego
schowek
a następnie otwórz terminal i jestem
zamiar powiększyć dla lepszego oglądania i
więc wkleję polecenie
Tutaj
i po prostu kliknij enter i jak możesz
zobacz tutaj używam Pythona 2.7
ale uwaga oznaczona gwiazdką tutaj mówi, że
Cloud SDK wkrótce zostanie przeniesiony do Pythona 3 i
tak, aby uniknąć konieczności aktualizacji
później chcesz sprawdzić swoją wersję
dla Pythona 3, więc możesz użyć a
podobne polecenie, wpisując python 3
przestrzeń minus kapitał v
i jak widać, używam wersji
3.7.3
i tak wracając do przewodnika mogę
zobacz tutaj, że jest to wersja wspierająca
jeśli nie masz wersji pomocniczej
Załączę link, jak zaktualizować
Twoja wersja
w tekście lekcji poniżej i tak teraz
skończyłem ten krok, ruszajmy
Przechodząc do następnego
skąd mogę pobrać plik archiwum
dla Google Cloud sdk ponownie najbardziej
maszyny będą uruchamiać pakiet 64-bitowy, więc
jeśli masz najnowszą wersję operacyjną
system dla mac os
powinieneś być gotowy, więc idę
kliknij ten pakiet
i zacznie się pobierać dla mnie i
po zakończeniu możesz kliknąć
pliki do pobrania i kliknij sam plik
i powinno się w nim wydobyć
folder ze wszystkimi plikami i folderami
w nim i tak samo jak inny szybki
pamiętaj, że Google woli, abyś zachował plik
Google Cloud SDK w swoim katalogu domowym
a więc podążając za przewodnikiem, do którego zmierzam
zrób dokładnie to i tak najłatwiej
aby przenieść folder do domu
katalog jest po prostu przeciągnij i upuść
do folderu domowego
w menu po lewej stronie powinno być
oznaczony małą ikoną domu i
zagnieżdżone w ulubionych, które mogę teraz przenieść
do mojego folderu domowego i potwierdź to
rzeczywiście jest tutaj, więc teraz się przeprowadza
ostatni krok, który jest wyświetlany jako opcjonalny
przewodnik prosi nas o zainstalowanie skryptu
dodaj teraz narzędzia cloud sdk do naszej ścieżki i
gorąco polecam zainstalowanie tego
script, aby można było dodać narzędzia do
zakończenie polecenia i wejdę
wykonanie polecenia nieco później
w następnych kilku lekcjach i tak dalej
oto polecenie, które muszę uruchomić
więc skopiuję to do mojego
schowek jeszcze raz i zamierzam się przenieść
z powrotem do mojego terminala, do którego idę
wyczyść mój ekran i tak, aby upewnić się, że jestem
w moim katalogu domowym, w którym znajduje się plik cloud sdk
folder to po prostu napiszę ls
i tak dla tych co nie wiedzą
ls to polecenie systemu Linux, które wyświetli listę wszystkich
swoje pliki i foldery w bieżącym
path i jak widać tutaj google
cloud sdk jest na mojej ścieżce i dlatego ja
mogę uruchomić ten skrypt, więc zamierzam to zrobić
wklej to tutaj
i wciskam enter
i tak pojawia się monit z pytaniem
czy chcę wyłączyć użycie
raportowania i dlatego, że chcę pomóc
ulepsz sdk Google Cloud, do którego idę
aby wpisać y dla tak i naciśnij enter i
tak jak już wyjaśniałem
narzędzia SDK w chmurze zostaną zainstalowane
moja ścieżka, więc to jest ten krok
dba o to i tak zrobię
wpisz j
i wprowadź
na tak, aby kontynuować i zwykle ścieżkę
to, co się pojawia, jest właściwe, chyba że
zmieniłeś to inaczej, więc idę
aby pozostawić to pole puste i po prostu nacisnąć enter
i to wszystko, zainstalowałem narzędzia
więc teraz, abym mógł uruchomić gcloud
init muszę uruchomić nową powłokę
mówi tutaj, aby zmiany zaczęły obowiązywać
więc idę tutaj na górę
menu po lewej stronie kliknij terminal i
zamknij terminal, więc teraz mogę ponownie uruchomić
terminal
jeszcze raz powiększę dla lepszego
oglądanie
a teraz mogę uruchomić gcloud init
w celu zainicjowania instalacji
ponownie monit o wykonanie diagnostyki
testy i widzę, że nie mam sieci
problemy, ale pokazuje mi, że muszę
zaloguj się, aby kontynuować chcę się zalogować
więc mam zamiar wpisać y na tak i uderzyć
Wchodzić
i tak pojawiła się nowa przeglądarka
monituje mnie o podanie mojego adresu e-mail i
hasło, więc teraz to zrobię
zamierzam autoryzować moje konto
weryfikacja dwuetapowa
nie zamierzam zapisywać tego hasła i
tak, chcę zezwolić na Google Cloud SDK
aby uzyskać dostęp do mojego konta Google
więc klikam zezwalaj
i pokazuje, że byłem
uwierzytelnione, więc teraz się przeprowadzę
z powrotem do mojego terminala i tak samo jak a
zanotuj, zanim przejdziemy do przodu, na wypadek gdybyś ty
nie wyświetlaj wyskakującego okienka w przeglądarce
zaloguj się na swoje konto Google, możesz
po prostu zaznacz ten adres URL, skopiuj go do
twojej przeglądarce i powinien cię o to poprosić
po prostu to samo, więc poruszanie się przed siebie
pokazuje, że jestem zalogowany jako
tonymuszka
gmail.com, co jest dokładnie tym, czego chciałem
i prosi mnie, żebym wybrał chmurę
projekt do użycia teraz chcę użyć projektu
tony, więc wpiszę 1 i wprowadzę
i to wszystko, czym był SDK w chmurze
skonfigurowany i po prostu dwukrotnie sprawdzić, czy jestem
zamierzam uruchomić gcloud
polecenie listy konfiguracji, aby pokazać mi moje
konfiguracja i jak widać tutaj my
konto to tonybowties
gmail.com moje raporty dotyczące wyłączania użycia to
równa fałszywemu
a mój projekt to projekt tony i znowu
moja aktywna konfiguracja jest ustawiona jako
domyślnie i tak o obejmuje
instalacja pakietu SDK w chmurze dla systemu Mac OS i tak dalej
w końcu przesiadam się na ubuntu
linux i skonfiguruj tam pakiet sdk w chmurze
i tak oto jesteśmy w ubuntu i jak i
zrobiłem w innych systemach operacyjnych, którymi jestem
zamierzam otworzyć przeglądarkę i jestem
szybko wkleję adres URL
przewodnik startowy
i dlatego chcemy kliknąć szybkie
zacznij od Debiana i Ubuntu i tak dalej
masz do wyboru albo
klikając link po lewej stronie
menu lub tutaj w menu głównym
a więc podążając za przewodnikiem
mówi nam to, jeśli chodzi o
wersja ubuntu jest zalecana
sdk powinien być zainstalowany na ubuntu
wydanie, które nie osiągnęło końca życia
przewodnik prosi również o utworzenie projektu
jeśli nie mamy już takiego, który mamy
już zrobione
więc teraz możemy kontynuować z
kroki i tak, ponieważ nie instalujemy
to wewnątrz obrazu dokera, do którego pójdziemy
naprzód i użyj poleceń tutaj
teraz możesz skopiować wszystkie polecenia na
raz
kopiując to do schowka, ale my
zaleca się zainstalowanie każdego z nich
jeden po drugim, więc skopiuję to
i zamierzam otworzyć mój terminal, jestem
zamiar powiększyć dla lepszego oglądania i
zamierzam wkleić to polecenie w i
kliknij enter, pojawi się monit
dla mojego hasła
i nie wyskakiwał żaden błąd, więc
oznacza to, że został pomyślnie wykonany
więc przechodzę do następnego
Komenda
zamierzam to skopiować
wróć do mojego terminala
i wklej go
teraz dla tych z was, którzy nie mają
curl, zostaniesz o to poproszony
zainstaluj go i wydaj polecenie uruchomienia
więc skopiuję i wkleję
Komenda
i kliknij wejdź
zamierzam wpisać y, aby uzyskać odpowiedź twierdzącą
kontynuuj i zainstaluje go
po kilku minutach dobrze, że teraz
curl został zainstalowany, mogę uruchomić
to polecenie ponownie zamierzam wyczyścić
najpierw ekran
i to również wykonane bez błędów
i tak teraz przechodzimy do ostatniego polecenia
to polecenie pobierze i zainstaluje
SDK Google Cloud
pojawia się monit o zainstalowanie niektórych pakietów
więc napiszę y, aby potwierdzić
kontynuuj, więc teraz się pobierze
i zainstaluj niezbędne pakiety
potrzebne do Google Cloud SDK i
w zależności od szybkości twojego internetu
a prędkość twojej maszyny to może
zająć od dwóch do pięciu minut
w porządku, a pakiet sdk Google Cloud był
zainstalowany
i tak teraz, gdy chmura sdk była
zainstalowany, możemy teraz zainicjować plik
konfiguracja
więc zamierzam wpisać gcloud init
ponownie monit z siecią
diagnostyka Wpiszę y, aby potwierdzić
zalogować się
i mam zamiar uzyskać monit dla mojego
e-mail i hasło
Zajmę się moim dwuetapowym
weryfikacja i zamierzam zezwolić
Google Cloud SDK, aby uzyskać dostęp do mojego google
konto i sukces jestem teraz
uwierzytelniony i przeniesiony z powrotem do
terminal tylko po to, aby to zweryfikować i znowu jestem
zamierzam wybrać projekt tony jako chmurę
projekt do wykorzystania
a zestaw SDK w chmurze został skonfigurowany jako
zawsze zamierzam zrobić podwójną kontrolę
uruchamianie listy konfiguracji gcloud
i zgodnie z oczekiwaniami ma te same szczegóły
podejdź, więc to jest szybki bieg
we wszystkich trzech systemach operacyjnych
Windows Mac OS i Ubuntu Linux, jak to zrobić
zainstalować Google Cloud SDK i to
pomoże Ci zacząć stawać się
bardziej znane i wygodniejsze w użyciu
interfejs wiersza poleceń i tak dalej
o podsumowania tej lekcji
więc możesz teraz oznaczyć tę lekcję jako
kompletny
i przejdźmy do następnego
[Muzyka]
witamy z powrotem w ostatnim demo, które odwiedziliśmy
poprzez pełną instalację chmury
SDK
i skonfigurowaliśmy nasze konto administratora
użyte w nim w tej demonstracji i
będzie przechodził przez proces zarządzania
sdk w chmurze, a to będzie wymagało sposobu
z niego korzystać i jak go dostosować
środowiska, jak również konfigurowanie
nasze inne konto użytkownika, abyśmy byli
potrafi zastosować konfiguracje przełączania
od jednego użytkownika do drugiego i tak zrobię
przejść przez inicjowanie i
upoważnienie
instalowanie konfiguracji i właściwości
i usuwanie komponentów, a także a
pełne przejście przez gcloud
powłoka interaktywna, więc zacznijmy od tego
demo, nurkując we wstępnie skonfigurowanym
terminal z zainstalowanym sdk i
skonfigurowany z moim drugim użytkownikiem tony
muszka as gmail.com
i tak oto jestem w terminalu mac os
i po prostu wiedz, że to nie ma znaczenia
w jakim systemie operacyjnym pracujesz
tak długo, jak sdk jest zainstalowane i ty
skonfiguruj swojego użytkownika i tak jak ty
widziałem w ostatniej lekcji po instalacji
pakiet SDK w chmurze, następnym krokiem jest zwykle
aby zainicjować pakiet sdk w chmurze
uruchamiając polecenie gcloud init i
ma to na celu wykonanie wstępnej konfiguracji
zadań, jak również autoryzację chmury
sdk, aby użyć poświadczeń konta użytkownika
aby mógł uzyskać dostęp do chmury Google i
więc w skrócie konfiguruje sdk w chmurze
konfiguracji i ustawia podstawowy zestaw
właściwości i zwykle obejmuje to
aktywne konto bieżący projekt i
jeśli interfejs API jest włączony, domyślny google
oblicz region i strefę silnika teraz jako a
zauważ, jeśli jesteś w zdalnym terminalu
sesji bez dostępu do przeglądarki
nadal może uruchomić polecenie gcloud init
ale dodając flagę konsoli dash dash
tylko myślnik
a to zapobiegnie wykonaniu polecenia
uruchomienie autoryzacji z poziomu przeglądarki
jak widziałeś podczas konfigurowania ostatniego
użytkownik, więc teraz, mimo że mam użytkownika
już skonfigurowane, nadal mogę uruchomić gcloud
init i da mi parę
różne opcje do wyboru, więc ja
może ponownie zainicjować tę konfigurację
z kilkoma nowymi ustawieniami lub mogę utworzyć plik
teraz nowa konfiguracja dla tego demo
ponieważ mamy już dwóch użytkowników i do
zademonstrować, jak się przełączać
różnych użytkowników chcę utworzyć nowego
konfiguracja z moim pierwszym użytkownikiem tak
zamierzam wpisać 2 i nacisnąć enter i
poprosi mnie o konfigurację
name teraz prosi mnie o konfigurację
imię, ponieważ podczas konfigurowania pierwszego
konfiguracja jest ustawiona jako domyślna i
ponieważ wiem, że to konto użytkownika
ma również pełny dostęp do rozliczeń
uprawnienia administracyjne, do których zamierzam
zadzwoń do tego mistrza konfiguracji i jestem
zamierza nacisnąć enter
wykonał niezbędne kontrole sieci i
teraz pyta mnie, na które konto i
chcesz na razie użyć tej konfiguracji
gdyby Tony Bowtie Ace miał dostęp do dwóch
różne konta Google Cloud, które chciałbym
możliwość dodania innej konfiguracji
tutaj i tak, bo idę się zalogować
z nowym kontem, które zamierzam założyć
dwa
i naciśnij enter
i tak znowu przywiodło mnie do mojej przeglądarki
window i zamierzam się zalogować za pomocą
inne konto
więc tutaj możesz wpisać pierwszy
konto, które stworzyłeś i dla mnie to
był antony gcloud ace gmail.com
naciskam następny i zamierzam wejść do mojego
hasło
poprosi mnie o moje dwa kroki
weryfikacja
i nie chcę zapisywać tego hasła
i zamierzam zezwolić na chmurę Google
sdk, aby uzyskać dostęp do mojego konta Google i jestem
teraz uwierzytelniony, więc wracam do
konsoli widać tutaj, że jestem
aktualnie zalogowany i pyta mnie
aby wybrać projekt w chmurze, którego chcesz używać od teraz
mam tylko jeden projekt w tym google
konto w chmurze, którym jestem subtelnym poetą
zamierza wybrać jeden
a ponieważ mam api silnika obliczeniowego
włączone, mogę teraz skonfigurować plik
domyślny region i strefa obliczeniowa i tak dalej
zamierzam nacisnąć y, aby tak skonfigurować
i jak widać jest ich 74
różne opcje do wyboru i jeśli
przewiń trochę w górę, powinieneś być
w stanie znaleźć strefę, w której jesteś
szukam i tak na ten kurs my
będą nas używać jako centralnego
myślnik a i tak to jest numer osiem tak
przewinę z powrotem w dół
i wpisz ósemkę
i tak teraz ma moja główna konfiguracja
został skonfigurowany z moją chmurą antony g
konto ace używające nas central 1a jako
strefa silnika obliczeniowego ponownie się dotyka
autoryzacja, gdybym nie chciał skonfigurować
całą konfigurację, którą mogę po prostu wpisać
w gcloud
uwierzytelnianie logowania
a to pozwoli mi autoryzować tylko
tylko konto użytkownika, więc gcloud init
autoryzowałby dostęp i wykonywał
kroki konfiguracji pakietu SDK w chmurze i uwierzytelnianie gcloud
login spowoduje autoryzację dostępu dopiero teraz
jak wspomniałem w poprzedniej lekcji ty
może korzystać z konta usługi dla
autoryzacja do narzędzi cloud sdk i
to byłoby świetne dla obliczeń
instancja lub aplikacja, ale tak
potrzebujesz pliku klucza konta usługi w kolejności
aby to zezwolić i tak wrócić do
naszych kont użytkowników podczas uruchamiania chmury
sdk możesz mieć tylko jedno aktywne konto
w dowolnym momencie i tak, aby sprawdzić moje
aktywne konto mogę wpisać polecenie
lista autoryzacji gcloud
a to da mi listę wszystkich
konta, które zostały autoryzowane i
więc za każdym razem, gdy uruchamiasz gcloud, inicjuj go
użyje tego konta jako aktywnego
konto i jak widać tutaj
antony gcloud ace gmail.com ma gwiazdkę
obok niego i jest to oznaczone jako
aktywne konto, a więc w istocie
Konto z gwiazdką obok to
aktywne konto i tak szukam
zmień moje aktywne konto z powrotem na tony
asa muszki iw porządku dla mnie zrobić
że polecenie jest wygodnie pokazane
tutaj i tak zamierzam iść dalej i
uruchom to
a konto byłoby pokazanym użytkownikiem
powyżej, więc kiedy wykonuję autoryzację gcloud
lista
Widzę, że moje aktywne konto jest teraz
powrót do tony muszka muszka gmail.com
teraz, jeśli chcesz zmienić konto
na podstawie polecenia zawsze możesz to zrobić
że przy użyciu konta flag dash dash
po poleceniu i wstaw użytkownika
konto, z którego chcesz korzystać i tak dalej
powiedzmy, że chciałem odwołać poświadczenia
z konta, którego nie potrzebuję
już mogę po prostu użyć polecenia
cofnięcie autoryzacji gcloud
następnie nazwę użytkownika i tak się stanie
odwołać dane uwierzytelniające dla tego konta
i tak robiąc to
usunie twoje poświadczenia i wszelkie inne
tokeny dostępu dla dowolnego konta
który wybierzesz, który jest obecnie na twoim
komputer i tak jeśli szukamy
to konkretne konto, z którego zawsze możemy skorzystać
polecenie gcloud info i da
nam ścieżkę do konfiguracji użytkownika
katalog i to jest ten katalog
przechowuje twoje zaszyfrowane dane uwierzytelniające i
tokeny dostępu
wraz z aktywnym
konfiguracje i inne
konfiguracje tak dobrze, jak tylko możesz
zobacz tutaj, uruchamiając polecenie gcloud info
podaruje Ci też inne
informacje wszystko z konta
projekt aktualne właściwości i
gdzie można znaleźć dzienniki, więc teraz
przechodzimy do konfiguracji
konfiguracja to nazwany zestaw gcloud
właściwości cli
i działa trochę jak profil i
więc wcześniej pokazałem, jak ustawić
stworzyć inną konfigurację przez gcloud
init, więc teraz, jeśli uruchomię konfigurację gcloud
list polecenie dałoby mi wszystko
informacje o aktywnej konfiguracji
więc jak widać tutaj, mój użytkownik ma
zmieniłem, ale moja konfiguracja pozostała
to samo teraz, co poprzednio w a
Tony Ace ma inną lekcję
nie mają dostępu do subtelnego projektu
poeta ten projekt należy do antony g
cloud ace i konfiguracja została ustawiona
z tego powodu teraz, jeśli Tony Bowtie Ace
miał dostęp do subtelnego poety
projekt, wtedy mógłbym tego użyć
konfiguracja, ale tak nie jest, więc ja
chcę przełączyć się z powrotem na moje inne
konfiguracja i sposób, w jaki bym to zrobił, to
wpisz polecenie
konfiguracje konfiguracji gcloud
aktywuj i konfigurację, którą ja
zestaw dla Tony Bowtie Ace jest
domyślna konfiguracja
a więc teraz, gdy został aktywowany, tj
może teraz uruchomić listę konfiguracji gcloud i as
możesz zobaczyć tutaj konfiguracja jest
z powrotem do ustawień domyślnych podczas
proces inicjalizacji dla tony bowtie
ace teraz, jeśli chcę utworzyć wiele
konfiguracje dla tego samego konta użytkownika
mogę po prostu wpisać polecenie gcloud
konfiguracje konfiguracyjne
tworzyć
ale gdybym chciał tylko zobaczyć
właściwości konfiguracyjne, które zawsze mogę
wpisz polecenie gcloud config
konfiguracje opisują
i jak widać po opisie i
potrzebował nazwy konfiguracji do
uzupełnij polecenie i tak zrobię
zrób to teraz
i otrzymałem wszystkie właściwości
dla tej konfiguracji teraz inna rzecz
którymi chciałem się podzielić, jeśli chodzi o
properties jest to, że możesz zmienić
projekt lub region obliczeniowy i strefę
po prostu wpisując polecenie
gcloud config ustaw teraz, jeśli chcę
zmienić projekt, który mogę po prostu wpisać
projekt i nazwę projektu, jeśli tak było
dla instancji obliczeniowej mogę po prostu
wpisz obliczenia
strefa ukośnika dla określonej strefy
i tylko jako uwaga tylko właściwości
które nie należą do właściwości podstawowej
sekcja to te, które można ustawić jako
dobrze, gdy ustawiasz właściwości
dotyczy to tylko aktywnych
konfiguracji, jeśli chcesz zmienić
konfiguracja jednego, który nie jest aktywny
wtedy musiałbyś się na to przełączyć i uciekać
polecenie gcloud config set i tak dalej
Idąc dalej, chciałem dotknąć
komponenty, które można zainstalować
części sdk i podczas instalacji
sdk komponenty gcloud bq gsutil
a podstawowe biblioteki są instalowane przez
default teraz prawdopodobnie widziałeś listę
Components po uruchomieniu gcloud init
polecenie i tak, aby zobaczyć wszystkie komponenty
ponownie możesz po prostu wpisać gcloud
składniki
polecenie listy
a jeśli przewiniesz w górę, możesz zobaczyć
wszystkie dostępne komponenty
które możesz zainstalować w dogodny dla siebie sposób
więc gdybym chciał zainstalować
komponent cubectl, który mogę wpisać w pliku
polecenie instalacji komponentów gcloud
cubectl i pojawi się monit z pytaniem
ja, jeśli chcę kontynuować z tym i
chcesz powiedzieć tak, a teraz pójdzie
przez proces ich instalacji
składniki
i tak tylko po to, aby sprawdzić, czy uruchomię plik
polecenie lista składników gcloud, którą możesz
zobacz tutaj, że mam kostkę ctl
składnik zainstalowany teraz, gdybym chciał
usuń ten komponent, który mogę po prostu wpisać
W
komponenty gclouda
usunąć
a następnie komponent, który chcę
usunąć
którym zamierzam być cubectl
poproszony, jeśli chcę to zrobić, idę
powiedzieć tak i przejdzie
etapy usuwania tego elementu
i został pomyślnie odinstalowany
a więc jeśli pracujesz z zasobem
że potrzebujesz komponentu, aby to zrobić
po prostu zainstaluj lub odinstaluj go za pomocą
polecenie komponentów gcloud i tak dalej
ostatnia rzecz dotycząca komponentów przed nami
pójść dalej
jest to, że możesz aktualizować swoje komponenty
aby upewnić się, że masz najnowszą wersję
i tak, aby zaktualizować wszystkie swoje
zainstalowane komponenty po prostu
uruchom polecenie aktualizacja składników gcloud
i tak zanim pójdę dalej i skończę
ta demonstracja, której chciałem dotknąć
interaktywna powłoka gcloud gcloud
interaktywna powłoka zapewnia bogatsze
doświadczenie powłoki upraszczające polecenia
i odkrywanie dokumentacji z Tobą
wpisz autouzupełnianie i tekst pomocy
fragmenty poniżej generuje sugestie
i autouzupełnianie dla gcloud bq gsutil
a także narzędzia wiersza poleceń cubectl
jak każde polecenie, które ma podrzędną stronę podręcznika
polecenia i flagi mogą być zakończone
wraz z pomocą online podczas wpisywania
polecenie i ponieważ jest to część
komponent beta, który muszę zainstalować i
więc uruchomię polecenie gcloud
komponenty instalują wersję beta i chcę
naciśnij tak, aby kontynuować, a to się skończy
naprzód i rozpocznij instalację
polecenia beta gcloud
więc teraz, gdy jest zainstalowany, idę
aby po prostu wyczyścić ekran i tak teraz
aby uruchomić interaktywny gcloud
Shell muszę uruchomić polecenie gcloud
beta
interaktywny
i tak teraz dla każdego polecenia, które wpisuję
otrzymam automatyczne sugestie, które to zrobią
pomóż mi moimi poleceniami i tak dalej
w całej okazałości idę
Zacznij pisać
i jak widać daje mi to
opcja między g cloud lub gsutil i i
może użyć strzałki, aby wybrać jedną z nich
a poniżej to również pokaże mi
różne flagi, których mogę do tego użyć
konkretne polecenia i sposób tworzenia struktury
ich i tak dla teraz ja jadę biegać
wersja gsutil
minus l i jak widać tutaj to jest
udzielając mi wszelkich informacji na ten temat
polecenie i co może zrobić i tak jestem
zamierza nacisnąć enter
i jak widać moja wersja gsutil jest
4.52
i wraz z numerem wersji jestem
udzielono również wszelkich szczegółowych informacji
w odniesieniu do tej wersji gsutil i
to może być używane z absolutnie każdym
polecenie używane w chmurze Google
platformę, więc idę dalej
i zrób to ponownie, ale uruchamiając a
inne polecenie, więc po prostu zamierzam
najpierw wyczyść ekran, a ja to zrobię
wpisz gcloud
obliczać
instancje i jak widać fragment
na dole ekranu jest wyświetlany
mi nie tylko komenda i jak to jest
zorganizowany, ale także adres URL dla
dokumentacja, więc kontynuuj na gcloud
instancje obliczeniowe zamierzam zrobić listę
i mam zamiar przefiltrować go za pomocą
flag myślnik myślnik filtr i zamierzam to zrobić
przefiltruj usa wschodnią strefę i jestem
zamierza nacisnąć enter
i zgodnie z oczekiwaniami nie ma instancji
u nas wschodnia 1a i jak masz właśnie
doświadczyłem, że jest to świetne narzędzie i ja
gorąco polecam, aby go użyć
kiedy tylko możesz teraz wiem, że to jest
dużo do przyjęcia
i wiele z tych poleceń nie będzie
pojawić się na egzaminie, ale znowu się dostać
wygodnie z wierszem poleceń i
sdk pomoże ci w drodze do
zostać inżynierem chmury
pomoże ci poczuć się naprawdę komfortowo
z wierszem poleceń i przed tobą
wiedz, że będziesz uruchamiać polecenia
wiersz poleceń i wolisz go
za pomocą konsoli i to wszystko
mieć dla tej demonstracji na temat zarządzania chmurą
sdk, dzięki czemu możesz teraz oznaczyć tę lekcję jako
zakończyć i przejść do następnego
jeden
witam z powrotem w tej demonstracji jestem
będzie mówić o zawsze
dostępna powłoka oparta na przeglądarce o nazwie
Powłoka w chmurze Powłoka w chmurze jest wirtualna
maszyna, która jest załadowana rozwojem
narzędzi i oferuje wytrwałą piątkę
gigabajtowy katalog domowy, na którym działa
Google Cloud Cloud Shell to jest to
zapewnia dostęp z wiersza poleceń do pliku
zasoby Google w chmurze w ramach
Powłoka chmurowa konsoli jest również dostarczana z plikiem
wbudowany edytor kodu, którym będę
nurkowanie i umożliwia przeglądanie
katalogi plików, a także widok i
edytuj pliki, wciąż uzyskując dostęp do
dostępny jest edytor kodu w chmurze
domyślnie z każdą powłoką w chmurze
instancji i opiera się na oprogramowaniu open source
redaktor thea
teraz dostępna jest usługa Cloud Shell
w dowolnym miejscu konsoli, po prostu
klikając ikonę pokazaną tutaj w
zdjęcie
i znajduje się w prawym górnym rogu
róg konsoli w kolorze niebieskim
pasek narzędzi, więc zacznijmy od
chmura, brudząc sobie ręce
i od razu w nią wskoczyć
i tak oto jesteśmy z powrotem w konsoli
i jestem zalogowany jako Tony Bowtie Ace
gmail.com i jak widać tutaj w
prawy róg
jak wspomniano wcześniej, znajdziesz
logo Cloud Shell i tak, aby je otworzyć
po prostu kliknij na to i będzie
aktywuj powłokę chmurową tutaj na
dno i dlatego, że to mój pierwszy raz
używając Cloud Shell, otrzymam ten monit
szybko wyjaśniając przegląd tego, co
Cloud Shell jest i zamierzam po prostu
naciśnij kontynuuj
i zamierzam zrobić terminal a
nieco większy, przeciągając tę ​​linię
do środka ekranu i tak dalej
kiedy uruchamiasz Cloud Shell, zapewnia
e2 mały
instancja google Compute Engine z uruchomioną a
system operacyjny Linux oparty na Debianie
jest to efemeryczna wstępnie skonfigurowana maszyna wirtualna
a środowisko, w którym pracujesz, to
kontener dokera działający na tej maszynie wirtualnej
instancje Cloud Shell są obsługiwane
na użytkownika na sesję
instancja utrzymuje się, dopóki powłoka w chmurze
sesja jest aktywna i po godzinie
bezczynności sesja kończy się i
vm jest odrzucany, możesz też
automatycznie dostosować swoje środowisko
w czasie rozruchu i pozwoli ci to zrobić
mieć preferowane narzędzia, gdy chmura
Shell uruchamia się, więc kiedy twoja powłoka w chmurze
instancja jest przewidziana, jest przewidziana
z 5 gigabajtami wolnego dysku trwałego
przechowywania i jest zamontowany w twoim domu
katalogu na maszynie wirtualnej
instancji i możesz sprawdzić swój dysk
pamięci, po prostu wpisując polecenie
df minus h i tutaj, gdzie pokazuje dev
dysk według id Google Home, część pierwsza, którą pokazuje
tutaj rozmiar jak 4,8 gigabajtów i to
będzie trwałym magazynem dyskowym
który jest zamontowany w twoim katalogu domowym
teraz, jeśli zauważyłeś, pokazuje to tutaj
Jestem zalogowany jako tony bowtie ace w
Cloud Shell i że mój identyfikator projektu to
ustawiony na projekt tony, więc świetna rzecz
o skorupie chmurowej
jest to, że jesteś automatycznie
uwierzytelnione jako konto Google
jesteś zalogowany, więc tutaj możesz
zobacz, jestem zalogowany jako tony bowtie ace i
więc wyobraź sobie to jak uruchamianie gcloud auth
zaloguj się i podaj swoje konto Google
ale bez konieczności robienia tego teraz
kiedy powłoka w chmurze jest uruchomiona
aktywny projekt w konsoli to
propagowane do Twojej konfiguracji gcloud
wewnątrz skorupy chmury, jak widać
tutaj mój projekt jest ustawiony na projekt tony
teraz, gdybym chciał to zmienić na a
inny projekt, którego mógłbym po prostu użyć
polecenie podane tutaj
gcloud config set projekt wraz z
identyfikator projektu, a to zmieni mnie na a
inny projekt teraz za kulisami
Cloud Shell jest dystrybuowany globalnie
w wielu regionach, więc kiedy ty
najpierw połącz się z Cloud Shell
automatycznie przypisany do najbliższego
dostępny region, a tym samym unikanie
wszelkie niepotrzebne opóźnienia, których nie masz
możliwość wyboru własnego regionu i
więc Cloud Shell zrobi to za Ciebie
optymalizując go, aby migrował do bliższego
region, kiedy tylko jest to możliwe, więc jeśli kiedykolwiek będziesz
ciekawe, gdzie jest twoja sesja Cloud Shell
jest obecnie aktywny
możesz po prostu wpisać to polecenie
zwiń metadane ukośne metadane obliczeniowe
ukośnik wersja jedno ukośnik wystąpienie ukośnik
strefa
a to da mi strefę, w której moja
instancja jest zlokalizowana i jak pokazano tutaj
jest teraz w nas East 1b, tak jak ty prawdopodobnie
widziałem za każdym razem, gdy podkreślam
coś, co jest na zdjęciu
nożyczki zbliżają się do powłoki chmurowej
niektóre zautomatyzowane i dostępne narzędzia, które
są wbudowane, a więc jeden z nich
dostępnych narzędzi jest to, że za każdym razem, gdy ja
zaznacz coś, co będzie
automatycznie skopiować go do schowka
dla mnie Cloud Shell ma również kilka
bardzo potężne preinstalowane narzędzia, które
chodź z nim, na przykład bash sdk w chmurze
hełm vima
git
docker i więcej, a także Cloud Shell ma
wsparcie dla wielu głównych różnych
języki programowania, takie jak java go
python node.js
rdzeń rubinowy i siatkowy dla biegaczy
Windows teraz, jeśli szukasz
dostępne narzędzie, które nie jest wstępnie zainstalowane
faktycznie możesz dostosować swój
environment podczas uruchamiania instancji
i automatycznie uruchom skrypt, który to zrobi
zainstaluj wybrane narzędzie i
skrypt działa jako root i możesz zainstalować
dowolny pakiet, który ci się podoba i tak dalej
zamówienie na dostosowanie tego środowiska
do pracy musi być plik oznaczony
jako kropka dostosuj środowisko podkreślenia
teraz, jeśli zrobimy ls tutaj, możesz to zobaczyć
wszystko, co mamy, to chmura readme dash
plik tekstowy powłoki, jeśli zrobimy ls spacja minus
al, aby wyświetlić również wszystkie ukryte pliki
widać, że kropka dostosować
plik środowiska podkreślenia nie
istnieją, a to dlatego, że musimy
stworzyć go sami i tak do tego
przykład chcę zainstalować terraform jako plik
dostępne narzędzie po uruchomieniu mojej instancji
więc muszę utworzyć ten plik, więc jestem
zamierza to zrobić za pomocą dotyku
polecenie, a następnie nazwę pliku
kropka dostosuj
środowisko podkreślenia naciśnij enter i if
czyszczę ekran i robię kolejne ls
spacja minus al Widzę, że moja kropka
dostosuj plik środowiska podkreślenia
został stworzony, więc teraz zamierzam to zrobić
potrzebuję skryptu do zainstalowania terraforma
co oznacza, że ​​​​musiałbym to edytować i
więc kolejna wspaniała cecha Cloud Shell
jest to, że jest wyposażony w edytor kodu i
mogę to zrobić na jeden z dwóch sposobów, które mogę
wejdź tutaj i kliknij otwórz
przycisk edytora, który otworzy nowy
tab lub mogę po prostu użyć polecenia edycji
z nazwą pliku i zamierzam to zrobić
tylko tak edytuj
kropka dostosuj środowisko podkreślenia i
po prostu wcisnę enter i tak jak ty
widzę, że dostałem monit z informacją, że tak
nie można załadować edytora kodu i to
jest tak, ponieważ podczas korzystania z edytora kodu ty
potrzebujesz włączonej obsługi plików cookie w przeglądarce i
ponieważ używam prywatnej przeglądarki
sesyjne pliki cookie są wyłączone i ponieważ
moje środowisko Cloud Shell utrzymuje się
zamierza otworzyć zwykłą przeglądarkę
window i zamierzam kontynuować tam, gdzie ja
przerwałem, więc wracam z
nowe okno przeglądarki ponownie zalogowany jako
Tony Bowtie Ace i tak tylko, żeby ci pokazać
trwałość, która ma miejsce w chmurze
Shell zamierzam uruchomić polecenie ls
spacja minus al i jak widać tutaj
środowisko dostosowywania nadal istnieje
i tak znowu chciałem zainstalować
terraform jako dodatkowe narzędzie w my
środowisko, więc zamierzam się otworzyć
edytora, wpisując edit dot
dostosuj środowisko podkreślenia i jestem
wciskam enter i oto jest
edytor, który się pojawił
jak widać tutaj jest zbudowany z
eclipse thea i jest to oprogramowanie typu open source
edytor kodu, z którego można pobrać
eclipse i tym właśnie jest edytor
zbudowany na teraz to menu tutaj po lewej stronie
Mogę zrobić to trochę większe i
ponieważ jedyny widoczny plik na moim
dysk stały to chmura readme
plik tekstowy kropki powłoki, którego nie widzę
moja kropka dostosuje środowisko podkreślenia
więc aby go otworzyć i edytować, jestem
przejść do menu u góry
edytor i kliknij plik otwórz
i tutaj będę mógł wybrać plik
którego potrzebuję, więc wybiorę
dostosuj środowisko i kliknij otwórz
więc wkleję w moim skrypcie
zainstalować terraform i po prostu idę
wkleić mój skrypt ze schowka
i dołączę skrypt do pliku
repozytorium github dla tych z was, którzy używają
terraform i mam zamiar przejść do
menu po lewej kliknij plik i
następnie naciśnij Zapisz i tak teraz w porządku dla mnie
aby to zadziałało
środowisko dostosowywania musi być
załadowany do mojej powłoki w chmurze, więc idę
trzeba go zrestartować i tak po to
to osiągnąć, zamierzam się przeprowadzić
do menu po prawej stronie idę
kliknij ikonę z trzema kropkami
i kliknij restart, a będziesz
przedstawiony z monitem, który mówi, że
natychmiast zakończy moją sesję
a następnie zostanie udostępniona nowa maszyna wirtualna
dla mnie, a ty również zostaniesz przedstawiony
opcjonalna odpowiedź od Google Telling
im, dlaczego ponownie uruchamiasz maszynę wirtualną i
służy to jedynie celom statystycznym
więc zamierzam kliknąć restart i jestem
będzie czekać, aż pojawi się nowa powłoka chmurowa
zainicjowany, a moja nowa powłoka w chmurze jest
zainicjowany i uruchomiony, więc ja
chcę dokładnie sprawdzić, czy terraform
został zainstalowany, więc idę
tutaj, aby otworzyć przycisk terminala
pasek narzędzi po prawej stronie i jestem
zamierzam wrócić do mojego terminala i
zamierzam po prostu uruchomić polecenie
Wersja terraform dash dash
i tak wygląda na to, że terraform był
zainstalowany i jak widać, działam
wersja.12, ale mówi, że mój terraform
wersja jest nieaktualna i że
najnowsza wersja to kropka 13. i tak dlatego
naprawdę chcę być na bieżąco
terraform, do którego chcę wejść
mój dostosuj plik środowiska i edytuj
moja wersja terraformu, więc kiedy my
Cloud Shell jest inicjowana
terraform.13 można zainstalować i tak jest
zamierzam po prostu wpisać polecenie edit
kropka dostosuj środowisko podkreślenia i
wracam do mojego edytora i zamierzam
zmień wersję terraform z punktu 12
do kropki 13, a następnie przejdź tutaj do
menu po lewej stronie kliknij plik, a następnie
zapisz, a teraz zamierzam zrestartować mój
maszyna ponownie
i wróć, gdy będzie w pełni
zaopatrzony i jestem z powrotem mój
maszyna została zainicjowana i jestem
zamierzam wrócić do mojego terminala przez
klikając przycisk otwórz terminal i
więc wpiszę komendę
Wersja terraform dash dash i jako ty
widzę, że jestem w wersji kropka 13 i jestem
zamierzam uruchomić proste polecenie terraform
aby zobaczyć, czy to działa i jak możesz
zobacz, odniosłem sukces w prowadzeniu terraforma
w Cloud Shell dostosowując teraz plik
środowisko nie jest na egzaminie, ale jest
taka niesamowita funkcja, którą chciałem
podświetl to dla ciebie z prawdziwym światem
na przykład terraform na wypadek, gdybyś był
z dala od komputera
i jesteś zalogowany w przeglądarce i ty
potrzebujesz specjalnych narzędzi do użycia w chmurze
shell jest to najlepszy sposób, aby to zrobić teraz
jak wspomniałem wcześniej, chmura sdk jest
preinstalowany na tym i tak wszystko
które pokazałem ci na ostatniej lekcji
w odniesieniu do sdk w chmurze można to zrobić
powłoka chmurowa, więc jeśli uruchomię plik
polecenie gcloud
beta interaktywna, którą mógłbym wychować
interaktywna powłoka chmurowa i będę
w stanie uruchomić te same polecenia, więc teraz if
idę dalej i uruchamiam polecenie
listę komponentów gcloud, będę w stanie
zobacz wszystkie zainstalowane komponenty i jako
widać tam z powłoką chmur
zainstalowanych jest więcej komponentów niż
co jest zainstalowane domyślnie
instalację sdk mogę również uruchomić
polecenie gcloud config list, aby zobaczyć
wszystkie właściwości w moim aktywnym
konfiguracja i tak to się pokazuje
wiesz, że instalacja sdk jest włączona
Cloud Shell jest tak samo wydajny jak
taki, który zainstalowałeś na swoim
komputer, jedyną różnicą jest tutaj
że sdk wraz ze wszystkimi innymi
narzędzia, które są instalowane w Cloud Shell
jest aktualizowana co tydzień, więc możesz
zawsze polegają na tym, że są aktualne
i tak przechodzimy do kilku dodatkowych funkcji
powłoki chmury, na którą chciałem zwrócić uwagę
oczywiste
tutaj na pasku narzędzi Cloud Shell po prawej stronie
obok otwartego terminala, który mogę otworzyć
zupełnie nowe karty otwierające się inaczej
projektowanie
lub nawet ten sam projekt
ale po prostu inny terminal i poruszanie się
do menu po prawej stronie chmury
powłoka ta ikona klawiatury może wysłać klucz
kombinacje, których normalnie byś nie zrobił
mieć dostęp do przejścia na bieg
ikona z tym jesteś w stanie zmienić
Twoje preferencje
i patrząc na pierwszy element na
listę, jeśli chodzi o motywy kolorów
może przejść od ciemnego motywu do jasnego
motyw lub jeśli wolisz inny kolor
w moim przypadku wolę ciemny motyw
jak również masz opcje zmiany
Twój rozmiar tekstu możemy przejść do największego
ale myślę, że po prostu zatrzymamy sprawy
do średniego i tyle
mamy
różne czcionki ustawienia kopiowania
z którego również pokazywałem Ci wcześniej
jako preferencje klawiatury również masz
opcja pokazywania paska przewijania
teraz przechodzimy do tej ikony tuż obok
bieg
to przycisk podglądu internetowego, a więc web
Przycisk podglądu został zaprojektowany tak, abyś mógł
może uruchomić dowolną aplikację internetową, która nasłuchuje
do żądań http w powłoce chmury i
możliwość przeglądania go w nowej przeglądarce internetowej
tab podczas uruchamiania tych aplikacji internetowych
podgląd internetowy obsługuje również aplikacje
uruchom w silniku aplikacji, teraz pamiętaj o tym
porty są dostępne tylko dla bezpiecznych
usługa proxy w chmurze, która
ogranicza dostęp przez https do twojego użytkownika
konto tylko i tak, aby to wykazać
funkcja zamierzam uruchomić prosty http
serwer, na którym działa strona hello world, więc
najpierw wyczyszczę ekran i
wtedy zamierzam wyjść z trybu interaktywnego
shell i znowu zamierzam wkleić
dla mojego schowka prosty skrypt, który
uruchomi mój prosty serwer http i as
widać, że działa na porcie 8080
a teraz mogę kliknąć w sieci
przycisk podglądu i mogę wyświetlić podgląd
to na porcie 8080
i otworzy się nowa karta przeglądarki internetowej
i tutaj zobaczę moją stronę hello world
teraz to tylko prosty przykład i tak dalej
Jestem pewien, że wielu z was może znaleźć świetne
używać do tego, więc przestanę
ten serwer http teraz, naciskając ctrl c
i tak samo jak szybki podgląd w Internecie
także działać na innym porcie w dowolnym miejscu
z portu 2000
aż do 65 000. teraz idziemy dalej
do pozostałych cech
naciskając przycisk więcej tutaj z
trzy kropki zaczynając od góry my
objęte restartem wcześniej, kiedy musieliśmy
zrestartuj naszą powłokę w chmurze, jeśli jesteś w stanie
zarówno przesyłać, jak i pobierać plik w ramach
Cloud Shell, gdy potrzebne są wymagania
jak również, jeśli mam źle skonfigurowany
konfiguracji mogę uruchomić system w trybie awaryjnym
i rozwiązać problem zamiast konieczności
zacząć od zera ponownie przechodząc do
boost cloud shell znany również jako boost
tryb to funkcja, która zwiększa Twoje
Cloud Shell vm z domyślnego e2 small
do nośnika e2, a więc w istocie pamięci
podskoczyć z 2 gigabajtów do 4 gigabajtów i
po aktywacji wszystkich sesji
będzie wzmocniony przez następne 24 godziny
i tylko jako szybka notatka
włączenie trybu doładowania powoduje ponowne uruchomienie chmury
shell i natychmiast kończy twoje
sesja, ale nie martw się danymi w swoim
katalog domowy będzie się utrzymywał, ale dowolny z
procesy, które uruchamiasz, będą
zostać utracone, jeśli chodzi o limit wykorzystania
Cloud Shell jest używany przez 50 godzin tygodniowo
limit, więc jeśli osiągniesz limit użytkowania
musisz poczekać, aż wyczerpie się Twój limit
zresetować, zanim będzie można korzystać z usługi Cloud Shell
ponownie, więc zawsze dobrze jest zachować swoje
oczy na to, jeśli jesteś ciężkim użytkownikiem
skorupy chmury
i powrót do menu ponownie ty
mieć swoje statystyki użytkowania, które
zbiera statystyki dotyczące poleceń, które
są wstępnie zainstalowane w maszynie wirtualnej i możesz
je włączyć lub wyłączyć
a także pomoc dla Cloud Shell
dostępne również tutaj, jeśli chcesz
przekaż opinię zespołowi Google Cloud
w odniesieniu do Cloud Shell jest to
miejsce, aby to zrobić, a więc ostatnia rzecz
o Cloud Shell, zanim to zakończymy
demo polega na tym, że jeśli nie masz dostępu do chmury
shell przez 120 dni, twój dysk domowy będzie
zostać usunięte teraz, nie martw się
otrzymać powiadomienie e-mail przed jego
usunięcie i jeśli po prostu zalogujesz się i
rozpocząć sesję, zapobiegniesz temu
jest teraz usuwany, posuwając się naprzód w tym
oczywiście będę całkiem używał Cloud Shell
trochę, więc nie krępuj się używać
Cloud Shell lub Cloud SDK
na swoim komputerze lub zachęcamy do obserwowania
razem ze mną w skorupie chmury wewnątrz
Twoje środowisko Google Cloud i tak dalej
śledzisz, upewnij się
że pilnujesz swojego limitu i
więc mam nadzieję, że ta demonstracja dała
masz naprawdę dobry wgląd w to, co
możesz zrobić z Cloud Shell i jego
ograniczenia i tyle
wszystko, co chciałem w tym zawrzeć
demonstracja powłoki chmurowej, więc możesz
teraz zaznacz to jako zakończone i przejdźmy
Przechodząc do następnego
[Muzyka]
Witam ponownie w tej lekcji i
demonstracja, którą zamierzam przejść
limity i kontyngenty oraz ich wpływ
korzystanie z chmury w chmurze Google Jestem
szybko omówię teorię
a następnie demonstracja, dokąd
znaleźć limity i jak je edytować
odpowiednio, więc chmura Google wymusza
limity wykorzystania zasobów dla projektu
właściciele
ustalenie sztywnego limitu ilości a
konkretny zasób Google Cloud twój
projekt może użyć, więc są dwa
rodzaje wykorzystania zasobów, które google
limity z kwotą pierwszy to stawka
przydział, taki jak żądania interfejsu API dziennie this
przydział resetuje się po określonym czasie, np
jako minuta lub dzień jest drugi
kwota alokacji
przykładem jest liczba virtual
maszyny lub systemy równoważenia obciążenia używane przez Ciebie
projekt
i ten limit nie jest resetowany w czasie
ale muszą być wyraźnie zwolnione, kiedy ty
nie chcą już korzystać z tego zasobu
na przykład usuwając klaster gke
teraz kwoty są egzekwowane dla różnych
powody
na przykład chronią inne Google
użytkowników chmury, zapobiegając nieprzewidzianym sytuacjom
skoki użycia
kwoty pomagają również w zasobach
zarządzanie, dzięki czemu możesz ustawić własne
limity korzystania z usług w Twoim
przydziału podczas opracowywania i testowania twojego
Aplikacje
każdy limit kontyngentu jest wyrażony w kategoriach
określonego zasobu policzalnego z
żądań dziennie do api na numer
systemów równoważenia obciążenia używanych przez Ciebie
aplikacji nie wszystkie projekty mają
te same kontyngenty na te same usługi i tak dalej
korzystając z tego bezpłatnego konta próbnego, możesz
mają bardzo ograniczone kwoty w porównaniu do
wyższy limit na zwykłym koncie jako
dobrze z korzystaniem z Google Cloud Over
czasie Twoje limity mogą wzrosnąć
odpowiednio, więc możesz również poprosić
więcej limitu, jeśli go potrzebujesz i skonfiguruj
monitorowanie i alerty
i monitorowanie chmury, aby Cię ostrzec
nietypowe zachowanie związane z wykorzystaniem przydziału lub kiedy
faktycznie kończy Ci się limit
oprócz przeglądania kwoty podstawowej
informacje w konsoli
Google Cloud pozwala monitorować limit
stosowanie
ograniczenia i błędy w większej głębokości za pomocą
api i interfejs użytkownika do monitorowania chmury
z metrykami przydziału pojawiającymi się w
eksplorator metryk, możesz ich następnie użyć
metryki do tworzenia niestandardowych pulpitów nawigacyjnych i
alerty
pozwalając Ci monitorować wykorzystanie limitów
czas
i otrzymuj powiadomienia, gdy np
zbliżasz się do limitu przydziału tylko twój
usługi obsługujące metryki przydziału to
wyświetlane i tak popularne obsługiwane
usługi obejmują silnik obliczeniowy
przepływ danych
cloud spanner monitorowanie chmury i chmura
rejestrowanie wspólnych usług, które nie są
obsługiwane obejmują chmurę silnika aplikacji
pamięć masowa i chmura sql teraz jako uwaga
mieć świadomość, że limity kwot są aktualizowane raz
dzień
a zatem nowe limity mogą potrwać do 24
godzin do odzwierciedlenia w google
konsola w chmurze, jeśli Twój projekt przekracza
określony limit podczas korzystania z usługi
platforma zwróci błąd
ogólnie
Google Cloud zwróci http
Kod błędu 429, jeśli używasz protokołu http lub
odpocząć, aby uzyskać dostęp do usługi
lub zasoby wyczerpane, jeśli używasz
grpc, jeśli używasz monitorowania w chmurze
możesz go użyć do zidentyfikowania limitu
związane z błędem
a następnie utwórz niestandardowe alerty
otrzymanie błędu kwoty i tak będzie
zagłębiając się w temat
monitorowanie później w trakcie teraz
Istnieją dwa sposoby przeglądania bieżącego
limity przydziału w konsoli Google Cloud
pierwszy korzysta ze strony kwot, która
daje ci listę wszystkich twoich
wykorzystanie przydziału projektu i ogranicza
drugi to użycie pulpitu nawigacyjnego API, który
podaje informacje o przydziale dla a
konkretny interfejs API
w tym limit zużycia zasobów w czasie
limity są również dostępne
programowo za pośrednictwem usługi
use api, więc przejdźmy do
konsola, na której dostarczę
demonstracja
o tym, gdzie szukać kwot
i jak je zwiększyć, kiedy potrzebujesz
Do
i tak oto jesteśmy z powrotem w konsoli
i tak jak wyjaśniłem wcześniej są
dwa główne sposoby przeglądania bieżącego limitu
granice
w konsoli i tak jest pierwszy
korzystając ze strony kwot i tak w celu
przejdź do strony limitów, do której muszę przejść
iam, więc zamierzam to zrobić teraz, idąc
aż do menu nawigacyjnego u góry
lewy narożnik
idę do jestem i admin i
przejść do kwot
i tak oto pokazano mi wszystkie kwoty
obecny interfejs API, który włączyłem jako
możesz zobaczyć tutaj, pokazuje mi usługę
nazwa limitu
status kontyngentu i szczegóły w tym
pokazuje panel tutaj po prawej stronie
mi trochę więcej informacji z
w odniesieniu do usługi i kwoty
i powiedzmy, że chciałem
zwiększyć mój limit w silniku obliczeniowym
interfejs API
w sieciach, więc wybiorę
ta usługa i tutaj po prawej stronie
panel ręczny Zamierzam zaznaczyć pole
to mówi globalnie i idę
z powrotem tutaj w lewym górnym rogu
i kliknij przycisk edytuj limity i
pojawi się panel i pojawi się monit
wprowadź nowy limit przydziału
wraz z opisem wyjaśniającym
google, dlaczego potrzebuję tego limitu przydziału
zwiększyć i tak po ukończeniu mojego
wniosek
mogę kliknąć gotowe, a następnie przesłać
wniosek i jak powiedziałem wcześniej raz
wniosek został przesłany, do którego trafi
ktoś w google do oceny
prośby o zatwierdzenie i nie martw się
te wzrosty limitów kontyngentów są zwykle
zatwierdzone w ciągu dwóch dni roboczych i
często może być wcześniej niż to również
świetny sposób na wprowadzenie wielu kwot
zmiany polega na kliknięciu na wybrany apis
zróbmy api BigQuery
i api magazynu danych w chmurze, więc mam
kliknąłem trzy i teraz mogę wrócić
do góry i kliknij edytuj
kwot i jak widać w pliku
panel Mam wszystkie trzy API, które chcę
aby zwiększyć moje limity, abym mógł wejść
wszystkie moje nowe żądania limitów dla każdego interfejsu API
a następnie mogę przesłać go jako luzem
request z całym moim nowym limitem przydziału
zmiany, więc zrobienie tego w ten sposób
zwiększyć wydajność
zamiast zwiększać kwoty na
każda usługa jeden po drugim i dlatego, że jestem
nie zamierza zgłaszać żadnych zmian kwot
zamknę ten panel i tak dalej
ponowne użycie strony kwot da
Ci listę wszystkich limitów projektu
użytkowania i jego ograniczeń i pozwalają na to
żądać odpowiednich zmian i tak teraz
przejście do drugiej drogi, którą ty
może wyświetlić Twoje obecne limity przydziału
zamierzam przejść do pulpitu nawigacyjnego API, który
da mi bardziej szczegółowy widok
w tym zużycie zasobów w czasie
więc żeby się tam dostać, cofnę się
w lewą stronę do nawigacji
menu idę do apis i
usługi i kliknij pulpit nawigacyjny
i tutaj zobaczę wszystkie nazwy
apis i zamierzam kliknąć na obliczenia
API silnika dla tej demonstracji
a tutaj w menu po lewej stronie ty
zobaczą kwoty
i tutaj, jak już mówiłem
możesz uzyskać naprawdę szczegółowe dane
w odniesieniu do zapytań żądania odczytu
lista żądań i cała masa innych
próśb, w które zamierzam się zagłębić
zapytania tutaj i widzę moje zapytania
dziennie za 100 sekund na użytkownika i na
100 sekund i widzę, że mój
zapytań na 100 sekund jest na granicy
2 000, więc gdybym chciał to zwiększyć
limit mogę po prostu kliknąć ołówek
Ikona
a panel po prawej stronie będzie
wyświetla monit o wprowadzenie nowego limitu przydziału, ale
obecnie widzę, że mój limit przydziału wynosi
na maksimum i że muszę złożyć wniosek
dla wyższego limitu, więc kiedy klikam
link, który przeniesie mnie z powrotem do mojego iam
strona, na której filtrowane są moje usługi i
mogę łatwo znaleźć usługę, którą byłem
patrząc na podniesienie mojego limitu przydziału i ja
może zwiększyć limit, odznaczając go
to pole i klikając edytuj limity
przycisk u góry strony i tak dalej
możesz zobaczyć stronę kwot, jak również
pulpit nawigacyjny API działa w tandemie, dzięki czemu
możesz uzyskać wszystkie potrzebne informacje
w odniesieniu do kwot i limitów oraz do
edytuj je odpowiednio i mam nadzieję, że to
dał ci dobry pomysł i kilka świetnych
wgląd
o tym, jak możesz przeglądać i edytować swoje limity
i limitów kwotowych zgodnie z art
zasobów, których używasz i tak dalej
podsumowuje to krótkie, ale ważne demo
o limitach i przydziałach, abyś mógł teraz oznaczyć
to jako kompletne i przejdźmy do
następna sekcja
[Muzyka]
Witamy spowrotem
i w tej sekcji będziemy
przechodząc moim zdaniem przez jedną z
najważniejsze usługi w chmurze Google
zarządzanie tożsamością i dostępem również
znany jako iam w skrócie i będę
nurkowanie w role tożsamości i
architekturę polityki, która da
bardzo dobrze rozumiesz, jak to zrobić
przyznawane są uprawnienia i jakie są zasady
są dziedziczone, więc zanim wskoczę do jestem
chciałem dotknąć zasady
najmniejszego przywileju tylko na sekundę
zasada najmniejszych uprzywilejowanych stanów
że program użytkownika lub proces
powinien mieć dostęp do niezbędnego minimum
konieczne przywileje
lub dokładne zasoby, których potrzebuje w celu
pełnić swoją funkcję np
jeśli lisa wykonuje funkcję tworzenia
do zasobnika w chmurze
lisa powinna mieć ograniczone możliwości tworzenia
uprawnienia tylko na dokładnie jednej chmurze
wiadro do przechowywania
ona nie potrzebuje czytać, edytować ani nawet
usuń uprawnienia do magazynu w chmurze
wiadro do wykonywania swojej pracy i tak jest
świetna ilustracja tego, jak to jest
zasada działa
i to jest coś, co dzieje się w
nie tylko Google Cloud, ale w każdej chmurze
środowiskiem, jak również lokalnie
środowisko, więc pamiętaj, że zasada
najmniejszego przywileju to coś, co ja
były i będą
dużo mówić na tym kursie i
jest to kluczowy termin, który pojawia się dość często
fragment
na każdym ważnym egzaminie
i jest zasadą, która obowiązuje w większości
środowisko pracy, aby ich uniknąć
zbędnych udzielonych uprawnień a
dobrze znana i niewypowiedziana zasada, jeśli chodzi
do bezpieczeństwa, dlatego chcę dotknąć
to przez krótką chwilę, więc teraz z tym
z drogi, do której chciałbym przejść
zarządzanie tożsamością i dostępem lub jestem
w skrócie, więc z czym jest naprawdę dobrze
za pomocą którego zarządzasz kontrolą dostępu
określenie, kto jest tożsamością
ma jaki dostęp, dla którego jest rolą
który zasób i to również obejmuje
organizacje
foldery i projekty
w pozwoleniu na dostęp do zasobu
nie jest przyznawana bezpośrednio użytkownikowi końcowemu
zamiast tego uprawnienia są pogrupowane w
role i role są następnie przyznawane
uwierzytelnionym członkom zasady iam
definiuje i egzekwuje, czym są role
przyznane którym członkom
a niniejsza polityka jest dołączona do a
zasób, więc gdy uwierzytelniony członek
próbuje uzyskać dostęp do zasobu sprawdza iam
politykę zasobów do ustalenia
czy czynność jest dozwolona i tak dalej
mając to na uwadze, chcę się zanurzyć
architektura polityki ją rozbija
za pomocą elementów niniejszej polisy
architektura da ci lepsze
zrozumienia, w jaki sposób ustalane są zasady
razem, więc teraz jaka jest polityka a
policy jest zbiorem kontroli powiązań
konfiguracja i metadane teraz
powiązanie określa, jak powinien wyglądać dostęp
przyznawane na środki
i wiąże jednego lub więcej członków z a
pojedyncza rola i każdy konkretny kontakt
warunków, które zmieniają sposób i czas
rola jest teraz przyznawana metadanym
zawiera dodatkowe informacje nt
zasady, takie jak etag i wersja
w celu ułatwienia zarządzania polityką i
w końcu określa pole konfiguracji audytu
dane konfiguracyjne sposobu dostępu
próby powinny być audytowane i tak teraz, tj
chciałem poświęcić chwilę, aby zanurkować głębiej
do każdego komponentu, zaczynając od elementu
teraz, jeśli chodzi o członków, jest to
tożsamość, która może uzyskać dostęp do zasobu
więc tożsamość członka to e-mail
adres powiązany z użytkownikiem
konto usługi lub grupa google, a nawet
nazwa domeny powiązana z pakietem ag
lub domen Cloud Identity teraz, kiedy to
przychodzi do konta Google to
reprezentuje każdą osobę, z którą wchodzi w interakcję
Google Cloud dowolny adres e-mail, który jest
może być powiązany z kontem Google
tożsamość, w tym gmail.com lub inną
domen teraz kontem usługi jest
konto należące do Twojej aplikacji
zamiast indywidualnego użytkownika końcowego
więc po uruchomieniu kodu, który jest hostowany
na gcp
to jest tożsamość, którą chcesz określić
aby uruchomić kod, grupa Google to a
nazwana kolekcja kont Google i
może teraz obejmować również konta usług
zalety korzystania z grup Google
które możesz przyznać i zmienić
uprawnienia
do odbioru wszystkich rachunków o godz
raz zamiast zmieniać dostęp jeden po drugim
jedna grupa Google może pomóc Ci zarządzać
użytkowników na dużą skalę i każdy członek a
grupa google dziedziczy role iam
przyznano tej grupie spadek
oznacza, że ​​możesz korzystać z grupy
członkostwo, aby zamiast tego zarządzać rolami użytkowników
nadawania ról iam poszczególnym osobom
użytkownicy przechodzący do domen G Suite to
reprezentuje Internet Twojej organizacji
nazwa domeny, np
antonyt.com i kiedy dodajesz użytkownika do
Twojej domenie G Suite nowe konto Google
jest tworzony dla użytkownika wewnątrz tego
grupa wirtualna, taka jak antony
domena antonyt.com ag suite w
rzeczywistość reprezentuje wirtualną grupę
wszystkie konta Google, które mają
został stworzony jak Google Groups G Suite
domen nie można używać do ustanawiania
tożsamość, ale po prostu umożliwiają
zarządzanie uprawnieniami teraz w chmurze
domena tożsamości jest jak domena ag suite
ale różnica polega na tym, że użytkownicy domeny
nie masz dostępu do G Suite
aplikacje i funkcje, więc para
więcej członków, do których chciałem się zwrócić
to wszyscy uwierzytelnieni użytkownicy i
wszyscy użytkownicy są członkami wszystkich uwierzytelnionych
users to specjalny identyfikator, który
reprezentuje każdego, kto jest uwierzytelniony
z kontem Google lub usługą
użytkowników konta, którzy nie są uwierzytelnieni
takie jak anonimowi goście nie są
uwzględnieni i wreszcie wszyscy użytkownicy
członek jest specjalnym identyfikatorem, który
reprezentuje każdego i wszystkich, więc każdy
użytkownik, który jest w Internecie, w tym
uwierzytelnionych i nieuwierzytelnionych użytkowników
a to obejmuje zabójstwo
dotykają się teraz różne typy członków
kolejnym elementem polityki jest
role teraz zanurzają się w role, to jest
nazwany zbiór uprawnień, które
przyznaj dostęp do wykonywania działań na
zasoby Google w chmurze
więc sednem są uprawnienia
co decyduje o tym, czym są operacje
dozwolone dla zasobu, który zwykle ale
nie zawsze odpowiada jeden do jednego z
metody odpoczynku, czyli każda chmura Google
usługa ma powiązane uprawnienia do
każdą metodę odpoczynku, którą ma tak nazwać
metoda, której potrzebuje dzwoniący
pozwolenie teraz te uprawnienia nie są
przyznawane użytkownikom bezpośrednio, ale
zgrupowane w ramach roli ty
następnie przyznałby role, które zawierają jedną
lub więcej uprawnień
możesz także utworzyć niestandardową rolę według
połączenie jednego lub więcej z dostępnych
iam uprawnienia i ponownie uprawnienia
umożliwić użytkownikom wykonanie określonych czynności
w zasobach Google Cloud, więc będziesz
zazwyczaj zobaczyć pozwolenie, takie jak
jeden, który tu widzisz
oblicz.instancje.lista
oraz w ramach uprawnień Google Cloud IAM
są reprezentowane w tej postaci
usługa.zasób.czasownik
więc jako podsumowanie ról jest to a
zbiór uprawnień
i nie możesz udzielić pozwolenia
bezpośrednio do użytkownika, ale przyznajesz
rolę użytkownikowi i wszystkie uprawnienia
że rola zawiera, więc jest to przykład
pokazano tutaj, gdzie wystąpienia obliczeniowe
uprawnienia są pogrupowane w a
roli, dzięki której możesz teraz nadawać uprawnienia
nadanie ról użytkownikowi grupy lub a
konto usługi, więc przejście do więcej
szerszym poziomie istnieją trzy rodzaje
role w IAM
istnieją prymitywne role
predefiniowane role
i niestandardowe role
z prymitywnymi rolami
są to role, które istniały wcześniej
wprowadzenie iam
i składają się z trzech określonych ról
właściciel, redaktor i przeglądający oraz te role
są koncentryczne, co oznacza, że
rola właściciela obejmuje uprawnienia w
rola redaktora i rola redaktora
obejmuje uprawnienia w przeglądarce
role i możesz zastosować prymitywne role
w zasobie projektu lub usługi
poziomy za pomocą konsoli api i
narzędzie gcloud tylko jako notatkę
nie może przyznać członkowi roli właściciela
dla projektu korzystającego z interfejsu API iam lub
narzędzie wiersza poleceń gcloud, które możesz tylko
dodawać właścicieli do projektu za pomocą chmury
konsola też
Google zaleca unikanie tych ról
jeśli to możliwe ze względu na charakter sposobu
dużo dostępu, w którym nadawane są uprawnienia
te konkretne role zalecane przez Google
w których używasz predefiniowanych ról
prymitywne role i tak wchodzić
predefiniowane role
są to role, które dają szczegółowe i
bardziej szczegółową kontrolę dostępu niż
prymitywne role do określonej chmury Google
zasoby i zapobiegać niechcianym
dostęp do innych predefiniowanych zasobów
role są tworzone i utrzymywane przez
google ich uprawnienia są
automatycznie aktualizowane w razie potrzeby, kiedy
dodawane są nowe funkcje lub usługi
Google Cloud teraz, jeśli chodzi o niestandardowe
role są zdefiniowane przez użytkownika i dozwolone
możesz spakować jeden lub więcej obsługiwanych
uprawnień, aby spełnić Twoje specyficzne potrzeby
w przeciwieństwie do ról predefiniowanych są role niestandardowe
nie jest obsługiwany przez Google, więc gdy jest nowy
uprawnienia lub usługi są
dodałeś do Google Cloud swoje niestandardowe role
nie będą aktualizowane automatycznie, kiedy
tworzysz niestandardową rolę, którą musisz wybrać
organizacji lub projektu, aby go utworzyć
w możesz następnie przyznać niestandardową rolę
organizacji lub projektu, jak również
żadnych zasobów w ramach tej organizacji
lub projekt i tylko jako notatkę nie możesz
tworzyć niestandardowe role na poziomie folderów
jeśli chcesz użyć niestandardowej roli w ramach
folder zdefiniuj niestandardową rolę na
rodzic tego folderu, a także custom
Dostępny jest tylko interfejs użytkownika ról
użytkownikom, którzy mają uprawnienia do tworzenia
lub domyślnie zarządzaj rolami niestandardowymi
właściciele projektów mogą teraz tworzyć nowe role
jest jedno ograniczenie, które chciałem
zwrocic uwage
i to jest to, że niektóre predefiniowane role
zawierać uprawnień, których nie ma
dozwolone w niestandardowych rolach, więc bardzo
Radzę sprawdzić, czy możesz
użyj określonego pozwolenia podczas tworzenia
rola niestandardowa role niestandardowe mają również
naprawdę fajna funkcja, która obejmuje
etap uruchamiania, który jest przechowywany w
właściwość stage dla roli, jaką pełni scena
informacyjny i pomaga śledzić
od tego, jak blisko jest każdej roli
ogólnie dostępne i te uruchamiają się
etapy są dostępne w przedstawionych etapach
Tutaj
alfa, która jest w fazie testów beta, która jest
przetestowane i oczekujące na zatwierdzenie oraz
oczywiście ga, który jest ogólnie dostępny
i będę miał do czynienia później
te role w nadchodzącej demonstracji
więc teraz przechodzimy do następnego komponentu
jest warunkami, więc warunkiem jest a
wyrażenie logiczne i służy do definiowania
i egzekwować
warunkowy
kontrola dostępu oparta na atrybutach dla
na jakie pozwalają warunki zasobów Google Cloud
ty do wyboru
nadawanie zasobom dostępu do tożsamości
znane również jako członkowie tylko wtedy, gdy są skonfigurowane
spełnione są warunki np
można zrobić, aby skonfigurować tymczasowe
dostęp dla użytkowników będących kontrahentami
i otrzymały specjalny dostęp
określony czas warunek
można umieścić w celu usunięcia
dostępu, którego potrzebowali po zawarciu umowy
zakończone warunki są określone w
powiązania ról polityki im zasobów
więc gdy warunek istnieje, dostęp
wniosek jest spełniony tylko wtedy, gdy spełniony jest warunek
wyrażenie jest prawdziwe, więc teraz przejdźmy do
metadane, które ten komponent zawiera zarówno e
tagi i wersja, więc najpierw dotykając e
gdy wiele systemów próbuje pisać do
ta sama polityka im w tym samym czasie
istnieje ryzyko, że systemy te mogą
nadpisać nawzajem swoje zmiany i
istnieje ryzyko, ponieważ aktualizacja pliku im
polisa obejmuje wiele operacji tzw
aby zapobiec temu problemowi iam
obsługuje kontrolę współbieżności za pośrednictwem
użycie pola etag w polityce
wartość tego pola zmienia się za każdym razem a
polityka jest teraz aktualizowana, jeśli chodzi o a
wersja
jest to dodany numer wersji
określić cechy, np
stan
oraz dla przyszłych wydań nowych funkcji
jest również używany, aby uniknąć złamania twojego
istniejące integracje z nową funkcją
wydania, które opierają się na spójności w
struktura polityki
również wtedy, gdy są nowe wersje schematu polityki
wprowadzone i wreszcie mamy
składnik auditconfig i jest on używany
w celu skonfigurowania rejestrowania inspekcji dla
polityka, którą określa
typy uprawnień są rejestrowane i jakie
tożsamości, jeśli są wyłączone
logging, a więc podsumowując, jest to a
polityki w całości
komponent, jak widać, gra a
inna część i pójdę
poprzez polityki i jakie są
zebrane w oświadczenia w późniejszym
lekcja, a więc jest jeszcze jedna rzecz
których chciałem dotknąć przed zakończeniem
ta lekcja i taka jest polityka
dziedziczenie, jeśli chodzi o zasoby
hierarchia i tak jak wyjaśniono w an
z wcześniejszej lekcji możesz ustawić politykę im
na dowolnym poziomie w hierarchii zasobów
poziom organizacji poziom folderów
poziom projektu lub poziom zasobów
a zasoby dziedziczą zasady programu
wszystkie ich zasoby macierzyste są skuteczne
zasady dotyczące zasobu
jest zjednoczeniem ustalonej na ten temat polityki
zasobu i odziedziczonych zasad
wyżej w hierarchii i tak dalej
chciałem powtórzyć, że ta polityka
Innymi słowy, dziedziczenie jest przechodnie
zasoby dziedziczą zasady z
projekt
które dziedziczą zasady z folderów
które dziedziczą zasady z
organizacja, więc organizacja
polityki na poziomie
stosuje się również na poziomie zasobów i tak dalej
tylko szybki przykład, jeśli zastosuję zasady
w projekcie X
na wszelkie zasoby w ramach tego projektu
skuteczną polityką będzie unia
tych polityk, w zależności od zasobów
odziedziczyć przyznaną polisę
projekt x, więc mam nadzieję, że to dało ci
lepsze zrozumienie tego, jaka jest polityka
przyznane, a także strukturę kursu
i to wszystko, co mam na tę lekcję
więc możesz teraz oznaczyć tę lekcję jako
zakończyć i przejść do następnego
jeden
[Muzyka]
witaj z powrotem iw tej lekcji chciałem
opierać się na ostatniej lekcji, w której my
przeszedł przez iam i architekturę polityki
i zagłębić się w politykę i
warunki przy ich stawianiu
razem w deklaracjach zasad jako chmura
inżynierów, których powinieneś umieć czytać i
rozszyfrować deklaracje polityczne i
zrozumieć, w jaki sposób są one łączone
przy użyciu wszystkich komponentów, które my
omówione wcześniej, tak dla odświeżenia
Chciałem przejść do polityki
architektura ponownie teraz, jak omówiłem
poprzednio zasady były zbiorem
instrukcje określające, kto ma jaki typ
dostępu jest dołączony do zasobu
i służy do wymuszania kontroli dostępu
za każdym razem, gdy ten zasób jest teraz dostępny
wiązanie w ramach tej polityki wiąże jedno
lub więcej członków z jedną rolą i
wszelkie warunki specyficzne dla kontekstu, więc w
innymi słowy role członków i
warunki są ze sobą powiązane za pomocą a
powiązanie połączone z metadanymi i
audyt config mamy politykę, więc teraz
wziąć to wszystko i umieścić
razem w przedstawionym oświadczeniu dotyczącym polityki
tutaj możesz zobaczyć wiązania, które mają
rola członków i warunki
pierwszym członkiem jest Tony Beautys
gmail.com pełniący rolę magazynu
admin i drugi członek jako
larkfetterlogowanie na gmail.com
pełniący rolę obiektu magazynowego
widza teraz, ponieważ skowronek tylko musi
przeglądaj pliki tego projektu w chmurze
przechowywanie do nowego roku warunkiem
zastosowano, że nie przyznaje
dostęp dla lark, aby wyświetlić te pliki
po 1 stycznia pojawił się e-tag
umieścić, a wersja ma numer 3
do stanu, w który się wprowadzę
nieco później niniejsze oświadczenie o polityce
została ustrukturyzowana w formacie json i
jest powszechnym formatem używanym w zasadach
stwierdzenia poruszające się mamy dokładne
to samo oświadczenie polityczne, ale było
sformatowany w yaml, jak widać
role i warunki członków w
wiązania są dokładnie takie same, jak również
Etag i wersja, ale ze względu na
formatowanie jest znacznie bardziej skondensowane
jak widać, deklaracje polityczne mogą być
napisane w zależności od json lub yaml
według twoich preferencji moje osobiste
wolę napisać moją politykę
instrukcje w yaml ze względu na krótsze
i czystszy format, więc będę się przenosić
przodu w tym kursie z więcej
instrukcje napisane w yaml, kiedy jesteś
chce zapytać o twoje projekty
przyznane polisy
łatwym sposobem na to byłoby zapytanie
go z wiersza poleceń, jak pokazano tutaj
tutaj zrobiłem zrzut ekranu od tony'ego
asa muszki w skorupie chmury i mieć
użył polecenia get projektów gcloud
kreska mam
policy z identyfikatorem projektu i tym
wychował wszystkich członków i role
w ramach wiązań
jak również etag i wersję dla
polityki, która została do tego dołączona
project i jak widać tutaj mam
żadnych warunków dla żadnego z moich
powiązania i tak ponownie za pomocą polecenia
projekty gcloud
pobierz zasady dash iam dash wraz z
identyfikator projektu wyświetli wszelkie zasady
które są dołączone do tego zasobu i
zasób jest identyfikatorem projektu, jeśli
zasób miał być wtedy identyfikatorem folderu
możesz użyć polecenia gcloud
menedżer kresek zasobów
foldery otrzymują myślnik iam-policy
z identyfikatorem folderu i dla organizacji
poleceniem byłoby gcloud
organizacje dostają kreskę
iam-policy wraz z organizacją
id teraz, ponieważ nie mamy żadnych folderów
lub organizacji w naszym środowisku
wpisanie tych poleceń nie przyniesie
coś i tylko jako notatkę za pomocą
te polecenia w powłoce chmury lub w
sdk wyświetli zasady
instrukcja sformatowana w yaml, więc teraz i
chciałem tylko poświęcić chwilę na nurkowanie
do wersji zasad, tak jak ja tego nie zrobiłem
szczegółowo omówione wersje, które chciałem
szybko omówić to i powody
każda numerowana wersja teraz wersja pierwsza z
schemat składni i am dla zasad
obsługuje powiązanie jednej roli z jedną lub więcej
członkowie
nie obsługuje roli warunkowej
powiązania i tak zwykle z wersją 1
nie zobaczysz żadnej wersji warunków
2 jest używany do wewnętrznego użytku Google i
więc zapytanie o zasady
zwykle nie zobaczysz wersji 2.
i wreszcie z wersją 3 this
wprowadza pole warunku w pliku
powiązanie roli, które ogranicza rolę
wiązanie poprzez przestrzeń kontaktową i atrybuty
oparte na zasadach, więc tylko jako notatkę, jeśli twój
żądanie nie określa zasad
wersja
Zakładam, że chcesz wersję
1 polisa i ponownie, jeśli polisa ma
nie zawierać żadnych warunków
wtedy iam zawsze zwraca wersję pierwszą
zasad niezależnie od numeru wersji
we wniosku, więc przechodząc do niektórych
ograniczenia polityki, jakie może mieć każdy zasób
mają tylko jedną polisę, która obejmuje
foldery i projekty organizacji
kolejne ograniczenie
jest to, że każda polityka iam może zawierać maksymalnie
do 1500 członków
i do 250 takich członków
mogą być grupami Google teraz podczas tworzenia
zmiany polityki zajmie to do siedmiu
minut, aby w pełni rozprzestrzenić się w całym
platforma Google Cloud to nie działa
dzieją się natychmiast, ponieważ iam ma charakter globalny
jest też limit 100
warunkowe powiązania ról na zasady
zagłębiając się trochę
warunki
są to atrybuty, które są albo
na podstawie zasobów lub na podstawie szczegółów
o prośbie, a to może się różnić
od znacznika czasu do pochodzenia lub
docelowy adres IP teraz jako ty
prawdopodobnie słyszał, jak użyłem tego terminu wcześniej
warunkowe powiązania ról to inna sprawa
nazwa zasady zawierającej warunek
w ramach wiążącej roli warunkowej
powiązania można dodawać do nowych lub istniejących
zasady iam
w celu dalszej kontroli dostępu do Google
zasobów w chmurze, jeśli chodzi o
atrybuty zasobów, które by to umożliwiły
stworzyć warunki, które oceniają
zasobu w żądaniu dostępu
w tym typ zasobu zasób
nazwa i nazwa usługi Google Cloud
pozwalają na to używane atrybuty żądania
zarządzać dostępem na podstawie dni lub godzin
tydzień może warunkowe wiązanie roli
być używany do udzielania dostępu ograniczonego w czasie
zasób zapewniający, że użytkownik nie może
dłuższy dostęp do tego zasobu po
określoną datę i godzinę wygaśnięcia oraz to
ustawia tymczasowy dostęp do chmury Google
zasobów przy użyciu roli warunkowej
powiązania w zasadach iam za pomocą
pokazanych tutaj atrybutów daty i godziny, możesz
egzekwować kontrole oparte na czasie, kiedy
wyświetlanie dostępu do danego zasobu
kolejny przykład działania opartego na czasie
stanie można się wyrównać
bardziej szczegółowe i obejmują zasięg geograficzny
region
wraz z dniem i godziną dostępu
w tej polityce dostęp ma tylko skowronek
w godzinach pracy, aby wyświetlić dowolne
obiekty w chmurze skowronek może
dostęp do tych obiektów tylko od poniedziałku do godz
piątek od dziewiątej do piątej ta polityka może również
służyć za doskonały przykład
kontrahentów wchodzących do Twojej firmy
ale potrzebuje dostępu tylko podczas pracy
godzin teraz przykład oparty na zasobach
pokazany tutaj warunek ma członek grupy
warunek związany z nim, gdzie tylko dev
dostęp został wdrożony dowolny
programistów należących do tej grupy
będzie miał dostęp tylko do zasobów maszyny wirtualnej
w ramach projektu muszki dla kota i zawiązane
wszelkie zasoby, których nazwa zaczyna się od
słowo rozwój teraz trochę
ograniczenia, jeśli chodzi o warunki
jest to, że warunki są ograniczone do
określone usługi
prymitywne role nie są obsługiwane i
członkowie nie mogą należeć do wszystkich użytkowników lub
wszystkich uwierzytelnionych członków użytkowników
warunki mają również limit 100
warunkowe powiązania ról na politykę jako
a także 20 powiązań ról dla tego samego
rola i ten sam członek i tak na koniec
część oświadczeń politycznych, których chciałem
dotknąć dzienników konfiguracji audytu i tego
określa konfigurację audytu dla a
usługi określa konfiguracja
jakie typy uprawnień są rejestrowane i
z jakich tożsamości, jeśli w ogóle, są zwolnione
rejestrowania i podczas określania audytu
configs muszą mieć co najmniej jeden audyt
zaloguj konfiguracje teraz, jak pokazano tutaj
ta polityka umożliwia odczyt danych i zapis danych
i administrator czytają logowanie we wszystkich usługach
jednocześnie wyłączając Tony'ego Bowtie Ace
gmail.com
od administratora odczytywanie logowania w chmurze
i to właściwie wszystko, czego chciałem
omówić w tej lekcji
w sprawie zasad oświadczeń politycznych
i warunki, więc bardzo polecam
gdy natkniesz się na więcej zasad
przeczytanie oświadczeń wymaga czasu
go i poznać dokładnie
do czego odnosi się to stwierdzenie i
jakie uprawnienia są przyznawane
a to pomoże Ci nie tylko w
egzaminu, ale także pomoże ci w czytaniu
i pisanie oświadczeń politycznych w przyszłości
i to wszystko, co mam na tę lekcję
więc możesz teraz oznaczyć tę lekcję jako
zakończyć i przejść do następnego
jeden
[Muzyka]
Witamy spowrotem
i w tej demonstracji mam zamiar
zrób praktyczną wycieczkę, pracując z iam tutaj
w konsoli Google Cloud idziemy
przeglądać dostępne usługi w
konsola iam, a także dotykanie
wiersz poleceń w powłoce chmury do
pokaż, jak zasady mogą być zarówno dodawane, jak i
zredagowane, które również przywieziemy
w innym nowym użytkowniku, aby naprawdę to przyniósł
demo do życia i pokazać, jak edytować
istniejące zasady, więc z tym jest
powiedział, zanurkujmy, więc jeśli pójdę tutaj
do mojej ikony użytkownika w prawym górnym rogu
rogu widzę, że jestem zalogowany jako
tony muszka as
gmail.com i jak widać na górze
Jestem tutaj w projekcie Tony, więc teraz do zdobycia
do iam mam zamiar przejść do
Menu nawigacji
i zamierzam przejść do jestem w admin i
nad do iam teraz ruszam nad tutaj do
menu po lewej stronie, przez które chciałem przejść
różne opcje, które mamy
jestem, więc pod samym iam to jest gdzie
dodawałbyś lub edytował uprawnienia
w odniesieniu do członków i ról dla
polityka dodana do Twojego projektu
co w moim przypadku to projekt tony i
Wrócę za chwilę
bardziej szczegółowo w odniesieniu do dodawania
i edytowanie uprawnień zasad
przechodząc do tożsamości i organizacji
teraz, chociaż nie dotknęliśmy chmury
tożsamość, ale omówię to w
wysoki poziom szczegółowości w innej lekcji
ale na razie wiedz, że tożsamość w chmurze jest
tożsamość chmury Google jako usługi
rozwiązanie i pozwala tworzyć i
zarządzać użytkownikami i grupami w Google
cloud teraz, jeśli byłem zalogowany do chmury
tożsamości, których miałbym całą masę
opcje tutaj, ale ponieważ jest to a
konta osobistego, którego nie mogę utworzyć lub
zarządzaj także użytkownikami, których nie mam
domena powiązana z dowolną tożsamością w chmurze
konto, a także dowolne konto G Suite
więc po prostu wiedz, że gdybyś miał chmurę
tożsamości lub G Suite
mieć kilka różnych opcji
wybrać, aby pomóc Ci zarządzać
Twoi użytkownicy i grupy oraz tutaj poniżej
zasady organizacji
Potrafię zarządzać polityką organizacji
ale ponieważ nie jestem organizacją
administrator polityki i nie mam
organizacja, niewiele mogę
tutaj po prostu wiedz, że kiedy masz
organizacji, możesz przyjść
tutaj, aby zarządzać i edytować swoje
zasady organizacji, które teraz przechodzą
kwot, omówiliśmy to trochę
szczegółowo w poprzedniej lekcji i ponownie
ma to na celu edycję dowolnych kwot dla dowolnego z
Twoje usługi na wypadek, gdybyś potrzebował limitu
zwiększyć przejście do kont usług
będę omawiać ten temat w wielkim
głębokość w późniejszej lekcji i będziemy
przechodzi przez praktyczną demonstrację
jak również teraz wiem, że nie dotknąłem
jak dotąd wiele na etykietach, ale wiedz o tym
etykiety to para klucz-wartość, która pomaga
organizujesz, a następnie filtrujesz swoje
zasobów w oparciu o ich etykiety te
te same etykiety są również przekazywane do Ciebie
system rozliczeniowy, dzięki czemu możesz się złamać
obniżyć opłaty rozliczeniowe według etykiety i
możesz także używać etykiet opartych na zespołach
komponenty centrów kosztów, a nawet
środowiska
więc na przykład, gdybym chciał oznaczyć etykietę my
maszyny wirtualne według środowiska, które mogę
po prostu użyj environment jako klucza i as
wartość, od której mogę użyć czegokolwiek
rozwój
do qa
do testowania
do produkcji i mógłbym po prostu dodać
tę etykietę i dodaj wszystko inne
środowiskach, a później będę mógł
teraz zapytanie oparte na tych konkretnych etykietach
dobrą zasadą jest etykietowanie wszystkich
swoje zasoby tak, że w ten sposób jesteś
w stanie je znaleźć o wiele łatwiej i
możesz o wiele łatwiej ich zapytać
więc posuwając się naprzód z każdym z twoich
upewnij się, że tworzysz zasoby
dodać kilka etykiet, aby uzyskać maksimum
elastyczność, więc odrzucę
te zmiany i idziemy dalej
do ustawień i dotknęliśmy ustawień
we wcześniejszej lekcji dotyczącej
projekty i tak tutaj mogłem zmienić
nazwa projektu, poda mi projekt
id numer projektu i jestem w stanie
przeprowadź migrację lub zamknij projekt teraz
jeśli chodzi o przejrzystość dostępu
zapewnia to przechwytywanie dzienników
działania podejmowane przez personel Google
kiedy uzyskują dostęp do Twoich treści
rozwiązywanie problemów, aby były jak chmura
dzienniki kontrolne, ale pomoc Google jest już dostępna
w celu umożliwienia przejrzystości dostępu dla
Twoja organizacja Google Cloud
Twoje konto Google Cloud musi mieć
plan wsparcia premium lub minimalny poziom
planu wsparcia 400 miesięcznie i
bo nie mam tego to bym nie był
w stanie włączyć przejrzystość dostępu teraz
chociaż przezroczystość dostępu nie jest włączona
egzamin
jest to świetna funkcja, o której warto wiedzieć w
w przypadku, gdy pracujesz w większym
środowisk, które mają takie wsparcie
plany i zgodność są najważniejsze
znaczenie teraz przechodzi do prywatności i
bezpieczeństwo to miejsce, w którym dostarcza google
wszyscy ich klienci Google Cloud
zgodność, której potrzebują, aby to zrobić
spełniają przepisy na całym świecie i
w różnych branżach, takich jak służba zdrowia
opieka i edukacja oraz ponieważ google
ma szeroką bazę w Europie google
zapewnia możliwości i umowy
zobowiązania utworzone w celu spełnienia danych
zalecenia dotyczące ochrony, dlatego
możesz zobaczyć tutaj wzór umowy ue
klauzule
oraz kontakty z przedstawicielami UE
pod przejrzystością i kontrolą jestem w stanie
aby wyłączyć dane użytkowania, które google
zbiera w celu dostarczenia lepszych danych
spostrzeżenia i rekomendacje i to jest to
wykonane na poziomie projektu, a także i
mieć możliwość przejścia do mojego
konto rozliczeniowe i mogłem wybrać
inne połączone konto rozliczeniowe
do innych projektów, które możesz zdobyć
zalecenia w sprawie i tak dalej
jest serwer proxy rozpoznający tożsamość
coś, co omówię w
późniejsza lekcja, więc nie dostanę
w szczegóły na ten temat teraz i
więc tak naprawdę chciałem się zagłębić
role teraz może to wyglądać znajomo jako i
poruszył ten temat bardzo krótko w A
poprzednia lekcja i oto, gdzie mogę
tworzyć role
mogę utworzyć niestandardowe role z
różne wybory i tutaj mam
dostęp do wszystkich uprawnień
a gdybym chciał, mogę odfiltrować
z różnych typów nazwy
uprawnienia, nawet status, powiedzmy
Szukałem konkretnego pozwolenia
i szukam wszystkich uprawnień
projekty, które mogłyby mi pomóc dokładnie znaleźć
czego szukam i
te filtry pozwalają mi naprawdę
szczegółowe, abym mógł znaleźć dokładne
pozwolenie i tak naprawdę możesz dostać
szczegółowy w odniesieniu do twojego
uprawnienia i tworzyć role, które są
dostosowane do Twojego środowiska, teraz idziemy dalej
do audytu dzienników tutaj mogę włączyć auto
dzienniki bez konieczności używania określonego
zasady, po prostu klikając opcję domyślna
autoconfig i tutaj mogę włączyć i
wyłączony
wszystkie wybrane rejestracje
a także dodaj teraz wszystkich zwolnionych użytkowników, tj
nie zalecamy ich włączania
ponieważ rejestrowanie inspekcji może stworzyć wyjątkowo
dużą ilość danych i może szybko
przedmuchaj wszystkie swoje 300 kredytów, więc
zamierzam to powstrzymać i wrócić do
główny ekran dzienników audytu i as
dobrze tutaj jestem w stanie uzyskać naprawdę
szczegółowo o tym, co chcę teraz zalogować
szybko dotykając dzienników kontroli w
wiersz poleceń, który chciałem szybko otworzyć
Cloud Shell i pokaż przykład
jak mogę edytować zasady, aby to zrobić
włącz rejestrowanie inspekcji, które właśnie zamierzam zrobić
ten trochę większy
i zamierzam wkleić moje polecenie
projekty gcloud otrzymują myślnik iam
polityka myślników
z identyfikatorem projektu, który jest projektem
tony
286016 i po prostu wcisnę enter
i jak widać tutaj to jest moje
aktualnej polityki i zgodnie z oczekiwaniami
dzienniki inspekcji nie są włączone z powodu
fakt, że pole konfiguracji audytu nie jest
obecny, abym mógł włączyć
dzienniki konfiguracji audytu, które będę musiał
edytuj politykę i tak najłatwiej
dla mnie, aby to zrobić, jest dla mnie uruchomieniem
to samo polecenie i wyślij je do pliku
gdzie mogę to edytować i zamierzam to zrobić
nazwij to
nowa polityka kresek kropka yaml i tak teraz
moja polityka została do tego wyprowadzona
plik, który zamierzam teraz przejść do edytora
i jak widać moja nowa policy.yaml jest
tutaj i tak dla mnie, aby umożliwić
dzienniki autoconfig zamierzam po prostu
dołącz go do pliku, a potem idę
aby przejść tutaj do górnego menu
i kliknij plik i zapisz i tak teraz
abym zastosował tę nową politykę
wracamy do terminala
a teraz wkleję
Komenda
Projekty gcloud ustawiają myślnik
iam-policy z identyfikatorem projektu i plikiem
nazwa pliku nowa polityka kresek kropka yaml i
po prostu wcisnę enter
i jak widać konfiguracje dziennika kontroli
zostały włączone dla wszystkich usług i
ponieważ może to zająć trochę czasu
odbicie w konsoli nie pokaże
od razu, ale tak czy inaczej dzienniki kontroli
zwykle zajmują dużo danych i ja
nie chcę przepuścić moich 300 kredytów
więc zamierzam je teraz wyłączyć
najłatwiejszym sposobem, aby to zrobić, jest
wyślij tę politykę do innej edycji pliku
go i ustawić ponownie, więc zamierzam to zrobić
Śmiało, zrób to, co ja zrobię pierwszy
wyczyść ekran, a potem idę
wklej moje polecenie podczas wysyłania go
do nowego pliku o nazwie zaktualizowane zasady kreski
kropka yaml, a ja wcisnę enter i teraz
Wejdę do edytora, więc mogę
edytuj plik teraz jedyną rzeczą, której chciałem
podkreślić, że mogłem
nadpisane
plik new dash policy, ale jeśli spojrzysz
tutaj w zaktualizowanej polityce e-tag
jest inny niż e-tag w starym
politykę, więc to mi pozwoliło
zaznacz e-tagi, jeśli chodzi o
edytowanie i tworzenie nowych polityk itp
podczas edytowania zasad upewnij się, że plik
etag jest poprawny, w przeciwnym razie będziesz
otrzymać błąd i nie można ustawić
nowa polityka, więc wracając do
zaktualizowany plik zasad, który zamierzam wziąć
out konfiguracje dziennika kontroli i idę
aby pozostawić tam pole auto configs
i mam zamiar przejść do menu kliknij na
plik, a następnie zapisz, teraz idę
nazad do terminala i ja jadę do
wklej nowe polecenie i to będzie
zaktualizować moją politykę i jak widać
dzienniki konfiguracji inspekcji zostały wyłączone i
polityka została zaktualizowana teraz to jest
ten sam proces, którego możesz użyć kiedy
chcesz zaktualizować dowolne części programu
polityki, jeśli chodzi o członków lub
role, a nawet dodanie wszelkich warunków
teraz przechodzimy do ostatniego elementu na
menu
to grupy
i jak widać tutaj, bo ja nie
mieć organizację, której ja nie jestem w stanie
wyświetl dowolne grupy, a więc gdybym miał
organizacja, w której mogłem zarządzać swoimi grupami
tutaj, na tej stronie, teraz cofając się
do iama
chciałem zagłębić się w politykę w
trochę więcej szczegółów teraz, co my
zobacz tutaj są uprawnienia i role
które zostały przyznane wybranym
członków w tym konkretnym projekcie, który
to projekt tony, teraz pamiętaj im
polityka jest całkowitym zbiorem członków
w których przypisano im role
co jest znane jako wiązanie, a następnie
wiązanie jest stosowane do tej warstwy i wszystkich
inne warstwy pod nim i odkąd jestem
w warstwie projektu ta polityka jest
dziedziczone przez wszystkie zasoby
pod nim i tak tylko w celu sprawdzenia
przez wiersz poleceń, do którego zamierzam
otwórz powłokę chmurową
i zamierzam wkleić polecenie
projekty gcloud otrzymują kreskę
iam-policy z moim identyfikatorem projektu
i wciskam enter
i jak widać tutaj polityka jest
odbicie dokładnie tego, co tutaj widzisz
w konsoli, jak widać tutaj
oto agent serwisowy, którego chcesz
znajdź tutaj i dwie pozostałe usługi
kont, które znajdziesz powyżej
a także Tony Bowtie Ace gmail.com i
wszystkie inne role, które im towarzyszą
członków, tak jak wspomniałem wcześniej
poszedł dalej i utworzył nowego użytkownika i tak dalej
dla tych, którzy idą za tobą
może iść dalej i śmiało tworzyć
nowy użytkownik Gmaila teraz to robi
demonstracja użytkownika, którego stworzyłem
o imieniu laura zachwycająca, teraz potrzebny tony
dodatkową rękę i postanowił ją zabrać
do zespołu z innego działu
teraz niestety żeby Laura mogła
pomóż Tony w projekcie, którego potrzebuje
dostęp do tego projektu i jak możesz
zobacz, że nie ma żadnego dostępu i tak dalej
idziemy dalej i to zmienimy
i dać jej dostęp do tego projektu tzw
zamierzam wrócić do mojej otwartej karty
dla Tony'ego Bowtie Ace'a i idziemy
naprzód i dać laura uprawnienia i tak
Pójdę dalej i kliknę to dodanie
przycisk u góry strony i
Monit poprosi mnie o dodanie nowego członka
więc teraz dodam tu Laurę
a oto ona i mam zamiar wybrać
rola
jako przeglądający projekt nie zamierzam dodawać
żadnych warunków i po prostu zamierzam
kliknij Zapisz, a polityka została
zaktualizowane i jak widać tutaj laura
otrzymał rolę projektu
widza, więc przechodzę do
inna otwarta karta, w której znajduje się konsola Laury
open i zamierzam po prostu zrobić a
odświeżać
a teraz Laura ma dostęp do wszystkich
zasoby w ramach projektu tony now laura
jest w stanie zobaczyć wszystko w
projekt, ale Laura nie jest w stanie tego zrobić
zrobić cokolwiek i tak, aby Laura mogła
załatwianie spraw to duża część jej pracy
będę tworzyć pliki za pomocą new
pomysły na jesienno-zimową linię łuku
więzi w 2021 r., a więc dlatego, że Laura trzyma
rolę obserwatora projektu, jaką jest w stanie pełnić
zobacz wszystko w chmurze oprócz niej
nie może tworzyć zasobników
aby przesłać edytować lub usunąć dowolne pliki lub
nawet foldery i jak widać tutaj
jest folder oznaczony jako bowtie inc
pomysły na jesień-zimę 2021, ale Laura nie może
tworzyć nowe zasobniki, ponieważ ona
nie ma wymaganych uprawnień jako
wiercenie studni w tym wiadrze
Laura nie może utworzyć żadnych folderów jako
wyjaśnił wcześniej
i to samo oznacza przesyłanie dowolnych
plików, więc mam zamiar anulować
to i tak, aby dać Laurze
odpowiednie uprawnienia do wykonywania jej pracy
oddamy Laurze magazyn
rola administratora i powrót do
otwarta konsola dla Tony Bowtie I'm
zamierza dać Laurze dostęp za pomocą
wiersz poleceń, więc zamierzam przejść do
w prawym górnym rogu i otwórz Cloud Shell
a więc polecenie, które muszę uruchomić
powierzyć Laurze rolę administratora magazynu
byłyby następującymi projektami gcloud
dodaj kreskę iam powiązanie polityki kreski myślnikiem
z identyfikatorem projektu dash dash członka
użytkownik, po którym następuje dwukropek, a następnie użytkownik
imię jakim jest laura zachwycająca gmail.com
kreska kreska rola i rola, która jest
administrator magazynu i zamierzam iść dalej
i naciśnij enter
i jak widać zostało wykonane
pomyślnie, więc jeśli odświeżę plik
stronę internetową tutaj będę mógł
zobacz zmiany odzwierciedlone w konsoli
a po odświeżeniu można zobaczyć tutaj
administrator magazynu został dodany do roli
dla laury zachwycającej gmail.com i tak dalej
idę do otwartej karty, w której znajduje się Laura
ma otwartą konsolę, mogę po prostu zrobić
odświeżać
i jeśli wrócę do strony głównej dla
przechowywanie w chmurze, możesz to zobaczyć tutaj
Laura ma teraz uprawnienia do tworzenia
wiadro laura również ma teraz uprawnienia
aby utworzyć nowe foldery, utwórz edytuj i
usuwać nowe pliki oprócz możliwości
utwórz nowe zasobniki do przechowywania i tak dalej
about kończy tę demonstrację
zapoznanie się z iam
zarówno w konsoli, jak i w wierszu poleceń
i mam też nadzieję, że to demo dał
trochę więcej pewności siebie
o pracy w powłoce z uruchomieniem
polecenia potrzebne do utworzenia nowego
powiązania wraz z edycją istniejących
zasady
a to zapewni ci komfort
kiedy musisz przypisać role do nowych i
istniejących użytkowników, którzy są dodawani do Twojego
gcp, więc możesz teraz zaznaczyć
tę lekcję jako zakończoną
i przejdźmy do następnego
witam ponownie na tej lekcji, na którą idę
zagłębić się w konta usług
teraz konta usług odgrywają potężną rolę
część w chmurze Google i może zezwolić na
inne podejście do aplikacji
interakcja z zasobami w google
Konta usług w chmurze są teraz zarówno kontem
tożsamość i zasób mogą powodować niektóre
zamieszanie dla niektórych i tak naprawdę
chciałem spędzić trochę czasu, łamiąc go
w dół dla lepszego zrozumienia, więc jestem
najpierw zacznę od wyjaśnienia
czym dokładnie jest konto usługi i tak dalej
Konto serwisowe jest szczególnym rodzajem konta
konto używane przez aplikację
lub instancja maszyny wirtualnej, a nie a
osoba
aplikacja korzysta z konta usługi
do uwierzytelniania między aplikacjami
i usługi gcp, aby użytkownicy
krótko mówiąc, nie są bezpośrednio zaangażowani
specjalny typ konta Google
ma reprezentować użytkownika innego niż człowiek
to musi być uwierzytelnione i być
upoważniony do dostępu do danych w google apis
w ten sposób konto usługi jest
tożsamość usługi i usługi
uprawnienia do kont kontrolują które
zasoby, do których usługa może uzyskać dostęp, oraz as
Uwaga konto usługi jest zidentyfikowane
przez jego adres e-mail
który jest unikalny dla konta teraz
różne typy kont usług
występują w trzech różnych smakach
zarządzane przez użytkownika
usługa domyślna i zarządzana przez Google
kont, jeśli chodzi o użytkownika
zarządzane konta usług
to są konta usług, które ty
tworzyć
jesteś odpowiedzialny za zarządzanie i
zabezpieczenia tych kont
i domyślnie możesz utworzyć do 100
konta usług zarządzane przez użytkowników w a
projektu lub możesz również poprosić o przydział
zwiększyć na wypadek, gdybyś potrzebował więcej teraz, kiedy
tworzysz usługę zarządzaną przez użytkownika
konto w twoim projekcie to ty
wybiera nazwę konta usługi
ta nazwa pojawia się w adresie e-mail
identyfikujący konto usługi
który używa następującego widocznego formatu
tutaj nazwa konta usługi
w kropce identyfikatora projektu
iam.gserviceaccount.com
teraz przechodzimy do usługi domyślnej
konta
podczas korzystania z niektórych usług Google Cloud
tworzą usługę zarządzaną przez użytkownika
konta, które umożliwiają usługę
wdrażaj zadania, które uzyskują dostęp do innych usług Google
zasobów w chmurze te konta są znane
jako domyślne konta usług, więc kiedy to
przychodzi do obciążeń produkcyjnych google
zdecydowanie zaleca utworzenie własnego
własne konta usług zarządzane przez użytkowników i
przydziel każdemu odpowiednią rolę
konto usługi, gdy usługa domyślna
konto jest tworzone automatycznie
przyznałeś rolę redaktora w swoim projekcie
teraz zgodnie z zasadą dzierżawy
uprzywilejowany Google zdecydowanie zaleca
że wyłączysz rolę automatyczną
dotacja
dodając ograniczenie do twojego
polityka organizacji
lub przez ręczne odwołanie roli redaktora
będzie domyślnym kontem usługi
przypisany adres e-mail
zgodnie z formatem, który widzisz tutaj
identyfikator projektu
na appspot.gserviceaccount.com
dla wszelkich kont usług utworzonych przez app
oblicz silnik i numer projektu myślnikiem
na developer.gserviceaccount.com
dla silnika obliczeniowego i wreszcie, kiedy to
dotyczy kont usług zarządzanych przez Google
są one tworzone i zarządzane przez Google
i są używane przez usługi Google
wyświetlana nazwa większości zarządzanych przez Google
rachunki usług
kończy się A
adres gserviceaccount.com teraz niektóre
te konta usług są widoczne, ale
inne są ukryte, więc np
agent usługi Google API to usługa
konto o nazwie z adresem e-mail, który
używa następującego formatu
numer projektu na cloudservices.gerisa
a to uruchamia wewnętrzne procesy Google
w twoim imieniu i to tylko jeden
przykład wielu zarządzanych przez Google
usług działających w Twoim środowisku
i tylko jako ostrzeżenie, że tak nie jest
zaleca się zmianę lub odwołanie
role, które są przyznawane interfejsowi Google API
agenta serwisowego lub dowolnego innego przedstawiciela Google
zarządzane konta usług w tym zakresie
jeśli zmienisz lub odwołasz te role
niektóre usługi w chmurze Google nie
dłuższa praca teraz jeśli chodzi o
uwierzytelnianie kont usług
uwierzytelnić przy użyciu kluczy konta usługi
więc każde konto usługi jest powiązane
z dwoma zestawami publicznego i prywatnego rsa
pary kluczy używane do uwierzytelniania
do google to oni zarządzają google
klucze, a użytkownik zarządza kluczami za pomocą
Google zarządza kluczami Google przechowuje oba
część publiczna i prywatna
klucz
obraca je regularnie i prywatnie
klucz jest zawsze przechowywany w depozycie i jest
nigdy bezpośrednio dostępne iam zapewnia
apis, aby używać tych kluczy do podpisywania w imieniu
konta usługi teraz podczas korzystania
pary kluczy zarządzane przez użytkownika oznacza to, że
jesteś właścicielem zarówno publicznego, jak i prywatnego
części pary kluczy, które możesz utworzyć
jedna lub więcej par kluczy zarządzanych przez użytkownika
zwane kluczami zewnętrznymi, których można użyć
spoza Google Cloud tylko Google
przechowuje publiczną część użytkownika
zarządzany klucz
więc jesteś odpowiedzialny za bezpieczeństwo
klucza prywatnego, jak i klucza
rotacja kluczy prywatnych nie może być
pobrane przez Google, więc jeśli używasz pliku
klucz zarządzania użytkownikami
pamiętaj, że jeśli zgubisz swój
klucz, który będzie używany przez Twoje konto usługi
skutecznie przestać działać google
zaleca przechowywanie tych kluczy w chmurze
km dla lepszego bezpieczeństwa i lepszego
są klucze zarządzane przez użytkowników zarządzających
niezwykle potężne poświadczenia i oni
mogą stanowić zagrożenie dla bezpieczeństwa, jeśli
nie są zarządzane poprawnie i jak możesz
zobacz tutaj klucz zarządzany przez użytkownika ma wiele
różne obszary, które muszą być
adresowane, jeśli chodzi o klucz
zarządzanie teraz, jeśli chodzi o obsługę
uprawnienia do konta
oprócz bycia tożsamością a
konto usługi to zasób, który ma
im zasady dołączone do niego i te
zasady określają, kto może korzystać z
konto usługi, więc na przykład
Lark może pełnić rolę redaktora na a
konto usługi i Laura może mieć
rola przeglądającego na koncie usługi, więc to
jest jak przydzielanie ról każdemu
inny zasób Google Cloud, tak jak a
notatka
domyślny silnik obliczeniowy i aplikacja
przyznawane są konta serwisowe silnika
role redaktora w projekcie, kiedy oni
są tworzone tak, aby wykonywany kod
w twojej aplikacji lub instancji vm ma
niezbędne uprawnienia, które możesz teraz przyznać
rolę użytkownika konta usługi w obu przypadkach
poziom projektu dla wszystkich usług
konta w projekcie lub w
poziom konta usługi, który teraz przyznaje
rolę użytkownika konta usługi użytkownikowi dla
projekt
daje użytkownikowi dostęp do wszystkich usług
konta w projekcie
w tym kont usług, które mogą być
tworzonych w przyszłości przyznających
rolę użytkownika konta usługi użytkownikowi dla
specyficzny
konto usługi daje użytkownikowi dostęp
tylko to konto usługi, więc proszę
świadomy przy przyznawaniu konta usługi
rola użytkownika do dowolnego członka teraz użytkownicy, którzy
przyznawane są użytkownikowi konta usługi
rola na koncie usługi może z niego korzystać
dostęp pośredni
wszystkie zasoby, do których usługa
konto ma dostęp
kiedy tak się dzieje, użytkownik się podszywa
konto usługi w celu wykonywania dowolnych zadań
korzystając z nadanych mu ról i uprawnień
i jest znane jako konto usługi
podszywanie się teraz, jeśli chodzi o
istnieją uprawnienia do konta usługi
także inna metoda o nazwie dostęp
zakresy zakresy kont usługi to
starsza metoda określania uprawnień
dla twojego egzemplarza
i są używane zamiast iam
role, do których są one specjalnie używane
usługa domyślna lub utworzona automatycznie
konta oparte na włączonym interfejsie API teraz
przed istnieniem dostępu do ról iam
zakresy były jedynym sposobem przyznawania
uprawnienia do kont serwisowych i
chociaż nie są one głównym sposobem
nadawanie uprawnień teraz
nadal musisz ustawić konto usługi
zakresy podczas konfigurowania instancji do
działać jako konto usługi, ale kiedy
korzystasz z niestandardowego konta usługi
nie będziesz używać zakresów, a ty
będzie używać ról iam
więc kiedy korzystasz z usługi domyślnej
uwzględnij instancję obliczeniową it
będzie domyślnie używać zakresów zamiast
Mam role i tak chciałem szybko
dotknij, jak używane są konta usług
teraz jeden ze sposobów korzystania z konta usługi
jest dołączenie tego konta usługi do
ratunek
więc jeśli chcesz rozpocząć bieganie długodystansowe
zadanie, które uwierzytelnia się jako usługa
konto, którego potrzebujesz, aby dołączyć usługę
konto do zasobu, który zostanie uruchomiony
zadanie, a to zwiąże usługę
konto do zasobu teraz inne
sposób korzystania z konta usługi jest
bezpośrednio podszywając się pod konto usługi
co trochę wyjaśniłem
wcześniej, więc raz przyznane wymagają
uprawnienia, jakie może mieć użytkownik lub usługa
bezpośrednio podszywać się pod tożsamość a
konto usługi w kilku wspólnych
scenariusze, w które możesz się wcielić
konto usługi bez wymagania
korzystanie z pobranej usługi zewnętrznej
klucz konta, jak również użytkownik może uzyskać
artefakty podpisane przez zarządzane przez google
klucz prywatny konta usługi
bez faktycznego pobierania
poświadczenie konta usługi i
jest to zaawansowany przypadek użycia i jest tylko
obsługiwane dla dostępu programowego teraz
chociaż będę najlepiej kryć
praktyki
na końcu tej sekcji chciałem
przejrzyj kilka najlepszych praktyk dotyczących obsługi
kont specjalnie, więc powinieneś
zawsze patrz na audyt usługi
konta
i ich klucze
używając konta usługi kropka
metoda listy kropek kluczy
lub strona przeglądarki dzienników w konsoli
teraz, jeśli Twoje konta usług nie potrzebują
klucze zewnętrzne
zdecydowanie powinieneś je usunąć
powinien zawsze przyznać konto usługi
tylko minimalny zestaw uprawnień
wymagane do osiągnięcia celu
należy również utworzyć konta usług
dla każdej konkretnej usługi tylko z
uprawnienia wymagane dla tej usługi
i wreszcie, kiedy to się stanie
wdrożenie rotacji kluczy, które powinieneś
skorzystaj z usługi iam
konto api, aby wykonać zadanie i tak dalej
to wszystko, co mam na temat tej lekcji
rachunki usług
więc możesz teraz oznaczyć tę lekcję jako
kompletny
i proszę dołącz do mnie w następnym gdzie
pracujemy w konsoli
[Muzyka]
Witamy spowrotem
więc w tej demonstracji zamierzam
wziąć udział w praktycznej wycieczce nurkowej
różne aspekty pracy z obydwoma
domyślne i niestandardowe konta usług
zaczniemy od nowa
obserwowanie istnienia nowego konta usługi
automatycznie tworzone wraz z przeglądaniem
zakresy obserwując, jak je edytować i
tworzenie niestandardowych kont usług, które
uzyskać trochę bardziej szczegółowe z
uprawnienia przypisane tak z tą istotą
powiedział, zanurkujmy, żebyście mogli zobaczyć
tutaj z prawego górnego rogu
Jestem zalogowany jako tony bowtie ace
gmail.com i patrząc tutaj z
górne menu rozwijane widać, że jestem
w projekcie muszki dla kota jesień 2021
a to zupełnie nowy projekt, który ja
stworzył specjalnie dla tego demo
więc obecnie nie mam zasobów
utworzone bez włączonej funkcji apis
teraz chcę przejść do iam so
podchodzę do lewej ręki
rogu do menu nawigacji
i zamierzam przejść do Jestem administratorem
i do iam i zgodnie z oczekiwaniami mam
nie ma tu innych członków niż ja tony
muszka as gmail.com bez żadnego innego
członków i jeśli przejdę tutaj do
menu po lewej stronie pod kontami usług
widać, że nie mam usługi
konta utworzone tak teraz, aby
wykazać domyślne konto usługi
Przejdę do nawigacji
menu i przejdź do silnika obliczeniowego i as
widać, że jest interfejs API silnika obliczeniowego
uruchamianie, więc może to potrwać
kilka minut, aby przygotować się dobrze i
api silnika obliczeniowego zostało włączone, więc
teraz, jeśli wrócę do iam, aby wziąć
spójrz na moje konta usług zgodnie z oczekiwaniami
mam domyślną usługę silnika obliczeniowego
konto teraz ponownie nie stworzyłem tego
ręcznie to konto usługi było
automatycznie utworzone, gdy włączyłem
api silnika obliczeniowego wraz z
agent usługi api i komputer
serwis silnika i to samo
zdarza się innym różnym api, które są
włączone, a więc teraz, kiedy mam
moje domyślne konto usługi, do którego chcę przejść
z powrotem do silnika obliczeniowego
i zamierzam iść dalej i stworzyć
vm, więc po prostu kliknę
na tworzeniu
mam zamiar zachować wszystko jako
domyślny, z wyjątkiem tego, że zamierzam zmienić
typ maszyny z e2 medium na e2
mikro, więc teraz będę przewijać
aż do miejsca, w którym jest napisane tożsamość i api
dostęp
teraz tutaj pod kontem usługi możesz
zobacz, że domyślny silnik obliczeniowy
konto usługi zostało podświetlone i
to dlatego, że nie mam innego
kont serwisowych, które jestem w stanie wykonać
wybierz od teraz, gdy usługa domyślna
Konto jest jedynym kontem usługi
mieć dostęp do
zakresy dostępu to jedyne uprawnienia
które będą dostępne do wyboru
od teraz pamiętaj, że zakresy dostępu to
starsza metoda określania uprawnień
w chmurze Google teraz w ramach zakresów dostępu
mogę wybrać z domyślnego zezwolenia
dostęp
zezwól na pełny dostęp do wszystkich interfejsów API w chmurze
i ustaw dostęp dla każdego interfejsu API, więc ja
chcesz kliknąć ustaw dostęp dla każdego interfejsu API
tylko na sekundę i tak jak widać
tutaj mam dostęp do ustawiania uprawnień
dla każdego interfejsu API jest różnica
że mam dostęp tylko do prymitywnych
role i tak teraz, że szukam
przyznaj dostęp do mojego konta usługi jestem
zamierza przyznać dostęp do magazynu w chmurze
na pojemności tylko do odczytu
i tak teraz, że przyznałem
uprawnienia do mojego konta usługi i'm
zamierzam teraz utworzyć moją instancję przez
po prostu klikając przycisk tworzenia
a więc teraz, gdy moja instancja została utworzona
chcę przejść do przechowywania w chmurze
zobaczyć dokładnie, co będzie na moim koncie usługi
mam dostęp, więc podejdę
do mojego menu nawigacyjnego i przewiń w dół
i kliknij pamięć i jak widać
tutaj wcześniej utworzyłem wiadro
o nazwie muszka atramentowa jesień zima 2012
projekty, a to za sprawą atramentu muszki
przywracanie starych projektów z 2012 roku
i czyniąc je aktualnymi i aktualnymi
w tym wiadrze znajduje się kilka plików
różnych pomysłów projektowych, które były najlepsze
Sprzedawcy w 2012 r
którą Tony Bowtie chciał ponownie wydać
do kolekcji jesień zima 2012 i
więc z nowym przyznanym dostępem do my
domyślne konto usługi, które powinienem mieć
dostęp do przeglądania tych plików w takiej kolejności
aby to przetestować, zamierzam wrócić
do menu nawigacji i wrócić do
Compute Engine i zamierzam wejść do ssh
mój egzemplarz
a więc teraz, kiedy włączyłem się do mojego
maszyna wirtualna
Chciałem najpierw sprawdzić, kto to jest
to jest uruchamianie poleceń, czy to moje
konto użytkownika, czy jest to moje konto usługi
i tak będę mógł to zrobić bardzo
łatwo, sprawdzając konfigurację i
mogę to zrobić, uruchamiając polecenie
lista konfiguracji gcloud i jak widać my
bieżąca konfiguracja pokazuje, że my
konto usługi jest członkiem
używany do uruchamiania tego polecenia w
projekt muszek dla kota jesień 2021 teraz jeśli
chciałem uruchomić dowolne polecenia za pomocą my
tony muszka as
konto użytkownika gmail.com, które mogę po prostu uruchomić
polecenie gcloud auth login i to
przeprowadzi mnie przez proces logowania
które widzieliśmy wcześniej w trakcie kursu
dla mojego Tony Bowtie Ace
konto gmail.com, ale teraz, odkąd jestem
uruchamianie wszystkich moich poleceń za pomocą mojej usługi
konto z tego silnika obliczeniowego
instancja używam uprawnień
przyznane temu kontu usługi, że my
widziałem wcześniej i tak odkąd ustawiłem
zakres przechowywania dla konta usługi do
tylko do odczytu powinniśmy być w stanie zobaczyć
zasobnik do przechowywania w chmurze i wszystkie pliki
w nim, po prostu uruchamiając gsutil
polecenie, aby wyświetlić zawartość pliku
wiadro zamierzam wpisać polecenie
gsutil ls dla listy i nazwy pliku
wiadro, a składnia tego byłaby
gs
dwukropek ukośnik ukośnik
po którym następuje nazwa zasobnika, który
byłoby Bowtie Inc
fw2012
projekty
i jak widać jesteśmy w stanie zobaczyć
wszystkie pliki znajdujące się w zasobniku i
więc działa zgodnie z oczekiwaniami i tak teraz
ponieważ zezwoliłem tylko na oglądanie
uprawnienia do tego konta usługi
nie może utworzyć żadnych plików z powodu braku
uprawnień, więc na przykład gdybym był
aby utworzyć plik
za pomocą polecenia dotyk
plik jeden, który teraz utworzyłem
tutaj na przykład, więc teraz chcę
skopiuj ten plik do mojego wiadra, więc jestem
zamierzam uruchomić polecenie gsutil
cp dla kopii
plik 1, który jest nazwą mojego pliku i
gs
dwukropek ukośnik do przodu ukośnik wzdłuż
z nazwą wiadra, którym jest łuk
krawat inc fw
2012
projekty i zgodnie z oczekiwaniami otrzymuję
wyjątek odmowy dostępu z monitem
mówiąc mi, że mam za mało
uprawnienia, a więc teraz, co pokazałem
jak utworzyć usługę domyślną
konto i nadaj mu uprawnienia do używania
zakresy dostępu stwórzmy teraz custom
konto usługi i odpowiednio je przypisać
uprawnienia
aby nie tylko odczytywać pliki z chmury
pamięci, ale mieć możliwość zapisywania plików
przechowywanie w chmurze, więc zamierzam to zrobić
teraz zamknij tę kartę
i zamierzam wrócić do tzw
Menu nawigacji
i wróć do IAM, gdzie możemy wejść
i utwórz nasze nowe konto usługi
w ramach kont usług
i jak widać tutaj jest to
domyślne konto usługi i ponieważ my
chcę utworzyć niestandardowy, zamierzam to zrobić
śmiało i wejdź na górę tutaj i
kliknij przycisk z napisem stwórz
konto usługi
i teraz jestem proszony o wprowadzenie niektórych
informacje dotyczące szczegółów dot
to konto usługi, w tym
nazwa konta usługi identyfikator konta
wraz z opisem i tak jestem
zadzwonię do tego konta usługi sa
myślnik muszka łącznik demo i jak możesz
zobacz, jak automatycznie propagował
identyfikator konta usługi i zamierzam podać
opis tego konta usługi
dostęp do odczytu i zapisu pamięci masowej
i zamierzam kliknąć przycisk
tworzyć
więc teraz zostałem poproszony o przyznanie
uprawnienia do konta usługi oraz i
można to zrobić, po prostu klikając na
rozwiń i wybierz rolkę, ale jestem
chce dostać trochę więcej
granularny, więc po prostu napiszę
w magazynie i jak widać nadchodzę
się z bardziej szczegółowymi rolami jako
w przeciwieństwie do prymitywnych ról, które ja
miał dostęp tylko przed przeszukaniem
więc zamierzam kliknąć obiekt pamięci masowej
przeglądarka umożliwiająca dostęp do odczytu do przechowywania w chmurze
nie zamierzam dodawać żadnych warunków i
zamierzam dodać kolejną rolę i to
czas
zamierzam dodać twórcę obiektów pamięci masowej
i to są wszystkie uprawnienia i
potrzeba dostępu do odczytu i zapisu do chmury
storage, więc teraz mogę po prostu kliknąć
kontynuuj i teraz pojawia się monit
aby dodać kolejnego użytkownika do działania jako usługa
konto i o tym rozmawialiśmy w
ostatnia lekcja o kontach usług
będąc zarówno członkiem, jak i zasobem teraz
zauważ, że mam opcję dla obu
rola użytkowników konta usługi i
rola administratorów konta usługi teraz jako
omówione wcześniej konto usługi
a rola mężczyzn ma zdolność przyznawania
innym użytkownikom rolę konta usługi
user i dlatego, że nie chcemy tego robić
że opuszczę obie te rzeczy
puste pola
i po prostu kliknij Gotowe, teraz już wiem
ostatnia lekcja, o której mówiłem o tworzeniu
niestandardowe klucze do uwierzytelniania
na wypadek, gdybyś hostował swój kod
lokalnie lub w innej chmurze, więc jeśli ja
chciałem to zrobić, mogę po prostu przejść do
menu akcji i kliknij utwórz klucz i
da mi możliwość utworzenia
klucz prywatny za pomocą json lub p12
format i ponieważ nie tworzę żadnego
klucze, po prostu kliknę anuluj
i tak, abym mógł to zastosować
konto usługi
do naszej instancji vm, do której teraz pójdę
wróć do menu nawigacji i idź
z powrotem do silnika obliczeniowego i tak teraz
zleć mi zmianę tej usługi
konto, do którego jest aktualnie przypisany
w tym przypadku zamierzam iść naprzód i
zaznacz tę instancję i kliknij
zatrzymywać się
teraz proszę zauważyć, że w celu zmiany
konta usług w dowolnej instancji
musisz go najpierw zatrzymać, zanim będzie można edytować
konto usługi, a więc teraz, gdy
instancja zatrzymała się idę drążyć
w dół do tej instancji
i klikam edytuj
teraz przewinę w dół do
spód
a na dole znajdziesz tzw
pole konta usługi i kliknij
lista rozwijana znajdę mój zwyczaj
konto usługi jako demo muszki, więc ja
chcesz to zaznaczyć i po prostu kliknij
zapisz, więc teraz, gdy wybrałem my
nowe konto usługi do wykorzystania w tym celu
vm mogę teraz uruchomić
instancję ponownie, aby przetestować
udzielonych uprawnień
i tak tylko jako szybka uwaga tutaj i
chciałem zwrócić waszą uwagę na
zewnętrzny adres IP za każdym razem, gdy się zatrzymuje i
uruchamianie instancji z efemerydą
ip innymi słowy nie jest przypisany a
statyczny adres IP, który otrzyma Twoja instancja maszyny wirtualnej
nowy adres IP i będę otrzymywać
w to dużo głębiej szczegółowo w
sekcja silnika obliczeniowego kursu i
więc teraz przejdę do tego przez ssh
instancja
teraz zamierzam uruchomić ten sam gsutil
polecenie, które zrobiłem wcześniej, aby wyświetlić listę
wszystkie pliki w wiadrze, więc idę
aby uruchomić polecenie gsutil ls dla listy
i gs
dwukropek ukośnik do przodu ukośnik łuk
krawat inc fw 2012 projekty
i jak widać, jestem w stanie przeczytać wszystko
pliki w wiadrze teraz
różnica w przyznanych uprawnieniach
dla konta usługi jest to, że jestem w stanie
zapisywać pliki w chmurze i tak dalej
w celu przetestowania, którego zamierzam użyć
polecenie dotykowe ponownie i zamierzam to zrobić
nazwij plik file2, więc teraz idę
aby skopiować ten plik do magazynu w chmurze
wiadro za pomocą polecenia gsutil cp
plik2 i nazwę zasobnika
gs dwukropek do przodu ukośnik do przodu ukośnik łuk
tie inc fw 2012 projekty i zgodnie z oczekiwaniami
plik został pomyślnie skopiowany jako my
mieć uprawnienia do zapisu w chmurze
storage i tak zanim to zakończę
pokaz, na który chciałem szybko iść
nad tym, jak dokładnie utworzyć usługę
konta
za pomocą wiersza poleceń, więc idę
zamknąć tę kartę i zamierzam to zrobić
skieruj się w prawy górny róg i
aktywuj moją powłokę chmurową, do której zamierzam
powiększ to okno i
więc teraz, aby wyświetlić usługę
konta, które obecnie posiadam
wykonam polecenie
gcloud
Ja jestem
konta serwisowe
lista
i tak zgodnie z oczekiwaniami silnik obliczeniowy
domyślne konto usługi wraz z
niestandardowe konto usługi, które utworzyłem
wcześniej nazywana sa Bowtie Demo jest teraz
wyświetlanie i tylko po to, aby zweryfikować
że pójdę do iam
w ramach kont usług i jak możesz
zobacz, że odzwierciedla dokładnie to samo w
konsola, więc teraz, abym ja to zrobił
utwórz nowe konto usługi za pomocą
wiersz poleceń, który zamierzam uruchomić
Komenda
tworzenie kont usługi gcloud iam
oraz nazwę konta usługi
którą nazwę sa-tony muszką
wraz z nazwą wyświetlaną jako esej
Tony Bowtie też i zamierzam uderzyć
Wchodzić
a moje konto usługi zostało utworzone
więc teraz, jeśli uruchomię polecenie gcloud, jestem
lista rachunków usług
powinienem zobaczyć moje nowe konto usługi i
jak również, jeśli zrobiłem odświeżenie tutaj na
konsoli widzę, że odbija
to samo, więc teraz, kiedy stworzyliśmy nasz
nowe konto usługi, które musimy przypisać
niektóre uprawnienia do niego w celu dla nas
aby móc z niego korzystać, więc jeśli przejdę
tutaj jestem w konsoli, którą widzę
tutaj, że moje konto usługi nie
nadano mu jakiekolwiek uprawnienia i tak dalej
Aby to zrobić, zamierzam po prostu
uruchom polecenie
projekty gcloud
dodaj myślnik iam-policy-binding
więc dodajemy powiązanie zasad i
potem nazwa projektu kocie muszki
jesień 2021 musimy dodać członka
czyli nowy adres e-mail konta usługi
adres wraz z rolą przechowywania
przeglądarka obiektów, którą zamierzam nacisnąć Enter
i jak widać
moim członkiem był Tony Bowtie
przypisano rolę przeglądającego obiekt pamięci masowej
a więc gdybym chciał przyznać inne
role do konta usługi, które mogę wykonywać
to też, więc jeśli zrobiłem odświeżenie
tutaj widzę, że konsola odbija
dokładnie to samo i tak w porządku dla mnie
aby użyć tego konta w mojej instancji, jestem
najpierw muszę zatrzymać moją instancję
dołącz moje konto usługi, a następnie rozpocznij
ponownie w górę mojej instancji, więc idę
do mojej muszli w chmurze, do której właśnie zmierzam
wyczyść ekran i wkleję
w poleceniu gcloud compute instances
zatrzymaj nazwę instancji wraz z
strefa i teraz, gdy instancja ma
zatrzymany, mogę teraz dodać moje konto Surface
do instancji i tak zamierzam użyć
polecenie gcloud compute instances
ustaw instancję konta usługi 1
wraz ze strefą i obsługą
adres e-mail konta, na który mam zamiar przejść
naprzód i naciśnij enter
i teraz został pomyślnie dodany
więc teraz, kiedy to się skończyło, mogę teraz
uruchom instancję za pomocą
uruchom instancje obliczeniowe gcloud
wraz z nazwą instancji i
strefa i tak teraz, jeśli przejdę do mojego
menu nawigacyjne i przejdź do obliczeń
engine i przejdź do instancji if
przewijam w dół
będę mógł zobaczyć, że moja nowa usługa
konto zostało dodane
a więc jest to świetna demonstracja dla
gdy chcesz dodać inną usługę
kont dla różnych aplikacji
w różnych przypadkach, a nawet na
różne zasoby i to jest ładne
wszystko, co chciałem zawrzeć w tym
demonstrację, więc możesz to teraz zaznaczyć
lekcję za zakończoną i przejdźmy dalej
Następny
Witamy spowrotem
w tej lekcji zamierzam się zagłębić
tożsamość w chmurze Tożsamość Google jako
oferta usług dla chmury Google, która
maksymalizuje efektywność ochrony użytkownika końcowego
dane firmy
i wiele więcej
teraz tożsamość w chmurze, jak powiedziałem wcześniej, jest
rozwiązanie tożsamości jako usługi, które
centralnie zarządza użytkownikami i grupuje to
byłby jedynym systemem dla
uwierzytelnianie i które zapewnia
jednokrotne logowanie dla wszystkich
pracowników organizacji do wykorzystania
dla wszystkich twoich wewnętrznych i zewnętrznych
zapewnia również tożsamość aplikacji w chmurze
masz większą kontrolę nad kontami
są używane w Twojej organizacji do
na przykład, jeśli programiści w twoim
organizacja korzysta z kont osobistych, takich jak
jako konta Gmail te konta są
poza twoją kontrolą
więc po przyjęciu tożsamości w chmurze jest to możliwe
zarządzać dostępem i zgodnością we wszystkich
użytkowników w Twojej domenie teraz, kiedy Ty
adoptuj tożsamość w chmurze, tworzysz chmurę
konto tożsamości dla każdego użytkownika
i grupy, do których możesz następnie użyć iam
zarządzać dostępem do zasobów Google Cloud
dla każdego konta Cloud Identity i dla Ciebie
może również skonfigurować tożsamość w chmurze do
sfederować tożsamości między google i
inni dostawcy tożsamości, tacy jak active
katalog i Azure Active Directory oraz
trochę bardziej się w to zagłębię
trochę później
więc teraz, jeśli chodzi o tożsamość w chmurze
daje o wiele więcej niż tylko użytkownikowi
i zarządzanie grupami zapewnia mnóstwo
funkcji, takich jak zarządzanie urządzeniami
bezpieczeństwo
pojedyncze logowanie
raportowanie
i zarządzanie katalogami
i będę nurkować głębiej w każdym z nich
jedną z tych cech tożsamości w chmurze
zaczynamy od zarządzania urządzeniami
pozwala to ludziom w dowolnej organizacji
uzyskiwać dostęp do swoich kont służbowych z telefonu komórkowego
urządzeń przy zachowaniu organizacji
bezpieczniejsze dane w dzisiejszym świecie
pracownicy chcą mieć dostęp do biznesu
aplikacje z dowolnego miejsca
czy w domu w pracy
czy nawet podróżowanie
a wielu nawet chce używać własnych
urządzenia, które jest również znane jako przynieść
własne urządzenie lub byod dla krótkiego użytkowania
zarządzanie urządzeniami mobilnymi
kilka sposobów, które można zapewnić
aplikacji biznesowych, których potrzebują pracownicy
na swoich urządzeniach osobistych podczas
wdrażanie polityk, które utrzymują
firmowy sejf na dane, który możesz utworzyć
biała lista zatwierdzonych aplikacji
gdzie użytkownicy mogą uzyskać dostęp do danych firmowych
bezpiecznie przez te aplikacje
możesz wymusić profile służbowe na Androidzie
urządzeń i wymagających zarządzanych
aplikacje na zasadach urządzeń z systemem iOS mogą
być również wypchnięty na tych urządzeniach
chronić firmowe dane i tożsamość jako
a także prowadzenie inwentaryzacji urządzeń
z danymi firmowymi obecnymi wtedy kiedy
tych urządzeń już nie ma
używane do użytku firmowego lub skradzione
urządzenie można następnie wyczyścić ze wszystkich swoich
zarządzanie urządzeniami danych korporacyjnych również
daje organizacjom moc egzekwowania
kody dostępu
a także audyt, który teraz przechodzi do
składnik bezpieczeństwa tożsamości w chmurze
tutaj jest weryfikacja dwuetapowa
wkracza teraz, jak wyjaśniono wcześniej
weryfikacja dwuetapowa lub do sv
jest funkcją bezpieczeństwa, która wymaga
użytkownikom weryfikować swoją tożsamość
coś, co znają, na przykład hasło
plus coś, co mają, np
fizyczny klucz lub kod dostępu i to może
może to być wszystko, od kluczy bezpieczeństwa po Google
podpowiedź
aplikacja uwierzytelniająca i kody zapasowe
więc stosowanie tożsamości w chmurze pomaga
najlepszych praktyk w zakresie bezpieczeństwa wraz z byciem
w stanie rozmieścić
dwuetapowa weryfikacja całości
spółki wraz z kontrolami egzekucyjnymi
a także może zarządzać hasłami do tworzenia
na pewno spełniają wymuszone
wymagania dotyczące hasła automatycznie tzw
jednokrotne logowanie to miejsce, w którym użytkownicy mogą uzyskać dostęp
wiele aplikacji
bez konieczności wpisywania nazwy użytkownika
i hasło dla każdej pojedynczej aplikacji
logowanie, znane również jako sso, może zapewnić
pojedynczy punkt uwierzytelniania przez
dostawca tożsamości znany również jako idp
w skrócie możesz skonfigurować sso za pomocą
google jako dostawcy tożsamości, aby uzyskać dostęp
mnóstwo aplikacji firm trzecich
jak również wszelkie lokalne lub niestandardowe
aplikacje w domu można również
dostęp do scentralizowanego pulpitu nawigacyjnego dla
wygodny dostęp do aplikacji
więc teraz, kiedy lisa się z nią loguje
referencje pracownicze, które będzie wówczas posiadała
dostęp do wielu aplikacji chmurowych, które
Bowtie Inc dział IT zatwierdził
poprzez katalog aplikacji sso
a to zwiększy zarówno bezpieczeństwo, jak i
produktywność dla lisa and bowtie inc as
Lisa nie będzie musiała wchodzić
osobną nazwę użytkownika i hasło dla
oddzielne aplikacje, które teraz wchodzą
raportowanie obejmuje dzienniki kontroli dla
loginy grupują urządzenia, a nawet tokeny
możesz nawet wyeksportować te dzienniki do
BigQuery do analizy
a następnie możesz tworzyć raporty z
te dzienniki, które dotyczą bezpieczeństwa
aplikacje i aktywność
teraz przechodzimy do ostatniego elementu
tożsamość w chmurze to zarządzanie katalogami
a to zapewnia informacje o profilu
dla użytkowników w Twojej organizacji
e-mail
i adresy grupowe oraz wspólne zewnętrzne
kontakty w katalogu za pomocą google
synchronizacja katalogów w chmurze lub gcds, możesz
zsynchronizuj dane w swoim google
konto z aktywnym Microsoft
katalog lub serwer ldap gcds nie
migrować dowolną zawartość, taką jak poczta e-mail
wydarzenia w kalendarzu lub pliki
Twoje konto Google, do którego gcds jest przyzwyczajone
zsynchronizuj wszystkie grupy użytkowników i
współdzielone kontakty, aby dopasować informacje
na twoim serwerze ldap, który może być twój
serwer Active Directory lub twój Azure
domena Active Directory jest teraz pobierana
głębiej w Google Cloud Directory Sync
chciałbym dotknąć Active Directory
na chwilę teraz Active Directory
jest bardzo popularną usługą katalogową
opracowany przez Microsoft i jest
kamień węgielny w większości dużych korporacji
środowiska lokalne to
uwierzytelnia i autoryzuje wszystkich użytkowników
i komputery w typie domeny Windows
podpisywanie sieciowe i wymuszanie bezpieczeństwa
zasady dla wszystkich komputerów i
instalowanie lub aktualizowanie oprogramowania jako
konieczne teraz, jak widać tutaj w
diagram lasu Active Directory
zawiera domenę Active Directory a
Bowtieinc.co
i federacją Active Directory
usługi bowtieinc.co, gdzie
lasem Active Directory jest
hierarchiczna struktura dla aktywnych
katalog, w którym znajduje się domena Active Directory
odpowiedzialny za przechowywanie informacji
o członkach domeny, w tym
urządzeń i użytkowników oraz weryfikuje ich
poświadczeń i definiuje ich dostęp
prawa do federacji Active Directory
usługi lub reklamy
to usługa pojedynczego logowania, w której
federacja jest środkiem łączącym a
tożsamości elektronicznej osoby i
atrybuty przechowywane w wielu
odrębne systemy zarządzania tożsamością tzw
możesz myśleć o tym jako o podzbiorze sso
ponieważ dotyczy wyłącznie uwierzytelniania
technologie używane do tożsamości federacyjnej
zawierać kilka typowych terminów, które możesz
usłyszeć mnie lub inne osoby z branży
od czasu do czasu, takich jak saml, które
oznacza znacznik potwierdzenia bezpieczeństwa
otwarty identyfikator języka, a nawet bezpieczeństwo
tokeny, takie jak proste tokeny sieciowe json
tokeny sieciowe i asercje saml i tak dalej
kiedy masz już tożsamości w swoim
środowiska lokalnego, w którym żyją
Active Directory potrzebujesz sposobu na powiązanie
te tożsamości do chmury i tak dalej
tutaj możesz użyć chmury Google
synchronizacja katalogów do automatycznego
aprowizuj użytkowników i grupy z aktywnych
katalogu do Cloud Identity lub G Suite
Synchronizacja katalogów Google Cloud jest bezpłatna
Google dostarczyło narzędzie, które implementuje
proces synchronizacji i można go uruchomić
w chmurze Google lub lokalnie
synchronizacja środowiska jest jednym ze sposobów
tak, że Active Directory pozostaje
źródło tożsamości w chmurze prawdy lub g
pakiet korzysta z federacji Active Directory
services lub adfs dla pojedynczego logowania
istniejące aplikacje korporacyjne i
inne usługi sas mogą nadal korzystać
your adfs jako dostawca tożsamości teraz i
wiem, że może to być recenzja dla niektórych, którzy
są zaawansowane w tym temacie, ale dla tych
kim nie jest to bardzo ważne
temat znany jako katalog Google Cloud
synchronizacja to duża część tożsamości w chmurze i
jest powszechnym sposobem, który jest używany w wielu
środowiska korporacyjne do synchronizacji są aktywne
katalog lub dowolny inny serwer ldap do
Google Cloud, zwłaszcza gdy chcesz
zachowaj swój katalog aktywny jako pojedynczy
źródło prawdy i to jest ładne
wszystko, co chciałem zawrzeć
jeśli chodzi o tożsamość w chmurze i
Google Cloud Directory Sync, więc możesz
teraz zaznacz tę lekcję jako ukończoną i
przejdźmy do następnego
[Muzyka]
witaj z powrotem teraz chciałem zamknąć
tę sekcję, przechodząc krótko przez
najlepsze praktyki, których należy przestrzegać podczas pracy
z zarządzaniem tożsamością i dostępem tzw
zdanie, które zostało omówione w
początek tej lekcji, która będzie
ciągle pojawiają się na egzaminie
zasada najmniejszego uprzywilejowania i znowu
w tym miejscu zastosowałbyś tylko
minimalny poziom dostępu wymagany do czego
jest do zrobienia i to jest możliwe
odbywa się przy użyciu predefiniowanych ról, tj
bardziej szczegółową rolę niż używanie
prymitywne role, które są bardzo szerokie
role o określonym zakresie, które są stosowane do
powinny być również całe role projektowe
przyznane w najmniejszym niezbędnym zakresie
więc na przykład przy przypisywaniu kogoś
potrzebne uprawnienia
do zarządzania wcześniej istniejącymi obliczeniami
instancje przypisując instancję obliczeniową
rola administratora może być wystarczająca do czego
muszą zrobić, a nie przypisywać
im rolę instancji obliczeniowej, która ma
pełna kontrola nad całym silnikiem obliczeniowym
zasoby instancji teraz, jeśli chodzi o
zasobów podrzędnych, których nie mogą ograniczyć
dostęp przyznany na jego rodzicu
więc zawsze pamiętaj, aby sprawdzić zasady
przyznane na każdym zasobie i upewnij się
rozumiesz hierarchię
dziedziczenie, którego również chcesz się upewnić
że ograniczasz dostęp do członków
umiejętności tworzenia i zarządzania serwisem
konta
jako użytkownicy, którym przyznano usługę
rola aktora konta dla konta usługi
może uzyskać dostęp do wszystkich zasobów, dla których
konto usługi ma dostęp i
nadanie komuś roli właściciela
należy ich używać z ostrożnością
mieć dostęp do modyfikacji prawie wszystkich
zasoby
w całym projekcie, w tym zasady iam i
rozliczanie przyznania roli redaktora może być
bardziej wystarczające dla potrzeb większości
przy użyciu ról pierwotnych
teraz, gdy mamy do czynienia z hierarchią zasobów
aby ułatwić sobie tworzenie struktury
środowisko
powinieneś spojrzeć na dublowanie swojego google
strukturę hierarchii zasobów chmury do
Twoja struktura organizacyjna w innym
słowa zasób Google Cloud
hierarchia powinna odzwierciedlać sposób, w jaki Twoja
firma jest zorganizowana, powinieneś również skorzystać
projekty do grupowania zasobów, które współużytkują
ta sama granica zaufania, jak również
ustalanie zasad w organizacji
poziomie, a raczej na poziomie projektu
niż na obecnym poziomie zasobów
wrócić do tego, o czym rozmawialiśmy wcześniej
zasada najmniejszych przywilejów
powinieneś skorzystać z tej wskazówki, aby udzielić dotacji
Mam role, to znaczy
dać tylko najmniejszy dostęp
niezbędne do Twoich zasobów i kiedy
przydzielanie ról w wielu projektach
zaleca się ich udzielanie w godz
na poziomie folderu zamiast na poziomie projektu
poziom
teraz nurkowanie z powrotem do kont usług a
zawsze powinna istnieć oddzielna granica zaufania
ubiegał się o jakąkolwiek aplikację w
innymi słowy utworzyć nowe konto usługi
gdy zaangażowanych jest wiele elementów
Twoja aplikacja, którą również chcesz złożyć
upewnij się, że nie usuniesz żadnej usługi
konta, które są używane przez bieganie
przypadków, w których Twoja aplikacja jest prawdopodobna
nie zdać
więc będziesz chciał zaplanować to w trakcie
zaplanuj teraz czas, aby uniknąć przestojów
wcześniej w tej sekcji omówiliśmy
klucze konta usługi i sposób ich
wchodzić w interakcje z Google Cloud i to jest
używany główny mechanizm uwierzytelniania
dla kluczy, więc chcesz się upewnić
wszystkie klucze zarządzane przez użytkownika są rotowane
okresowo, aby uniknąć kompromitacji
możesz obrócić klucz, tworząc nowy
aplikacje do przełączania klawiszy, aby korzystać z
nowy klucz, a następnie usunięcie starego klucza
ale pamiętaj, aby najpierw utworzyć nowy klucz
przed usunięciem starego, jak to będzie
skutkować częściami lub nawet całością
awaria aplikacji, a także kiedy
praca z kluczami konta usługi to jest to
zawsze dobrą praktyką jest nazywanie swojego
klucze serwisowe, a to będzie odzwierciedlać twoje
użyj dla tych kluczy i uprawnień dla
te klucze, żebyś wiedział, czym one są
używane, gdy patrzysz na nie teraz
gdy udzielasz dostępu do usługi
konta, które chcesz upewnić się, że tylko
ci, którzy naprawdę potrzebują dostępu, są tymi, którzy naprawdę potrzebują dostępu
które to mają
inni w twoim otoczeniu powinni być
ograniczone, aby uniknąć nadużyć teraz, kiedy
chodzi o prowadzenie konta usługi
klucze bezpieczne Nie mogę tego wystarczająco podkreślić
nigdy nie chcę sprawdzać źródła tych kluczy
kod lub pozostaw je w plikach do pobrania
katalog, ponieważ jest to najlepszy sposób na nie
tylko narażanie kluczy, ale
narażając całe środowisko
być dostępne publicznie
teraz dotknęliśmy trochę audytu, ale my
tak naprawdę nie zagłębiał się w to szczegółowo
i zajmiemy się tym później w
oczywiście, ale dotykając najlepszych
praktyki
chcesz mieć pewność, że sprawdzisz swoją chmurę
regularnie kontroluj dzienniki i kontroluj wszystko, czym jestem
zasady zmieniają się za każdym razem, gdy edytujesz dowolny dokument iam
polityki generowany jest dziennik, który rejestruje
że zmiana i tak zawsze chcesz
okresowo sprawdzaj te dzienniki, aby je wykonać
pewien, że nie ma żadnych zmian, które są
poza zakresem bezpieczeństwa, którego również chcesz
sprawdzić, aby zobaczyć
kto ma uprawnienia do edycji tych iam
polityki i upewnić się, że ci, którzy
trzymaj ich, masz do tego prawo
istotą jest to, że chcesz ograniczyć kogo
ma możliwość edycji polityk i
kiedy te dzienniki kontroli zostały
wygenerowane, do którego chcesz je wyeksportować
przechowywanie w chmurze, abyś mógł
przechowywać je do długoterminowego przechowywania jako
te dzienniki są zwykle przechowywane przez tygodnie
a nie lata powrotu do służby
klucze do konta
dostęp do klucza konta usługi powinien być
okresowo kontrolowane pod kątem wglądu
niewłaściwe użycie lub nieautoryzowany dostęp i wreszcie
dzienniki kontroli również powinny być ograniczone do
tylko ci, którzy potrzebują dostępu i inni
nie powinien mieć uprawnień do ich przeglądania
i można to zrobić, dodając rolę do
móc przeglądać te dzienniki teraz, kiedy
dotykając zarządzania polityką, którą chcesz
aby udzielić dostępu do wszystkich projektów w Twoim
organizacja za pomocą organizacji
poziom polityki, który również chcesz przyznać
role do grupy Google zamiast
poszczególnych użytkowników, ponieważ jest to łatwiejsze do dodania
lub usunąć członków z grupy Google
zamiast aktualizować politykę im i
wreszcie, gdy musisz przyznać wiele
role do zadania, które powinieneś utworzyć
Grupa Google, ponieważ jest to o wiele łatwiejsze
nadaj role tej grupie, a następnie
dodaj użytkowników do tej grupy w przeciwieństwie do
do dodawania ról dla każdego użytkownika
i to wszystko, co chciałem omówić
tę krótką, ale bardzo ważną lekcję nt
najlepsze praktyki, jeśli chodzi o iam now
Wiem, że to nie jest najbardziej ekscytujące
temat, ale stanie się niezwykle
konieczne, gdy masz do czynienia
zarządzanie grupami użytkowników i politykami w
środowiskach, które wymagają użycia iam
bezpiecznie i proszę o tym pamiętać
kiedykolwiek pracujesz w jakimkolwiek
środowisko, ponieważ pomoże ci to przyznać
odpowiednie uprawnienia, jeśli chodzi o
te różne tematy, więc teraz bardzo
polecam zrobić sobie przerwę chwycić
herbatę lub kawę przed przejściem do
następna sekcja i tak na razie możesz zaznaczyć
tę lekcję jako kompletną i kiedykolwiek
jesteś gotowy, dołącz do mnie w następnym
Sekcja
[Muzyka]
Witamy spowrotem
teraz chciałem, aby było to tak proste, jak
możliwe dla tych uczniów, którzy tego nie robią
mieć doświadczenie w sieci lub jakiekolwiek
ogólna wiedza o sieciach, czyli
dlaczego chciałem dodać to szybko
odświeżenie sieci, aby rozpocząć
sekcja sieciowa tego kursu, tzw
mając to na uwadze, zanurzmy się w tym
zanim pojawiły się komputery internetowe
samodzielny i nie miał
możliwości wysyłania e-maili
przesyłać pliki ani udostępniać żadnych informacji
szybko do przodu o jakiś czas
ludzie zaczęli łączyć swoje
komputery razem, aby się dzielić i móc
robić rzeczy, które nowoczesne sieci
może dzisiaj zrobić część bycia w tym
sieć jest w stanie zidentyfikować każdą z nich
komputer, aby wiedzieć, gdzie wysłać i
odbierać pliki
ten problem został rozwiązany za pomocą
adres identyfikujący każdy komputer w sieci
sieci, podobnie jak ludzie, używają adresu ulicy
określić, gdzie mieszkają
aby poczta i paczki mogły być
dostarczony im adres IP jest używany
zidentyfikować komputer lub urządzenie na dowolnym
sieć, więc komunikacja między
machine zostało zrobione przy użyciu ip
adres
numeryczna etykieta przypisana do każdego
urządzenie podłączone do sieci komputerowej
który używa protokołu internetowego do
komunikacja znana również jako ip w skrócie
więc aby ten system działał a
wprowadzono system łączności
które zdefiniowały, jak będzie wyglądać sieć
funkcjonować
ten system został złożony jako
spójny model warstw protokołów
definiowanie interoperacyjności
między urządzeniami sieciowymi a oprogramowaniem w
warstwy
standaryzować różne protokoły
komunikuje się w tym stosie this
stos jest określany jako systemy otwarte
modelu połączenia lub możesz usłyszeć
wielu określa to jako siedmiowarstwowe osi
model teraz to nie jest głębokie nurkowanie
kurs networkingu, ale czułem
muszą pokryć to, co jest konieczne
dla zrozumienia pierwiastków
nauczane na tym kursie
dla tych, którzy chcą dowiedzieć się więcej nt
model osi i warstwy w nim zawarte
proszę sprawdzić linki, które mam
w poniższym tekście lekcji
tak dla tej lekcji i następnej ja będę
pokrywać nią określone warstwy
protokoły, które są wyróżnione tutaj i
pomoże ci zrozumieć networking
pojęcia w tym kursie za pomocą bitu
lepsza przejrzystość
więc będę pokrywał warstwę 3, która jest
warstwa sieciowa 4 to tzw
warstwa transportowa i warstwa 7 to tzw
warstwa aplikacji, więc będę pierwszy
warstwę pokrywającą 3, czyli sieć
warstwa wraz z protokołem internetowym
teraz są dwie wersje
protokołu internetowego i są zarządzane
globalnie przez regionalny internet
rejestry znane również jako rir the
pierwszy to ipv4
to oryginalna wersja internetu
protokół, który po raz pierwszy pojawił się na scenie w
1981 druga wersja to ipv6, czyli
nowsza wersja zaprojektowana w 2017 roku do czynienia
z problemem adresu IPv4
wyczerpanie oznacza, że ​​ilość
użyteczne adresy IP powoli się zużywały
i będę omawiać obie wersje
protokół internetowy w trochę
głębokość, więc najpierw zanurzmy się w ipv
wersja 4. więc ipv4 można odczytać w
czytelna dla człowieka notacja reprezentowana w
zapis dziesiętny z kropkami składający się z
cztery liczby
każdy w zakresie od 0 do 255 oddzielone przez
kropkuje każdą część między kropkami
reprezentuje również znaną grupę 8 bitów
jako oktet prawidłowy zakres adresu IP
adres zaczyna się od 0.0.0.0
i kończy się na 255.255.255.255.
a to dałoby całkowitą liczbę
z ponad 4,2 miliarda adresów IP
zakres ten był postrzegany jako niezwykle duży
wtedy aż do liczby ip
dostępne adresy były szybkie
malejąca ze względu na wiele ipconnected
urządzeń, które mamy dzisiaj
i to jest, gdy nowe adresowanie
wprowadzono architekturę tzw
adresowanie klasowe, gdzie adres
został podzielony na mniejsze zakresy i to
został ci pierwotnie przydzielony, kiedy ty
potrzebny adres IP przez jednego z
rejestry odnotowane wcześniej, więc dla dowolnego danego
adres IP, które zwykle składają się z dwóch
oddzielne komponenty pierwszej części
adres służy do identyfikacji
sieci, której częścią jest adres
używana jest część, która pojawia się później
określić konkretnego hosta w ramach tego
sieci teraz pierwsza część została przypisana
dla Ciebie i Twojej firmy przez
rejestry
a druga część była dla ciebie, aby to zrobić
jak chcesz i tak te adresy IP
zostały przydzielone z mniejszych zakresów
wyjaśnione wcześniej zwane klasami
pierwszy zakres klas to klasa a
i zaczęło się od 0.0.0.0
i zakończył na poziomie 127,255
a to dałoby całkowitą liczbę
ponad 2,1 miliarda adresów ze 128
różne sieci klasy adresy IP
może obsługiwać ponad 16 milionów hostów na
sieci i tych, którzy zostali przydzieleni
adresy w tej klasie
miał stałą wartość pierwszego oktetu
drugi trzeci i czwarty oktet był wolny
dla firmy do przypisania jako oni
wybierz klasę, w której adresy IP miały być
używane przez wielkie sieci, takie jak te
wdrażane przez dostawców usług internetowych
i tak, kiedy ips zaczęło się zmniejszać, wielu
firmy zwracają tej klasie sieć
bloki z powrotem do rejestrów, aby pomóc
z rozszerzeniem pojemności adresowania i
więc następnym zakresem jest klasa b i to jest to
połowa wielkości klasy a sieć
zasięg sieci klasy B rozpoczął się o pierwszej o godz
128.0.0.0
i zakończ na 191.255.255.255
i niesie łączną liczbę ponad 1
miliardów adresów IP z ponad 16 000
sieciuje stałą wartość w tej klasie
jest pierwszego i drugiego oktetu
trzeci i czwarty oktet można zrobić
jak lubisz adresy IP w tej klasie
miały być używane dla średnich i dużych
sieci wielkości w przedsiębiorstwach i
organizacji następny zakres to klasa c
a to jest połowa wielkości klasy b
network rozpoczyna się zasięg sieci klasy c
w 192
i kończy się na 223.255.255.255
i niesie łącznie ponad pół
miliard adresów z ponad dwoma milionami
sieci i może obsługiwać do
256 zawiera stałą wartość tej klasy
jest pierwszym drugim i trzecim oktetem i
z czwartą możesz zrobić, jak chcesz
adresy IP w tej klasie
były najczęstszą klasą i były
być używany w małych firmach iw domu
sieci teraz jest jeszcze kilka
klasy, które nie były powszechnie używane
zwane klasą d i klasą e
i to wykracza poza zakres tego
oczywiście, więc nie będziemy o tym rozmawiać
i tak było w zwyczaju
przypisać publiczne adresy IP do urządzeń włączonych
Internet i zezwolił na komunikację
między urządzeniami teraz problem z
adresowanie klasowe polegało na tym
firmy, które potrzebowały większego adresu
bloków niż zapewniona sieć klasy c
otrzymali blokadę klasy B, która w
większość przypadków była znacznie większa niż wymagana
i to samo stało się z
wymagają więcej ips niż klasa b
i uzyskanie klasy w sieci blokuje to
problem wprowadził wiele zmarnowanych ips
ponieważ nie było prawdziwego środka i
więc był to sposób na zajęcie się każdym
teraz były publicznie rutowalne adresy IP
określone zakresy, które zostały przeznaczone dla
użytku prywatnego i zostały zaprojektowane do użytku
w sieciach prywatnych, czy lokalnie
lub w chmurze i znowu ich nie ma
przeznaczony do użytku publicznego, a także nie
mają potrzebę komunikowania się przez
publiczny internet i tak te prywatne ip
przestrzenie adresowe zostały znormalizowane za pomocą
Standard RFC 1918
i znowu te adresy IP są
przeznaczony do użytku prywatnego i może być używany
gdziekolwiek chcesz, o ile są
wciąż utrzymywane prywatne szanse są siecią
z którymi się zetknąłeś, czy to a
dostawcy usług w chmurze w Twojej sieci domowej lub
publiczne Wi-Fi będzie korzystać z jednego z nich
klasy, aby zdefiniować swoją sieć i
są one podzielone na trzy zakresy
pierwszy to pojedyncza klasa a z
10.0.0
kończący się na 10.255.255.255.
zakres klasy B
od 172.16.0.0
Do
172,31 kropki
i wreszcie klasa c, która się wahała
od 192.168.0.0
do 192.168.255.255.
teraz dla tych sieci, które ich używają
prywatne adresy IP w publicznym Internecie
proces, którego by użyli, jest procesem
zwane translacją adresów sieciowych
lub w skrócie nat
i omówię to w a
inna lekcja w dalszej części sekcji
ta metoda adresowania klasowego ma
został zastąpiony czymś nieco większym
wydajne tam, gdzie mogą być bloki sieciowe
zdefiniowano bardziej szczegółowo i wykonano należycie
do internetu, gdy zabraknie IPv4
adresy, ponieważ potrzebowaliśmy je przydzielić
ips wydajniej teraz ta metoda jest
zwany bezklasowym routingiem między domenami lub
w skrócie cydr teraz na bazie cydru
sieci, do których nie jesteś ograniczony
te trzy klasy sieci klasy a
b i c zostały usunięte z jakiegoś powodu
wydajniejszy, co ci na to pozwoli
tworzyć sieci w dowolnym z nich
zakresy zakresów cydru są reprezentowane przez
jego początkowy adres IP zwany siecią
adres
po którym następuje tak zwany przedrostek
który jest ukośnikiem, a następnie liczbą this
liczba ukośników reprezentuje rozmiar
sieć im większa liczba
mniejsza sieć i mniejsza
liczba, im większa sieć, tym większa
przykład tutaj
192.168.0.0 to adres sieciowy
a prefiks to ukośnik 16. teraz w
ten wysoki poziom nie jest konieczny
zrozumieć matematykę, która za tym stoi, ale ja
będzie zawierał link w tekście lekcji
dla zainteresowanych
dowiedz się więcej o tym wszystkim, czego potrzebujesz
pamiętaj, że jest tak, jak powiedziałem wcześniej
im większy numer prefiksu, tym mniejszy
sieć i mniejszy prefiks
numer im większa sieć, więc tak samo
przykład wielkości tego ukośnika 16
sieć jest tutaj reprezentowana przez this
zakreśl jego zakres adresów IP to 192.168.0.0
kończący się na 192.168.255.255.
a kiedy zrozumiesz matematykę, ty
będzie w stanie powiedzieć, że ukośnik 16
zakres oznacza, że ​​sieć jest
stała wartość w pierwszym i drugim
oktet hostów w sieci lub
range to wartości dowolnych elementów w
trzeci lub czwarty oktet, więc ta sieć
w sumie zapewni nam 65
536
adresy IP teraz powiedzmy, że zdecydowałeś
stworzyć dużą sieć, taką jak ta
i chciałeś przeznaczyć część tego na
inna część Twojej firmy, którą możesz
po prostu zrób to, dzieląc go na dwie części
i zostań z dwiema sieciami ukośnymi 17
więc zamiast jednego ukośnika 16 sieci
będzie miał teraz 2 17 sieci i każda
sieć zostanie przypisana 32
768 adresów IP, więc po prostu je złamać
w dół poprzedniej sieci, która była
192.16
ukośnik 16 z pierwszymi dwoma
oktety to sieć, która jest
192.168
pozostawia trzeci i czwarty oktet
rozdawaj jak chcesz a te trzecie
i czwarte oktety
są tym, czego potrzebujesz, aby je utworzyć
dwie sieci, więc patrząc na niebieską połowę
zakres adresów rozpocznie się od 0.0 i
zakończy się na 127,255.
zielona połowa rozpocznie się w połowie
przez sieć slash 16, która to zrobi
Być
128,0 i kończy na 255,255.
więc co z tego, że chciałem się złamać
tę sieć jeszcze bardziej i zepsuć
to na cztery sieci dobrze za pomocą cydru
zakresy, co sprawia, że ​​​​rzeczy są dość łatwe, ponieważ
mogę go mieć ponownie i jak pokazano tutaj i
podzieliłby dwie ukośne 17 sieci na
utwórz cztery sieci slash 18, więc jeśli i
wziął niebieskie półkole i podzielił je
na dwie części, a następnie dzielenie zielonego
półkole do
to pozostawiłoby mnie z czterema ukośnikami 18
sieci, jak widać tutaj niebieska ćwiartka
zacznie się od 192.168.0.0
kończący się dwoma ostatnimi oktetami
63.255
i czerwona ćwiartka, która zaczyna się od
gdzie skończył się niebieski
zaczynając od ostatnich dwóch oktetów 64,0
i kończąc na 127,255.
zielona dzielnica znów ruszyła
z wcześniej zdefiniowanym 128.0
sieć, w której znajduje się czerwona dzielnica
przerwane i kończące się na dwóch ostatnich
oktety są
191.255 i wreszcie żółta ćwiartka
zaczynając od miejsca, w którym jest zielony
kwarta zakończyła się na poziomie 192,0 z ostatnią
dwa oktety kończące się na
255,255 i tak by nas to zostawiło
cztery mniejsze sieci slash 18 zerwane
w dół od dwóch poprzednich
17 sieci z każdą z tych sieci
składający się z 16
384 adresów IP i możemy kontynuować
ten proces stale mający
sieci i dzieląc je na
mniejsze sieci tego procesu
dzieląc każdą sieć na dwie mniejsze
sieci są znane jako podsieci i każda z nich
czas podzielić sieć na podsieci i utworzyć dwie
mniejsze sieci numer w
prefiks wzrośnie, więc to wiem
jest już dużo do przyjęcia, więc to
byłby dla ciebie idealnym momentem na złapanie
kawa albo herbata i kończę
część pierwsza tutaj, a część druga będzie
kontynuacja zaraz po części pierwszej tzw
możesz teraz oznaczyć tę lekcję jako zakończoną
i do zobaczenia w następnym
część druga
[Muzyka]
witaj z powrotem i jestem na tej lekcji
będzie obejmował drugą część
odświeżenie sieci teraz część druga
ta lekcja zaczyna się natychmiast od
koniec części pierwszej, więc z tą istotą
powiedział, zanurkujmy
teraz wiem, że ten odświeżacz sieci ma
wypełniono toną liczb
z podstawowym nurtem matematyki, ale ja
chciałem, żebyś skupił się na tym, dlaczego tak jest
wszystko nabierze sensu później, chciałem
najpierw wprowadź twarde rzeczy, aby to zrobić
przez cały czas trwania tego kursu
być w stanie przetrawić te informacje
i zrozumieć, gdzie to pasuje
podczas omawiania różnych sieci
części chmury Google to również będzie
pomóc ci ogromnie w prawdziwym świecie jako
jak również egzamin podczas konfigurowania
sieci i wiedzieć, jak wykonać pracę
inżyniera
więc wchodząc w to, chciałem
po prostu zrób krótką recenzję bez klasy
routing między domenami lub cydr, tak jak
omówione w pierwszym odświeżeniu ipv4
adres jest podany w postaci dziesiętnej z kropkami
notacja obok ukośnika 16 to
prefiks i określa, jak duża jest sieć
jest i dlatego zanim przejdę dalej, chciałem
dać kilka referencji, które znalazłem
pomocne w ustaleniu rozmiaru
sieci i tak oto mam
wymieniono trzy najczęstsze
przedrostki
że ciągle wpadam na to, że ja
Myślę, że byłoby to niezwykle pomocne
odniesienie dla ciebie, więc jeśli spojrzysz na
pierwszy adres ip
192.168.0.0
z ukośnikiem 8, tak jak przedrostek ukośnik 8
należą do klasy, do której należy sieć
pierwszy oktet
jak również będąc częścią sieci
adres zostanie naprawiony, a więc host
część tego byłaby czymkolwiek po tym
więc adres może mieć wartość 192 kropek
a ten asortyment cydrów dałby ci spokój
16 milionów adresów IP zajmuje drugie miejsce
wspólna sieć, którą widzę, to ukośnik 16
network, a to spowodowałoby upadek tego adresu IP
w sieci klasy b, która jest pierwsza
dwa oktety ustalone i będące siecią
część oznaczająca, że ​​wszystko po 192.168.1
będzie częścią hosta, co oznacza, że
adres może być
192.168.cokolwiek i to by ci dało
65536 adresów ip i tak dla trzeciego
adres ip, który jest prawdopodobnie najbardziej
pospolity, który widzę
to sieć slash 24, która podlega
sieć klasy c, co oznacza, że ​​pierwsza
trzy oktety są stałe, a czwarty
oktet może mieć wartość od zera do dwóch
pięć pięć i to by ci dało
256 adresów IP i inny wspólny
który jest najmniejszy, jaki zobaczysz
to przedrostek ukośnika 32, a to jest jeden
którego stale używam do białych list
mój adres IP i ponieważ ukośnik 32 to
jeden adres IP, który jest dobry
wiedzieć, kiedy konfigurujesz VPN dla
siebie lub umieszczasz swój adres IP na białej liście
adres z domu lub pracy i dla
ostatnia wzmianka, jak również jest
największa sieć to adres IP
0.0.0.1
ukośnik 0, który obejmuje wszystkie adresy IP
adresy i zobaczysz to często
używany do bramy internetowej w dowolnym
środowisko chmurowe i oto kilka z nich
wspólne przedrostki, które pojawiają się bardzo
często i mam nadzieję, że to odniesienie
pomoże ci teraz wrócić do osi
model, który omówiłem ipv4 w sieci
warstwa, więc teraz czas na dyskusję
ipv6 teraz, jak zauważyłem wcześniej
notacja IPv4 jest nazywana dziesiętną z kropkami
a każda liczba między kropkami to an
oktet o wartości od 0 do 255. now
pod tym wszystkim każdy oktet jest wymyślony
o wartości 8-bitowej i mający cztery
numery w adresie IP, który by to zrobił
to 32-bitowa wartość ipv6 jest znacznie dłuższa
wartość i jest reprezentowana w systemie szesnastkowym
a każde ugrupowanie to dwa oktety
16 bitów i jest często określany jako a
hextet teraz, ponieważ te adresy są bardzo
dopóki widzisz, że jesteś w stanie
skróć je, usuwając zbędne
zera, więc ten pokazany tutaj przykład to
ten sam adres co powyżej, więc jeśli
istnieje sekwencja zer, którą możesz
po prostu zastąp je jednym zerem, więc wejdź
to adres każdej grupy czterech zer
może być reprezentowany przez jedno zero i if
masz wiele grup zer w jednym
adres
możesz usunąć je wszystkie i zastąpić je
z podwójnymi dwukropkami, więc każdy z tych ipv6
adresy, które tu widzisz, są dokładnie takie same
to samo teraz każdy adres ipv6 to 128
bitów i jest reprezentowany w postaci a
podobny sposób do
ipv4 zaczynając od adresu sieciowego
i kończąc na przedrostku każdego hextetu
ma 16 bitów, a numer prefiksu to the
liczba bitów reprezentujących
sieć z tym przykładem
ukośnik 64 odnosi się do adresu sieciowego
podkreślone na zielono, czyli rok 2001
dwukropek de3 każdy hextet to 16 bitów, a
przedrostek to 64. więc to cztery grupy
16 i stąd wiemy, która część
jest częścią sieciową adresu i
która jest hostową częścią adresu
ponownie zwróć uwagę na podwójny dwukropek tutaj i
jak wyjaśniłem wcześniej wszelkie niepotrzebne
zera można zastąpić podwójnym dwukropkiem
więc ten adres reprezentowałby a
mnóstwo zer i tak dodając wszystkie
zeruje początkowy adres sieciowy ipv6
wyglądałby teraz tak, ponieważ
adres sieci zaczyna się od dwukropka 2001 de3
z kolejnymi dwoma hextetami zer jako
adres sieciowy określony przez
przedrostek ukośnika 64, który wynosi cztery
hextetów oznacza, że ​​sieć kończy się na
ten adres sieciowy, po którym następują wszystkie fs
i to jest proces, w jaki sposób możemy
określić początek i koniec każdego
sieć ipv6 teraz, jak ci pokazałem
wcześniej ze wszystkimi adresami IPv4, którymi są
reprezentowane przez 0.0.0.0.0
a ponieważ adresy IPv6 są
reprezentowane przez ten sam adres sieciowy
i prefiks możemy reprezentować ipv6
adresy jako podwójny dwukropek ukośnik zero i
zobaczysz to często podczas używania
ipv6 i tak wiem, że tak jest naprawdę
skomplikowane, ale chciałem tylko dać
nie oczekuję ekspozycji IPv6
żebyś to od razu zrozumiał
w końcu powinno stać się dużo
jaśniejsze, gdy przechodzimy przez kurs i
obiecuję ci, że stanie się dużo
łatwiejsze, sam miałem trudności z próbowaniem
zrozumieć tę koncepcję sieci
ale po kilku dniach udało mi się
strawić to i jak wróciłem i zrobiłem
trochę praktyki zaczęło dużo robić
więcej sensu do mnie i tak wiem jak my
iść z kursem
że zacznie to mieć dla ciebie sens
jak również teraz, kiedy omówiliśmy
warstwa 3 w modelu osi, który chciałem uzyskać
do warstwy 4, która jest transportem
warstwa z pakietami ip omawiająca tcp i
udp i tak w najprostszej postaci pakiet
jest podstawową jednostką informacji w
transmisja sieciowa, więc większość sieci
użyj tcpip jako protokołu sieciowego lub zestawu
zasad komunikacji między
urządzenia i zasady tcpip wymagają
informacje do podzielenia na pakiety
które zawierają segment danych
przekazany wraz z protokołem i
jego numer portu adres pochodzenia
oraz adres, pod który dane mają trafić
zostać wysłane teraz udp jest kolejnym protokołem, który
jest wysyłany z ip i jest używany w określonych sytuacjach
aplikacje, ale głównie w tym kursie, tj
będzie odnosić się do tcpip i tak jak ty
widać na tym schemacie pakietu ip
to jest podstawowy datagram tego, co a
pakiet wyglądałby ponownie z tym
źródłowy i docelowy adres IP
numer portu protokołu i dane
sobie teraz jest to głównie po to, aby dawać
masz wysoki poziom zrozumienia tcpip
i udpip i nie jest głębokim nurkowaniem
sieci teraz przechodzi do warstwy 7
model osi
ta warstwa jest używana przez sieć
aplikacje lub aplikacje, które używają
internet i jest ich dużo
protokoły, które należą teraz do tej warstwy
te aplikacje nie znajdują się w tym
warstwa, ale użyj w tym protokołów
warstwa do działania, więc aplikacja
warstwa świadczy usługi dla sieci
aplikacji za pomocą protokołów
do wykonywania działań użytkownika i będziesz to robić
zobacz, jak wiele z tych protokołów jest
poruszane podczas przechodzenia przez ten kurs
poprzez zasoby w chmurze Google, takie jak
http lub https do równoważenia obciążenia DNS
który używa udp na porcie 53 i ssh na porcie
22 za logowanie do hostów i tyle
to tylko kilka z wielu scenariuszy
gdzie warstwa 7 i protokoły, które
przebywać w tej warstwie, pojawiać się w tej
oczywiście i będziemy nurkować w wielu
więcej na kolejnych lekcjach i tak dalej
about podsumowuje to odświeżenie sieci
lekcja
i nie martw się, jak powiedziałem wcześniej
nie spodziewając się, że odbierzesz rzeczy
to pierwsze podejście
sprawy zaczną nabierać większego sensu
przechodzimy przez kurs i zaczynamy
wprowadzając te koncepcje sieciowe
praktyka również nie krępuj się wrócić i
ponownie przejrzyj kilka ostatnich lekcji
jeśli rzeczy nie miały dla ciebie sensu
pierwszy raz lub jeśli natkniesz się na jakieś
wyzwania związane z tworzeniem sieci na przyszłych lekcjach
i to jest wszystko, co chciałem
okładkę, dzięki czemu możesz teraz oznaczyć tę lekcję jako
zakończyć i przejść do następnego
jeden
[Muzyka]
witamy z powrotem w tej lekcji będziemy
omówienie podstawowej usługi sieciowej
wirtualnej chmury prywatnej gcp lub vpc dla
w skrócie jest to usługa, która pozwala
do tworzenia sieci w chmurze Google
zarówno z prywatnymi, jak i publicznymi
opcje łączności zarówno w chmurze
wdrożeń i lokalnej chmury hybrydowej
wdrożeń jest to usługa, którą ty
musi dobrze wiedzieć, bo jest ich wielu
pytania, które pojawiają się na egzaminie
jeśli chodzi o vpcs, to powiedziawszy
przejdźmy teraz do tego, co zarządza vpcs
funkcjonalność sieciową dla Twojego
zasoby Google Cloud to jest
sieć zdefiniowana programowo i nie jest
ograniczone fizycznymi ograniczeniami
sieci w centrum danych to ma
zostały wyodrębnione dla sieci vpc
w tym związane z nimi trasy i
reguły zapory sieciowej są zasobami globalnymi
nie są związane z żadnym konkretnym
regionie lub strefie są zasobami globalnymi
i obejmują wszystkie dostępne regiony
kula ziemska, jak wyjaśniono wcześniej, vpcs są
również zamknięte w projektach
projekty są logicznym kontenerem, w którym
twoje vpcs na żywo
teraz te vpcs nie mają zakresów ip, ale
są po prostu konstruktem wszystkich
indywidualne adresy IP i usługi
w tej sieci adresy IP i
zakresy są określone w
podsieci, w które będę się zagłębiać
też trochę później
ruch do i z instancji może być
kontrolowane za pomocą reguł zapory sieciowej
reguły są implementowane na vms
siebie, aby można było kontrolować ruch
i rejestrowane, gdy opuszcza lub przybywa do a
vm
teraz zasoby w sieci vpc
mogą komunikować się ze sobą za pomocą
przy użyciu wewnętrznych lub prywatnych adresów IPv4
i podlegają one obowiązującym
zapora sieciowa rządzi tymi zasobami
musi być w tym samym vpc dla
Komunikacja
w przeciwnym razie muszą przejść przez publiczność
Internet z przypisanym publicznym adresem IP lub
użyj połączenia równorzędnego vpc lub
nawiązać połączenie VPN inne
ważną rzeczą do zapamiętania jest to, że vpc
sieci obsługują tylko emisję pojedynczą IPv4
ruchu nie obsługują ruchu IPv6
w sieci vms w vpc
sieć może wysyłać tylko do ipv4
miejsca docelowe
i odbierać ruch tylko z ipv4
źródeł, jednak możliwe jest tworzenie
adres IPv6 dla obciążenia globalnego
Balancer teraz, chyba że tak zdecydujesz
wyłącz go, od którego zaczyna się każdy nowy projekt
domyślna sieć w vpc domyślna
network to sieć vpc w trybie automatycznym
predefiniowanych podsieci przydzielana jest podsieć
dla każdego regionu bez nakładania się
cydr blokuje również każdą domyślną sieć
ma domyślną regułę zapory
te reguły są skonfigurowane tak, aby zezwalać
ruch przychodzący
dla icmp
ruch rdp i ssh z dowolnego miejsca
jak również ruch wchodzący z wewnątrz
sieć domyślna dla wszystkich protokołów
i porty, więc są dwa różne
rodzaje sieci vpc
tryb automatyczny lub tryb niestandardowy tryb automatyczny
sieć ma również jedną podsieć na region
domyślna sieć to tak naprawdę auto
tryb sieci, jak wyjaśniono wcześniej
z których korzystają te automatycznie utworzone podsieci
zestaw predefiniowanych zakresów adresów IP z rozszerzeniem a
uciąć 20 bloków cydru, które mogą być
rozszerzony do ukośnika 16 bloków cydru
z tych podsieci
mieścić się w zakresie domyślnym
10.128.0.0 ford slash 9 blok cydru i
w miarę udostępniania nowych regionów gcp
są nowe podsieci w tych regionach
automatycznie dodany do trybu automatycznego
sieci korzystające z zakresu adresów IP w tym bloku
teraz niestandardowa sieć nie
automatycznie tworzyć podsieci
zapewnia ten typ sieci
pełną kontrolę nad swoimi podsieciami i IP
zakresy, a także kolejna notatka auto
sieć w trybie można przekonwertować na a
sieć w trybie niestandardowym, aby uzyskać większą kontrolę
ale pamiętaj, że ta konwersja jest
jeden sposób, co oznacza, że ​​niestandardowe sieci
nie można zmienić na sieci w trybie automatycznym
więc przy podejmowaniu decyzji o różnych typach
sieci, z których chcesz korzystać
upewnij się, że przejrzałeś wszystkie swoje
rozważania teraz tryb niestandardowy vpc
sieci są bardziej elastyczne i lepsze
nadaje się do produkcji i google
zaleca korzystanie z niestandardowego trybu vpc
sieci w produkcji, więc tutaj jest
przykład projektu, który zawiera trzy
sieci, które obejmują wszystkie te sieci
wielu regionach na całym świecie, tak jak Ty
widać tutaj po prawej stronie i
każda sieć zawiera oddzielne maszyny wirtualne i
więc ten diagram ma to pokazać
vm, które są w tej samej sieci lub vpc
może komunikować się prywatnie nawet wtedy, gdy
umieszczone w oddzielnych regionach, ponieważ vms
w sieci a są w tej samej sieci
mogą komunikować się przez wewnętrzny adres IP
adresy, mimo że są w środku
różne regiony zasadniczo twoje vms
mogą się komunikować, nawet jeśli istnieją w
różnych lokalizacjach na całym świecie, jak
o ile znajdują się w tej samej sieci
maszyny wirtualne w sieci b i sieci c
nie znajdują się w tej samej sieci, dlatego wg
domyślnie te maszyny wirtualne muszą się komunikować
zewnętrzne adresy IP, mimo że znajdują się w
ten sam region, w którym nie ma wewnętrznego adresu IP
dozwolona jest komunikacja między
sieci, chyba że skonfigurujesz sieć vpc
peering lub użyj teraz połączenia VPN i
chciał przywrócić ostrość do
domyślny vpc na minutę, chyba że ty
stworzyć politykę organizacyjną, która
zabrania, że ​​nowe projekty będą zawsze
zacznij od domyślnej sieci, która ma
jedna podsieć w każdym regionie i znowu to
jest w tym sieć vpc w trybie automatycznym
konkretny przykład, który pokazuję a
domyślny vpc z siedmioma wartościami domyślnymi
regiony wyświetlane wraz z ich adresem IP
zakresów i ponownie chcę to podkreślić
sieci vpc wraz z powiązanymi
trasy i reguły firewalla są globalne
zasoby, z którymi nie są powiązane
dowolny konkretny region lub strefę, więc
podsieci w nich są regionalne i tak dalej
kiedy tworzona jest sieć vpc w trybie automatycznym
jest jedna podsieć z każdego regionu
automatycznie utworzone w nim te
automatycznie utworzone podsieci używają zestawu
predefiniowanych zakresów adresów IP, które się w nich mieszczą
blok cydru, który tu widzisz
z 10.128.0.049
i w miarę powstawania nowych regionów Google Cloud
dostępny
są nowe podsieci w tych regionach
automatycznie dodawane do trybu automatycznego vpc
sieci
używając zakresu adresów IP z tego bloku w
dodatek do automatycznie tworzonych
podsieci można dodać więcej podsieci
ręcznie w trybie automatycznym sieci vpc w
regiony, które wybierzesz za pomocą ip
mieści się w zakresie poza 10.128.0.049
teraz, jeśli używasz domyślnego vbc lub
utworzyłeś już vpc w trybie automatycznym
możesz przełączyć sieć vpc z auto
mode na tryb niestandardowy i to jest a
konwersja jednokierunkowa tylko w trybie niestandardowym
sieci vpc nie można zmienić na automatyczne
tryb sieci vpc teraz to przynosi
teorii w praktyce w odniesieniu do
domyślny vpc
Chciałem poświęcić trochę czasu na zrobienie krótkiego
demo, więc kiedy tylko będziesz gotowy, dołącz do mnie
konsola
i tak oto jesteśmy z powrotem w konsoli
a jeśli pójdę tutaj w prawym górnym rogu
rogu jestem zalogowany jako tony bowties pod adresem
gmail.com i na górze listy rozwijanej
menu projektu Jestem zalogowany w projekcie
tony i ponieważ to demo jest ukierunkowane
wokół domyślnego vpc, którego chcę
przejdź do sieci vpc, więc idę
przejdź tutaj do lewego górnego rogu
do menu nawigacji
i zamierzam na to kliknąć i przewinąć
w dół
do sieci vpc w sieci
i tak jak widać tutaj po lewej stronie
menu ręczne jest kilka różnych
opcje, z których mogę wybierać, ale ja
nie będzie dotykał żadnego z tych tematów
ponieważ mam inne lekcje, które będą głębokie
zagłębić się w te tematy w tym demo
Chciałbym ściśle dotknąć
domyślny vpc i jak widać w
projekt tony, który utworzył plik default
vpc dla mnie z jedną podsiecią w każdej
region mający własny zakres adresów IP
i tak tylko jako przypomnienie, kiedy tylko ty
utwórz nowy projekt, który zrobi domyślny vpc
być automatycznie tworzone dla Ciebie i
kiedy te podsieci zostały utworzone
mają drogę do publiczności
internet i taka jest bramka internetowa
wymieniono tutaj odpowiednią zaporę ogniową
reguły wraz z globalnym routingiem dynamicznym
a dzienniki przepływu są wyłączone i ponownie i
będzie zagłębiać się w routing i
dzienniki przepływu w późniejszych lekcjach w
sekcja teraz wcześniej, którą wskazałem
że można przekonwertować vpc w trybie automatycznym
do niestandardowego vpc i jest to tak proste, jak
klikając ten przycisk, ale nie chcemy
jeszcze to zrobić i co chciałbym zrobić
do to przejść do domyślnego vbc
i pokazać wszystkie różne opcje
jak widać tutaj dns api nie ma
została włączona, więc dla większości z was a
dobrym pomysłem byłoby włączenie go i tak dalej
zamierzam iść dalej i zrobić to teraz jako
dobrze widać tutaj, że mogę zrobić
dostosowania do każdego z nich
podsieci lub mogę zmienić
konfiguracja samego vpc, więc jeśli i
kliknij ten przycisk edycji tutaj w
do góry mogę zmienić podsieć
tryb tworzenia wraz z dynamiką
tryb routingu, do którego przejdę za
późniejsza lekcja i to samo z
zasady serwera dns i tak, aby to zrobić
Demo trochę bardziej ekscytujące chcę
aby pokazać proces rozszerzania
podsieć, więc wejdę do nas
centralną, którą zamierzam drążyć tutaj
a oto cała konfiguracja
ustawienia dla domyślnej podsieci w pliku
nas jeden region centralny i tak dla mnie
edytuj tę podsieć, którą mogę po prostu kliknąć
przycisk edycji tutaj u góry i
więc tuż pod zakresem adresów IP jestem
monit z notatką mówiącą, że ip
zakresy muszą być unikalne i
nienakładające się, jak powiedzieliśmy wcześniej i
jest to bardzo ważny punkt, o którym należy wiedzieć
kiedy tworzysz architekturę dowolnego vpcs lub jego
odpowiednie sieci podrzędne, więc jestem
zamierzam iść dalej i zmienić podsieć
z zakresu cydru 20
i zamierzam to zmienić na 16. Jestem
nie zamierzam dodawać żadnych dodatkowych zakresów adresów IP
zamierzam zostawić prywatny dostęp do Google
i tak zostawię wszystko
inaczej jak jest
i po prostu kliknij zapisz i tak raz
to się skończyło, będę mógł zobaczyć
że mój zakres podsieci zmieni się z a
ukośnik 20 do ukośnika 16. i tak oto ty
widać teraz zakres adresów IP
zmieniono na ukośnik 16. jeśli wrócę do
strona główna sieci vpc mogę
zobacz, czy zakres adresów IP to
teraz inny niż wszystkie
pewnie pytasz, dlaczego nie mogę po prostu
zmień zakres adresów IP na wszystkich
podsieci naraz, więc nawet jeśli bym to zrobił
uwielbiam to robić
niestety google nie daje
opcja, którą musi mieć każda podsieć
skonfigurowane jeden po drugim, aby zmienić ipa
zakres adresów teraz chciałem szybko
wskocz do domyślnych reguł zapory i
jak omówiono wcześniej zasady dot
przychodzące ssh
rdp
i icmp zostały wstępnie wypełnione
wraz z domyślną regułą, która zezwala
połączenia przychodzące dla wszystkich protokołów
i porty
między instancjami w tej samej sieci
więc jeśli chodzi o trasy z poważaniem
do sieci vpc jedyna tak naprawdę
chcesz dotknąć, jest trasą domyślną
do internetu i tak bez tego
przekierować dowolną z podsieci w tym vpc
nie miałby dostępu do kierowania ruchu do
internet i tak, gdy domyślny vpc
tworzona jest domyślna brama internetowa
jest również tworzony i teraz do niego wracam
strona główna sieci vpc i
chciał przejść przez ten proces
zwiększenia zakresu adresów IP
ale robiąc to za pomocą wiersza poleceń
więc idę w górę w prawo
róg dłoni i otwórz chmurę, jestem
zrobimy to trochę większe
i tak dla tego demo mam zamiar
zwiększyć zakres adresów dla
podsieć w nas zachodnia od ukośnika 20 do
ukośnik 16, więc wkleję
Komenda
czyli sieci obliczeniowe gcloud
podsieci rozszerzają się
zakres ip kreski, a następnie nazwę
sieć, która jest domyślna, jak również
region i zamierzam zrobić uswest1 razem
z długością przedrostka, która ma zamiar
mieć 16 lat, więc wciskam enter
poproszono mnie, aby się upewnić
to jest to, co chcę robić, więc tak
chcesz kontynuować, więc będę pisać
w y dla tak i naciśnij enter i tak dalej
kilka sekund, powinienem dostać trochę
potwierdzenie i zgodnie z oczekiwaniami moja podsieć
został zaktualizowany i tak, bo lubię
aby zweryfikować wszystko, do czego teraz zmierzam
wyczyść ekran i wkleję
w poleceniu sieci obliczeniowe gcloud
podsieci opisują, a następnie podsieć
nazwa, która jest domyślna wraz z
region, który byłby uswest1 idę
aby kliknąć enter i jak widać
tutaj zakres ipsider jest spójny
z tym, co zmieniliśmy i jeśli to zrobię
szybkie odświeżenie w przeglądarce
będę mógł zobaczyć, że konsola ma
odzwierciedla to samo i zgodnie z oczekiwaniami
zakres adresów IP tutaj dla nas na zachód
jeden w konsoli odzwierciedla to, które
widzimy tutaj w Cloud Shell i tak teraz
zakończ to demo, które chciałem szybko pokazać
jak mogę usunąć domyślne vpc i
odtworzyć go, więc wszystko, co muszę zrobić, to zrobić
zagłębić się w ustawieniach
a następnie kliknij Usuń sieć vpc
tutaj na górze wezmę a
monit, aby zapytać mnie, czy jestem pewien i jestem
po prostu kliknij usuń teraz po prostu
jako notatkę, jeśli masz jakiekolwiek zasoby, które
jesteś w żadnej sieci vpc, której nie będziesz
w stanie usunąć vpc, który musiałbyś
najpierw usuń zasoby, a następnie
usuń vpc później dobrze i to
został pomyślnie usunięty i jako ty
widzi, że nie ma lokalnych sieci vpc
w tym obecnym projekcie i tak chcę
śmiało i odtwórz domyślny vpc, więc
po prostu kliknę na utwórz vpc
network i tak oto pojawia się monit
wprowadź garść informacji
za utworzenie tej nowej sieci vpc i tak dalej
zgodnie z duchem domyślnych vpcs
zamierzam nazwać ten vpc domyślną
zamierzam umieścić domyślne w
opis i tworzenie podsieci
mode zamierzam kliknąć na automatyczne i
jak widać, pojawił się monit
mnie te zakresy adresów IP będą
przypisane do każdego regionu w twoim vpc
network i jestem w stanie przejrzeć ip
zakresy adresów dla każdego regionu i as
podany przed zakresem adresów IP dla
każdy region będzie zawsze taki sam
za każdym razem, gdy tworzę
ten domyślny vpc lub utwórz vpc w pliku
tryb automatycznego tworzenia podsieci
teraz jako uwaga tutaj w ramach reguł zapory
jeśli nie wybiorę tych reguł zapory
żaden nie zostanie faktycznie utworzony, więc if
tworzysz nową domyślną vpc be
koniecznie je sprawdzę, więc idę
zostawić wszystko tak jak jest i jestem
po prostu zejść na dno i
kliknij przycisk tworzenia i wewnątrz
za minutę powinienem mieć nowy
domyślny vpc utworzony w porządku i wróciliśmy
w biznesie był domyślny vpc
odtworzony ze wszystkimi tymi podsieciami w
jego odpowiednie regiony wszystkie ip
zakresy adresów reguły zapory
wszystko, co widzieliśmy wcześniej w
domyślny vpc i to w zasadzie tyle
wszystko, co chciałem omówić w tym demo
domyślna sieć vpc wraz z
lekcja na temat vpcs, więc możesz to teraz zaznaczyć
lekcję za zakończoną i przejdźmy dalej
Następny
witam z powrotem i jestem na tej lekcji
będę omawiał sieć vpc
podsieci teraz terminy podsieć i podsieci
network są synonimami i są używane
zamiennie w chmurze Google jako
usłyszysz, jak używam jednego z nich w tym
lekcja, ale odnoszę się do tego samego
rzeczą teraz, gdy tworzysz zasób w
Google Cloud wybierasz sieć i
podsieć, a więc ponieważ potrzebna jest podsieć
przed utworzeniem zasobów trochę dobra
niezbędna jest wiedza, która się za tym kryje
zarówno budowanie, jak i chmura Google
jak na egzaminie tak i na tej lekcji będę
obejmujące podsieci na głębszym poziomie
wszystkie jego cechy i funkcjonalność tzw
powiedziawszy to, zanurzmy się
teraz każda sieć vpc składa się z jednego lub
bardziej przydatne partycje zakresu adresów IP
zwane podsieciami znanymi również w google
chmura jako podsieci, którymi jest każda podsieć
powiązany z regionem i vpc
sieci nie mają żadnego adresu IP
zakresy z nimi związane zakresy ip
są zdefiniowane dla podsieci sieci
musi mieć co najmniej jedną podsieć przed tobą
może z niego korzystać i jak wspomniano wcześniej, kiedy
utworzysz projekt, który utworzy
domyślna sieć vpc z podsieciami w każdej
region automatycznie uruchomi się tryb automatyczny
w ramach tej samej funkcjonalności, teraz niestandardowej
z drugiej strony uruchamiają się sieci vpc
bez podsieci, co daje pełną kontrolę
nad tworzeniem podsieci i możesz tworzyć
więcej niż jedną podsieć na region
nie może zmienić nazwy ani regionu a
podsieć po jej utworzeniu
musisz usunąć podsieć i zastąpić ją
dopóki żadne zasoby go nie używają
podstawowe i drugorzędne zakresy dla podsieci
nie może pokrywać się z żadnym przydzielonym zakresem
dowolny pierwotny lub wtórny zakres
inną podsieć w tej samej sieci
lub dowolne zakresy adresów IP podsieci w sieci równorzędnej
sieci innymi słowy muszą być
unikalny ważny blok cydru teraz, kiedy to
przychodzi do adresów IP podsieci google
vpc w chmurze ma niesamowitą funkcję
pozwala zwiększyć przestrzeń ip dowolnego
podsieci bez wyłączania obciążenia lub
przestojów, jak pokazano wcześniej w
poprzednią lekcję i to daje
elastyczność i możliwości rozwoju
Twoje potrzeby, ale niestety są
pewne zastrzeżenia, że ​​nowa podsieć nie może
pokrywają się z innymi podsieciami w tej samej sieci
Sieć vpc w dowolnym regionie również nowa
podsieci muszą pozostać wewnątrz RFC 1918
przestrzeni adresowej, jaką musi spełniać nowy zakres sieci
być większy niż oryginał, co oznacza
długość przedrostka musi być mniejsza w
numer i raz podsieć została
rozwinięty, nie można cofnąć rozszerzenia
teraz sieć w trybie automatycznym zaczyna się od a
ukośnik 20 zakres, który można rozszerzyć do a
16 zakres ip, ale nie większy też możesz
przekonwertować sieć w trybie automatycznym na a
sieć w trybie niestandardowym, aby zwiększyć ip
zakres jeszcze dalej i znowu to jest
konwersja jednokierunkowa
sieci vpc w trybie niestandardowym nie mogą być
zmieniono na sieci vpc w trybie automatycznym
teraz w dowolnej sieci utworzonej w
chmura google
zawsze będą jakieś adresy IP
których nie będziesz mógł używać i
są one zarezerwowane dla Google i tak dalej
każda podsieć ma cztery zarezerwowane adresy IP
adresy w swoim podstawowym zakresie adresów IP i
tak jak uwaga, nie ma zarezerwowanych adresów IP
adresy w drugorzędnych zakresach IP i
te zarezerwowane adresy IP można postrzegać jako
pierwsze dwa i ostatnie dwa ip
adresy w zakresie cydru teraz
pierwszy adres w podstawowym zakresie adresów IP
dla podsieci jest zarezerwowany dla
połączyć w sieć drugi adres w
Podstawowy zakres adresów IP dla podsieci to
zarezerwowane dla bramy domyślnej i
umożliwia dostęp do Internetu
przedostatni adres w głównym adresie IP
zakres dla podsieci jest zarezerwowany
Google Cloud do potencjalnego wykorzystania w przyszłości
i ostatni adres oraz zakres ip
dla podsieci jest dla rozgłaszania
a więc to o obejmuje ten krótki jeszcze
ważna lekcja na temat podsieci sieci vpc
te cechy i funkcjonalności
podsieci, które zostały ci przedstawione
pomoże ci zrobić lepszy projekt
decyzje, które dadzą ci trochę więcej
wiedza i elastyczność, jeśli chodzi
do przypisywania ipspace w twoim vpc
sieci i to wszystko, co muszę
przykryj tę lekcję, abyś mógł teraz
zaznacz tę lekcję jako zakończoną i przejdźmy do rzeczy
przejść do następnego
[Muzyka]
witaj z powrotem i jestem na tej lekcji
będzie przechodzić
routing i prywatny dostęp do Google
teraz, chociaż routing tak naprawdę się nie wyświetla
na egzaminie chciałem ci dać
wewnątrz spojrzeć na to, jak ruch jest kierowany tzw
kiedy budujesz w chmurze Google
będziesz dokładnie wiedział, czego będziesz potrzebować
zrobić, jeśli chcesz edytować te trasy
w jakikolwiek sposób lub jeśli musisz zbudować nowy
te, które zaspokoją twoją konkretną potrzebę teraz
prywatny dostęp do google wyskakuje z głowy
na egzaminie ale tylko na wysokim poziomie ale
chciałem wejść trochę głębiej
usługi i dostać się do przepływu danych
kiedy usługa jest włączona
powiedziawszy, zanurzmy się teraz w google
Trasy w chmurze definiują ścieżki, które
ruch sieciowy pobierany jest z instancji maszyny wirtualnej
do innych miejsc docelowych tych miejsc docelowych
może znajdować się w twoim vpc w chmurze Google
network na przykład w innej maszynie wirtualnej lub
poza nim w sieci vpc trasa
składa się z jednego miejsca docelowego
i pojedynczy następny przeskok, gdy instancja
w sieci vpc wysyła pakiet google
cloud dostarcza pakiet do trasy
następny przeskok, jeśli jest miejscem docelowym pakietu
adres znajduje się na trasie
zakres docelowy
i tak wszystkie te trasy są przechowywane
tablica routingu dla vpc teraz dla
ci z was, którzy nie znają A
tablica routingu w sieciach komputerowych a
tablica routingu to tablica danych przechowywana w
router lub host sieciowy, który wyświetla listę
trasy do określonej sieci
miejsca docelowe, a więc w tym przypadku vpc
jest odpowiedzialny za przechowywanie tras
table, a także każda instancja vm ma plik
kontroler, który jest o wszystkim informowany
obowiązujące trasy
z tablicy routingu sieci
pakiet opuszczający vm
jest dostarczany do odpowiedniego następnego przeskoku
odpowiedniej trasy na podstawie a
kolejność trasowania teraz chciałem wziąć
kilka minut, aby przejść przez
różne typy tras, które są
dostępne w chmurze Google teraz w Google
cloud istnieją dwa rodzaje routingu
jest wygenerowany system, który
oferuje trasę domyślną i podsieci oraz
następnie są niestandardowe trasy, które
obsługują trasy statyczne i trasy dynamiczne
więc najpierw chciałem objąć system
wygenerowane trasy w trochę
głębokość i tak każda nowa sieć czy
może to być automatyczny vpc lub niestandardowy vpc
ma dwa typy tras generowanych przez system
domyślna trasa, którą możesz usunąć lub
zastąp i jedną trasę podsieci dla każdego z nich
jego podsieci teraz, gdy tworzysz vpc
sieć Google Cloud tworzy system
wygenerowana trasa domyślna i ta trasa
służy dwóm celom, określa ścieżkę
poza siecią vpc, w tym
ścieżka do Internetu oprócz
wystąpienia tej trasy muszą się spełniać
dodatkowe wymagania, jeśli potrzebują
dostęp do internetu również trasą domyślną
zapewnia standardową ścieżkę dla private
dostęp do Google i jeśli chcesz
całkowicie odizolować swoją sieć od
Internet lub jeśli musisz wymienić
trasę domyślną z trasą niestandardową
może teraz usunąć domyślną trasę, jeśli ty
usuń domyślną trasę i nie rób tego
zamień pakiety przeznaczone na zakresy ip
które nie są objęte innymi trasami
upuścił ostatnio wygenerowany system
Trasa domyślna ma priorytet 1000
ponieważ jego przeznaczenie jest najszersze
możliwe, które obejmuje wszystkie adresy IP
w
Zakres 0.0.0.0.0 używany tylko przez Google Cloud
to, jeśli trasa jest bardziej szczegółowa
miejsce docelowe nie dotyczy pakietu
i będę przechodzić do priorytetów w
tylko trochę i tak teraz, kiedy już
pokonałem domyślną trasę, którą chciałem
wejdź do trasy podsieci teraz podsieć
trasy są generowanymi przez system trasami, które
zdefiniuj ścieżki do każdej podsieci w vpc
sieci każda podsieć ma co najmniej jedną
trasa podsieci, której miejsce docelowe jest zgodne
podstawowy zakres adresów IP podsieci if
podsieć ma drugorzędne zakresy adresów IP
Google Cloud tworzy trasę podsieci z
odpowiednie miejsce docelowe dla każdego
zasięg drugorzędny, którego nie może mieć żadna inna trasa
miejsce docelowe, które pasuje
lub jest bardziej szczegółowy niż miejsce docelowe
trasy podsieci, którą możesz utworzyć
niestandardowa trasa, która ma szerszy
zakres docelowy, który zawiera
teraz zakres docelowy trasy podsieci
gdy tworzona jest podsieć, odpowiedni
trasa podsieci dla głównej podsieci
tworzony jest również dodatkowy zakres adresów IP
sieci vpc w trybie automatycznym tworzą podsieć
trasa dla podstawowych zakresów adresów IP każdego z nich
ich automatycznie tworzonych podsieci
możesz usunąć te podsieci, ale tylko wtedy, gdy
konwertujesz sieć vpc w trybie automatycznym na
trybie niestandardowym i nie można usunąć pliku
trasy podsieci, chyba że zmodyfikujesz lub usuniesz
podsieć, więc kiedy usuniesz podsieć
wszystkie trasy podsieci zarówno dla sieci podstawowej, jak i
zakresy drugorzędne są usuwane
automatycznie nie można usunąć
trasa podsieci dla głównej podsieci
zasięg w jakikolwiek inny sposób i tak jak a
zwróć uwagę, kiedy sieci są połączone przez
przy użyciu komunikacji równorzędnej sieci vpc, co zrobię
wejdź trochę później do jakiejś podsieci
importowane są trasy z jednej sieci
do innej sieci i odwrotnie
i nie można go usunąć, chyba że się złamiesz
relacji równorzędnej, a więc kiedy ty
zerwij wszystkie relacje równorzędne
zaimportowane trasy podsieci z drugiej
network są automatycznie usuwane, więc teraz
że omówiliśmy wygenerowany system
trasy, które chciałem przejść do custom
trasy są teraz trasami niestandardowymi
trasy statyczne, które możesz utworzyć
obsługiwane ręcznie lub dynamicznie
automatycznie przez jednego lub więcej Twoich
routery w chmurze i na których są one tworzone
górę już utworzonego systemu
generowane trasy docelowe dla niestandardowych
trasy nie mogą być zgodne ani specyficzne niż
dowolnej trasy podsieci w sieci
Trasy statyczne mogą używać dowolnego z static
trasy kolejne przeskoki i można je utworzyć
ręcznie, jeśli korzystasz z chmury Google
Console, aby utworzyć tunel VPN w chmurze
który używa routingu opartego na zasadach lub jednego
czyli statyczne trasy VPN oparte na trasach
dla zdalnych selektorów ruchu są
stworzony dla ciebie i tak po prostu, aby ci dać
trochę więcej jasności i trochę
trochę kontekstu, który zawarłem a
zrzut ekranu tutaj dla wszystkich różnych
trasy, które są dostępne dla następnego
Hop, mamy domyślną bramę internetową
aby zdefiniować ścieżkę do zewnętrznego adresu IP
adresy określają instancję i this
gdzie ruch kierowany jest do ul
podstawowy wewnętrzny adres IP maszyny wirtualnej
interfejs sieciowy w sieci vpc
gdzie definiujesz trasę, podaj ip
adres to miejsce, w którym podajesz wewnętrzny
adres IP przypisany do wirtualnej maszyny Google Cloud
jako następny skok do tuneli VPN w chmurze
użyj routingu opartego na zasadach i opartego na trasach
vpn możesz kierować ruch do VPN
tunel, tworząc trasy, których następny
chmiel odnosi się do tunelu z nazwy i
region i tak dla przypomnienia chmura google
ignoruje trasy, których następnymi przeskokami są chmury
tunele VPN, które są wyłączone i na koniec
wewnętrzny niski poziom tcp i udp równoważy cię
może użyć adresu IP modułu równoważenia obciążenia jako
następny przeskok, który rozdziela ruch
wśród zdrowych instancji zaplecza custom
trasy statyczne, które używają tego następnego przeskoku
nie można ograniczyć do określonych instancji
przez tagi sieciowe i tak podczas tworzenia
trasy statyczne zawsze będziesz pytany
dla różnych potrzebnych parametrów
w celu stworzenia tej trasy i tak dalej
tutaj zrobiłem zrzut ekranu z
console, aby dać ci nieco więcej kontekstu
w odniesieniu do informacji, które są
potrzebne, więc najpierw jest nazwa i
opis
więc te pola identyfikują trasę a
nazwa jest wymagana, ale opis jest
opcjonalna i każda trasa w twoim projekcie
musi mieć unikalną nazwę, następna to the
sieć i każda trasa musi być
powiązany z dokładnie jedną siecią vpc
w tym przypadku zdarza się
sieć domyślna, ale jeśli masz inną
dostępnych sieci, które możesz kliknąć
na rozwijanej strzałce i wybierz a
innej sieci w zakresie docelowym
to pojedynczy blok cydru IPv4
zawiera adresy IP systemów
które odbierają przychodzące pakiety i ip
zakres musi zostać wprowadzony jako prawidłowy adres IPv4
blok cydru, jak pokazano w przykładzie
poniżej pola teraz, jeśli wiele tras
mają identyczne miejsca docelowe priorytetem jest
używany do określenia, która trasa powinna być
używany, więc niższa liczba wskazywałaby na a
wyższy priorytet, na przykład trasa z
wartość priorytetu 100 ma wyższą
priorytet niż jeden z wartością priorytetu
200, czyli najwyższy priorytet trasy
oznacza najmniejszą możliwą liczbę nieujemną
numer, a także inny świetny przykład
jeśli spojrzysz wstecz na swoje domyślne trasy
wszystkie trasy podsieci mają priorytet
zero i domyślną bramę internetową
ma priorytet 1000 i dlatego
trasy podsieci będą miały priorytet
przez domyślną bramę internetową i
wynika to z mniejszej liczby tzw
Pamiętaj, dobra zasada jest taka
im niższa liczba, tym wyższa
priorytet im wyższy numer tym niższy
teraz priorytetem jest trochę
bardziej szczegółowe, możesz określić listę
tagi sieciowe, aby tylko trasa
dotyczy przypadków, które mają co najmniej
jeden z wymienionych tagów, a jeśli nie
określ dowolne tagi, a następnie google cloud
stosuje trasę do wszystkich instancji w
sieć i wreszcie następny przeskok który
został pokazany wcześniej, jest poświęcony
do tras statycznych, które mają następne przeskoki
które wskazują opcje pokazane wcześniej
więc teraz, gdy omówiłem trasy statyczne
trochę szczegółów, w które chcę wejść
trasy dynamiczne są teraz trasami dynamicznymi
zarządzane przez jeden lub więcej routerów w chmurze i
pozwala to na dynamiczną wymianę
trasy między siecią vpc a
sieć lokalna z trasami dynamicznymi
ich miejsca docelowe zawsze reprezentują ip
wykracza poza Twoją sieć vpc
a ich następnymi przeskokami są zawsze bgp peer
adresów, którymi może zarządzać router w chmurze
trasy dynamiczne dla tuneli VPN w chmurze
korzystających z routingu dynamicznego
połączenie z chmurą i nie martw się, zrobię to
za chwilę dostaniemy się do routerów w chmurze
szczegółów w późniejszej lekcji, którą teraz chciałem
poświęcić minutę na przejście przez wyznaczanie tras
zamówienie i kolejność kierowania dotyczy
priorytety, których trochę dotknąłem
nieco wcześniej, teraz trasy podsieci są zawsze
rozważane jako pierwsze, ponieważ Google Cloud
wymaga, aby trasy podsieci miały
najbardziej konkretne miejsca docelowe pasujące do
zakresy adresów IP ich odpowiednich
podsieci, jeśli nie ma odpowiedniego miejsca docelowego
znaleziony google cloud upuszcza pakiet i
odpowiada z błędem nieosiągalności sieci
trasy generowane przez system dotyczą wszystkich
instancje w sieci vpc zakres
instancji, do których prowadzi trasa podsieci
Apply nie można zmienić, chociaż można
zastąpić domyślną trasę i tak po prostu
uwaga niestandardowe trasy statyczne dotyczą wszystkich
instancje lub konkretne instancje, więc jeśli
trasa nie ma tagu sieciowego
trasa ma zastosowanie do wszystkich wystąpień w
sieć teraz sieci vpc mają specjalne
trasy, które są używane dla niektórych
usługi i są to tzw
specjalne ścieżki powrotu w chmurze google
te trasy są zdefiniowane poza twoim
sieć vpc w produkcji Google
network nie pojawiają się w twoim vpc
tablicy routingu sieci, której nie możesz
usunąć je lub zastąpić je lub jeśli ty
usunąć lub zastąpić domyślną trasę w
swoją sieć vpc, chociaż możesz
kontrolować ruch do iz nich
usługi przy użyciu reguł zapory sieciowej i
usługi objęte są obciążeniem
Balancers rozpoznaje Internet proxy lub iap jako
jak również dns w chmurze i tak przed końcem
tę lekcję chciałem poruszyć prywatnie
google uzyskaj dostęp teraz tylko do instancji vm
mają wewnętrzne adresy IP, z których mogą korzystać
prywatny dostęp do Google i to pozwala
im dotrzeć do zewnętrznych adresów IP
apis i usług Google źródło
Adres IP pakietu może być
główny wewnętrzny adres IP serwera
interfejs sieciowy lub adres w pliku
alias zakres ip, który jest przypisany do
interfejs, jeśli wyłączysz prywatne google
dostęp do instancji vm nie może już
dotrzeć do google apis i usług oraz woli
być w stanie wysyłać ruch tylko w obrębie
prywatny dostęp do sieci vpc google nie ma
wpływ na instancje, które mają
zewnętrzne adresy IP i nadal może
dostęp do internetu, którego nie potrzebują
specjalna konfiguracja do wysyłania żądań
na zewnętrzne adresy IP Google
apis i usługi, które włączysz jako prywatne
dostęp Google do podsieci według podsieci
podstawie i jest to ustawienie dla podsieci w
sieć vpc, a ja ci pokażę
to w nadchodzącej demonstracji, w której będziemy
budujemy teraz własną niestandardową sieć vpc
mimo że następny skok do
wymagane trasy są nazywane domyślnymi
bramka internetowa
oraz adresy IP dla google apis i
usługi to zewnętrzne żądania kierowane do Google
apis i usługi z vms tylko to
przechowuj wewnętrzne adresy IP w podsieci 1
gdzie włączony jest prywatny dostęp do Google
nie są przesyłane przez publiczny Internet
te żądania pozostają w Google
network, a także maszyny wirtualne, które mają tylko
wewnętrzne adresy IP nie spełniają wymagań
wymagania dotyczące dostępu do Internetu
w celu uzyskania dostępu do innego zewnętrznego adresu IP
adresy
poza tymi dla google apis i
usługi dotykające teraz tego diagramu
Tutaj
reguły firewalla w sieci vpc mają
został skonfigurowany, aby umożliwić dostęp do Internetu
vm1 może uzyskać dostęp do Google API i usług
w tym przechowywanie w chmurze, ponieważ jego
interfejs sieciowy znajduje się w podsieci 1
który ma włączony prywatny dostęp do Google
a ponieważ ta instancja ma tylko plik
wewnętrzny adres IP
dotyczy to prywatnego dostępu do Google
instancja teraz z vm2, do której może również uzyskać dostęp
Google API i usługi, w tym chmura
storage, ponieważ ma zewnętrzny adres IP
adres prywatny dostęp do google nie ma
wpływ na tę instancję, ponieważ ma
zewnętrzny adres ip i prywatne google
dostęp do tego nie został włączony
podsieć i ponieważ oba te elementy
instancje znajdują się w tej samej sieci
nadal są w stanie komunikować się ze sobą
inny przez wewnętrzną trasę podsieci i
więc to tylko jeden ze sposobów, gdy jest prywatny
można zastosować dostęp do Google
niektóre inne opcje prywatnego dostępu jako
cóż, możesz użyć prywatnego dostępu do Google
aby połączyć się z Google API i usługami
z sieci lokalnej przez a
tunel vpn w chmurze lub połączenie w chmurze
bez żadnych zewnętrznych adresów IP
masz również możliwość korzystania
prywatny dostęp do Google przez vpc
sieciowe połączenie równorzędne, które jest
znany jako dostęp do usług prywatnych i
wreszcie ostatnia opcja dostępna dla
trwa łączenie prywatnego dostępu do Google
bezpośrednio z bezserwerowych usług Google
przez wewnętrzne połączenie vpc teraz i
wiedz, że było dużo teorii
weź, ale obiecuję, że będzie tego dużo
łatwiejsze, a konceptów będzie mniej
skomplikowane, kiedy zaczniemy to umieszczać
w praktyce wkrótce w wersji demonstracyjnej
budowania własnego niestandardowego vpc i tak dalej
to właściwie wszystko, co chciałem zawrzeć
jeśli chodzi o routing i prywatne
dostęp do Google, abyś mógł teraz to zaznaczyć
lekcję za zakończoną i przejdźmy dalej
Następny
[Muzyka]
witaj z powrotem i jestem na tej lekcji
będziemy teraz omawiać adresowanie IP
poszedłem na lekcję odświeżającą sieć
nieco głębiej na temat adresów IP
są rozkładane i wykorzystywane do
komunikacja w sieciach komputerowych w
ta lekcja, w którą się wprowadzę
dostępne typy adresowania IP w
chmura google i sposób ich wykorzystania
należy zwrócić uwagę na każdy inny scenariusz
egzamin będzie przeglądem wysokiego poziomu
trzeba wiedzieć, jeśli chodzi o ip
adresowanie, ale szczegóły za nim
da ci lepsze zrozumienie
kiedy używać każdego typu adresu IP so
powiedziawszy to, zanurzmy się
teraz adresowanie IP w blokach Google Cloud
całkiem sporo kategorii
i naprawdę zacznij od ustalenia, czy
planujesz komunikację
wewnętrznie w twoim vpc lub for
użycie zewnętrzne do komunikowania się z
świat zewnętrzny przez Internet raz
Ty określasz rodzaj komunikacji
między którymi chcesz aplikować
zasoby, trzeba podjąć jeszcze kilka decyzji
wykonane w odniesieniu do innych opcji
i będę przechodzić przez te
opcje w ciągu sekundy, aby to zrobić
zwiększ te opcje
strawne, od którego chciałem zacząć
opcje dostępne dla wewnętrznego ip
adresy
teraz wewnętrzne adresy IP nie są
publicznie reklamowane, są używane tylko
w sieci teraz każda sieć vpc
lub sieć lokalna ma co najmniej jeden
wewnętrzne zasoby zakresu adresów IP z
komunikują się z wewnętrznymi adresami IP
inne zasoby, tak jakby wszystkie były na
ta sama sieć prywatna teraz każda maszyna wirtualna
instancja może mieć jedną podstawową wewnętrzną
adres IP, który jest unikalny dla vpc
sieć i możesz przypisać konkretny
wewnętrzny adres IP podczas tworzenia maszyny wirtualnej
instancja lub możesz zarezerwować static
wewnętrzny adres IP dla twojego projektu i
przypisz ten adres do swoich zasobów, jeśli
nie podajesz adresu, pod którym będzie
automatycznie przypisany do maszyny wirtualnej w
w obu przypadkach adres musi należeć do
zakres adresów IP podsieci i tak dalej
twoja sieć to sieć vpc w trybie automatycznym
adres pochodzi z podsieci regionu
jeśli twoja sieć jest vpc w trybie niestandardowym
sieć, musisz określić, która podsieć
adres ip pochodzi od teraz all
podsieci mają podstawowy zakres sider, który
to zakres wewnętrznych adresów IP
które definiują podsieć każdej instancji maszyny wirtualnej
otrzymuje swój główny wewnętrzny adres IP
z tego zakresu można również przydzielić
alias ip mieści się w zakresie tego podstawowego zakresu
lub możesz dodać dodatkowy zakres do
podsieć i przydziel zakresy aliasów IP od
użycie drugiego zakresu aliasu ip
zakresy nie wymagają dodatkowej podsieci
zakresy te drugorzędne zakresy podsieci
jedynie zapewnić narzędzie organizacyjne
teraz, gdy używasz aliasów IP, możesz
skonfigurować wiele wewnętrznych adresów IP
reprezentujących kontenery lub aplikacje
hostowane w maszynie wirtualnej bez konieczności definiowania
oddzielny interfejs sieciowy i możesz
przypisz zakresy ip aliasów vm z jednego z nich
podstawowe lub pomocnicze zakresy podsieci
gdy skonfigurowane są zakresy aliasów IP
Google Cloud automatycznie instaluje vpc
trasy sieciowe dla podstawowego i aliasowego adresu IP
zakresy dla podsieci podstawowej
interfejs sieciowy twojego kontenera
Orchestrator lub gke nie muszą
określ połączenie sieciowe vpc dla
tych tras, co upraszcza wyznaczanie tras
ruch i zarządzanie kontenerami już teraz
przy wyborze vpc w trybie automatycznym lub
niestandardowy vpc, który będziesz mieć możliwość
wybierz efemeryczne IP lub a
statyczny adres IP jest teraz efemerycznym adresem IP
adres IP, który się nie utrzymuje
poza żywotność zasobu dla
przykład podczas tworzenia instancji lub
reguła przekierowania bez określania adresu IP
adres Google Cloud automatycznie
przypisz zasobowi efemeryczny adres IP
adres i ten efemeryczny adres IP to
zwalniane po usunięciu zasobu
kiedy adres ip zostanie zwolniony, tak jest
za darmo, aby ostatecznie zostać przydzielony
inny zasób, więc nigdy nie jest świetny
opcja, jeśli polegasz na tym adresie IP do
pozostań bez zmian to efemeryczne ip
adres może być przypisany automatycznie
i zostanie przypisany z wybranych
podsieć regionu, jeśli masz
efemeryczne adresy IP, które są
obecnie w użyciu
możesz promować te adresy
statyczne wewnętrzne adresy IP, aby
pozostają z twoim projektem, dopóki ty
aktywnie je usunąć i tylko jako notatkę
zanim zarezerwujesz istniejące IP
adres będziesz potrzebować wartości
adres IP, który chcesz teraz promować
rezerwacja statycznego adresu IP
przypisuje adres do Twojego projektu
dopóki wyraźnie tego nie zwolnisz
przydatne, jeśli jesteś zależny od
konkretny adres IP dla konkretnego
usługę i trzeba zapobiec innej
zasobu z możliwości korzystania z tego samego
Adresy statyczne adresu są również przydatne
jeśli chcesz przenieść adres IP z
jednego zasobu Google Cloud do innego i
masz te same opcje kiedy
tworzenie wewnętrznego modułu równoważenia obciążenia jako
robisz z instancjami vm i tak teraz
omówiliśmy wszystkie opcje
wewnętrzne adresy IP, które chciałbym
przejdź dalej, aby objąć wszystkie dostępne
opcje dla zewnętrznych adresów IP teraz
możesz przypisać zewnętrzny adres IP
instancja lub reguła przekazywania, jeśli ty
muszą komunikować się z Internetem
z zasobami w innej sieci lub
musisz komunikować się z publicznym google
źródła usług w chmurze z zewnątrz a
Sieć vpc w chmurze Google może adresować a
określony zasób przez zewnętrzny adres IP
adres, o ile zezwalają na to reguły zapory
połączenie i tylko zasoby z
zewnętrzny adres IP może wysłać i
odbierać ruch bezpośrednio do iz
poza siecią i jak wewnętrzny ip
adresy zewnętrzne adresy IP mają
możliwość wyboru z efemerycznego lub
statyczny adres IP jest teraz efemeryczny
zewnętrzny adres IP to adres IP
to nie trwa dłużej niż życie
zasobu, a więc następuje to samo
reguły jako efemeryczne wewnętrzne adresy IP
więc kiedy tworzysz instancję lub
reguła przekierowania bez określania adresu IP
adres zasobu jest automatycznie
przypisany efemeryczny zewnętrzny adres IP
adres i to jest coś, co ty
zobaczymy dość często efemeryczne zewnętrzne
adresy ip są zwalniane z a
zasób, jeśli usuniesz zasób dla
vm występuje efemeryczny zewnętrzny adres IP
Adres zostanie również zwolniony, jeśli zatrzymasz
instancja, więc po ponownym uruchomieniu
przypadku jest mu przypisany nowy efemeryczny
zewnętrzny adres IP i jeśli masz
istniejąca maszyna wirtualna, która nie ma pliku
zewnętrzny adres IP, który możesz przypisać
do niego reguły przekierowania zawsze mają adres IP
adres zewnętrzny lub wewnętrzny tzw
nie musisz przypisywać adresu IP
do reguły przekierowania po jej utworzeniu
a jeśli twoja instancja ma efemerydę
zewnętrzny adres IP i chcesz
trwale przypisać ip do twojego
projekt jak efemeryczne wewnętrzne IP
adresy, które możesz promować
adres IP z efemerycznego na statyczny
iw tym przypadku promowanie efemerydy
zewnętrzny adres IP na statyczny zewnętrzny
adres ip teraz podczas przypisywania static
adres IP są one przypisane do a
projekt długoterminowy, dopóki nie zostaną
wyraźnie zwolniony z tego zadania
i pozostań przywiązany do zasobu do czasu
są jawnie odłączone dla vm
instancji statyczne zewnętrzne adresy IP
pozostają dołączone do zatrzymanych instancji
dopóki nie zostaną usunięte i to jest to
przydatne, jeśli jesteś zależny od
konkretny adres IP dla konkretnego
usługi, takie jak serwer sieciowy lub globalny
system równoważenia obciążenia, który potrzebuje dostępu do
internetowe statyczne zewnętrzne adresy IP
może mieć charakter regionalny lub globalny
ratunek
w regionalnym statycznym adresie IP
zasobów tego regionu
lub zasobów stref w tym regionie
aby użyć adresu IP i tylko jako notatkę
możesz użyć własnego publicznie rutowalnego
prefiksy adresów IP jako chmura Google
zewnętrznych adresów IP i reklamować je
w internecie jest tylko jedno zastrzeżenie
musisz posiadać i przynieść co najmniej a
24 blok cydru i tak teraz mamy
omówiono ip wewnętrzne i zewnętrzne
opcje adresowania, do których chciałem się przenieść
wewnętrzne rezerwacje adresów IP teraz
statyczne wewnętrzne adresy IP zapewniają taką możliwość
aby zarezerwować wewnętrzne adresy IP
z zakresu ip skonfigurowanego w pliku
podsieć, a następnie przypisz te zarezerwowane
wewnętrzne adresy do zasobów jako
potrzebne zarezerwowanie wewnętrznego adresu IP
usuwa ten adres z dynamiki
pulę alokacji i zapobiega temu
wykorzystywane do automatycznego przydziału
z możliwością rezerwacji statycznej
wewnętrzne adresy IP, których zawsze możesz użyć
ten sam adres IP dla tego samego
zasób, nawet jeśli musisz usunąć i
odtworzyć zasób, więc kiedy nadejdzie
do wewnętrznej rezerwacji adresu IP
może albo zarezerwować statyczny wewnętrzny adres IP
adres przed utworzeniem powiązanego
zasób lub możesz utworzyć zasób
z efemerycznym wewnętrznym adresem IP
a następnie promować to efemeryczne IP
adres na statyczny wewnętrzny adres IP
i tak po prostu dać ci trochę więcej
kontekst Mam tutaj diagram, aby cię uruchomić
przez to, więc w pierwszym przykładzie ty
utworzy podsieć z twojego vpc
sieć, którą następnie zarezerwujesz
wewnętrzny adres IP z tej podsieci
podstawowy zakres adresów IP, a na tym diagramie to
oznaczony jako 10.12.4.3
i odbędzie się jako zarezerwowane na później
użyj z zasobem, a następnie kiedy ty
zdecydować się na utworzenie instancji vm lub
wewnętrzny moduł równoważenia obciążenia, którego możesz użyć
zarezerwowany adres IP, który został utworzony w
poprzedni krok, który następnie adres IP
zostaje oznaczony jako zastrzeżony i używany
teraz dotykając drugiego przykładu ciebie
najpierw utworzyłby podsieć z twojego
sieć vpc
następnie utworzyłbyś instancję vm lub
wewnętrzny system równoważenia obciążenia z albo
automatycznie przydzielany efemeryczny adres IP
adres lub konkretny adres IP, który
wybrałeś spośród tego konkretnego
podsieć i tak raz efemeryczny ip
adres jest w użyciu, możesz go promować
efemeryczny adres IP na statyczny
wewnętrzny adres IP, a następnie
stać się zastrzeżone i używane teraz, kiedy to
przychodzi na zewnętrzny adres IP
rezerwacja
jesteś w stanie uzyskać statyczny zewnętrzny
adres IP, korzystając z jednego z poniższych sposobów
dwie opcje, możesz zarezerwować nową
statyczny zewnętrzny adres IP, a następnie
przypisz adres do nowej instancji vm
lub możesz promować istniejący efemeryczny
zewnętrzny adres IP, aby stał się statyczny
zewnętrzny adres IP teraz w przypadku
zewnętrzne adresy IP, które możesz zarezerwować
dwa różne typy
regionalny adres IP, którego można użyć
przez instancje maszyny wirtualnej z co najmniej jedną siecią
interfejsy lub przez sieciowe systemy równoważenia obciążenia
te adresy IP można również utworzyć
w konsoli lub za pomocą polecenia
zgodnie z ograniczeniem, które chcesz
zezwalać tylko na tworzenie ipv4 ip
adresy, innym typem jest globalny adres IP
adres, który może być używany do global
równoważenia obciążenia i można je utworzyć
w konsoli lub za pomocą polecenia
linia, jak pokazano tutaj, ograniczenie tutaj
jest to, że musisz wybrać premię
warstwę usług sieciowych w celu utworzenia
globalny adres IP
i po zarezerwowaniu adresu możesz
w końcu przypisz go do instancji podczas
tworzenie instancji lub do istniejącej
przykład i tak jak widać jest
dużo do przyjęcia, jeśli chodzi o
zrozumienie adresowania IP i mam nadzieję
ta lekcja dała ci coś lepszego
wgląd w to, jaki rodzaj ips powinien
być używane w określonym scenariuszu, teraz nie
martw się, opcje mogą wydawać się przytłaczające
ale kiedy zaczniesz pracować z ip
adresy częściej opcje będą
stają się o wiele bardziej jasne, czego używać
i kiedy i jak powiedziałem na początku
potrzebne są tylko koncepcje wysokiego poziomu
wiedzieć na egzamin, ale znając
opcje pozwolą ci ulepszyć
decyzje
w Twojej codziennej roli inżyniera chmury
i to właściwie wszystko, czego chciałem
do pokrycia, jeśli chodzi o adresowanie IP
w Google Cloud i tak teraz, gdy już to zrobiliśmy
omówiono teorię adresowania IP
w chmurze Google chciałem to przynieść
do konsoli, aby zobaczyć wersję demonstracyjną, w której my
zajmie się tworzeniem obu
wewnętrzny i zewnętrzny statyczny adres IP
adresy, tak jak wyjaśniłem wcześniej
było dużo do przyswojenia z tą lekcją, więc
teraz byłaby ku temu doskonała okazja
wstań i rozciągnij się
herbatę lub kawę i kiedy tylko jesteś
gotowy, dołącz do mnie z powrotem w konsoli, więc ty
może teraz oznaczyć tę lekcję jako ukończoną i
do zobaczenia w następnym
[Muzyka]
witam z powrotem w tej demonstracji jestem
będziemy zastanawiać się, jak tworzyć i
zastosować zarówno wewnętrzną, jak i zewnętrzną statykę
adresy IP, które pokażę, jak to zrobić
utwórz je zarówno w konsoli, jak i w pliku
linii poleceń, a także jak promować
adresy IP z efemerycznych adresów IP do
statyczne ips i kiedy skończymy tworzyć
wszystkie adresy IP, które pokażę
kroki, jak je teraz usunąć
jest tu wiele do zrobienia, więc zróbmy to
zanurz się teraz w tej demonstracji, jestem
będzie używać projektu, który ma
utworzono domyślny vpc, więc w moim przypadku i
będzie używać projektu bowtieinc dev i
więc zanim zaczniesz, upewnij się, że twój
w projekcie tworzony jest domyślny vpc
że tak wybrałeś, aby to zrobić
że udam się do
menu nawigacji zamierzam przewinąć w dół
do sieci vpc i zobaczymy
tutaj domyślny vpc był
utworzone, więc mogę iść dalej i zacząć
demonstracja i tak po pierwsze
chciałem pokazać, jak tworzyć
statyczny wewnętrzny adres IP i tak dalej
każ mi zademonstrować, że jestem
będzie używać instancji vm i tak dalej
zabieram sie za nawigacje
menu ponownie i zamierzam przewinąć w dół
do obliczania silnika
więc tutaj stworzę mój nowy
instancję, po prostu klikając przycisk Utwórz
instancja i tak pod nazwą zamierzam
zachowaj ją jako instancję 1. w regionie ty
chcę wybrać nas na wschód i idę
aby zachować wybraną strefę jako domyślną
pod typem maszyny mam zamiar wybrać
z listy rozwijanej i wybierz e2 micro i
zostawię wszystko inne jak
domyślnie przewinę w dół
tutaj do zarządzania dyskami bezpieczeństwa
networking i najem duszy i jestem
zamiar wybrać kartę sieci z
Tam
i tak poniżej mam zamiar wybrać
w interfejsach sieciowych domyślnie
interfejs sieciowy i tutaj jest miejsce, w którym ja
może utworzyć mój statyczny wewnętrzny adres IP i tak dalej
klikając menu rozwijane pod podstawowym
wewnętrzny adres IP zobaczysz efemeryczny
automatyczny efemeryczny zwyczaj i rezerwa
statyczny wewnętrzny adres IP, więc jesteś
zamierza wybrać rezerwę statyczną wewnętrzną
adres IP, a pojawi się wyskakujące okienko
z monitem o wypełnienie niektórych pól
out, aby zarezerwować statyczny wewnętrzny adres IP
adres i tak pod nazwą jadę do
nazwij to
statyczny myślnik wewnętrzny i dla
dla celów tego demo zamierzam odejść
podsieć i statyczny adres IP jako
aktualnie wybrany, gdybym chciał
wybierz konkretny adres IP, który mogę kliknąć
na tej liście rozwijanej i wybierz pozwól mi
wybierz, a to da mi wybór
aby wprowadzić niestandardowy adres IP z rozszerzeniem
wybrany do tego zakres podsieci
określonej sieci podrzędnej, a więc dlatego, że jestem
nie zamierzam tego robić, wybieram
przypisz automatycznie, że wychodzę
cel jako nie udostępniony i jadę
aby po prostu kliknąć rezerwę i to jest to
zamierzam zarezerwować ten konkretny adres IP
adres i teraz jak widać tutaj i
mieć podstawowy wewnętrzny adres IP oznaczony jako
static internal i tak będzie
być moim pierwszym statycznym wewnętrznym adresem IP
i tak po wykonaniu tych kroków ty
możesz po prostu kliknąć gotowe i możesz
zejdź na dół i po prostu
kliknij utwórz, aby utworzyć instancję
i kiedy instancja zakończy tworzenie
zobaczysz wewnętrzny statyczny adres IP
adres i jak widać tutaj twój
statyczny wewnętrzny adres IP był
przypisany do sieci domyślnej
interfejs na instancji 1. i tak w kolejności
abym mógł zobaczyć ten statyczny wewnętrzny adres IP
adres w konsoli mogę to zobaczyć
w sieciach vpc i przejdź do
określony vpc i znajdź go w statycznym
wewnętrzne adresy IP, ale chciałem
pokazać, jak go wyświetlić, wysyłając do niego zapytanie
przez wiersz poleceń i tak po kolei
aby to zrobić, po prostu pójdę do góry
pasek menu po prawej stronie i
otwórz Cloud Shell i raz Cloud Shell
pojawił się, który zamierzasz po prostu wkleić
w poleceniu
lista adresów gcloud compute i to
da mi listę wewnętrznego adresu IP
adresy, które są dostępne i tak teraz
zostanie wyświetlony monit o autoryzację
to wywołanie API przy użyciu moich poświadczeń i i
zdecydowanie tak, więc klikam
autoryzuj i zgodnie z oczekiwaniami static
wewnętrzny adres IP, który stworzyliśmy
wcześniej się pojawił, jest oznaczony jako
wewnętrzny w regionie nas wschód jeden w
domyślna podsieć i status to in
użyj i tak, jak omówiliśmy w ostatnim
lekcja statyczne adresy IP utrzymują się nawet
po usunięciu zasobu i
więc, aby to zademonstrować, przejdę teraz do tego
usuń instancję, do której zamierzam po prostu przejść
zaznacz instancję i przejdź do
top i kliknij usuń, do którego zamierzasz
pojawi się monit, aby upewnić się, czy chcesz
usuń to tak, robię, więc zamierzam
kliknij usuń, a więc teraz, gdy plik
instancja została usunięta, zamierzam to zrobić
ponownie zapytaj o adresy IP, używając
to samo polecenie gcloud compute
lista adresów, którą zamierzam nacisnąć enter
i jak widać tutaj adres ip
static myślnik wewnętrzny nadal występuje, ale
status jest teraz oznaczony jako zarezerwowany i
więc gdybym chciał użyć tego adresu IP
w innym przypadku mogę to zrobić przez
po prostu klikając utwórz instancję w górę
tutaj w górnym menu, a potem mogę
wybierz static dash internal jako mój adres IP
adres, więc szybko zamykam
dół chmury
i mam zamiar zostawić nazwę jako
przykład jeden region
może wybrać nas na wschód i jedziemy
aby zachować wybraną strefę jako domyślną
pod typem maszyny, do której zamierzasz
wybierz typ maszyny e2 micro
aby przewinąć w dół do zarządzania zabezpieczeniami
dyski łączą się w dzierżawę dusz i
Wybieram zakładkę Networking
spod tego miejsca
i pod interfejsami sieciowymi idę
aby wybrać domyślny interfejs sieciowy
i pod podstawowym wewnętrznym adresem IP
jeśli kliknę listę rozwijaną, mam
możliwość wyboru kreski statycznej
wewnętrzny statyczny adres IP, a więc i
chciał przejść dalej, aby zademonstrować, jak to zrobić
promować wewnętrzny efemeryczny adres IP
na wewnętrzny statyczny adres IP i tak dalej
w tym celu wybieram
na efemerycznej automatycznej i zamierzam
przewiń w dół i kliknij gotowe i jestem
iść do przodu i stworzyć
instancji i gdy instancja jest gotowa
będę mógł wejść i edytować
interfejs sieciowy i taka jest instancja
zwarty i gotowy, więc idę wiercić
w dół do instancji
i zamierzam wspiąć się na górę i
kliknij edytuj, przewinę w dół
do interfejsów sieciowych i zamierzam to zrobić
edytuj domyślny interfejs sieciowy tak
przewinę trochę w dół
more i tutaj pod wewnętrznym iptype i'm
zamierzam kliknąć menu rozwijane i jestem
Wybieram statyczny
więc tutaj bierzesz prąd
adres IP, który jest 10.142.0.4
i promowanie go do statycznego wewnętrznego adresu IP
adres i tak będziesz
monit z wyskakującym okienkiem potwierdzającym
rezerwacja dla tego statycznego wewnętrznego adresu IP
adres i zauważ, że nie mam
wszelkie inne opcje i tak wszystko idę
zrobić, to wpisać nazwę i zamierzam to zrobić
nazwij to awansem
static i zamierzam kliknąć rezerwę
a to będzie promować wewnętrzny adres IP
adres z efemerycznego adresu IP do
statyczny adres IP, więc teraz jestem po prostu
kliknij gotowe
i zamierzam przewinąć w dół i kliknąć
na save i tak teraz bo chcę
zweryfikuj adres IP, do którego zamierzam się udać
naprzód i ponownie otwórz powłokę chmury
i zamierzam użyć tego samego polecenia
którego użyłem wcześniej, czyli gcloud
obliczyć listę adresów i zamierzam to zrobić
wciśnij Enter
zgodnie z oczekiwaniami promowany statyczny adres IP
adres jest wyświetlany jako wewnętrzny adres IP
adres w regionie nas wschód 1 cal
domyślna podsieć i jej stan to w
use i tak samo jak podsumowanie, które stworzyliśmy
statyczny wewnętrzny adres IP dla
pierwszej instancji i drugiej
na przykład promowaliśmy efemerydę
wewnętrzny adres IP na statyczny
wewnętrzny adres IP i udało nam się
zweryfikuj to za pomocą usługi Cloud Shell
lista adresów gcloud compute
polecenie i to jest koniec części
jedno z tego demo było trochę
długo, więc zdecydowałem się zerwać i
byłaby to świetna okazja do
żebyś wstał i się porozciągał
sobie kawę lub herbatę i kiedy tylko
jesteś gotowy dołącz do mnie w części drugiej gdzie
zaczynamy od zaraz od godz
koniec części pierwszej, więc możesz to teraz zaznaczyć
jako kompletne i do zobaczenia w następnym
jeden
[Muzyka]
Witamy z powrotem to jest druga część
tworzenie wewnętrznego i zewnętrznego ip
adresy demo i będziemy zaczynać
zaraz od końca pierwszej części tzw
powiedziawszy to, zanurzmy się i
więc teraz, gdy przeszliśmy przez to, jak to zrobić
oba tworzą statyczne adresy IP i
promować efemeryczne adresy IP na statyczne
adresy IP dla wewnętrznych adresów IP
chcę iść dalej i przejść przez
to samo z zewnętrznymi adresami IP, więc idę
najpierw zacznij od usunięcia tego
na przykład zamierzam iść dalej i kliknąć
na usunięcie
i tak zamiast robić to przez
interfejs silnika obliczeniowego, który chcę przejść
do zewnętrznego interfejsu adresu IP
które można znaleźć w sieci vpc
menu
więc idę przed siebie w lewo
róg strony kliknij menu nawigacyjne
i zamierzam przewinąć w dół do vpc
sieć
iz menu tutaj po lewej stronie
stronie możesz po prostu kliknąć zewnętrzny adres IP
adresy
a tutaj zobaczysz konsolę gdzie
możesz utworzyć statyczny zewnętrzny adres IP
adres i tak, aby rozpocząć proces ty
można po prostu kliknąć rezerwę statyczną
adres i tutaj zostaniesz poproszony
z mnóstwem pól do wypełnienia
utwórz ten nowy zewnętrzny statyczny adres IP
adres i tak dla nazwy tego
statyczny adres IP, który możesz po prostu wywołać
ta zewnętrzna kreska statyczna, do której zamierzam
użyj tego samego w opisie teraz tutaj
w ramach poziomu usług sieciowych, który mogę wybrać
z premii lub standardu
i jak widać aktualnie używam
poziom usług sieci premium i if
Najeżdżam kursorem na znak zapytania tutaj
mówi mi o tym trochę więcej
poziom usług sieciowych i jak widać
poziom premium pozwala mi wyżej
wydajność, a także mniejsze opóźnienia
routingu, ale pojawia się ten routing premium
za opłatą
natomiast standardowa usługa sieciowa
poziom oferuje niższą wydajność w porównaniu
do warstwy usług sieci premium i
jest trochę bardziej opłacalny, ale
wciąż zapewnia wydajność, to znaczy
porównywalne z innymi dostawcami usług w chmurze
i tak po prostu zostawię to jako
wybrano domyślnie i jak omówiliśmy w
poprzednia lekcja ipv6 zewnętrzna statyczna
Adresy ip mogą być używane tylko dla global
równoważenia obciążenia i tak odkąd jesteśmy tylko
używając go na przykład adresu IPv4
wystarczy i tak jako uwaga dot
poziom usług sieciowych, jeśli kliknę
standardowe ipv6 jest również wyszarzone
wybór globalny i to dlatego
w celu wykorzystania globalnego równoważenia obciążenia
musisz korzystać z sieci premium
poziom usług, więc zawsze, gdy tworzysz
globalny system równoważenia obciążenia, proszę go zachować
na uwadze, ponieważ twój koszt może wzrosnąć, więc jestem
zamierzam przełączyć to z powrotem na premium i
więc pod typem zamierzam to zachować
regionalny i pod regionem, do którego zamierzam
wybierz ten sam region, co moja instancja
będzie w którym jest nas wschód 1 i
ponieważ nie utworzyłem instancji
jednak nie ma do czego go przyczepić i
więc zamierzam kliknąć menu rozwijane
i kliknij na żaden i tak samo jak inny
zauważ, że chciałem to szybko podkreślić
uwaga, że ​​statyczny ip
adresy
nie dołączony do instancji lub niski
balancera nadal rozliczane są według stawek godzinowych
rate, więc jeśli nie używasz żadnych statycznych
adresy IP
pamiętaj, aby je usunąć w inny sposób
zostaniesz obciążony i tak dalej
wygląda dobrze tutaj, aby utworzyć mój zewnętrzny
statyczny adres IP, więc po prostu to zrobię
kliknij rezerwuj
a to stworzy moją zewnętrzną statykę
adres IP
i ustaw jego status jako zarezerwowany
jak widać tutaj zewnętrzne statyczne
adres IP został utworzony i tak będzie
znajdź wszystkie zewnętrzne statyczne adresy IP
adresy, które utworzysz w przyszłości
właśnie tutaj, w tym menu, a będziesz
nadal być w stanie zapytać o to wszystko
zewnętrzne adresy IP z polecenia
line i tak teraz, aby to przypisać
adres IP do interfejsu sieciowego jestem
wracam do nawigacji
menu i przewiń w dół do silnika obliczeniowego
i utwórz nową instancję, abyś mógł przejść
naprzód i kliknij utwórz instancję, którą jestem
iść naprzód i zachować nazwę
ta instancja jako instancja pierwsza i w
region, który wybieram, to wschodni
Zamierzam zachować strefę jako
wybrane ustawienie domyślne i pod typem maszyny
mam zamiar wybrać e2 micro machine
wpisz, do którego przewinę w dół
zarządzanie dyskami bezpieczeństwa sieci i
dzierżawa duszy i mam zamiar wybrać
zakładka sieci i tutaj w sieci
interfejsy, które zamierzam wybrać
domyślny interfejs sieciowy, do którego zamierzam
przewiń trochę w dół tutaj i poniżej
zewnętrzny adres IP
wybrano efemeryczny, ale jeśli i
kliknij menu rozwijane, będę miał
możliwość wybrania adresu IP, który właśnie mieliśmy
utworzony, który jest zewnętrzną kreską
statyczny adres IP, więc wybiorę
że mam zamiar kliknąć gotowe i ty
może zejść w dół i kliknąć utwórz i tak dalej
teraz, gdy instancja zostanie utworzona, zrobię to
zobacz zewnętrzny adres IP
zewnętrznej statyki zgodnie z przypisanym
zewnętrzny adres IP i zgodnie z oczekiwaniami tutaj jest
a ponieważ zawsze lubię weryfikować swoje
praca, zamierzam iść naprzód i otworzyć się
Cloud Shell i zweryfikuj go
linia poleceń
więc teraz zamierzam zapytać wszystkich moich
dostępne statyczne adresy IP przy użyciu
polecenie lista adresów obliczeń gcloud
wcisnę enter
i jak widać tutaj zewnętrzne
statyczny adres IP 34.75.76
we wschodnich stanach USA jeden region jest obecnie w użyciu
a to dlatego, że jest przypisany do
interfejs sieciowy w instancji pierwszej
i tak zanim przejdziemy dalej i zakończymy
to demo jest jeszcze jeden krok, który ja
chciałem przejść i to jest do
promować efemeryczny zewnętrzny adres IP
na statyczny zewnętrzny adres IP i tak dalej
Przejdę tutaj do górnego menu
i utwórz nową instancję, do której zamierzam
zostaw nazwę tutaj jako instancję drugą
w regionie mam zamiar wybrać nas
wschodnia mam zamiar zachować strefę
wybrane ustawienie domyślne w typie maszyny
mam zamiar wybrać e2 micro machine
wpisz zamierzam zostawić wszystko inne
jako domyślny i zamierzam przewijać
aż do dysków bezpieczeństwa zarządzania
networking i dzierżawa duszy i wybierz
kartę sieciową i zamierzam to zrobić
sprawdź, czy zamierzam używać
efemeryczne zewnętrzne IP po utworzeniu
tej instancji, jeśli przewinę w dół tutaj a
trochę widzę, że zewnętrzny
będzie używany efemeryczny adres IP
creation i będzie to adres IP
że będę promować do statycznego ip
przez wiersz poleceń, więc zamierzam to zrobić
śmiało i przewiń w dół, kliknij gotowe
a potem przewinę w dół i
kliknij utwórz i raz tę instancję
jest tworzony, to mogę iść dalej i
promować efemeryczne zewnętrzne IP
adres w porządku, a instancja została
tworzony wraz z jego zewnętrznym
efemeryczny adres IP, więc teraz mogę iść
naprzód i promuj to efemeryczne IP
adres, abym mógł to zrobić
zamierzam przenieść się z powrotem do mojej skorupy w chmurze
i zamierzam szybko wyczyścić ekran
i zamierzam użyć polecenia gcloud
utwórz adresy obliczeniowe, a następnie plik
nazwa, której chcemy użyć dla tego statycznego
zewnętrzny adres IP, więc zadzwonię
ten promowany zewnętrzny zamierzam użyć
adresy kresek flagowych i tak tutaj
będę potrzebował zewnętrznego adresu IP, który
promuję
czyli 104.196.219.42
więc skopiuję to do mojego
schowek i zamierzam go tutaj wkleić
w wierszu poleceń, a teraz zamierzam to zrobić
dodaj flagę regionu
wraz z regionem nas wschodnim i
Idę dalej i wciskam enter
i sukces mój efemeryczny zewnętrzny adres IP
adres został podniesiony do statycznego
zewnętrzny adres IP i oczywiście do
zweryfikuj to po prostu wpiszę
lista adresów gcloud compute
polecenie, które zamierzam nacisnąć enter i jako
oczekiwany tutaj jest promowany
zewnętrzny adres IP 104.196.219.42
oznaczony jako zewnętrzny w usa wschodnim
regionie, a stan jest oznaczony jako w
używać, więc chciałem poświęcić chwilę
pogratulować ci, że przez to przeszedłeś
ta demonstracja tworzenia wewnętrznego
i zewnętrzne adresy IP, jak również
promowanie ich tak samo jak podsumowanie, które masz
utworzył statyczny wewnętrzny adres IP w
w połączeniu z tworzeniem nowej instancji
i przypisanie go do tej instancji ty
następnie utworzył kolejną instancję i użył
efemeryczny adres IP, a następnie awansował go na
statyczny wewnętrzny adres IP
następnie utworzyłeś zewnętrzny statyczny adres IP
adres za pomocą konsoli i przypisany
to do zupełnie nowej instancji
utworzył kolejną instancję za pomocą pliku
zewnętrzny efemeryczny adres IP i
awansował go na statyczny zewnętrzny adres IP
adres i zrobiłeś to wszystko za pomocą obu
konsola i wiersz poleceń, więc i
chciałem pogratulować ci wspaniałego
pracę teraz, zanim zakończymy tę demonstrację
chciałem przejść przez kroki
czyszczenie wszelkich resztek zasobów tzw
pierwszą rzeczą, którą chcesz zrobić, to usunąć
te instancje, abyś mógł je wybrać
wszystko i przejdź do góry i kliknij
usuń, zapyta cię, czy chcesz
aby usunąć te dwie instancje, tak, robimy
kliknij usuń, a to usunie
swoje instancje i zwolnij zewnętrzne
adresy IP, abyś mógł
usuń je i tak teraz, gdy
instancje zostały usunięte, zamierzam to zrobić
przejdź do menu sieci vpc i jestem
przechodzę do zewnętrznego ip
konsola adresowa
i tutaj mogę usunąć plik zewnętrzny
adresy ip, więc wybiorę
wszystkie z nich i mam zamiar iść do
górne menu i kliknij zwolnij statyczne
adres i powinieneś otrzymać monit
z pytaniem, czy chcesz usunąć oba
te adresy odpowiedź brzmi: tak, kliknij
przy usuwaniu iw ciągu kilku sekund te
zewnętrzne adresy IP należy usunąć
więc teraz wszystko, co pozostało do usunięcia, to
dwa statyczne wewnętrzne adresy IP
i jak już powiedziałem, ponieważ nie ma
konsoli, aby móc przeglądać dowolne z nich
statyczne wewnętrzne adresy IP, które muszę
zrób to za pomocą wiersza poleceń, więc jestem
zamierzam wrócić do mojej skorupy w chmurze
idę wyczyścić ekran i idę
aby wyświetlić listę adresów IP aktualnie w my
sieci i tak tutaj są promowani
statyczne i statyczne wewnętrzne, a więc
polecenie usunięcia dowolnego statycznego adresu IP
adresy są następujące gcloud compute
adresy usuwają nazwę ip
adres, który chcę usunąć, który jest
promowane statyczne, a potem będę potrzebować
flaga regionu i będzie to region
nas wschód jeden i ja jadę pójść przodem
i naciśnij enter, wyświetli się monit, jeśli
Chcę to kontynuować i jestem
zamiar wpisać y dla tak naciśnij enter
i sukces został usunięty i tak
tylko podwójne sprawdzenie, które zamierzam zrobić
szybka weryfikacja
i tak, został usunięty i tak dalej
to, co pozostało do usunięcia, to static
wewnętrzny adres IP, więc zamierzam to zrobić
wklej w poleceniu
adresy gcloud compute usuwają nazwę
adresu IP, który chcę usunąć
która jest statyczną kreską wewnętrzną wraz z
flaga regionu nas wschodnia idę
iść dalej i nacisnąć enter
y, aby kontynuować
i sukces i ostatnia weryfikacja do
upewnij się, że wszystko jest wyjaśnione i
jak widać nie mam już statycznego ip
adresy i tak to się kończy
demonstracja tworzenia przypisania i
usuwanie zarówno statycznych wewnętrznych, jak i statycznych
zewnętrzne adresy IP i tak znowu ja
chciałem pogratulować ci wspaniałego
praca i tak to prawie wszystko ja
chciał zakryć
w tym demo na temat tworzenia wewnętrznych i
zewnętrzne statyczne adresy IP, abyś mógł
teraz oznacz to jako ukończone i zobaczę
ty w następnym
[Muzyka]
Witamy spowrotem
w tej lekcji będę nurkować
pewne zabezpieczenia sieci poprzez wprowadzenie vpc
reguły zapory usługa używana do filtrowania
przychodzący i wychodzący ruch sieciowy
w oparciu o zestaw reguł zdefiniowanych przez użytkownika
pojęcie, że powinieneś być sprawiedliwy
zaznajomiony na egzamin
i pojawia się niezwykle często kiedy
pracuje jako inżynier w chmurze google
jest to z pewnością niezbędne zabezpieczenie
warstwę, która uniemożliwia niepożądanym dostęp do
Twojej infrastruktury chmurowej
teraz reguły zapory vpc mają zastosowanie do danego
projekt i sieć
a jeśli chcesz, możesz również złożyć wniosek
reguły firewalla w całej organizacji
ale będę trzymał się ściśle vpc
reguły zapory w tej lekcji teraz vpc
reguły zapory pozwalają zezwalać lub odmawiać
znajomości
do lub z instancji maszyny wirtualnej
w oparciu o konfigurację, którą ty
sprecyzować
i te zasady dotyczą zarówno przychodzących
połączenia lub połączenia wychodzące
ale nigdy oba jednocześnie włączone
reguły zapory vpc są zawsze egzekwowane
niezależnie od ich konfiguracji i
systemu operacyjnego, nawet jeśli ich nie mają
uruchomiono teraz każdą sieć vpc
działa jako rozproszony firewall
kiedy reguły zapory sieciowej są zdefiniowane w pliku
połączenia na poziomie sieci są dozwolone lub
odrzucone na podstawie instancji
więc możesz pomyśleć o zaporze vpc
zasady jako istniejące nie tylko między twoimi
instancji i innych sieci
ale także między poszczególnymi przypadkami
w tej samej sieci teraz, kiedy ty
utwórz regułę zapory vpc, którą określisz a
sieć vpc i zestaw komponentów, które
zdefiniuj, co robi reguła
komponenty umożliwiają celowanie
określone rodzaje ruchu
na podstawie portów protokołów ruchu
źródła i miejsca docelowe podczas tworzenia
lub zmodyfikuj regułę zapory sieciowej
określ instancje
do którego ma to zastosowanie
za pomocą docelowego składnika
reguły teraz oprócz reguł zapory
że tworzysz chmurę google ma inne
zasady, które mogą mieć wpływ na przychodzące lub
połączenia wychodzące, np
Google Cloud nie zezwala na określone adresy IP
protokoły
takie jak ruch wychodzący na porcie TCP 25
w sieci vpc i innych protokołach
niż tcp udp
icmp i gre
na zewnętrzne adresy IP chmury Google
zasoby są zablokowane w chmurze google
zawsze zezwala na komunikację między maszyną wirtualną
instancja i odpowiadające jej metadane
serwer pod adresem 169.254
i ten serwer jest niezbędny do
działanie instancji
więc instancja może uzyskać do niej dostęp niezależnie od tego
wszystkich skonfigurowanych reguł zapory
serwer metadanych zapewnia pewne podstawowe
usługi do instancji, takie jak dhcp dns
metadane i sieć instancji rozstrzygania
protokół czasowy lub ntp teraz tylko jako uwaga
każda sieć ma dwie domniemane zapory ogniowe
reguły zezwalające na połączenia wychodzące
i blokować połączenia przychodzące firewall
utworzone przez Ciebie reguły mogą je zastąpić
domniemane zasady teraz pierwsza dorozumiana reguła
to reguła zezwalająca na wyjście, a to jest reguła
reguła ruchu wychodzącego, której działaniem jest zezwolenie i
miejsce docelowe to wszystkie ips i
priorytet jest najniższy z możliwych i pozwala
dowolna instancja wysyła ruch do dowolnej
miejsce docelowe, z wyjątkiem ruchu zablokowanego
przez google cloud drugi sugerowany
reguła zapory to reguła odmowy ruchu przychodzącego
i jest to reguła ruchu przychodzącego, której akcja
to deny, a źródłem są wszystkie ips i
priorytet jest najniższy z możliwych i
chroni wszystkie instancje poprzez blokowanie
połączenia przychodzące do nich teraz wiem
poruszyliśmy to wcześniej w a
poprzedniej lekcji, ale czułem taką potrzebę
przynieś to, ponieważ są one wstępnie wypełnione
zasady i zasady, o których mówię
być w odniesieniu do domyślnego vpc
sieci i jak wyjaśniono wcześniej te
reguły mogą być usuwane lub modyfikowane jako
konieczne zasady, jak widać tutaj
w tabeli zezwalaj na połączenia przychodzące
z dowolnego źródła do dowolnej instancji na serwerze
sieci, jeśli chodzi o włączenie icmp rdp
port 3389 dla pulpitu zdalnego systemu Windows
protokół i dla ssh na porcie 22. i as
cóż, ostatnia reguła zezwala na wnikanie
połączenia dla wszystkich protokołów i portów
między instancjami w sieci i to
zezwala na połączenia przychodzące do vm
instancje od innych w tym samym
sieć i wszystkie z nich mają regułę
priorytet sześć pięć pięć cztery, czyli
drugi do najniższego priorytetu tzw
łamanie reguł zapory ogniowej istnieje
kilka cech wprowadzonych przez Google
miejsce, które pomagają zdefiniować te zasady i
charakterystyka jest następująca
reguła zapory ma zastosowanie do przychodzących lub
połączenia wychodzące
i nie obsługują tylko obu reguł zapory
połączenia ipv4, więc przy określaniu a
źródło reguły ruchu przychodzącego lub a
miejsce docelowe reguły wyjścia według
adres
możesz użyć tylko adresu IPv4 lub ipv4
zablokuj również notację poufnych informacji
działanie reguł zapory sieciowej to zezwolenie lub
zaprzeczyć, że nie możesz mieć obu jednocześnie
czas i reguła dotyczy połączeń
o ile jest to egzekwowane np
możesz wyłączyć regułę dla
rozwiązywania problemów, a następnie włącz
teraz z powrotem, kiedy tworzysz plik
reguły zapory musisz wybrać vpc
sieci, podczas gdy reguła jest egzekwowana o godz
poziom instancji, na którym jest skonfigurowana
oznacza to, że jest powiązany z siecią vpc
nie można udostępniać reguł zapory sieciowej
sieci vpc, w tym
sieci połączone przez sieć vpc
peering lub za pomocą tuneli vpn w chmurze
kolejna ważna rzecz, na którą należy zwrócić uwagę
reguły zapory sieciowej polegają na tym, że są one stanowe
a to oznacza, kiedy połączenie jest
dozwolone przez zaporę w obu
pasujący ruch powrotny w tym kierunku
połączenie jest dozwolone, nie możesz
skonfiguruj regułę zapory, aby odmówić
powiązany ruch zwrotny związany z odpowiedzią
ruch musi pasować do pięciu krotek
zaakceptowany ruch żądań, ale z
adresy źródłowe i docelowe oraz
porty odwrócone, tak jak uwaga dla
tych, którzy mogą się zastanawiać, co to za piątka
Tuple jest, miałem na myśli zestaw
pięć różnych wartości, które obejmują a
połączenie tcpip i tak by było
źródłowy adres IP adres docelowy port źródłowy
port docelowy i protokół google
cloud kojarzy przychodzące pakiety z
odpowiednie pakiety wychodzące za pomocą
tabela śledzenia połączeń Google Cloud
implementuje śledzenie połączeń
niezależnie od tego, czy protokół
obsługuje połączenia, jeśli połączenie jest
dozwolone między źródłem a celem lub
między celem a miejscem docelowym
ruch odpowiedzi jest dozwolony tak długo, jak
stan śledzenia połączeń firewalli
jest aktywny, a także nuta a
Stan śledzenia reguł zapory sieciowej to
uważane za aktywne, jeśli co najmniej jeden pakiet
jest teraz wysyłany co 10 minut wraz z
wiele cech, które tworzą
w górę reguły zapory są również
składniki reguły zapory sieciowej, które są zgodne
z tym tutaj mam zrzut ekranu z
konsola z konfiguracją
składniki reguły zapory sieciowej oraz i
chciałem poświęcić chwilę na podkreślenie
te komponenty dla lepszej przejrzystości tzw
teraz pierwszym komponentem jest sieć
i to jest sieć vpc, którą ty
chcesz, aby reguła zapory była stosowana do
następny to priorytet, o którym rozmawialiśmy
wcześniej i to jest liczba
priorytet, który określa, czy
reguła jest stosowana jako tylko najwyższa
reguła pierwszeństwa, której inne składniki
stosowany jest ruch dopasowania i pamiętaj
im niższa liczba, tym wyższa
priorytet im wyższy numer tym niższy
teraz priorytetem jest następny komponent
kierunku ruchu i są
reguły ruchu przychodzącego, które mają zastosowanie do ruchu przychodzącego
połączenia z określonych źródeł do
cele w chmurze Google i oto gdzie
reguły ruchu przychodzącego mają zastosowanie do ruchu przychodzącego
połączenia z określonych źródeł do
Cele Google w chmurze
a zasady ruchu wychodzącego mają zastosowanie do połączeń
zamiar określić miejsca docelowe z
cele, a następny to działanie
mecz i ten komponent albo na to pozwala
lub zaprzecza, co określa, czy
reguła zezwala lub blokuje połączenie
teraz cel jest tym, co określa który
przypadki, do których stosuje się reguła i
możesz określić cel, używając jednego z
następujące trzy opcje pierwsza
opcja
są wszystkimi instancjami w sieci i
jest to reguła zapory, która działa
dokładnie to, co mówi, dotyczy wszystkich
instancje w sieci drugie
opcja to instancje według tagów docelowych i
tutaj obowiązuje reguła zapory
tylko do instancji z dopasowaniem
tag sieciowy, więc wiem, że nie
wyjaśniłem to wcześniej, ale tag sieciowy
to po prostu ciąg znaków dodany do a
tags w zasobie, więc powiedzmy, że i
miał kilka przypadków, które były
Rozważany rozwój mogę po prostu
rzuć na nich tag sieciowy za pomocą a
tag sieciowy dev i zastosuj
niezbędną regułę zapory dla wszystkich
serwery deweloperskie utrzymujące sieć
tag dev, więc jest trzecia opcja
instancje według docelowych kont usług
tutaj obowiązuje reguła zapory
tylko do instancji, które używają określonego
konto usługi i tak dalej
komponentem jest filtr źródłowy i to
jest źródłem reguł ruchu przychodzącego lub
miejsce docelowe dla reguł wyjścia źródło
parametr ma zastosowanie tylko do ruchu przychodzącego
zasady i musi to być jeden z nich
następujące trzy wybory źródło ip
zakresy i tutaj określasz
zakresy adresów IP jako źródła dla
pakiety wewnątrz lub na zewnątrz
chmura google druga to źródło
tagi i stąd źródło
instancje są identyfikowane przez dopasowanie
tag sieciowy i konta usługi źródłowej
gdzie wystąpienia źródłowe
są identyfikowane przez konta usług
używają, możesz również skorzystać z usługi
konta, aby utworzyć reguły zapory sieciowej
są nieco bardziej szczegółowe, a więc jednym z nich
ostatnie składniki reguły zapory
to protokoły i porty, które możesz
określić protokół lub ich kombinację
protokoły i ich porty, jeśli pominiesz
zarówno protokoły, jak i porty zapory
reguła ma zastosowanie do całego ruchu na
dowolny protokół i dowolny port, a więc kiedy to
nabiera statusu wykonawczego
reguły zapory znajduje się menu rozwijane po prawej stronie
pod wszystkimi komponentami, gdzie ty
może włączyć lub wyłączyć egzekwowanie
i jak powiedziałem wcześniej, jest to świetny sposób
aby włączyć lub wyłączyć regułę zapory
bez konieczności usuwania go i jest świetny
w celu rozwiązania problemu lub udzielenia dotacji
tymczasowy dostęp do dowolnych instancji i
chyba że postanowisz inaczej
wszystkie reguły zapory sieciowej są włączone, gdy
są tworzone, ale możesz też wybrać
utwórz regułę w stanie wyłączonym i tak dalej
obejmuje to reguły zapory vpc w
całość i pokażę
jak zaimplementować reguły zapory vpc
wraz z budowaniem niestandardowego vpc
niestandardowe trasy
a nawet prywatny dostęp do Google
wszystko razem w demo po tym
lekcję, aby dać ci kilka praktycznych umiejętności
wcielenia tego wszystkiego w życie i tak dalej
to właściwie wszystko, co chciałem zawrzeć
jeśli chodzi o reguły zapory vpc, tak
możesz teraz oznaczyć tę lekcję jako zakończoną
i przejdźmy do następnego gdzie
nurkujemy i budujemy nasz niestandardowy vpc, więc
teraz jest idealny czas na kawę
lub herbaty i kiedy tylko będziesz gotowy, dołącz do mnie
w konsoli
Witamy spowrotem
w tej demonstracji chcę wziąć wszystko
pojęcia, których nauczyliśmy się do tej pory
w tej sekcji sieci i umieścić go
wszystko w praktyce pokazano na tym schemacie
oto architektura dokładnie czego
będziemy budować w tym demo jesteśmy
zacznij od utworzenia niestandardowego vpc
a następnie stworzymy dwa
podsieci
jeden publiczny i jeden prywatny
w dwóch oddzielnych regionach wtedy jedziemy
aby utworzyć zasobnik do przechowywania w chmurze
w nim jakieś obiekty, a potem to zrobimy
utwórz kilka instancji do zademonstrowania
dostęp do pamięci masowej w chmurze, jak również
komunikacja między instancjami i
wreszcie stworzymy kilka
reguły zapory dla kierowania ruchu do
wszystkie właściwe miejsca, do których też się wybieramy
zaimplementuj prywatny dostęp do Google
i wykazać dostępność do
pliki w chmurze z pliku private
instancja bez zewnętrznego adresu IP, więc to
może być trochę poza twoim komfortem
strefa dla niektórych
ale nie martw się, będę z tobą każdego dnia
krokiem w drodze i innym niż tworzenie
instancje, które mają wszystkie kroki tutaj
zostały omówione na poprzednich lekcjach
jest tu wiele do zrobienia, więc
kiedy tylko będziesz gotowy, dołącz do mnie
konsoli i tak oto jesteśmy z powrotem w
console i jak widać tutaj w
prawy róg, na który jestem zalogowany
tony bowtie ace gmail.com i obecnie
Jestem zalogowany w ramach projektu tony i tak dalej
aby zacząć z czystą kartą
zamierzam stworzyć nowy projekt i tak dalej
po prostu kliknę na projekt
menu rozwijanego i kliknij nowy projekt
Zadzwonię do tego projektu
Bowtie Inc i nie mam żadnych
organizacje, więc po prostu
kliknij utwórz, a także dla tych z
robisz tę lekcję, ja też bym to zrobił
polecam, aby stworzyć zupełnie nowy
projektu, abyś mógł zacząć od nowa
znowu wybieram sie do
projekt spada i zamierzam
wybierz jako projekt atrament muszkę i
teraz, gdy mam nowy, świeży projekt, tj
mogę teraz utworzyć moją sieć vpc, więc jestem
zamierza przejść do lewego rogu
do menu nawigacyjnego i idę
przewiń w dół do sieci vpc i tak dalej
ponieważ sieci vpc są powiązane
interfejs API silnika obliczeniowego
musimy go włączyć, zanim będzie to możliwe
utwórz dowolne sieci vpc, abyś mógł przejść
naprzód i włącz ten interfejs API, więc raz this
api zakończyło się i jest włączone, będziemy
w stanie stworzyć naszą sieć vpc
ok, a api zostało włączone i jako
możesz zobaczyć domyślną sieć vpc
została utworzona z podsiecią w każdym
region wraz z odpowiadającym mu adresem IP
zakresy adresów i tak dla tego demo
stworzymy zupełnie nowy vpc
network wraz z kilkoma niestandardowymi podsieciami
więc w tym celu zamierzam to zrobić
idź tutaj na górę, a ja idę
kliknij utwórz sieć vpc i tak tutaj
pojawia się monit o kilka pól do wypełnienia
na zewnątrz
więc pod nazwą mam zamiar pomyśleć o
nazwa kreacji, którą mogę nazwać moim vpc
network, więc po prostu ją wywołam
niestandardowe pod opisem zamierzam
nazwij to zwyczajem
sieć vpc i zamierzam przejść w dół
tutaj do podsieci i ponieważ tworzę
niestandardowe podsieci, które zamierzam zachować
w trybie niestandardowym w trybie tworzenia podsieci
więc będę potrzebować publicznej podsieci
i prywatną podsieć i będziesz mógł
aby pobrać wartości z pliku tekstowego
repozytorium github w sub
folder sieci w obszarze sieci
services, więc zamierzam utworzyć mój
najpierw podsieć publiczna i zamierzam to zrobić
po prostu nazwij publiczną podsieć public for
region, w którym zamierzam użyć nas na wschód i
zakres adresów IP będzie wynosił 10.0.0.0
ukośnik 24 i wychodzę
wyłączam prywatny dostęp do google i idę
aby po prostu kliknąć Gotowe i teraz mogę
utwórz prywatną podsieć pod spodem
podsieć publiczna, którą zobaczysz, dodaj podsieć
możesz po prostu kliknąć na to i
nazwa nowej podsieci będzie taka jak Ty
zgadłem, że to prywatne w regionie jestem
użyje nas East 4 i IP
zakres adresów
pamiętaj, aby użyć 10.0.5.0.24
i opuścimy prywatne google
dostęp wyłączony na razie i będziemy skręcać
to nieco później w wersji demonstracyjnej
więc możesz teraz kliknąć Gotowe i
zanim klikniemy na stwórz chcemy
włącz dns api i kliknij
enable przeniesie Cię do dns api
stronę główną i możesz kliknąć opcję Włącz
włącz api w porządku, więc teraz, gdy mamy
nasza sieć skonfigurowana wraz z naszym
podsieci publiczne i prywatne, jak również
dns jest włączony, możemy teraz po prostu
kliknij utwórz, ale zanim to zrobię, ja
chciałem dać ci trochę wglądu
w odniesieniu do wiersza poleceń, tak jak ja
dzielone przed wszystkim, co może być
wykonane w konsoli można wykonać przez
wiersz poleceń, a więc jeśli kiedykolwiek ty
chciałeś to zrobić lub chciałeś dostać
trochę znać linię poleceń
lepsza
po wypełnieniu wszystkich pól
w zakresie tworzenia zasobów w
konsoli, którą będziesz mieć do wyboru
łącze wiersza poleceń, które możesz po prostu
kliknij i tutaj otrzymasz wszystko
polecenia, aby utworzyć wszystko to samo
zasobów z tymi samymi preferencjami
przez wiersz poleceń i będę
podając te polecenia na lekcji
tekst, abyś mógł się z nim zapoznać
siebie za pomocą poleceń, których należy użyć w
w celu zbudowania dowolnych sieci za pomocą
wiersz poleceń, ale to jest świetne
odniesienie do użycia w dowolnym momencie i
więc klikam zamknij
a teraz mam zamiar kliknąć utwórz
iw ciągu minuty lub dwóch zwyczaj
sieć vpc zostanie utworzona i będzie gotowa
użyj w porządku, a niestandardowa sieć vpc ma
został stworzony wraz z jego publicznością i
prywatna podsieć i tak po prostu uzyskać
trochę więcej wglądu w ten zwyczaj
sieć vpc, do której zamierzam się zagłębić
To
i jak widać tutaj, są to podsieci
odpowiednio oznaczone jako prywatne i publiczne
wraz z zakresem adresów IP regionu
brama i prywatny dostęp do Google
trasy, jak widać tutaj, to
wygenerowane przez system trasy, które miałem
omówione we wcześniejszej lekcji
obie trasy podsieci do odpowiednich
ip wraz z trasą domyślną
ze ścieżką do Internetu, jak również
ścieżka do prywatnego dostępu do Google teraz my
nie ma tu jeszcze żadnych reguł zapory sieciowej
ale dodamy je za kilka
minut, a więc teraz, kiedy stworzyłeś
sieć vpc z odpowiednimi
podsieci, do których się udamy
przechowywanie w chmurze i tworzenie wiadra razem
z wgraniem niezbędnych plików tzw
idę znowu do tzw
Menu nawigacji
i zamierzam przewinąć w dół do magazynu
więc zgodnie z oczekiwaniami nie ma wiader
obecny tutaj w chmurze i tak dalej
będziemy po prostu iść naprzód i tworzyć
nasze pierwsze wiadro, przechodząc tutaj do
górne menu i kliknięcie na utwórz wiadro
i tak oto zostałem poproszony o nazwanie
moje wiadro i dla tych z was, którzy są
tutaj po raz pierwszy, jeśli chodzi o
nazywanie zasobnika pamięci zgodnie z potrzebami
być wyjątkowym na skalę światową, a to oznacza
że nazwa musi być niepowtarzalna w całym
teraz cała platforma chmurowa Google
nie martw się, wchodzę
dalsze szczegóły z tym w chmurze
lekcja przechowywania z tym wszystkim
konkretne szczegóły, jeśli chodzi o nazwiska
klasy przechowywania i uprawnienia i tak dalej
w międzyczasie możesz wymyślić
nazwij swoje wiadro coś takiego
rezonuje z tobą i tak dla mnie jestem
zamierzam nazwać moje Bucket Bowtie Inc Dash
file dash access, więc teraz zamierzam to zrobić
po prostu kliknij Kontynuuj i tak samo jak a
Uwaga dla tych, którzy nie mogą
kontynuować przez to, ponieważ nazwa
dla twojego wiadra nie jest unikalny na skalę światową
więc spróbuj znaleźć taki, który jest teraz, kiedy
chodzi o typ lokalizacji, do której właśnie się wybieram
kliknij na region i możesz zachować
domyślna lokalizacja jako używana i ja
pozostawię wszystkie inne opcje jako
default i zejdę do
na dole i kliknij Utwórz i tak dla tych
z was, którzy stworzyliście swoje wiadro
może teraz przesyłać pliki i te pliki
można znaleźć w repozytorium github
w folderze zasobnika pamięci masowej w chmurze pod
usługi sieciowe, więc teraz idę
aby kliknąć przesyłanie plików
oraz w ramach usług sieciowych
sekcja pod zasobnikiem do przechowywania w chmurze ty
znajdzie te trzy pliki jpeg i Ciebie
można je po prostu wybrać i kliknąć otwórz
i tak są teraz przesyłane do
wiadro, więc teraz jestem gotowy, aby przejść dalej
do następnego kroku, więc powinieneś to zrobić
stworzył sieć vpc z private
i podsieci publicznej wraz z tworzeniem
własne wiadro w chmurze i
przesłałem trzy pliki jpeg, więc
teraz, gdy to jest zrobione, możemy teraz tworzyć
instancje
które będą miały dostęp do tych plików i
więc znowu przejdę do
menu nawigacyjne w lewym górnym rogu
róg i przewiń w dół do silnika obliczeniowego
i tutaj kliknę utwórz
i tak znowu zostanę poproszony o
kilka pól do wypełnienia i tak dalej
instancja, którą najpierw utworzę
publiczną instancję ponownie zamierzam zdobyć
naprawdę kreatywny i nazwij to
publiczna instancja myślnika pod etykietami i'm
zamierzam dodać etykietę
pod klucz
zamierzam wpisać environment i under
wartość, którą zamierzam wpisać publicznie, jestem
zejść na dół i kliknąć
na zapisz iw regionie, do którego zamierzam
wybierz nas na wschód1 i możesz opuścić
strefa jak nas na wschód 1b przesuwa się w dół
typ maszyny wybieram e2
micro jako typ maszyny tylko dlatego, że
Jestem świadomy kosztów i chcę
obniżyć koszty, więc zamierzam to zrobić
przewiń w dół do tożsamości i dostępu do interfejsu API
i pod kontem usługi powinieneś
mieć domyślną usługę silnika obliczeniowego
konto już wstępnie wybrane teraz pod
zakresy dostępu, które chcę mieć
odpowiednie uprawnienia, aby móc
odczytywać i zapisywać w pamięci masowej w chmurze
z dostępem do odczytu i zapisu do obliczeń
engine i możesz kliknąć zestaw
access dla każdego interfejsu API i możesz przewijać
aż do silnika obliczeniowego
kliknij menu rozwijane i wybierz
czytaj pisz, a to da opinii publicznej
na przykład określony dostęp, który ma
musi ssh do prywatnej instancji
więc teraz ustawię dostęp
do przechowywania w chmurze, więc zamierzam przewinąć
aż do przechowywania, które zamierzam kliknąć
z rozwijanego menu i wybierz czytaj i pisz
a to spowoduje odczytanie instancji
dostęp do zapisu do przewijania pamięci w chmurze
trochę dalej idę
przejdź do zarządzania dyskami bezpieczeństwa
networking i sprzedałem najem i jestem
zamierzam to kliknąć
przewiń trochę tutaj
i możesz kliknąć kartę sieciową
co poprosi cię o kilka
opcje, które możesz skonfigurować dla
sieciowanie instancji tak poniżej
tagi sieciowe, które chcę wpisać publicznie
i możesz kliknąć enter, możesz wtedy
przewiń w dół do miejsca, w którym jest napisane sieć
interfejsy i kliknij bieżący
interfejs, który jest domyślny i tutaj
otworzy wszystkie opcje i tak dalej
pod siecią, którą chcesz kliknąć
rozwijane i ustaw go z domyślnego na
niestandardowa podsieć publiczna
automatycznie propagowane, więc możesz
zostaw to tak, jak jest, a także chcesz zrobić
upewnij się, że twój podstawowy wewnętrzny adres IP
jak również twój zewnętrzny adres IP są ustawione na
efemeryczne i możesz zostawić wszystko
inne opcje jako domyślne i proste
kliknij gotowe i ponownie przed kliknięciem
podczas tworzenia możesz kliknąć polecenie
line link i pokaże ci wszystko
polecenia potrzebne do utworzenia tego
instancja za pomocą wiersza poleceń, więc jestem
idź dalej i zamknij to
więc zostawię wszystkie inne
opcje jako domyślne i zamierzam to zrobić
kliknij utwórz, a więc teraz, gdy my
tworzona jest publiczna instancja i'm
zamierzam iść dalej i utworzyć mój prywatny
instancja
używając tych samych kroków, które zrobiłem dla
ostatnia instancja, więc idę dalej
i kliknij utwórz instancję tutaj w
top, a więc pierwszą rzeczą, do której idę
zostanie wyświetlony monit o podanie nazwy
instancja
i tak zamierzam wywołać tę instancję
prywatna instancja myślnika i oto idę
aby dodać etykietę, której kluczem jest środowisko
a wartość jest prywatna, do której zamierzam
zejdź tutaj na dół i kliknij
ratować
iw regionie mam zamiar wybrać nas
wschód 4
i możesz zachować strefę jako domyślną
wybrany pod typem maszyny, do której jedziemy
aby wybrać e2 micro i ponownie
przewijanie w dół do tożsamości i interfejsu API
dostęp w ramach zakresów dostępu dla
domyślne konto usługi, do którego zamierzam
kliknij zestaw dostępu dla każdego interfejsu API i
przewinę w dół do pamięci masowej
zamiar kliknąć menu rozwijane i
wybieram dostęp do odczytu
napisz i na ostatni krok mam zamiar
przejdź do zakładki sieciowej pod
zarządzanie dyskami bezpieczeństwa sieci i
dzierżawa duszy i pod tagami sieciowymi jestem
zamierza nadać tej instancji sieć
tag prywatny i w ramach sieci
interfejsy, które chcemy edytować i
zmień go z domyślnego na
niestandardowa sieć i zgodnie z oczekiwaniami
domyślnie wybrał podsieć prywatną
a ponieważ to będzie a
prywatna instancja, do której nie zamierzamy
daj temu zewnętrzny adres IP, więc zamierzam to zrobić
kliknij listę rozwijaną i wybierz brak
i ze wszystkimi innymi opcjami ustawionymi jako
domyślnie zamierzam po prostu kliknąć
tworzyć
a to utworzy moją prywatną instancję
wraz z posiadaniem mojej publicznej instancji
w ramach podsumowania stworzyliśmy nowy
niestandardowa sieć vpc
wraz z prywatną i publiczną podsiecią
utworzyliśmy zasobnik do przechowywania i dodaliśmy
dostęp do niektórych plików w nim i
stworzyliśmy private i public
instancję i przypisanie usługi
konto w publicznej instancji odczytane
dostęp do zapisu zarówno do silnika obliczeniowego, jak i
przechowywanie w chmurze wraz z publicznym adresem IP
adres i przypisanie usługi
konto w prywatnej instancji odczyt
dostęp do zapisu tylko do przechowywania w chmurze i
brak publicznego ip i tak to koniec
część pierwsza tego demo
i byłaby to świetna okazja
żebyś wstał i się przeciągnął
zrób sobie kawę lub herbatę
i kiedy tylko będziesz gotowy, możesz dołączyć
ja w części drugiej
gdzie zaraz wyruszymy
od końca części pierwszej, więc możesz iść
naprzód i ukończ ten film, a ja to zrobię
do zobaczenia w części drugiej
[Muzyka]
Witamy spowrotem
to jest druga część niestandardowego demo vpc
i zaczniemy dokładnie tam, gdzie my
przerwane od części pierwszej, więc z tym
mówiąc, zanurzmy się, a więc teraz
ostatnią rzeczą, którą należy zrobić, jest
po prostu stwórz kilka reguł zapory i tak dalej
z tymi regułami zapory ogniowej to da
mi dostęp ssh do instancji publicznej
a także zezwalając na prywatne
komunikacja z instancji publicznej
do prywatnej instancji, jak również
dając dostęp do ssh
z instancji publicznej do prywatnej
przykład, a to nam na to pozwoli
dostęp do plików w zasobniku z poziomu
prywatna instancja i tak w celu
utwórz te reguły zapory, które muszę przejść
z powrotem do mojej sieci vpc, więc zamierzam to zrobić
ponownie przejdź do lewego rogu
menu nawigacji
i przewiń w dół do sieci vpc tutaj
w menu po lewej stronie zobaczysz
zapora sieciowa, którą zamierzam kliknąć
i tutaj zobaczysz wszystkie domyślne
reguły zapory sieciowej dla domyślnej sieci
więc dla nas stworzyć kilka nowych
niestandardowy vpc, który zamierzam przejść tutaj
na górę i kliknij utwórz zaporę ogniową
i tak pierwsza reguła, którą chcę utworzyć
jest dla mojej publicznej instancji i chcę
nadaj mu publiczny dostęp, a także ssh
access i tak zamierzam to nazwać
odpowiednio jako publiczny dostęp do myślnika i'm
dam temu ten sam opis
zawsze dobrym pomysłem jest włączenie dzienników, ale
dla tej demonstracji, którą zamierzam zachować
wyłącz je w sieci, do której zamierzam
wybierz niestandardową sieć, do której zamierzam
zachować priorytet na 1000 kierunku
ruchu będzie stanowił ruch przychodzący, a
akcja na meczu będzie dozwolona i tak dalej
w tym miejscu pojawiają się znaczniki docelowe
grać, jeśli chodzi o udzielanie dostępu
sieć, więc cele, do których się wybieramy
zachowaj to jako określone tagi docelowe
i pod tagami docelowymi możesz po prostu
pisać publicznie
pod filtrem źródłowym możesz go zachować
w zakresach ip
a źródłowy zakres adresów IP będzie wynosił 0.0.0.0
ukośnik 0. i nie zamierzamy
dodaj tutaj drugi filtr źródłowy, więc
przejście do protokołów i portów poniżej
tcp zamierzam to wyłączyć i dodać
w porcie 22. i dlatego, że chcę być
w stanie pingować instancję, do której zamierzam
trzeba dodać inny protokół, który jest
icmp
i ponownie, jak wyjaśniono wcześniej
wyłączenie linku reguły spowoduje wyświetlenie pliku
egzekucja i jak widać jest
włączone, ale jeśli chcesz je utworzyć
reguły zapory sieciowej w przyszłości i mieć je
wyłączone, możesz to zrobić tutaj, ale
pozostawimy tę opcję włączoną i jesteśmy
po prostu kliknij utwórz i to
utworzy publiczną regułę zapory dla
nasza publiczna instancja w naszym niestandardowym vpc
sieć i tak zamierzamy teraz iść
naprzód i utwórz prywatną zaporę ogniową
reguły i tak zamierzam to nazwać
prywatny dostęp do deski rozdzielczej
odpowiednio zamierzam umieścić
opis taki sam w sieci
zamierzam wybrać naszą niestandardową sieć
zachować priorytet na 1000 kierunek
ruch powinien odbywać się na wejściu i
akcja na meczu powinna być dozwolona
tagi docelowe, które możesz wpisać w prywatnych i
następnie naciśnij enter i ponieważ chcę być
w stanie dotrzeć do prywatnej instancji z
instancja publiczna źródłowy zakres adresów IP
będzie
10.0.0.1
ukośnik 24. nie będziemy dodawać
drugi filtr źródłowy i poniżej
protokoły i porty, do których zmierzamy
po prostu dodaj port tcp 22
i znowu chcę dodać icmp
dzięki czemu mogę pingować instancję
i zamierzam kliknąć utwórz
i tak mamy teraz nasze dwie zapory ogniowe
zasady dostępu prywatnego i publicznego
a jeśli przejdę do niestandardowego vpc
sieć i zagłębiam się w nią
będę mógł zobaczyć te selektywne
reguły zapory w ramach odpowiednich
karta reguł zapory sieciowej i teraz, kiedy to zrobiliśmy
stworzyliśmy naszą sieć vpc wraz z
utworzoną przez nas publiczną i prywatną podsieć
zasobnik do przechowywania w chmurze z plikami
że potrzebujemy dostępu do instancji
który będzie miał dostęp do tych plików wraz z
reguły zapory sieciowej, które pozwolą na
właściwa komunikacja, możemy teraz kontynuować
przetestować wszystko, co zbudowaliśmy i
upewnij się, że wszystko działa jak
oczekiwany, więc zacznijmy od tego
pierwsze logowanie do instancji publicznej
więc możesz przejść do
menu nawigacji i przewiń w dół do
silnik obliczeniowy
i możesz ssh do instancji publicznej
klikając ssh pod connect
i to powinno otworzyć nową kartę lub plik
nowe okno logowanie za pomocą twojego
aktualnie uwierzytelnione poświadczenia są w porządku
i jesteśmy zalogowani do naszej instancji i
Powiększę dla lepszego oglądania
i tak tylko po to, aby upewnić się, że wszystko
działa zgodnie z oczekiwaniami, wiemy, że nasz
reguła zapory sieciowej jest poprawna, ponieważ my jesteśmy
w stanie ssh do instancji, a teraz i
chcę sprawdzić, czy mam dostęp do moich plików
w wiadrze i tak, aby to zrobić
zamierzam uruchomić polecenie gsutil ls
dla listy, a następnie ukośnik dwukropka gs
ukośnik wraz z moją nazwą zasobnika
czyli muszka inc
łącznik plik dostęp do iPhone'a i idę
nacisnąć enter i jak widać mam
dostęp do wszystkich plików w zasobniku
a ostatnią rzeczą, którą chciałem sprawdzić, jest
jeśli mogę pingować instancję prywatną, tak
najpierw wyczyszczę ekran i
Zamierzam udać się z powrotem do
Console zamierzam skopiować adres IP
prywatnej instancji do mojego schowka
a potem wracam do siebie
do mojego terminala i zamierzam wpisać
ping zamierzam wkleić adres IP
i sukces
jestem w stanie pomyślnie pingować
prywatna instancja
z publicznej instancji
używając protokołu icmp i możesz trafić
Control c, aby zatrzymać ping, więc teraz, gdy i
wiedzieć, że moja publiczna instancja ma plik
odpowiednie uprawnienia dostępu do chmury
składowanie
a także możliwość pingowania mojego prywatnego
na przykład chcę mieć możliwość sprawdzenia, czy i
może ssh
do prywatnej instancji z mojej publicznej
instancja, więc najpierw wyczyszczę
mój ekran, a następnie wkleję
to polecenie, abym mógł wejść do ssh
prywatna instancja g cloud computing ssh
kreska kreska projekt i moja nazwa projektu
która jest muszka inc dash zone i
strefa, w której znajduje się moja instancja
nas wschód 4c wraz z nazwą
instancja, która jest prywatną instancją myślnika
i wraz z kreską flagową
wewnętrzny myślnik ip stwierdzający, że używam
wewnętrzny adres IP w celu ssh do
instance i zamierzam nacisnąć enter i
więc teraz zostałem poproszony o
hasło w celu zabezpieczenia mojego klucza rsa
pair jako jedna jest generowana do logowania
do prywatnej instancji teraz jest
zawsze dobra praktyka, jeśli chodzi o
security, aby zabezpieczyć parę kluczy za pomocą
hasło, ale dla tego demo jestem po prostu
zostawię to puste
więc po prostu wciskam enter
znowu wcisnę enter
teraz nie chce mi się w to za bardzo zagłębiać
ale chciałem dać ci trochę kontekstu
o tym, co się tutaj dzieje, więc kiedy się logujesz
do instancji w chmurze Google z os
logowanie wyłączone google zarządza
autoryzowany plik kluczy
dla nowych kont użytkowników na podstawie kluczy ssh
w metadanych, a więc klucze, które są
generowanych, do których są używane
po raz pierwszy są obecnie
przechowywane w metadanych instancji tzw
teraz, gdy jestem zalogowany do mojego prywatnego
na przykład zamierzam szybko wyczyścić moje
ekran i tylko jako notatkę, którą będziesz mógł
wiedzieć, czy jesteś zalogowany
do swojej prywatnej instancji, patrząc
tutaj na twoją prośbę, więc teraz chcę
upewnij się, że mogę pingować moją publiczność
instancja, więc szybko napiszę
polecenie ping, którym zamierzam się zająć
do konsoli, którą zamierzam złapać
adres IP instancji publicznej
zamierzam wrócić do mojego terminala i
wklej go i zgodnie z oczekiwaniami jestem w stanie
pinguj moją publiczną instancję z mojego prywatnego
na przykład zamierzam po prostu iść naprzód i
naciśnij kontrolkę c, aby zatrzymać i zamierzam to zrobić
wyczyść ekran, więc teraz chcielibyśmy
sprawdzić, czy mamy do nich dostęp
pliki w zasobniku do przechowywania w chmurze
którą stworzyliśmy wcześniej
więc teraz użyję tego samego
Komenda
do którego użyłem w instancji publicznej
wyświetlić listę wszystkich plików w magazynie w chmurze
Bucket, więc użyję gsutil
polecenie ls dla listy wraz z dwukropkiem gs
ukośnik ukośnik ukośnik i
nazwa wiadra, która jest łącznikiem z atramentem muszki
file, jeśli dostęp i zamierzam uderzyć
Wchodzić
i jak widać tutaj nie dostaję
odpowiedź i polecenie się zawiesza
a wynika to z tego, że
do tego potrzebny jest dostęp z zewnątrz
dotrzeć do magazynu w chmurze i tej instancji
ma tylko wewnętrzny lub prywatny adres IP, więc
dostęp do plików w chmurze
wiadro nie jest teraz możliwe, aby
dostęp do przechowywania w chmurze i zestawu
zewnętrzne adresy IP używane przez Google
apis i usługi, za pomocą których możemy to zrobić
włączenie prywatnego dostępu Google na
podsieć używana przez interfejs sieciowy vms
więc idziemy dalej i robimy
to teraz, więc uderzę
Control c, aby się zatrzymać i idę
z powrotem do konsoli, do której zamierzam się udać
menu nawigacyjne i zamierzam
przewiń w dół do sieci vpc
a potem się zagłębię
prywatna podsieć i zamierzam edytować
to w ramach prywatnego dostępu do google idę
włączyć i zejdę na dół
na dół i kliknij zapisz i przez
nadanie tej podsieci prywatnego dostępu Google
zezwolę na prywatną instancję i
wszelkie instancje z prywatnymi adresami IP
aby uzyskać dostęp do dowolnego publicznego interfejsu API
takie jak przechowywanie w chmurze, więc teraz, kiedy idę
wróć do mojej instancji, którą zamierzam wyczyścić
ekran tutaj i zamierzam uruchomić
ponownie polecenie gsutil
i sukces
jesteśmy teraz w stanie uzyskać dostęp do pamięci w chmurze
ze względu na włączenie prywatnego dostępu do Google
odpowiednią podsieć prywatną
więc najpierw chciałem ci pogratulować
dotarcie do końca tego demo
i mam nadzieję, że to demo było
niezwykle przydatne, ponieważ jest to prawdziwe życie
scenariusz, który może się wydarzyć i tak po prostu
podsumowanie, że utworzyłeś niestandardową sieć
z dwiema utworzonymi niestandardowymi podsieciami a
zasobnik do przechowywania w chmurze i przesłał trochę
pliki do niego utworzyłeś plik public
instancja i prywatna instancja, a następnie
stworzył kilka reguł zapory sieciowej do kierowania
traffic, a następnie przetestowałeś to wszystko, używając
wiersz poleceń do komunikacji z tobą
włącz także prywatny dostęp Google dla
instancja tylko z wewnętrznym adresem IP
aby uzyskać dostęp do publicznego interfejsu Google, aby
może uzyskać dostęp do pamięci w chmurze i tak dalej
fantastyczna robota z twojej strony, ponieważ była to
dość złożone demo
i możesz spodziewać się takich rzeczy jak co
których doświadczyłeś w tym demo do popu
w swojej roli bycia chmurą
inżynierem w dowolnym momencie, więc zanim pójdziesz, bądź
pamiętaj o usunięciu wszystkich posiadanych zasobów
Utworzony
i jeszcze raz gratulacje za świetną robotę tak
możesz teraz oznaczyć to jako zakończone i
do zobaczenia w następnym
witam z powrotem w tej lekcji będę
przeglądanie komunikacji równorzędnej sieci vpc i jak to zrobić
możesz komunikować się prywatnie
vpcs w tym samym lub innym
organizacja vpc network peering i vpc
peering są w tym przypadku używane zamiennie
lekcji, ponieważ są one używane do komunikowania się
to samo teraz dla instancji w jednym
vpc do komunikacji z instancją w
inny vpc, przez który kierowaliby ruch
jednak publiczny internet
komunikować się prywatnie między dwoma vpcs
Google Cloud oferuje usługę o nazwie vpc
Peering i będę przechodzić przez
teoria i koncepcje peeringu vpc
przez całą lekcję, więc z tym
mówiąc, zanurzmy się
teraz peering vpc umożliwia równorzędne vpc
sieci
więc obciążenia w różnych vpc
sieci mogą komunikować się w trybie prywatnym
spacja, która następuje po rfc
Norma z 1918 roku umożliwiająca w ten sposób prywatne
łączność w dwóch sieciach vpc
ruch pozostaje w sieci Google
i nigdy nie przechodzi przez publiczny Internet
vpc peering zapewnia elastyczność
sieci równorzędne, które są tego samego lub
różne projekty wraz z możliwością
do równorzędnych z innymi sieciami w różnych
organizacje vpc peering również Ci to daje
kilka zalet w porównaniu z zewnętrznym
adresy IP lub VPN do połączenia
pierwszy to zmniejszenie opóźnień w sieci jako
cały ruch równorzędny pozostaje w obrębie
szybki sieciowy peering vpc firmy Google
oferuje również większe bezpieczeństwo sieci jako
nie musisz ujawniać usług
do publicznego internetu i sobie z tym poradzić
większe ryzyko związane z ruchem
kompromitujesz się lub jeśli próbujesz
w celu osiągnięcia standardów zgodności dla Twojego
umożliwi ci peering vpc organizacji
aby osiągnąć wymagane standardy
i wreszcie zmniejsza się peering sieciowy vpc
koszty sieci, oszczędzając na ruchu wychodzącym
koszty ruchu wychodzącego z gcp, więc w a
za zwykłą sieć Google pobiera opłaty
ruch komunikuje się za pomocą publicznych adresów IP
nawet jeśli ruch odbywa się w obrębie tego samego
zone teraz możesz to ominąć i zapisać
pieniądze za pomocą wewnętrznych adresów IP do
komunikować się i utrzymywać ruch
w sieci gcp
teraz istnieją pewne właściwości lub
cechy charakterystyczne dla równorzędnych vpcs
i chciałem zwrócić na to uwagę
lepsze zrozumienie najpierw równorzędnego vpc
sieci pozostają administracyjne
oddzielne, więc co to dokładnie oznacza
cóż, oznacza to, że kieruje zapory ogniowe vpns
i inne narzędzia do zarządzania ruchem są
administrowane i stosowane oddzielnie w
każdej z sieci vpc, więc to ma zastosowanie
do każdego vpc niezależnie, który również
oznacza, że ​​każda strona peeringu
stowarzyszenie
jest również konfigurowany niezależnie, więc kiedy
łączysz jeden vpc z drugim ty
musisz wejść do każdego vpc, którym jesteś
łączenie zarówno inicjować, jak i
nawiązać połączenie równorzędne
aktywny tylko wtedy, gdy konfiguracja z
obie strony pasują, to oznacza również, że
każdy vpc może usunąć komunikację równorzędną
stowarzyszenie w dowolnym momencie teraz podczas
vpc peering z peerami vpc zawsze
wymień wszystkie trasy podsieci, które również posiadasz
możliwość wymiany tras niestandardowych
podsieci i trasy statyczne są globalne i
trasy dynamiczne mogą być regionalne lub globalne
dana sieć vpc może być równorzędna
wiele sieci vpc, ale istnieje
limit, który możesz osiągnąć, w którym ty
musiałbym sięgnąć do google i
poproś o zwiększenie limitu teraz kiedy
istnieje peering z sieciami vpc
pewne ograniczenia, które ty
powinien wiedzieć o pierwszym wyjściu z podsieci
zakres cydru w jednej równorzędnej sieci vpc
nie może nakładać się na trasę statyczną w
inna sieć równorzędna, której dotyczy ta reguła
zarówno trasy podsieci, jak i trasy statyczne tzw
kiedy tworzona jest podsieć vpc lub podsieć
zakres ip jest rozszerzony o chmurę google
przeprowadza kontrolę, aby upewnić się, że
nowy zakres podsieci nie pokrywa się z
zakresy ip podsieci w tym samym vpc
sieci lub w bezpośrednio równorzędnym vpc
sieci, jeśli tworzy lub
ekspansja zawiedzie również Google Cloud
zapewnia, że ​​żadne nakładające się adresy IP podsieci
zakresy
są dozwolone w sieciach vpc, które
pojawiły się wspólne sieci i
ponownie, jeśli tworzy lub
ekspansja zakończy się niepowodzeniem, o czym teraz mowa
routing podczas tworzenia nowej podsieci w
pojawiła się sieć vpc
peering sieci vpc nie zapewnia
szczegółowe kontrolki tras do odfiltrowania
które zakresy cydru podsieci są osiągalne
w czystych sieciach są one obsługiwane
przez reguły zapory sieciowej, aby umożliwić dostęp
ruch z instancji vm w peer
sieć, musisz utworzyć zezwolenie na ruch przychodzący
reguły zapory domyślnie przychodzące
ruch do vms jest blokowany przez implikację
odmowa reguły wnikania to kolejny kluczowy punkt
należy zauważyć, że przechodnia komunikacja równorzędna nie jest
obsługiwane i tylko bezpośrednio peering
sieci mogą się komunikować, więc muszą
przeglądać bezpośrednio na tym diagramie
sieć a jest równorzędna z siecią b i
sieć b jest połączona z siecią c i
więc jeśli jedna instancja próbuje
komunikować się z sieci a do sieci c
nie można tego zrobić, chyba że jest to sieć a
bezpośrednio połączone z siecią c an
niezwykle ważny punkt, na który należy zwrócić uwagę
vpc peering to kolejna rzecz, na którą należy zwrócić uwagę
że nie możesz użyć tagu lub usługi
konto z jednej sieci równorzędnej w
inną sieć równorzędną, którą każdy z nich musi mieć
ich własne, ponieważ znowu są każdym
niezależnie działać, jak wspomniano wcześniej
i tak ostatnia rzecz, którą chciałem
okładka polega na tym, że wewnętrzny DNS nie jest
dostępne dla silnika obliczeniowego w trybie równorzędnym
sieci, ponieważ muszą używać adresu IP do
komunikować, a więc to o okładkach
tę krótką, ale ważną lekcję nt
teoria i koncepcje peeringu vpc oraz
więc teraz, kiedy omówiliśmy całą teorię
Zamierzam przyjąć te koncepcje
w demo, w którym będziemy łączyć dwa
sieci razem i weryfikując
komunikacja między nimi, a więc ty
może teraz oznaczyć tę lekcję jako ukończoną i
kiedy tylko będziesz gotowy, dołącz do mnie
konsola
Witamy z powrotem w tym praktycznym
demonstracja
przejdziemy przez kolejne kroki
utworzyć połączenie równorzędne z dwóch
vszt
w dwóch oddzielnych projektach, jak pokazano tutaj
na diagramie, a następnie zweryfikować to
połączenie działa, do którego zmierzamy
utwórz dwie instancje, po jednej w każdej sieci
i pingować jedną instancję od drugiej
na przykład to demo jest bardzo podobne do
niestandardowe demo vpc, które zrobiłeś
wcześniej, ale dodajemy kolejny
warstwę złożoności, dodając vpc
peering sieciowy, więc jest całkiem sporo
trochę do zrobienia tutaj, więc chodźmy dalej i
po prostu zanurz się
ok, więc wracamy do konsoli
jak widać w prawym górnym rogu
róg Jestem zalogowany jako tony muszki
gmail.com i dla tego konkretnego demo i
będzie korzystać z dwóch projektów, z których oba projektu
tony i projekt bowtie inc, a jeśli ty
obecnie nie masz dwóch projektów
może iść do przodu i stworzyć sobie nowy
projekt lub dwa projekty, jeśli masz
żaden, więc zamierzam kontynuować tutaj
z projektem tony i pierwszą rzeczą i
chcesz zrobić, to utworzyć dwie sieci w
dwa oddzielne projekty, więc idę
aby przejść do menu nawigacji w
lewy górny róg i idę
przewiń w dół do sieci vpc
tutaj zamierzam stworzyć mój pierwszy vpc
network i zamierzam to nazwać
tusz muszkowy
kreska a dam to samo
opis
a następnie pod podsieciami, do których zamierzam
pozostaw tryb tworzenia podsieci pod
custom pod nazwą podsieci, którą możesz
nazwij tę podsieć kreską a
zamierzam użyć jednego regionu usa wschodniego
i dla zakresu adresów IP, do którego idę
aby użyć 10.0, to jest 0.0 ukośnik 20.
a resztę zostawię
opcje jako domyślne i idę
w dół i kliknij utwórz
teraz, gdy ta sieć jest tworzona, jestem
zamierzam przejść do muszki projektowej
inc i zamierzam utworzyć vpc
sieć tam, więc pod nazwą zamierzam
nazwij tę muszkę Inc
b i pod opisem, którego zamierzam użyć
to samo w podsieciach, które zamierzam zachować
tryb tworzenia podsieci jako niestandardowy i poniżej
nowa podsieć Nazwę tę podsieć
podsieć b region będzie używany 4
a zakres adresów IP będzie wynosił
10.4.0.0
ukośnik 20. możesz zostawić wszystkie
inne opcje jako domyślne i przewiń w dół
na dół i kliknij utwórz jako
ta sieć jest tworzona, idę
wrócić do projektu Tony i jadę
aby utworzyć regułę zapory sieciowej dla muszki
kreska atramentu a
w tej regule zapory, jak wyjaśniono w
ostatnia lekcja, na którą pozwolimy
komunikacja z jednej instancji do
inne i tak zamierzam kliknąć
utworzyć zaporę sieciową
i pod nazwą zamierzam to nazwać
projekt
tony dash poniżej opisu idę
używać tego samego
w sieci mam zamiar wybrać
sieć źródłowa, która będzie muszką
inc dash to priorytet, którego będę się trzymać
1000 kierunek ruchu powinien być
ingress i akcja na meczu powinny być
zezwól na cele, które zamierzam wybrać
wszystkie instancje w sieci i pod
filtr źródłowy zamierzam zachować ip
wybrane zakresy i źródłowy zakres adresów IP
specjalnie dla tego demo będzie
być 0.0.0.0
ukośnik 0. i znowu to jest
specjalnie użyte w tym demo i
nigdy nie należy używać w
środowisko produkcyjne w
production powinieneś używać tylko
źródłowe zakresy adresów IP, którymi jesteś
komunikowanie się z protokołami i zgodnie z nimi
i porty, ponieważ muszę się zalogować
instancji, aby móc pingować drugą
na przykład będę musiał się otworzyć
tcp na porcie 22. w innych protokołach
możesz dodać icmp, a to pozwoli
polecenie ping do użycia, zamierzam to zrobić
pozostaw wszystkie pozostałe opcje jako domyślne
i zamierzam kliknąć utwórz i teraz
że ta reguła zapory została utworzona
Muszę wrócić do projektu Bowtie
inc i tam utwórz regułę zapory
również
zamierzam nazwać tę regułę zapory
muszka inc kreska b zamierzam to dać
ten sam opis w sieci jestem
wybieram kreskę z atramentem muszka b i'm
zamierza zachować priorytet jako 1000 i
kierunek ruchu powinien być
ingress oraz akcja na meczu
powinno umożliwiać przewijanie w dół
cele zamierzam wybrać wszystkie
instancji w sieci i ponownie pod
filtr źródłowy zamierzam zachować ip
wybrane zakresy i pod źródłowym adresem IP
zakresy, w które zamierzam wejść
0.0.0.0 ukośnik 0. i poniżej
protokoły i porty, które zamierzam wybrać
tcp z portem 22, a także pod innym
protokoły, które zamierzam wpisać icmp, jestem
zostawie wszystko inne jako
default i zamierzam kliknąć Utwórz
teraz po utworzeniu obu sieci
i utworzyłeś obie reguły zapory
może teraz rozpocząć tworzenie instancji so
bo jestem już w projekcie muszka
inc idę w lewą stronę
menu nawigacyjne i zamierzam przewinąć
w dół do silnika obliczeniowego i tworzenia my
instancja, więc po prostu kliknę
tworzyć
i zachować konwencję nazewnictwa
zamierzam nazwać tę instancję instancją
b nie zamierzam dodawać żadnych etykiet dla
teraz w regionie mam zamiar wybrać nas
wschód 4 i możesz opuścić strefę jako
wybór domyślny i pod typem maszyny
mam zamiar wybrać e2 micro i jestem
przewiń w dół i
zamierzam kliknąć zarządzanie
dyski bezpieczeństwa sieci i sprzedawane
najmu, żebym mógł wejść do
kartę sieci, aby zmienić sieć
domyślny interfejs sieciowy, więc jestem
zamierza kliknąć domyślną sieć
interfejs iw sieci mam zamiar
wybierz bowtie inc b i podsieć ma
już został wybrany dla mnie i wtedy
zamierzam przewinąć w dół, kliknij gotowe
a resztę zostawię
opcje jako domyślne i kliknij Utwórz
i tak jak to się tworzy, zamierzam to zrobić
przejdź do projektu tony
i zamierzam utworzyć moją instancję
Tam
i zamierzam nazwać tę instancję
przykład w regionie, do którego zamierzam
wybierz nas na wschód1 możesz opuścić strefę
jako domyślny wybrany w maszynie
wpisz wybieram e2 micro i
przewijając tutaj do dołu jestem
przejdzie do zakładki sieci
w ramach zarządzania dyskami bezpieczeństwa
networking i dusza
i tutaj zamierzam edytować sieć
interfejs i zmień go z domyślnego
sieć, aby muszka kreska atramentu i jak ty
widać, że podsieć była
automatycznie wybrany dla mnie
więc teraz mogę po prostu kliknąć Gotowe
Zostawię wszystkie inne opcje
jako domyślny i zamierzam kliknąć
tworzyć
więc w ramach podsumowania stworzyliśmy dwa
oddzielne sieci w dwóch oddzielnych
projektów wraz z odpowiadającymi im
podsieci i reguły zapory sieciowej
z utworzeniem instancji w każdym
sieć, a więc teraz, gdy mamy jedno i drugie
skonfigurowanych środowisk, nadszedł czas, aby to zrobić
utwórz połączenie równorzędne vbc i tak dalej
ponieważ jestem w projekcie Tony, zamierzam
zacznij od tego projektu i jestem
przejść do menu nawigacji
i przewiń w dół do sieci vpc i poniżej
sieć vpc w menu po lewej stronie jesteś
zamierzam kliknąć na peering sieci vpc
i przez interfejs pokazany tutaj
będziemy mogli stworzyć naszą sieć vpc
peering, więc teraz klikniesz
utwórz połączenie i pojawia się monit
niektóre informacje, których będę potrzebować i
ponieważ łączymy się z innym vpc
w innym projekcie będziesz potrzebować
identyfikator projektu oraz nazwę
sieć vpc, z którą chcesz się łączyć
i tak jak wyjaśniono we wcześniejszym
lekcja zakresy adresów IP podsieci w obu
sieci nie mogą się pokrywać, więc proszę o to
upewnij się, że jeśli używasz zakresów adresów IP
poza tymi, dla których są podane
ta demonstracja obejmuje zakresy ip
używasz nie nakładają się tak raz ty
masz te informacje, możesz kliknąć
Kontynuować
i tak tutaj zostaniesz poproszony o
niektóre pola do wypełnienia
informacje, o które zostałeś poproszony
zebrać na poprzednim ekranie i tak
ponieważ mamy już te informacje
możemy iść dalej i zacząć wypełniać
pola, więc nazwę to peeringiem
peering połączenia
ab i pod siecią vpc, do której zamierzam
wybierz kreskę atramentową muszka i pod okiem
sieć vpc, którą wybierzemy
inny projekt, który powinien być Bowtie Inc
a nazwą sieci vpc będzie muszka
inc myślnik b i zamierzam zostawić wszystko
inne opcje jako domyślne i tak dalej
pod nazwą sieci vpc zobaczysz
wymieniać niestandardowe trasy i tutaj mogę
wybierz, aby zaimportować i wyeksportować niestandardowe
trasy, które wcześniej utworzyłem tzw
wszelkie specjalne trasy, które stworzyłem
przed faktycznym połączeniem równorzędnym i
może przenieść je do innej sieci
aby spełnić moje wymagania i tak jestem
Nie zamierzam tego teraz robić, idę
aby to zamknąć i zamierzam po prostu
kliknij utwórz i tak to się skończy
tworzenie i jest oznaczony jako nieaktywny i
to dlatego, że odpowiedni
połączenie peeringowe w projekcie Bowtie ma
jeszcze do skonfigurowania status będzie
zmienić na zielony znacznik wyboru w obu
sieci i oznaczone jako aktywne
są podłączone, jeśli ten stan pozostaje bez zmian
nieaktywne, powinieneś ponownie sprawdzić swoje
konfigurację i odpowiednio ją zmodyfikuj
teraz zabieram się za projekt
bowtie inc i zamierzam utworzyć
odpowiednie połączenie równorzędne ja
zamierzam kliknąć raz utwórz połączenie
masz swój identyfikator projektu i vpc
sieć, możesz kliknąć kontynuuj i
dla nazwy tego połączenia równorzędnego
Nazwę to peering dash ba
odpowiednio w sieci vpc idę
aby wybrać muszkę inc b i under peered
sieć vpc, którą zamierzam wybrać
inny projekt tutaj, który chcesz wpisać
twój identyfikator projektu dla mnie zamierzam
wklej mój identyfikator projektu tony i
pod nazwą sieci vpc, którą zamierzam wpisać
w Bowtie Inc
a i zamierzam zostawić wszystkie inne
opcje jako domyślne i zamierzam to zrobić
kliknij utwórz, a więc teraz, gdy to zrobiliśmy
ustanowione połączenia na każdym z
połączenia równorzędne w każdym vpc, jeśli
informacje, które wprowadziliśmy, to
poprawnie, powinniśmy otrzymać zielone
znacznik wyboru stwierdzający, że peering
połączenie jest połączone i sukces tutaj
mamy status jako aktywny i jeśli idę
do projektu tony, który powinienem był mieć
ten sam zielony znacznik wyboru w statusie
dla połączenia równorzędnego i as
oczekiwany status ma zielony znacznik wyboru
mark i jest oznaczony jako aktywny, więc teraz w
aby wykonać połączenie parowania
test, który będę musiał pobrać
wewnętrzny adres IP instancji w drugim
network, która znajduje się w projekcie bowtie
i dlatego, że nie ma znaczenia który
instancja, do której się loguję, tak jak obaj
dostęp ssh i ping zamierzam po prostu
przejdź do menu nawigacji, do którego idę
przejść do obliczania silnika i
zamierzam nagrać wewnętrzny adres IP
instancja a, a teraz idę do głowy
przejdź do projektu muszki i zaloguj się
instancja b i pingowanie instancji a i tak dalej
aby ssh do tej instancji, jestem
zamierzam kliknąć przycisk ssh poniżej
connect i powinno otworzyć nową przeglądarkę
dla mnie, logując mnie do instancji
Ok, jestem zalogowany tutaj i zamierzam to zrobić
powiększ dla lepszego oglądania i tak teraz
zamierzam uruchomić polecenie ping przeciwko
instancja a przy użyciu wewnętrznego adresu IP, który i
skopiowałem wcześniej i zamierzam uderzyć
wchodzisz i jak widać ping działa
więc teraz możemy potwierdzić, że plik vpc
nawiązywane jest połączenie peeringowe i
dwie instancje w różnych vpc
sieci komunikują się za ich pośrednictwem
prywatne ips i możesz śmiało uderzać
kontrolka c, aby zatrzymać ping i tak po prostu
jako podsumowanie stworzyłeś dwa oddzielne
sieci vpc z własnym oddzielnym
podsieci w dwóch oddzielnych projektach
utworzył niezbędne reguły zapory w
każda z tych sieci wraz z
tworzenie instancji w każdym z nich
sieci, a następnie ustanowiłeś vpc
połączenie peering ustanawiające
konfiguracja w każdym vpc, który następnie wykonałeś
test łączności, logując się do jednego z
instancje i pingowanie drugiej
na przykład, więc mam nadzieję, że to pomoże cementować
teoria peeringu vpc, którą ty
nauczył się na poprzedniej lekcji i ma
dał ci pewien kontekst, jeśli chodzi o
konfigurowanie każdego końca komunikacji równorzędnej
połączenie, więc chciałem poświęcić chwilę
aby pogratulować ukończenia tego
demo, więc wszystko, co pozostało, to
oczyścić wszystkie zasoby, które my
utworzone w tym demo i możesz
zacznij od wybrania instancji i
usuwanie ich w każdej sieci, jak również
reguły firewalla i sieci
do siebie się udam
projekt Tony, a ja zamierzam to zrobić
to samo tam i tak można zrobić
dokładnie to, co zrobiłeś z ostatnim
instancja tutaj możesz ją wybrać, kliknij
usuń i usuń instancję i tak dalej
następnie usuniemy peering
połączenie, więc jedziemy do
menu nawigacyjne, do którego zmierzamy
przewiń w dół do sieci vpc i na
menu po lewej stronie, które będziemy przewijać
aż do komunikacji równorzędnej sieci vpc i tak jest
zamiar wybrać pojawiające się połączenie
idziemy na górę i klikamy
przy usuwaniu, a następnie usuń komunikację równorzędną
połączenie
więc teraz usuniemy plik
reguła zapory, więc przejdziemy do
zapora ogniowa
wybieramy regułę zapory
u góry klikniemy usuń
a następnie usuń regułę zapory i
na koniec chcemy usunąć plik
sieć vpc, którą stworzyliśmy, więc jesteśmy
zamierzamy przejść do sieci vpc, jesteśmy
przejdziemy do szczegółów niestandardowego vpc
u góry, na który będziemy klikać
usuń sieć vpc, a następnie jedziemy
kliknąć na usuń i tak teraz, gdy mamy
usunięto wszystkie zasoby w projekcie
Tony, wrócimy do naszego
drugi projekt muszka projektu i zrób
to samo, więc zrobimy to jako pierwsi
zacznij od komunikacji równorzędnej vpc
połączenie, więc przejdziemy do niego
peeringu sieciowego vpc, do którego zamierzamy się udać
wybierz pojawiające się połączenie
zamierzam kliknąć usuń u góry i
usuń połączenie równorzędne, a następnie jesteśmy
przejdziemy do zapory ogniowej
wybierz regułę zapory przejdź do
top i kliknij usuń, a następnie usuń
reguła zapory i wreszcie jesteśmy
przejdziemy do sieci vpc, którymi jesteśmy
zamierzam zagłębić się w zwyczaj
sieć, którą klikniemy na usuń
sieć vpc u góry i usuń plik
sieć vpc
a więc teraz, kiedy ci się udało
usunięto wszystkie zasoby, które możesz teraz
oznacz tę lekcję jako ukończoną, a ja to zrobię
do zobaczenia w następnym i gratulacje
ponownie na wielkiej pracy ukończenia
ten demot
[Muzyka]
witaj z powrotem i jestem na tej lekcji
będziemy omawiać koncepcje i
terminologia współdzielonych vpcs ja też
przejdziemy do szczegółowych przypadków użycia
i w jaki sposób współdzielone vpcs będą używane
różne scenariusze, więc z tą istotą
powiedział, zanurkujmy
teraz, gdy tworzony jest vpc, zwykle tak jest
związany z konkretnym projektem, co teraz
dzieje się, gdy chcesz udostępnić zasoby
w różnych projektach, ale nadal tak jest
osobne rozliczanie i dostęp w ramach
same projekty
w tym miejscu do gry wchodzą współdzielone vpcs
współdzielone vpcs umożliwiają organizacji
łączyć zasoby z wielu projektów
do wspólnej sieci vpc w ten sposób
mogą bezpiecznie komunikować się ze sobą
i wydajnie wykorzystując wewnętrzne adresy IP z
tej sieci, gdy używasz współdzielonych vpcs
wyznaczasz projekt jako gospodarza
projekt i dołączyć jeden lub więcej innych
projektuje do niego sieci vpc
w projekcie głównym są uważane za
współdzielone sieci vpc, tak jak a
przypomnienie projektu, w którym bierze udział
współdzielony vpc jest albo projektem hosta, albo
projekt usługowy może projekt główny
zawierać co najmniej jedną współdzieloną sieć vpc
projekt usługi to dowolny projekt, który
został dołączony do głównego projektu przez a
udostępniony administrator vpc, na który pozwala ten załącznik
go do udziału we wspólnym vpc i
tylko jako uwaga, projekt nie może być jednym i drugim
gospodarz i projekt usługowy
jednocześnie musi to być jeden lub
inne i możesz tworzyć i używać
wiele projektów hosta, jednak każdy
projekt usługi można dołączyć tylko do
pojedynczy projekt główny to także a
powszechna praktyka posiadania wielu usług
projekty zarządzane przez różne
działów lub zespołów w organizacji
i tak dla jasności dla tych, którzy
zastanawiasz się projekt, który nie
uczestniczyć we wspólnym vpc
nazywa się samodzielnym projektem
i ma to na celu podkreślenie, że tak jest
ani głównym projektem, ani usługą
projekt teraz, jeśli chodzi o
administrowania tymi współdzielonymi vpcs my
należy kierować się zasadą
najmniejsze uprawnienia i tylko przypisanie
niezbędny dostęp potrzebny do określonego
użytkowników, więc tutaj podzieliłem role
które są potrzebne do włączenia i administrowania
współdzielony vpc, który ma administrator współdzielonego vpc
uprawnienia do włączania projektów głównych
dołączaj projekty usług do projektów hosta
i delegować dostęp do niektórych lub wszystkich
podsieci we współdzielonych sieciach vpc do
obsługuj administratorów projektów, jeśli chodzi o
administrator projektu usługi jest udostępniony
vpc admin dla danego projektu hosta i
jest zwykle również właścicielem projektu
chociaż przy definiowaniu każdej usługi
administrator projektu może współużytkowany administrator vpc
zezwolić na korzystanie z całego hosta
projekt lub tylko niektóre podsieci i kiedy
chodzi o obsługiwanie tam administratorów projektów
to dwa odrębne poziomy uprawnień
które można zastosować, pierwszym jest projekt
uprawnienia na poziomie i jest to usługa
administrator projektu, do którego można zdefiniować
mieć uprawnienia do używania wszystkich podsieci w
projekt hosta, jeśli chodzi o podsieć
uprawnienia na poziomie projektu usługi
admin może otrzymać bardziej restrykcyjne
zestaw uprawnień do korzystania tylko z niektórych
podsieci, teraz chciałem się przenieść do niektórych
przypadki użycia, które dadzą ci trochę więcej
kontekst, w jaki sposób współdzielone vpcs są używane w
określone środowiska zilustrowane tutaj
to prosty wspólny scenariusz vpc tutaj a
projekt główny został utworzony i
dołączone do projektów usługowych do niego
administrator projektu usługi w projekcie usługi
A
można skonfigurować, aby uzyskać dostęp do wszystkich lub niektórych
podsieci we współdzielonej sieci vpc
administrator projektu usługi z co najmniej
uprawnienia na poziomie podsieci do 10.0.2.0
24 podsieć utworzyła vm1 w strefie
znajduje się w jednym z zachodnich stanów USA
instancja otrzymuje swój wewnętrzny adres IP
adres
10.0.2.15 z 10.0.2.0
24 blok cydru teraz projekt serwisowy
administratorzy w projekcie usługi b mogą być
skonfigurowany, aby uzyskać dostęp do wszystkich lub niektórych z nich
podsieci we współdzielonej sieci vpc a
administrator projektu usługi z co najmniej
uprawnienia na poziomie podsieci do
10.10.4.0 ma ukośnik 24 podsieci
utworzono vm2 w strefie znajdującej się w usa
region centralny 1, który otrzymuje ta instancja
jego wewnętrzny adres IP
10.10.4.1
od
10.10.4.0 ukośnik 24 blok cydru
i oczywiście samodzielny projekt
nie uczestniczy we wspólnym vpc
w ogóle, ponieważ nie jest ani hostem, ani a
projekt usługi i ostatnia rzecz do
notatka
instancje w załączonych projektach usług
do głównego projektu przy użyciu tego samego współdzielonego
sieć vpc
mogą komunikować się ze sobą za pomocą
efemeryczne lub rezerwowe statyczne
wewnętrzne adresy IP i będę
obejmujące zarówno efemeryczne, jak i statyczne IP
adresy w dalszej części pod
zewnętrzne adresy IP silnika obliczeniowego
zdefiniowane w projekcie głównym są tylko
możliwe do wykorzystania przez zasoby w tym projekcie
nie są dostępne do użytku w serwisie
projekty przechodzą do następnego przypadku użycia
to projekt wielu hostów do tego użytku
przypadku, gdy organizacja używa dwóch
rozwój oddzielnych projektów głównych i
produkcja
a każdy projekt główny ma dwie usługi
dołączone do nich projekty są hostami
projekty mają jedną wspólną sieć vpc
z podsieciami skonfigurowanymi do korzystania z tego samego
cydr obejmuje zarówno testy, jak i
sieci produkcyjne zostały celowo
skonfigurowany w ten sam sposób, więc w ten sposób
kiedy pracujesz z zasobami powiązanymi z a
zakres podsieci zostanie automatycznie
przetłumaczyć z jednego środowiska na
drugi przechodzi do następnego przypadku użycia
jest teraz w tym środowisku hybrydowym
przypadku użycia organizacja ma jeden
projekt hosta z pojedynczym udostępnionym vpc
sieć, w której znajduje się współdzielona sieć vpc
połączone przez VPN w chmurze z
sieć lokalna niektóre usługi i
aplikacje są hostowane w gcp podczas
inne są trzymane na terenie iw ten sposób
oddzielne zespoły mogą zarządzać każdym z nich
własne projekty usługowe
a każdy projekt nie ma uprawnień do
inne projekty usługowe, jak również każdy
projekt usługi może być również rozliczany
oddzielnie poziom podsieci lub poziom projektu
zostały udzielone uprawnienia dot
niezbędnych administratorów projektu usługowego
aby mogli tworzyć instancje, które używają
współdzielona sieć vpc i ponownie
wystąpienia w tych projektach usług mogą
być skonfigurowany do komunikacji z
usługi wewnętrzne
takich jak bazy danych lub serwery katalogowe
zlokalizowane na terenie i wreszcie ostatnie
przypadek użycia to dwuwarstwowa usługa sieciowa
organizacja ma usługę internetową, która
jest podzielony na dwa poziomy i
różne zespoły zarządzają każdym poziomem
projekt usług poziomu pierwszego reprezentuje
element skierowany na zewnątrz za
http lub https moduł równoważenia obciążenia warstwy 2
projekt usługi reprezentuje wewnętrzny
usługa, na której opiera się poziom 1 i
jest zrównoważony za pomocą wewnętrznego tcp lub
równoważenia obciążenia udp, na który pozwala udostępniony vpc
mapowanie każdej warstwy usługi sieciowej
do różnych projektów, aby mogli
być zarządzane przez różne zespoły
udostępnianie hostowi wspólnej sieci vpc
zasoby, które są potrzebne dla obu poziomów
teraz omówimy całkiem sporo w tej lekcji
jeśli chodzi o wszelkie koncepcje
współdzielone vpcs, które objęliśmy zarówno hosta, jak i
projekty usługowe i role, które pełnią
grać i ich ograniczenia my też poszliśmy
nad różnymi potrzebnymi rolami
do administrowania tymi współdzielonymi vpcs i my
omówiono różne przypadki użycia, jak to zrobić
używaj współdzielonych vpcs dla różnych scenariuszy
i tak to obejmuje wszystko, co ja
chciałem omówić na tej lekcji
więc możesz teraz oznaczyć tę lekcję jako
zakończyć i przejść do następnego
jeden
[Muzyka]
witaj z powrotem i jestem na tej lekcji
będziemy omawiać dzienniki przepływu vpc
dzienniki przepływu są niezbędnym narzędziem
monitorowanie i analizowanie ruchu
wchodzenie i wychodzenie z vpcs z vm
dzienniki przepływu wystąpień są niezbędne
wiedzieć na egzamin, jak powinieneś wiedzieć
możliwości i przypadków użycia itd
to powiedziawszy, zanurzmy się
więc dzienniki przepływu vpc rejestrują próbkę
przepływy sieciowe
wysyłane i odbierane przez instancje maszyny wirtualnej
łącznie z instancjami używanymi jako google
węzły mechanizmu Kubernetes, które te dzienniki mogą
być używany do analizy kryminalistycznej monitorowania sieci
analiza bezpieczeństwa i wydatków w czasie rzeczywistym
optymalizacja po włączeniu przepływu vpc
dzienniki, które włączysz dla wszystkich maszyn wirtualnych w podsieci
więc w zasadzie włączyłbyś vpc
dzienniki przepływu dla poszczególnych podsieci
dzienniki przepływu są agregowane według połączenia
z maszyn wirtualnych silnika obliczeniowego i wyeksportowane do
w czasie rzeczywistym te dzienniki mogą być eksportowane
rejestrowanie w chmurze znane wcześniej jako
stackdriver przez 30 dni, jeśli zajdzie taka potrzeba
być przechowywane dłużej niż 30 dni
można wyeksportować do magazynu w chmurze
wiadro do dłuższego przechowywania, a następnie
czytać i pytać przez logowanie w chmurze google
chmury próbki pakietów, które opuszczają i
wprowadź maszynę wirtualną, aby teraz generować dzienniki przepływu
każdy pakiet jest przechwytywany do własnego
zapis w dzienniku około jednego na 10
pakiety są przechwytywane, ale to próbkowanie
stawka może być niższa w zależności od
vm's load i tak jak uwaga, nie możesz
dostosuj tę stawkę, według której ta stawka jest zablokowana
Google Cloud i nie można go zmienić
w jakikolwiek sposób i ponieważ dzienniki przepływu vpc nie
przechwycić każdy pakiet, który kompensuje
pominięte pakiety przez interpolację z
przechwyconych pakietów, teraz jest ich wiele
różne przypadki użycia dzienników przepływu vpc
i chciałem zająć krótką chwilę
przejdź przez nie pierwszy, który chciałem
wspomina się o monitorowaniu sieci vpc flow
dzienniki zapewniają dostęp w czasie rzeczywistym
wgląd w przepustowość sieci i
wydajność, dzięki czemu można monitorować vpc
sieci wykonaj diagnostykę sieci
zrozumieć zmiany w ruchu drogowym i pomóc
prognozowana pojemność
do planowania pojemności można również
analizuj wykorzystanie sieci za pomocą dzienników przepływu vpc
i możesz analizować przepływy w sieci
dla ruchu między regionami i strefami
ruch do określonych krajów na
Internet
i na podstawie analizy możesz
zoptymalizować wydatki na ruch sieciowy
teraz świetny przypadek użycia dzienników przepływu vpc
to kryminalistyka sieciowa
więc na przykład, jeśli zdarzy się incydent
może sprawdzić, które ips rozmawiały z kim
i kiedy i możesz też spojrzeć na dowolne
skompromitowanych ips, analizując wszystkie
przychodzące i wychodzące przepływy sieciowe i
w końcu
Dzienniki przepływu vpc mogą być używane w czasie rzeczywistym
Analiza bezpieczeństwa
możesz wykorzystać transmisję strumieniową w czasie rzeczywistym
apis za pomocą pub sub i zintegrować je
z kartą SIM lub informacjami bezpieczeństwa
system zarządzania zdarzeniami, taki jak splunk
Rapid7 lub logarytm i to jest bardzo
powszechny sposób dodania dodatkowej warstwy
bezpieczeństwa do obecnie istniejącego
środowisko, a także świetny sposób
spełniają wszelkie normy zgodności, które są
potrzebne dla Twojej organizacji teraz vpc
dzienniki przepływu są rejestrowane w określonym
rekordy dziennika formatu zawierają pola podstawowe
które są podstawowymi polami każdego dziennika
pola rekordów i metadanych, które dodają
dodatkowe pola metadanych informacji
można pominąć, aby zaoszczędzić na kosztach przechowywania, ale
pola podstawowe są zawsze uwzględniane i
nie można pominąć niektórych pól dziennika
format wielopolowy z więcej niż jednym
fragment danych w danym polu
Na przykład
pole połączenia, które widzisz
baza ma format szczegółów ip
który zawiera źródło i
docelowy adres IP i port
plus protokół w jednym polu
przepływy, które mają punkt końcowy w gke
klaster można opatrzyć adnotacją za pomocą gke
adnotacje, które mogą zawierać szczegóły dotyczące
klaster
pod i obsługa punktu końcowego gke
adnotacje są dostępne tylko z a
niestandardowa konfiguracja pól metadanych
teraz, gdy włączysz dzienniki przepływu vpc
można ustawić filtr oparty zarówno na podstawie, jak i
pola metadanych, które zachowują tylko dzienniki
które pasują do filtra, którym są wszystkie inne dzienniki
odrzucone przed napisaniem
logowanie, które oszczędza pieniądze i
skraca czas potrzebny na znalezienie
wyświetlone informacje, których szukasz
oto próbka z konsoli w
zarówno klasyczna przeglądarka logów, jak i
przeglądarka logów w podglądzie i tak w
klasyczna przeglądarka logów, możesz po prostu
wybierz podsieć od pierwszej
menu rozwijanego i od drugiego pociągnięcia
w dół menu możesz wybrać
compute.googleapis.com
przepływy podkreślenia vpc z ukośnikiem do przodu i
to da ci informację, że
musisz wyciągnąć cały przepływ vpc
logs w podglądzie przeglądarki logów
zrobione w podobny sposób, ale zapytanie jest
pokazany tutaj w konstruktorze zapytań i can
odpowiednio wyregulować pociągając w górę
dzienniki przepływu vpc muszą być wykonane w ramach
console podczas przeglądania ich w google
chmura i tak ostatnia rzecz, którą chciałem
pokazać przed zakończeniem tej lekcji jest
próbka samego dziennika pokazany dziennik
oto przykład dziennika przepływu vpc
wygląda jak
i jak widać tutaj obok każdego
polu zobaczysz małą strzałkę
kliknięcie tych strzałek spowoduje rozwinięcie
pole i ujawniają wiele podpól
które widzieliście na ostatnim slajdzie i będzie
udzieli ci niezbędnych informacji
musisz przeanalizować swoje dzienniki przepływu vpc
ten przykład pola połączenia to
pokazuje pięć krotek, które to opisują
połączenie, które wyraźnie widać
tutaj na szczycie i gdybym miał iść
dalej w dół i rozwiń więcej z nich
pola, znajdę więcej informacji
co pomogłoby mi lepiej przeanalizować więcej
rejestrowanie informacji dla mojego problemu, który ja
próbuję rozwiązać teraz nie chciałem
idź zbyt głęboko w logowanie, tak jak ja
nurkowanie w pełnej sekcji na jego temat
własny w dalszej części kursu, ale
Chciałem, żebyś wyczuł, co
rodzaj danych, jakie mogą dostarczyć dzienniki przepływu vpc
i jak może ci pomóc w twojej specyfice
przypadek użycia, jak również na egzaminie i tak dalej
to właściwie wszystko, co chciałem zawrzeć
w odniesieniu do dzienników przepływu vpc, więc możesz
teraz zaznacz tę lekcję jako ukończoną i
przejdźmy do następnego
[Muzyka]
witam ponownie na tej lekcji, na którą idę
obejmują ogólne omówienie podstaw
podstawowa usługa, która obsługuje
szkielet internetu, jaki znamy
dziś ta fundacja nazywa się dns lub
używany jest system nazw domen dns
szeroko w chmurze Google, głównie z
perspektywa infrastruktury i jest wykorzystywana
w prawie każdej innej chmurze
środowisku lub sieci komputerowej na
planety jest teraz całkiem sporo do omówienia
w tej lekcji w odniesieniu do dns so
powiedziawszy to, zanurzmy się
teraz dns lub system nazw domen to a
globalnie zdecentralizowane rozproszone
baza danych, która pozwala przechowywać ip
adresy i inne dane
i wyszukaj je po imieniu w tym systemie
używa nazw czytelnych dla człowieka, takich jak
google.com i tłumaczy go na
język, który rozumieją komputery
to na przykład numeryczne adresy IP
ludzie uzyskują dostęp do informacji online za pośrednictwem
nazwa domeny, taka jak google.com komputery
używać adresów IP, aby uzyskać dostęp do informacji
online jak 172.217.
teraz, niezależnie od tego, czy wpiszesz google.com, czy
adres IP do przeglądarki internetowej, oba będą
połącz się z google.com dns tłumaczy
nazwę domeny na adres IP, aby
przeglądarka internetowa wie, gdzie się połączyć
i wiemy, co wpisać do sieci
przeglądarka przez dns możesz połączyć a
nazwę domeny na hosting
Poczta
i inne usługi
teraz zagłębiam się w to jako ip
adresy są podstawą
komunikacji między urządzeniami w sieci
internecie są trudne do zapamiętania i
może się często zmieniać nawet za to samo
usługi, aby obejść te problemy my
nadawał nazwy adresom IP na przykład
jeśli chodzi o nasz komputer
komunikować się z
www.google.com użyje DNS
system, aby zrobić to teraz w dns
baza danych zawiera potrzebne informacje
przekonwertować www.google.com
nazwę domeny na adres ip i to
część informacji jest przechowywana w
kontener logiczny zwany strefą po drodze
przez którą strefa jest zapisana
co jest obecnie powszechnie znane jako plik strefy
w tym pliku strefy znajduje się rekord dns
co łączy nazwę
www i adres IP twojego laptopa
musi się komunikować
z konkretną witryną i tą strefą
plik jest hostowany przez tak zwaną nazwę
serwer lub serwer ns w skrócie i tak zrobię
zagłębić się w ten temat w
tylko minutę, więc w skrócie, jeśli możesz
zapytaj strefę o rekord
www.google.pl
wtedy twój komputer może się komunikować
serwer WWW i DNS jest tym, co go tworzy
wszystko się dzieje
teraz chciałem przejść do historii
o tym, jak dns powstał tak wcześnie
sieci komputerowe prosty plik tekstowy
o nazwie plik hosta został utworzony
mapowane nazwy hostów na adresy IP i
umożliwiło to ludziom odniesienie się do innych
komputery po imieniu i ich
komputery przetłumaczyły tę nazwę na ip
adres, gdy wymagał komunikacji
z tym problemem są rozmiary sieci
zwiększyło się podejście do pliku hosta
niepraktyczne, bo to
musiały być przechowywane na każdym komputerze jako
każdy komputer musiałby rozwiązać problem
te same nazwy hostów i aktualizacje były
trudne do zarządzania, jak wszystkie
komputery musiałyby otrzymać
zaktualizowany plik w sumie ten system był
nie skalowalne
teraz przezwyciężyć te i inne
ograniczeń system dns został opracowany
i zasadniczo zapewniony system dns
aby znaleźć sposób na uporządkowanie nazw za pomocą a
strukturę nazwy domeny zapewniał również a
dynamiczny system usług protokołów
i metody
do przechowywania aktualizacji i pobierania ip
adresy komputerów hostów
teraz, gdy omówiłem, czym jest dns
i dlaczego go używamy, w które chciałem się zagłębić
struktura systemu dns teraz
struktura zaczyna się od kropki u podstawy
jeśli chcesz, a to można znaleźć później
każdą nazwę domeny, którą wpisujesz
przeglądarki, której prawie nigdy nie zobaczysz
to, a to dlatego, że Twoja przeglądarka to zrobi
automatycznie umieścić go bez twojego
wiedząc, że możesz spróbować z dowolną domeną
w dowolnej przeglądarce i prawie to zrobisz
zawsze wymyślić ten sam wynik
kropka jest wstawiona za ciebie i zapewni
trasa dla Ciebie i to jest miejsce, w którym my
zacznij psuć system dns
teraz przestrzeń nazw domen składa się z a
hierarchiczna struktura danych, taka jak ta
masz na swoim komputerze każdy węzeł
etykieta i zero lub więcej zasobów
rekordy, które przechowują informacje
powiązany z nazwą domeny
sama nazwa domeny składa się z etykiety
połączone z imieniem swojego rodzica
węzeł po prawej stronie oddzielony kropką tzw
jeśli chodzi o dns, nazwa domeny to
zawsze montowane od prawej do lewej to
hierarchia lub drzewo jest podzielone na
strefy zaczynające się od strefy głównej a dns
strefa może składać się tylko z jednej domeny lub
może składać się z wielu domen i sub
domeny w zależności od administracji
wybory menedżera strefy, które teraz dostają
bezpośrednio do niego serwerem głównym jest
pierwszy krok w tłumaczeniu tekstu czytelnego dla człowieka
nazwy hostów na adresy IP katalogu głównego
Domena składa się z 13 systemów dns
rozsianych po całym świecie znanym
zbiorczo jako główne serwery dns
są one oznaczone literami a
przez m
obsługiwane przez 12 organizacji, m.in
verisign cogent i nasa, póki są
13 adresów IP, które je reprezentują
systemów jest w rzeczywistości więcej niż 13
serwerami są niektóre adresy IP
właściwie klaster serwerów dns i tak dalej
składa się również każdy z tych serwerów dns
pliku strefy głównej, który zawiera plik
adres autorytatywnego serwera nazw
dla każdej domeny najwyższego poziomu i ponieważ
utrzymanie tego jest tak dużym przedsięwzięciem
zaktualizowana iana lub przypisany internet
organ liczbowy został wyznaczony jako
organ, który zarządza i administruje
ten plik i dołączę link
tekst lekcji dla tych z was, którzy są
chcąc zagłębić się w treść
tego pliku strefy głównej, jak również
dowiedzieć się trochę więcej nt
organizacja iana teraz, podczas gdy dns
serwery root ustalają hierarchię
większość procesu rozpoznawania nazw jest
delegowane do innych serwerów dns, więc po prostu
poniżej trasy dns w hierarchii znajdują się
serwery domeny najwyższego poziomu
znany również jako tld w skrócie top
domena poziomu przyjmuje tld podany w
zapytanie użytkownika, na przykład www.google
i zawiera szczegółowe informacje na temat dot-com tld
serwer nazw firm, które
administrować tymi domenami są nazwane
rejestrów i obsługują
autorytatywne serwery nazw dla tych najlepszych
domeny poziomu, na przykład verisign
rejestr najwyższego poziomu dot com
domeny ponad sto milionów domen
zostały zarejestrowane w dot com top
domeny poziomu i tych DNS najwyższego poziomu
serwery
obsługiwać domeny najwyższego poziomu, takie jak com dot
org dot net i dot io i to też może
być określany jako gtld, który jest
ogólne domeny najwyższego poziomu i cctld
który jest najwyższym poziomem kodu kraju
domena taka jak kropka ca dla Kanady kropka uk dla
Wielka Brytania i kropka dla Włoch
delegowane serwery DNS najwyższego poziomu
tysiące serwerów DNS drugiego poziomu
obecnie sprzedawane są nazwy domen drugiego poziomu
firmom i innym organizacjom oraz
rejestruje się ponad 900 akredytowanych rejestratorów
i zarządzać domenami drugiego poziomu w
domena dot com dla użytkowników końcowych
drugim poziomem tej struktury jest
składa się z milionów nazw domen
serwery DNS drugiego poziomu mogą dalej
delegować strefę, ale najczęściej
przechowywać rekordy poszczególnych hostów dla a
nazwa domeny to jest serwer w
dół łańcucha wyszukiwania DNS, gdzie ty
zazwyczaj znajduje rekordy zasobów
i to właśnie te rekordy zasobów
odwzorowuje usługi i nazwy hostów na ip
adresy i odpowie za pomocą
rekord zasobu, którego dotyczy zapytanie, ostatecznie
pozwalając przeglądarce internetowej na tworzenie
żądanie dotarcia do wymaganego adresu IP
aby uzyskać dostęp do strony internetowej lub innej sieci
zasobów teraz jest jeszcze jedna koncepcja
które chciałem zakryć
zanim przejdziemy dalej, a to jest sub
domena teraz niektórzy z was zauważyli i
zastanawiałem się, skąd pochodzi subdomena
w grę w odniesieniu do dns
ma dobrą strukturę, jest to rekord zasobu
która mieści się w domenie drugiego poziomu
aw hierarchii dns subdomena to a
domena, która jest częścią innej domeny main
domena, ale chciałem umieścić ją tutaj
tylko po to, aby dać ci zrozumienie
gdzie spadłyby subdomeny, więc teraz
rozumiemy, jak dns jest zorganizowany i
chciał przejść przez załamanie
przepływ danych DNS, aby dać ci trochę
lepszych kontaktów jest teraz osiem
kroki w wyszukiwaniu DNS najpierw zaczynamy
z klientem dns, który jest pokazany tutaj
jako laptop Tony'ego Bowtiego, a to jest
urządzenie klienckie, które może być również plikiem
telefonem lub tabletem i jest skonfigurowany
oprogramowanie do wysyłania zapytań dotyczących rozpoznawania nazw
do serwera dns, więc kiedy klient tego potrzebuje
aby rozwiązać nazwę zdalnego hosta na jej nazwę
adres IP w większości przypadków wysyła a
żądanie do rekursywnego programu rozpoznawania nazw dns
który zwraca adres ip
zdalny host do klienta rekurencyjnie
resolwer
to serwer dns, który jest skonfigurowany do
przeszukuje inne serwery DNS, dopóki nie znajdzie
odpowiedź na pytanie będzie
zwróć odpowiedź lub błąd
wiadomość do klienta, jeśli nie może
odpowiedz na zapytanie, a zapytanie będzie
ostatecznie przekazany do dns
klient jest w istocie rekursywnym narzędziem do rozwiązywania problemów
pełni rolę pośrednika między klientem
i serwer nazw dns, który zwykle jest
dostawcy usług internetowych usługę
operatora lub sieci korporacyjnej
upewnij się, że resolwer jest w stanie to zrobić
poprawnie uruchomić dns plik wskazówek dotyczących roota
dostarczane z prawie każdą operacją
system i ten plik zawiera adres IP
adresy dla głównych serwerów nazw this
obejmuje również narzędzie do rozpoznawania nazw DNS, ale w
przypadku, gdy nie jest w stanie odpowiedzieć na zapytanie
klient będzie mógł jeszcze wykonać
teraz zapytanie do serwerów nazw dns
po otrzymaniu zapytania dns od a
klient
ten rekurencyjny program rozpoznawania nazw też to zrobi
odpowiedz z danymi z pamięci podręcznej lub wyślij
żądanie do głównego serwera nazw i in
w tym przypadku program tłumaczący wysyła zapytanie do dns
główny serwer nazw serwer główny
odpowiada resolwerowi za pomocą
adres domeny najwyższego poziomu lub tld dns
serwer, taki jak com lub dot net, który
przechowuje informacje dla swoich domen
teraz podczas wyszukiwania google.com the
żądanie jest skierowane w stronę dot-com
tld, więc w naturalny sposób wykonuje to resolver
żądanie do com tld, a następnie tld
serwer nazw następnie odpowiada adresem IP
adres serwera nazw domeny
google.com i na koniec resolver
wysyła zapytanie do nazwy domeny
serwer, na którym znajduje się adres IP dla google.com
następnie wrócił do resolwera z
serwer nazw, dla którego ten adres IP jest przechowywany w pamięci podręcznej
okres czasu określony przez
serwer nazw google.com i ten proces
jest tak, że w przyszłości wniosek o to
nazwa hosta może zostać rozwiązana z jego
cache zamiast wykonywania całości
proces od początku do końca i tak dalej
ci z was, którzy nie są świadomi, że pamięć podręczna to a
komponent, który przechowuje dane tak, że
jakie mogą być przyszłe żądania dotyczące tych danych
szybciej służył temu celowi
buforowanie służy do tymczasowego przechowywania danych
lokalizacja, która skutkuje ulepszeniami
pod względem wydajności i niezawodności danych
żądania buforowania dns obejmuje przechowywanie
dane bliżej żądającego klienta
aby można było rozwiązać zapytanie dns
wcześniejsze i dodatkowe zapytania dalej
w dół łańcucha wyszukiwania DNS można uniknąć
a tym samym poprawiając czasy ładowania danych dns
mogą być buforowane w różnych lokalizacjach
w dół łańcucha, z których każdy będzie przechowywać
rekordy dns przez określony czas
określony przez czas życia znany również
w skrócie ttl, a ta wartość to the
czas życia dla tego rekordu domeny a
oznacza to wysoki ttl dla rekordu domeny
lokalne programy rozpoznawania nazw DNS będą przechowywać odpowiedzi w pamięci podręcznej
dłużej i udzielać szybszych odpowiedzi
jednak wprowadzanie zmian w rekordach dns
może trwać dłużej ze względu na konieczność oczekiwania
aby wszystkie zapisy kasowe wygasły
alternatywnie rekordy domeny z niskim
ttls może zmieniać się znacznie szybciej, ale
resolwery dns będą musiały odświeżyć swoje
notuje częściej i tak w tym finale
krok, na który resolwer DNS odpowiada
przeglądarkę internetową o adresie ip
żądana domena początkowo i raz
te osiem kroków wyszukiwania DNS ma
zwrócił adres IP dla
www.google.pl
przeglądarka jest w stanie wykonać żądanie
dla strony internetowej, podobnie jak przeglądarka
dotrzeć do adresu ip
serwer i zażądać strony internetowej, która
zostanie załadowany w przeglądarce teraz i
wiem, że prawdopodobnie była to recenzja
ci, którzy są nieco bardziej zaawansowani, kiedy
chodzi o zrozumienie dns, ale dla
inni, którzy są całkiem nowi w
podstawy dns, mam nadzieję, że tak
dał ci podstawowe zrozumienie tego, co
dlatego go używamy i jak to działa
posuwając się naprzód w kursie, w którym będę
omawianie dns w odniesieniu do różnych
usługi i potrzebne rekordy zasobów
w strefach przez nie używanych
dane usługi i to w zasadzie tyle
wszystko, co chciałem omówić, jeśli chodzi o
podstawy dns, więc teraz możesz
zaznacz tę lekcję jako zakończoną i przejdźmy do rzeczy
przejść do następnego
[Muzyka]
witam ponownie na tej lekcji, na którą idę
nurkuj teraz w typach rekordów dns dns
rekordy zasobów są podstawą
elementy informacyjne nazwy domeny
system są to wpisy w dns
baza danych zawierająca informacje nt
hosty te rekordy są fizycznie
przechowywane w plikach strefy na DNS
serwer ta lekcja przejdzie przez niektóre
z najczęściej używanych rekordów DNS
z którymi będziemy się spotykać przez cały czas
to oczywiście tak z tym jest powiedziane
zanurzmy się teraz w pierwszym nagraniu
chciałem dotknąć, są serwery nazw
rekordy znane również jako rekordy ns dla
krótki ten rekord identyfikuje, które dns
serwer zawiera aktualne rekordy dla
domena, w której zwykle znajdują się te serwery
u rejestratora dostawcy usług internetowych
lub firmy hostingowej ns rekordy są
utworzone w celu identyfikacji używanego serwera nazw
dla każdej nazwy domeny w danej strefie
w tym przykładzie mamy strefę kropki co
który będzie miał wiele serwerów nazw
rekordy dla
bowtieinc.co teraz ten serwer nazw
rekordy są sposobem delegowania kropki
dzieje się dla bowtieinc.co i wskazują
na serwerach, które hostują
strefa inc.co zarządzana przez bowtie
inc i pokazany tutaj przepływ zapytania
zaczyna się od strefy głównej przechodząc do
dot co zone, gdzie leży rekord
serwery nazw dla bowtieinc.com
i spływa do Bowtieinc.cozone
które zawierają wszystkie niezbędne zapisy
dla Bowtieinc.co
następna płyta, którą chciałem dotknąć
na są rekordy a i aaa i to jest
skrót od rekordów adresowych dla ipv4 i
odpowiednio adresy IP ipv6 i this
rekord wskazuje nazwę domeny na adres IP
adres, na przykład podczas wpisywania wwe
w przeglądarce internetowej system DNS to zrobi
przetłumacz tę nazwę domeny
na adres IP 52.54.92.195
przy użyciu zapisanych w rekordzie informacji
muszka.co
plik strefy dns rekord a łączy a
nazwę domeny strony internetowej na adres IPv4
który wskazuje na serwer, na którym
pliki witryny są dostępne teraz, gdy nadejdzie
do rekordu aaa, który łączy stronę internetową
domenę na adres IPv6, na który wskazuje
ten sam serwer, na którym znajduje się strona internetowa
pliki na żywo i rekordy są najprostsze
typ rekordów dns i jeden z nich
podstawowe rekordy używane w serwerach dns ty
może wiele zrobić z rekordami, w tym
używanie wielu rekordów dla tego samego
domeny w celu zapewnienia redundancji
to samo można powiedzieć
dla rekordów aaa dodatkowo wielokrotność
domeny mogą wskazywać ten sam adres
w takim przypadku każdy miałby swój własny a
lub rekord aaa wskazujący na ten sam adres IP
adres
przejście do rekordów cname nazwa ac
rekord skrót od nazwy kanonicznej rekordu
jest typem rekordu zasobu, który mapuje
może to być jedna nazwa domeny do drugiej
naprawdę wygodne podczas uruchamiania wielu
usługi takie jak serwer ftp i
serwer e-commerce, na którym działa każdy
różnych portów z jednego adresu IP
możesz np
wskaż ftp ftp.bowtieinc.co
i shop.bowtieinc.co
do wpisu dns dla bowtieinc.co
który z kolei ma zapis, który
wskazuje na adres IP, więc jeśli ip
adres ciągle się zmienia
wystarczy zmienić zapis
jedno miejsce w dns rekord dla ukłonu
krawat inc kropka co i tak samo jak uwaga cname
rekordy muszą zawsze wskazywać na inny
nazwę domeny i nigdy bezpośrednio do adresu IP
następny adres to txt zapisuje tekst
record lub w skrócie txt jest rodzajem
rekord zasobu, który zawiera tekst
informacji do źródeł poza Twoim
domena, która może być używana dla wielu
dowolnych celów wartość rekordów może
być tekstem czytelnym dla człowieka lub maszyny
w wielu przypadkach używane są rekordy tekstowe
zweryfikować własność domeny lub nawet do
dostarczać informacji czytelnych dla człowieka nt
serwer sieć lub centrum danych to
jest również często używany w bardziej uporządkowany sposób
moda na nagrywanie niewielkich ilości
odczytywalne maszynowo dane do DNS
system, domena może mieć wiele podatków
zapisy z nim związane
dostarczył implementację serwera dns
obsługuje to każdy rekord może z kolei
zawierać jeden lub więcej ciągów znaków
ten przykład
Google chce zweryfikować stronę bowtieinc.co
domenę, aby można było skonfigurować pakiet G Suite i
wymaga weryfikacji przez domenę do
google poprzez utworzenie rekordu tekstowego
i dodanie go do strefy, którą zrobi Google
następnie podaj tekstowy rekord weryfikacyjny
dodać do rekordów DNS dostawcy hostingu domeny
i rozpocznij skanowanie w poszukiwaniu rekordu tekstowego do
zweryfikować domenę
dostarczony rekord tekstowy jest następnie dodawany
przez administratora domeny i z tyłu
sceny, które google robi a
kontrola weryfikacyjna w określonych odstępach czasu
kiedy Google w końcu zobaczy rekord
istnieje, własność domeny jest potwierdzona
i G Suite można włączyć dla
domena i jest to typowy przykład
jak wykorzystywane są rejestry podatkowe
do mx rejestruje dns
mx znany również jako mail
rekord wymiany jest rekordem zasobu
który kieruje e-mail do serwera pocztowego
Rekord mx wskazuje, w jaki sposób wiadomości e-mail
powinny być kierowane i do jakiego serwera
poczta powinna przejść do podobnych rekordów cname an
Rekord mx musi zawsze wskazywać inny
domena teraz rekordy mx składają się z dwóch
części priorytetem
i nazwa domeny mają priorytet
liczby przed domenami dla tych mx
rekordy i wskazać preferencje
kolejność, w jakiej serwer pocztowy
należy stosować, im niższa jest preferencja
numer im wyższy priorytet, więc in
ten przykład
Laura wysyła e-maila do Tony'ego Bowtiego na adres tony at
Bowtieinc.co
rekordy mx są częścią tego procesu
ponieważ dns musi wiedzieć, gdzie wysłać
mail do i przyjrzymy się domenie
dołączony do adresu e-mail, który jest
bowtieinc.co, więc klient dns będzie działał
zwykłe zapytanie dns, najpierw przechodząc do
korzeń następnie do
cotld i wreszcie do bowtieinc.co
wtedy otrzyma rekord MX który
w tym przykładzie jest dwóch z nich pierwszy
jeden reprezentujący pocztę
mail.bowtieinc.co
a drugi jest inny
serwer pocztowy poza bieżącą domeną
aw tym przypadku jest to serwer poczty Google
z aspmx.l.google.com
i jest to w pełni kwalifikowana domena
imię jako kropka po prawej stronie tego
rekord sugeruje, więc tutaj serwer to zrobi
zawsze spróbuj mail.bowtieinc.co
po pierwsze dlatego, że 5 jest mniejsze niż 10. i
to da mail.bowtieinc.co
wyższy priorytet w wyniku a
błąd wysyłania wiadomości, serwer to zrobi
domyślnie aspmx.l.google.com
jeśli obie wartości są takie same, to tak
byłby nisko zrównoważony w obu przypadkach
serwerów, niezależnie od używanego serwera
pobiera wynik zapytania z powrotem i to
używa tego do łączenia się z serwerem pocztowym
dla bowtieinc.co przez protokół smtp
i używa tego protokołu do dostarczania wszystkich
e-mail i tak wyglądają rekordy mx
używany do wysyłania e-mailem następnego rekordu, który chciałem
do pokrycia są rekordy wskaźników
znane również jako rekordy ptr dla krótkich i
zapewnia to powiązaną nazwę domeny
z adresem IP, więc wskaźnikiem DNS
record jest dokładnym przeciwieństwem a
rekord, który zawiera adres IP
powiązany z nazwą domeny dns
rekordy wskaźników są używane w odwrotnych DNS
wyszukiwania, jak omówiliśmy wcześniej, gdy a
użytkownik próbuje połączyć się z nazwą domeny w
w ich przeglądarce następuje wyszukiwanie DNS
dopasowanie nazwy domeny do ip
Adres odwrotnego wyszukiwania DNS to
przeciwieństwem tego procesu i jest to a
zapytanie rozpoczynające się od adresu IP
i wyszukuje nazwę domeny podczas dnsa
rekordy są przechowywane pod podanym
rekordy wskaźników DNS nazwy domeny są
przechowywane pod odwrotnym adresem IP i
kończące się kropką w środku
addr kropka arpa, więc w tym przykładzie plik
rekord wskaźnika dla adresu iap
52.54.90
będzie przechowywany pod 195.92.54.52
wstawić kropkę
addr kropka arpa adresy ipv6 są
zbudowany inaczej niż IPv4
istnieją adresy i rekordy wskaźników IPv6
w innej przestrzeni nazw
Wewnątrz.arpa rekordy wskaźnika ipv6 są
przechowywane pod odwróconym adresem IPv6
i konwertowane na 4-bitowe sekcje jako
w przeciwieństwie do sekcji 8-bitowych, jak w ipv4 i
jak również domena.ip6.arpa
jest dodawany na końcu rekordów wskaźnika
używany najczęściej w odwrotnych DNS
wyszukiwania do rozwiązywania problemów ze spamem
problemy z dostarczaniem poczty e-mail i logowaniem i tak dalej
ostatnia płyta, którą chciałem nagrać
są zapisy soa znane również jako
początek zapisów władzy i to
rekord zasobu jest tworzony dla Ciebie, kiedy
tworzysz strefę zarządzaną i
określa autorytatywne informacje
w tym globalne parametry dotyczące DNS
strefa, w której przechowywane są płyty soa, jest ważna
informacje o domenie lub strefie np
jako adres e-mail
administratora, kiedy domena była ostatnia
aktualizowane i jak długo serwer powinien
czekaj między odświeża każdą strefę dns
zarejestrowany musi mieć wpis Soa jako
zgodnie z rfc 1035 i jest dokładnie
jeden rekord soa na strefę rekord soa
zawiera podstawowe informacje o Tobie
zone, więc nie jest to możliwe dla twojej strefy
pracować bez tych informacji oraz i
będzie zawierał link w tekście lekcji
dla zainteresowanych nurkowaniem
głębiej i zrozumieć wszystko
informacje, które są nimi objęte
soa zapisuje odpowiednio zoptymalizowane i
zaktualizowany rekord soa może zmniejszyć przepustowość
między serwerami nazw zwiększają prędkość
dostępu do witryny i upewnić się, że witryna jest
żyje nawet wtedy, gdy główny serwer DNS
nie działa, a co do okładek
wszystko, co chciałem omówić, kiedy
chodzi o rekordy zasobów w DNS
więc możesz teraz oznaczyć tę lekcję jako
kompletny
i przejdźmy do następnego
[Muzyka]
Witamy spowrotem
w tej lekcji będę omawiać
znana jest również translacja adresów sieciowych
w skrócie nat jest to powszechne
proces
używany w biznesie domowym i dowolnej chmurze
sieci, które napotkasz wiedząc
i zrozumienie, które ci pomoże
osiągnąć, dlaczego miałbyś go używać i co
sprawia, że ​​jest to tak niezbędny proces
teraz jest tu całkiem sporo do omówienia, więc
powiedziawszy to, zanurzmy się
teraz na wysokim poziomie nat to sposób na mapowanie
wiele lokalnych prywatnych adresów IP do a
publiczny adres IP przed przeniesieniem
informacji odbywa się to poprzez zmianę
dane adresu sieciowego w ip
nagłówek pakietu danych while
podróż przez sieć w kierunku
miejsce docelowe
gdy pakiety przechodzą przez urządzenie nat
źródłowy lub docelowy adres IP
adres jest zmieniony
następnie pakiety powracające w drugim
kierunek są tłumaczone z powrotem na
oryginalne adresy
i jest to typowy proces
używany w większości routerów domowych
dostarczanych przez twoją usługę internetową
dostawca teraz pierwotnie nat został zaprojektowany
poradzić sobie z niedoborem darmowego ipv4
adresów zwiększając liczbę
komputerów, które mogą działać na jednym
publicznie rutowalny adres IP i tak dalej
ponieważ urządzenia w prywatnej przestrzeni IP
na przykład 192.168.0.0
nie może poruszać się po publicznym Internecie
co jest potrzebne tym urządzeniom
komunikować się teraz z publicznym Internetem
ipv6 został zaprojektowany w celu przezwyciężenia ipv4
brakuje i ma mnóstwo dostępnych
adresy i dlatego nie ma rzeczywistego
potrzeba teraz nat, jeśli chodzi o ipv6
nat ma dodatkową zaletę dodawania
warstwa bezpieczeństwa i prywatności wg
ukrywanie adresu IP swoich urządzeń
od świata zewnętrznego i tylko pozwalać
pakiety do wysłania i odebrania z
pochodzące prywatne urządzenie i tak to
to wysoki poziom tego, co nat jest teraz
jest wiele typów, że nie będę
pokrycie
które na wysokim poziomie robią to samo
czyli tłumaczyć prywatne adresy IP
do publicznych adresów IP, ale różne
typy nat obsługują ten proces
inaczej, więc najpierw mamy static nat
który odwzorowuje pojedynczy prywatny adres IP
na publiczny adres IP
więc mapowanie jeden do jednego, które daje
urządzenie z prywatnym adresem IP
dostęp do publicznego internetu w obu
kierunki
jest to powszechnie używane, gdy jeden konkretny
urządzenie z adresem prywatnym
dostęp do publicznego internetu w następnej kolejności
typem nat jest dynamiczny nan i tak jest
podobny do static nat, ale nie działa
ten sam statyczny przydział prywatnego adresu IP
przestrzeń adresowa
jest mapowany na pulę publicznych adresów IP
adresy i są przydzielane losowo jako
potrzebne, gdy adres IP już nie istnieje
potrzebny adres IP jest zwracany
do basenu gotowego do wykorzystania przez innego
urządzenie
ta metoda jest powszechnie stosowana gdzie
wiele wewnętrznych hostów z prywatnym adresem IP
adresy
dzielą się równą lub mniejszą kwotą
publiczne adresy IP
i jest przeznaczony do efektywnego wykorzystania
publicznych ips i wreszcie jest port
tłumaczenie adresu lub pat
gdzie jest wiele prywatnych adresów IP
przetłumaczone przy użyciu jednego publicznego adresu IP
adres i określony port
a to chyba jest twój dom
używany router i obejmie wszystkie
urządzeń używanych w sieci domowej
ta metoda wykorzystuje porty do pomocy
rozróżniać poszczególne urządzenia
i jest również metodą stosowaną do
cloudnat w chmurze google, którą będę
pokrycie w późniejszej lekcji, więc i
chciał zagłębić się w nieco więcej szczegółów
jak działają te metody
zaczynając od statycznego nie
teraz, aby przygotować scenę dla statycznych, a nie ja
zacznie od prywatnego
sieć tutaj po lewej stronie
i przestrzeń publiczną ip tutaj na
Prawidłowy
a router lub nie urządzenie w
środku w tym przykładzie jest serwer
po lewej stronie, do którego potrzebny jest dostęp
usługi zewnętrzne i dla tego przykładu
usługą zewnętrzną, z której korzystamy, jest
serwis Bowtress witryna do udostępniania zdjęć
na wszelkiego rodzaju niesamowite muszki
więc serwer po lewej jest prywatny
z prywatnym adresem IP 192.168.0.5
a to oznacza, że ​​ma adres w
ip wersja 4 prywatna przestrzeń adresowa
co oznacza, że ​​nie może kierować pakietów
przez publiczny internet, bo to tylko
ma prywatne ip
usługi kosmetyczki z drugiej strony
ma publiczny adres IP, który jest
54.5.4.9
więc problem, na który napotykamy, polega na tym, że
adres prywatny nie może być kierowany przez
publiczny internet, bo jest prywatny i
publiczny adres trustu beau
praca
nie może bezpośrednio komunikować się z żadnym
adres prywatny, ponieważ public i
adresy prywatne mogą się komunikować
publiczny internet jest tym, czego potrzebujemy
przetłumacz adres prywatny, który
serwer po lewej ma
do publicznego adresu IP, z którym można się komunikować
serwis po prawej stronie i odwrotnie
teraz to urządzenie będzie mapować
prywatne ip na publiczne ip
używanie i utrzymywanie tabeli nat i in
ten przypadek statycznego nat urządzenia nat
będzie miał odwzorowanie jeden do jednego
prywatny adres IP na publiczny adres IP
adres i może być przypisany do
określone urządzenie, które w tym przypadku jest
serwer oznaczony jako 192.168.0.15
i tak aby serwer na
lewy
komunikować się z pięknością
service serwer wygeneruje plik
pakiet jak zwykle ze źródłowym adresem IP
pakiet jest prywatnym adresem IP serwera
adres i docelowy adres IP
pakiet jest adresem IP Bowtrust
service teraz router w środku jest
domyślną bramę dla dowolnego miejsca docelowego
więc wszelkie pakiety IP, które są przeznaczone
wszystko poza siecią lokalną jest wysyłane
do routera, jak widać tutaj
z wpisem w tabeli tak będzie
zawierać prywatny adres IP
192.168.0.15
i zmapowany na adres publiczny który
w tym przypadku jest to 73.6.2.33
i są one statycznie odwzorowywane na jeden
kolejny i tak w miarę przechodzenia pakietu
przez urządzenie nat źródło
adres pakietu jest tłumaczony
z adresu prywatnego do zmapowanego
adres publiczny i powoduje to nowy
pakiet, więc ten nowy pakiet nadal ma
beautrest jako miejsce docelowe
ale teraz ma prawidłowy publiczny adres IP
jako źródło
a więc to jest to tłumaczenie
dzieje się przez nat teraz ten proces
działa w podobny sposób w drugim
kierunek
więc kiedy odbiera usługę kosmetyczki
pakiet widzi źródło jako to
publiczny adres IP
więc kiedy odpowiada danymi, swoim pakietem
ma swój adres IP jako źródło
oraz publiczny adres IP poprzedniego serwera
adres jako miejsce docelowe
więc wysyła ten pakiet z powrotem do tego
publiczny adres IP, więc kiedy pakiet dotrze do
urządzenie nat, tabela jest sprawdzana
rozpoznaje wtedy, że ip jest dla
serwer i tak tym razem dla przychodzących
ruch drogowy
docelowy adres IP jest aktualizowany
odpowiedni prywatny adres IP i
następnie pakiet jest przekazywany do
prywatny serwer i oto jak
static nat działa na źródłowy adres IP
jest tłumaczony z mapowanego prywatnego adresu IP
na publiczne ip
a dla ruchu przychodzącego miejsce docelowe
adres ip jest tłumaczony z
przydzielony publiczny adres IP do odpowiedniego
prywatne IP bez konieczności
skonfiguruj publiczny ip
na dowolnym urządzeniu prywatnym
ponieważ zawsze mają swoje prywatne IP
adresy
teraz chciałem podać analogię do
nat i jest to bardzo powszechna analogia
używana jest usługa telefoniczna, więc w
ten przykład
Laura jest nowym kierownikiem firmy Bow tie Inc
nowa lokalizacja w Montrealu i została wprowadzona
nowy publiczny numer telefonu
514-555-8437
chociaż jak widać tutaj laura też
ma prywatne rozszerzenie
jeden trzy trzy siedem teraz, jeśli George
zadzwoniłem do Laury pod ten publiczny numer
dotarłby do Laury bez nigdy
znając jej prywatny numer wewnętrzny, więc
rozszerzenie prywatne zachowuje się jak to prywatne
adres IP
a publiczny numer telefonu działałby jako
publiczny adres IP i tak by było
telefoniczna analogia dla statycznego nat i
więc to już koniec części pierwszej
Lekcja trochę się dłużyła, więc ja
postanowił zerwać to byłoby
świetna okazja, aby wstać i
rozciągnij się, zrób sobie kawę lub
herbatę i kiedy będziesz gotowy, możesz
dołącz do mnie w części drugiej, gdzie będziemy
zaczynając bezpośrednio od końca
część pierwsza, abyś mógł iść dalej i
dokończ ten film i do zobaczenia
w części drugiej
[Muzyka]
Witamy z powrotem to jest druga część
lekcja translacji adresów sieciowych i
zaczniemy dokładnie tam, gdzie my
przerwana od części 1.
więc powiedziawszy to, zanurzmy się
teraz przechodzimy do dynamicznego nat
ta metoda jest podobna do metody static nat
z wyjątkiem tego, że urządzenia nie są przydzielone a
stały publiczny ip
publiczny adres IP jest przydzielany z a
pula adresów IP
jak są potrzebne i mapowanie
public to private to podstawa alokacji w
w tym przykładzie włączone są dwa urządzenia
w lewo i zgodnie z tabelą nat
są dwa publiczne adresy IP
dostępne do użytku
73.6.2.33
i 73.6.2.34
więc kiedy jest laptop po lewej stronie
chce uzyskać dostęp do usługi kosmetycznej
wygeneruje pakiet, w którym
adres IP źródła
jest adresem prywatnym 192.168.0.13
a docelowy adres IP to 54.5.4.9
więc wysyła ten pakiet i ponownie
router w środku jest domyślny
brama dla wszystkiego, co nie jest lokalne jako
pakiet przechodzi przez router lub
urządzenie nat
sprawdza, czy prywatny adres IP ma adres
bieżący przydział adresowania publicznego
z basenu, a jeśli nie i jeden
jest dostępny, przydziela jeden
dynamicznie i w tym przypadku
73.6.2.34
jest przydzielony
więc źródłowy adres IP pakietu
jest tłumaczone na ten adres
a pakiety są wysyłane do
usługa kosmetyczki i taki jest ten proces
tak samo jak statyczne nie do tej pory
ale ponieważ dynamiczny nat je przydziela
adresy ip są dynamicznie wielokrotne
prywatne urządzenia mogą udostępniać jeden
publiczny adres IP
tak długo, jak urządzenia nie używają
ten sam publiczny adres IP w tym samym czasie i tak dalej
gdy urządzenie jest gotowe
komunikacji, do której adres IP jest zwracany
basen i jest gotowy do użycia przez inny
urządzenie teraz tylko jako notatkę, jeśli nie ma
dostępne publiczne adresy IP
router odrzuca wszelkie nowe połączenia
dopóki nie wyczyścisz mapowań nat
ale jeśli masz tyle publicznych ip
adresy jako hosty w Twojej sieci
nie napotkasz tego problemu i tak dalej
w tym przypadku, ponieważ niższy serwer jest
szuka dostępu do kanału modowego
praca
dostępny jest publiczny adres IP
w basenie
z 73.6.2.33
dając w ten sposób dostęp do opinii publicznej
internet i dostęp do moda tube tzw
Podsumowując, urządzenie nat odwzorowuje private
ip z publicznym adresem IP w tabeli nat i
publiczne ip są przydzielane losowo i
dynamicznie z puli teraz tego typu
węzeł jest używany, gdy wiele wewnętrznych
hosty z prywatnymi adresami IP
dzielą się równą lub mniejszą kwotą
publiczne adresy IP, gdy wszystkie z nich
prywatnych urządzeń w pewnym momencie będą potrzebne
dostęp publiczny
teraz przykład dynamicznego nat używającego
analogia telefoniczna
byłoby, gdyby Laura i dwie inne muszki
inc pracownicy
Lisa i Jane
miał prywatne numery telefonów
a to będzie reprezentować twoje prywatne
ips
w tym przykładzie Bowtie Inc ma trzy
publiczne numery telefonów
teraz, gdy jakikolwiek pracownik wychodzi
połączenia są kierowane do dowolnej publiczności
linia jest otwarta w tym czasie, więc dzwoniący
id po stronie odbiornika
pokazałby jedną z trzech publiczności
numery telefonów w zależności od tego, który był
podane dzwoniącemu i tak by się stało
reprezentować publiczne ips publicznie
pula ip
teraz ostatni rodzaj nat, który chciałem
mówić o tym, którym jesteś
prawdopodobnie najbardziej znane i to jest
tłumaczenie adresu portu, które jest również
znany jako brak przeciążenia i to jest
rodzaj, którego prawdopodobnie nie używasz w swoim domu
czym jest translacja adresów portów sieciowych
pozwala na dużą liczbę prywatnych urządzeń
udostępnić jeden publiczny adres IP
dając mu mapowanie wiele do jednego
architektura teraz w tym przykładzie będziemy
korzystać z trzech prywatnych urządzeń na
lewy
wszyscy, którzy chcą uzyskać dostęp do fashiontube na
Prawidłowy
popularna witryna do udostępniania wideo
najnowsze trendy w modzie męskiej
udostępniane przez miliony na całym świecie
a ta strona ma publiczny adres IP
62.88.44.88
i dostępny za pomocą portu tcp 443 teraz
sposób, że tłumaczenie adresu portu lub pat
Pracuje
jest użycie zarówno adresów IP, jak i
porty
aby umożliwić udostępnianie wielu urządzeniom
ten sam publiczny adres IP przy każdym połączeniu tcp
oprócz źródła i celu
adres IP
ma port źródłowy i docelowy
port źródłowy jest losowo przydzielany przez
klienta, o ile jest to port źródłowy
zawsze wyjątkowy niż wielu prywatnych klientów
mogą używać tego samego publicznego adresu IP i
wszystkie te informacje są zapisane w
nat na urządzeniu nat
w tym przykładzie załóżmy, że
publiczny adres IP tego urządzenia NAT to
73.6.2.33
więc kiedy laptop w lewym górnym rogu
generuje pakiet i pakiet jest
idąc do kanału moda, jego docelowy adres IP
adres to 62.80
a jego portem docelowym jest 443. teraz
źródłowy adres IP tego pakietu to adres laptopa
prywatny adres IP 192.168.6
a port źródłowy to 35535
który jest losowo przypisanym efemerydą
port, więc pakiet jest kierowany przez
urządzenie nat
iw tranzycie rekordy urządzeń nat
źródłowy adres IP i oryginalne źródło
port prywatny
i przydziela nowy publiczny adres IP
oraz nowy publiczny port źródłowy, który w
ten przypadek to 8844
zapisuje te informacje w pliku
nie stół, jak pokazano tutaj, i dostosowuje się
kieszeń, aby jej źródłowy adres IP
to publiczny adres IP, na który nat
używane jest urządzenie i port źródłowy
ten nowo przydzielony port źródłowy i
ten nowo dostosowany pakiet jest przekazywany
na fashiontube teraz proces jest
bardzo podobnie z ruchem powrotnym
gdzie pakiet zweryfikuje
zarejestrowane adresy IP i porty
w tabeli nat przed przekazaniem
pakiet z powrotem do źródła, z którego pochodzi
teraz, jeśli środkowy laptop z ip
192.168.0.14
zrobił to samo, a następnie ten sam proces
to wszystko byłoby śledzone
informacje byłyby zapisywane w nat
table nowy publiczny port źródłowy
przydzielony i przetłumaczy pakiet
dostosowanie źródłowego adresu IP pakietu
i port źródłowy, a także ten sam proces
stałoby się dla laptopa na
bottom generując pakiet z rozszerzeniem
źródłowy i docelowy adres IP z rozszerzeniem
dodanie źródła i celu
porty i gdy są kierowane przez nat
urządzenie przechodzi przez jego tłumaczenie
zapisywanie informacji w nat
stół i ponownie dociera do celu
ruch powrotny będzie weryfikowany przez
zarejestrowane ips i porty w tabeli nat
przed przekazaniem pakietu z powrotem do niego
źródło pochodzenia i tak samo jak a
podsumowanie, jeśli chodzi o adres portu
tłumaczenie, które urządzenie nat zapisuje
źródłowy adres IP i port źródłowy w tabeli nat
źródłowy adres IP jest następnie zastępowany przez a
publiczny adres IP i publiczny port źródłowy
i są przydzielane z puli, która
pozwala na przeciążenie i jest to a
architektura typu „wiele do jednego”.
i tak dla analogii telefonicznej dla pat
użyjmy przykładu operatora telefonicznego, więc w
tę instancję George próbuje wywołać
laura teraz george zna tylko skowronka laura
administrator wykonawczy i ma tylko skowronki
numer telefonu George nie ma
prywatna linia Laury, publiczny telefon Larka
liczba jest równoważna z posiadaniem a
publiczny adres IP George dzwoni do skowronka, który
następnie łączy George'a z Laurą zastrzeżenie
oto, że skowronek nigdy się nie poddaje
numer telefonu Laury w rzeczywistości Laura
nie ma publicznego numeru telefonu i
można wywołać tylko przez skowronka i oto
gdzie nat może dodać dodatkową warstwę
bezpieczeństwo, zezwalając tylko na potrzebne porty
być dostępne bez pozwolenia nikomu
aby połączyć się z dowolnym portem, mam nadzieję, że tak
pomógł ci zrozumieć proces
translacja adresów sieciowych
jak odbywa się tłumaczenie
oraz proces używania tabeli nat do
osiągnąć translację pakietów
wraz z jego przeznaczeniem tak właśnie jest
powszechne w większości środowisk, które ty
spotka i to jest bardzo ważne
aby w pełni zrozumieć różne typy
z nie
i jak można go używać w tego typu przypadkach
środowisk i to w zasadzie tyle
wszystko, co chciałem zakryć
na tej lekcji adresu sieciowego
tłumaczenie, dzięki czemu możesz to teraz zaznaczyć
lekcja jako zakończona
i przejdźmy do następnego
[Muzyka]
Witamy z powrotem, więc teraz, kiedy to omówiliśmy
podstawy dns wraz z
różne typy rekordów, na których chciałem się skupić
w usłudze dns Google Cloud o nazwie
cloud dns teraz cloud dns jest w pełni
zarządzana usługa, która zarządza serwerami DNS
dla określonych stref i od chmury
dns pojawia się na egzaminie tylko na wysokim poziomie
poziom i, którego omówię
co ta usługa może z tym zrobić
mówiąc, zanurzmy się teraz w dns w chmurze
działa jako autorytatywny serwer DNS dla
strefy publiczne, które są widoczne dla
internet lub dla stref prywatnych, które są
widoczne tylko w Twojej sieci i jest
powszechnie określane jako dns Google jako
usługa dns w chmurze ma serwery, które
obejmują cały świat, czyniąc go globalnym
elastyczna usługa teraz, gdy jest
usługi globalnej nie ma możliwości wyboru
określone regiony, aby rozmieścić swoje strefy
i zasady serwera DNS, które po prostu dodajesz
twoje rekordy i zasady dotyczące stref i to
jest dystrybuowany wśród DNS Google
serwerów na całym świecie cloud dns
także jedna z niewielu chmur Google
usługi oferujące 100
dostępność wraz z niskimi opóźnieniami
dostęp
wykorzystując ogromny globalny zasięg Google
sieci szkieletowej teraz w celu użycia
dns w chmurze z określonym publicznie
dostępna domena musi być nazwą domeny
zakupiony za pośrednictwem nazwy domeny
rejestratora i możesz zarejestrować domenę
nazwę za pośrednictwem domen google lub innych
wybrany rejestrator domen w chmurze
dns nie zapewnia tej usługi i
tylko jako uwaga, aby utworzyć private
strefy zakupu nazwy domeny
nie jest teraz konieczne, jak wspomniano wcześniej
dns w chmurze oferuje elastyczność
hosting zarówno stref publicznych, jak i prywatnych
zarządzane strefy DNS są teraz strefami publicznymi
strefy, które są widoczne dla publiczności
internet, a więc kiedy dns w chmurze jest
zarządzanie posiadaną domeną publiczną
publiczne autorytatywne serwery nazw, które
odpowiadaj na zapytania DNS strefy publicznej dla
Twoja konkretna domena teraz, gdy nadejdzie
do stref prywatnych, które umożliwiają
zarządzać niestandardowymi nazwami domen
dla zasobów Google Cloud bez
upublicznienie jakichkolwiek danych dns
internet może być tylko strefą prywatną
zapytany przez zasoby w tym samym projekcie
gdzie jest zdefiniowana i jak omówiliśmy
wcześniej strefa jest kontenerem dns
rekordy, które są odpytywane przez dns so from
perspektywa strefy prywatnej mogą
być pytany tylko przez jeden lub więcej vpc
sieci, które do tego upoważniasz i
tak jak zauważ sieci vpc, które ty
zezwolenie musi znajdować się w tym samym miejscu
project jako strefę prywatną do zapytania
rekordy hostowane w zarządzaniu strefami prywatnymi
w innych projektach wykorzystanie peeringu dns
jest teraz potrzebny, nie chcę też go dostać
głęboko w peering dns
ale po prostu wiedz, że peering sieci vpc
nie jest wymagane dla cloud dns
strefa peeringu do obsługi stref peeringu
nie zależy teraz od komunikacji równorzędnej sieci vpc
każda utworzona strefa zarządzana jest
powiązany z projektem Google Cloud
a kiedy ta strefa zostanie utworzona, tak jest
hostowane przez zarządzane serwery nazw Google
teraz te strefy są zawsze hostowane
Google zarządza serwerami nazw w ramach
Google Cloud, aby tworzyć rekordy
i zestawy rekordów, a te serwery to zrobią
następnie przydzielone do tego konkretnego
strefa hostująca twoje rekordy i rekord
zestawy i tak jako szybkie przypomnienie a
zestaw rekordów to zbiór dns
rekordy w strefie, które mają to samo
nazwy i są najbardziej tego samego typu
rekordy zawierają jeden rekord, ale tak jest
nierzadko zdarza się, że rekordy są świetne
przykładem tego są rekordy lub ns
zapisy, o których mówiliśmy wcześniej i
te zapisy można zwykle znaleźć w
pary
a więc teraz dać praktyczne
przykład dns w chmurze, który chciałem przynieść
teorię w praktyce poprzez krótki
demo, w którym będę tworzyć zarządzany
strefa prywatna, więc kiedy tylko będziesz gotowy
dołącz do mnie w konsoli i tak oto jesteśmy
są z powrotem w konsoli i jestem zalogowany
jako tonybowties gmail.com i ja
obecnie w projekcie bowtie inc, więc teraz
aby dostać się do dns w chmurze, zamierzam przejść
do menu nawigacyjnego, do którego zmierzam
przewiń w dół do usług sieciowych i przejdź
przejść do dns w chmurze
a ponieważ aktualnie nie mam
strefy
pojawia się monit z tylko jedną opcją która
jest utworzenie strefy, więc zamierzam to zrobić
śmiało i stwórz strefę i tak tutaj
Zostałem poproszony o kilka
różne opcje w celu utworzenia my
strefa dns, a więc pierwsza opcja, którą ja
have to typ strefy i ponieważ jestem
tworzenie prywatnej strefy, do której idę
po prostu kliknij prywatne i muszę
podaj nazwę strefy, do której idę
Zadzwoń do Tony'ego Bowtie'go. Następnym razem będę jadł
podać nazwę dns, którą zadzwonię
Tony Bowtie Dot prywatne i pod
opis zaraz wpiszę
strefa prywatna dla muszki Tony'ego i tak dalej
następne pole, które otrzymałem, to
pole opcji w miejscu, w którym aktualnie się znajduje
oznaczone jako domyślne prywatne, więc jeśli pójdę
tutaj po prawej stronie i
otwórz menu rozwijane, które otrzymałem
opcje przekazywania zapytań do innego
serwer DNS peering zarządza wyszukiwaniem wstecznym
stref i użyj katalogu usług
namespace i tak w zależności od typu
scenariusza jednej z tych pięciu opcji w
większość przypadków wystarczy, więc zamierzam to zrobić
zachowaj go jako domyślny prywatny i poniżej
sieci, mówi, że twoja prywatna strefa będzie
być widoczne dla wybranych sieci
i tak zamierzam kliknąć na spadek
w dół i daję tylko opcję
sieć domyślna, ponieważ jest to
jedyna sieć jaką mam i tak mam
zamiar go wybrać
i zamierzam kliknąć na biały
przestrzeń i jeśli czuję taką ochotę, mogę
po prostu kliknij skrót do
wiersz poleceń i tutaj dostaję to
określone polecenia, gdybym miał użyć
wiersz poleceń, aby utworzyć ten dns
zone, więc kliknę tutaj zamknij
i zamierzam kliknąć utwórz i jako
możesz zobaczyć tutaj moja strefa była
utworzony wraz z kilkoma dns
zapisuje jako pierwsze moje imię
rekordy serwera, jak również mój początek
akta władzy i tak jako uwaga do
wiedzieć na egzamin podczas tworzenia strefy
te dwa rekordy będą zawsze tworzone
zarówno rekord soa, jak i rekord ns
i przechodząc do innych opcji tutaj
mogę dodać inny zestaw rekordów, jeśli zechcę
aby ponownie dns nazwać typ rekordu
którego mam całe mnóstwo rekordów
typy do wyboru to ttl i ip
adres, ale nie zamierzam go dodawać
rekordy, więc po prostu anuluję i
klikając w użyciu przez mogę zobaczyć które
sieć vpc korzysta z tej strefy i as
oczekiwano, pojawi się domyślna sieć
i mam też możliwość dodania
inna sieć, ale ponieważ nie mam
inne sieci nie mogę nic dodać
więc ja też po prostu anuluję
mieć możliwość usunięcia dowolnych sieci
więc jeśli kliknę to, mogę usunąć plik
sieć lub mogę też usunąć sieć
klikając na menu hamburgera i tak dalej
jak widzisz mam kilka opcji
do wyboru przy tworzeniu stref i
zestawy płytowe a więc to o okładkach
wszystko, co chciałem ci pokazać
tutaj w dns w chmurze
ale zanim pójdę, pójdę przed siebie
i posprzątać, a ja po prostu kliknę
na śmietniku tutaj po prawej stronie
strona strony strefy i zamierzam
zostanie wyświetlony monit, jeśli chcę usunąć strefę
tak, mam zamiar kliknąć usuń
i tak to prawie obejmuje
wszystko, co chciałem ci pokazać
w odniesieniu do dns w chmurze, więc możesz teraz
zaznacz tę lekcję jako zakończoną i przejdźmy do rzeczy
przejść do następnego
witamy ponownie, zanim wejdziemy do
część kursu poświęcona silnikowi obliczeniowemu
chciałem pokryć podstawowy fundament
co sprawia, że ​​te maszyny wirtualne są możliwe
i tu jest podstawowe zrozumienie
wirtualizacji wchodzi teraz w grę
jest to jedynie lekcja wprowadzająca
wirtualizacji i nie dostanę
zbyt głęboko w jego podstawy
służy tylko jako podstawowa podstawa
w jaki sposób silnik obliczeniowy uzyskuje swoje funkcje
pod maską i jak to możliwe
poprzez wykorzystanie wirtualizacji dla
głębsze zrozumienie nt
wirtualizacji, które będę uwzględniał
linki w tekście lekcji dla tych, którzy
chcą dowiedzieć się więcej, ale na razie
zapewni to wystarczającą ilość teorii
pomogą Ci zrozumieć, jak działa silnik obliczeniowy
Pracuje
więc biorąc to pod uwagę, zanurzmy się w tym
czym dokładnie jest wirtualizacja
wirtualizacja to proces uruchamiania
wiele systemów operacyjnych na serwerze
jednocześnie teraz przed wirtualizacją
stał się popularny, zastosowano model standardowy
gdzie byłby system operacyjny
zainstalowany na serwerze
więc serwer składałby się z typowych
sprzęt jak procesor
karty sieciowe pamięci i inne urządzenia
takich jak karty wideo urządzenia usb i
pamięć, a następnie system operacyjny
działałby teraz na wierzchu sprzętu
istnieje środkowa warstwa operacyjna
system przełożonym, jeśli chcesz, to znaczy
odpowiedzialny za interakcję z
podstawowego sprzętu i jest to znane jako
jądro, którym jądro zarządza
dystrybucja zasobów sprzętowych
komputera sprawnie i uczciwie
wśród wszystkich uruchomionych procesów
na komputerze teraz działa jądro
w tak zwanym trybie jądra lub
tryb uprzywilejowany, ponieważ działa uprzywilejowany
instrukcje, które wchodzą w interakcję z
sprzęt bezpośrednio teraz działa
system pozwala na uruchamianie innego oprogramowania
na górze jak aplikacja
ale nie może wchodzić w bezpośrednią interakcję z
sprzęt, z którym musi współpracować
system operacyjny w trybie użytkownika lub
tryb nieuprzywilejowany, więc kiedy zdecyduje skowronek
zrobić coś w aplikacji, która
musi używać sprzętu systemowego, który
aplikacja musi przejść przez
system operacyjny, którego potrzebuje, aby zrobić to, co jest
znany jako wywołanie systemowe i to jest
model działania na jednym systemie operacyjnym
jeden serwer teraz, gdy minął serwery
tradycyjnie uruchamia jedną aplikację
na jednym serwerze z jednym systemem operacyjnym
w starym systemie liczba serwerów
dalej by się montował
ponieważ każda nowa aplikacja wymagała jej
własny serwer i własny system operacyjny
w rezultacie drogie zasoby sprzętowe
zostały zakupione, ale nie były używane i każdy
serwer wykorzystałby około 20
swoich zasobów na przeciętnym serwerze
zasoby były wówczas znane jako
niewykorzystany teraz przyszedł czas, kiedy
było wiele systemów operacyjnych
zainstalowany na jednym komputerze
odizolowane od siebie z każdym
własny system operacyjny
aplikacji, do których był to doskonały model
skonsolidować sprzęt i zachować
wykorzystanie wysokie, ale jest główny
problem, który pojawił się przy każdym procesorze
moment w czasie mógł mieć tylko jedno
działa jako uprzywilejowany, więc ma wiele
systemy operacyjne działają samodzielnie
w stanie niezmienionym
i spodziewają się, że będą biegać samodzielnie
w uprzywilejowanym stanie z systemem uprzywilejowanym
instrukcje
powodowało niestabilność systemów
powodując nie tylko awarie aplikacji, ale
awaria systemu teraz hiperwizor jest czym
rozwiązany ten problem jest mały
warstwa oprogramowania, która umożliwia wiele
systemy operacyjne, które będą działać obok każdego z nich
Inny
współdzielenie tego samego fizycznego komputera
zasobów, które pochodzą z tych systemów operacyjnych
jako maszyny wirtualne lub maszyny wirtualne i takie są
pliki, które naśladują całe przetwarzanie
środowisko sprzętowe w oprogramowaniu
hypervisor znany również jako wirtualny
monitor maszyny lub vmm
zarządza tymi maszynami wirtualnymi, gdy działają razem
siebie, oddziela maszyny wirtualne
od siebie logicznie przypisując każdy z nich
swój własny kawałek podłoża
obliczanie pamięci procesora i innych urządzeń
jak sieć graficzna i pamięć masowa
zapobiega ingerencji vms
siebie, więc jeśli na przykład jeden
system operacyjny ulegnie awarii lub
naruszyć bezpieczeństwo, zrobią to inni
przetrwać i kontynuować bieg teraz
hypervisor nigdy nie był tak wydajny jak how
widzicie to tutaj, przeszło przez to trochę
główne iteracje, które nadały jej strukturę
jak wiemy to dzisiaj początkowo
trzeba było zrobić wirtualizację
oprogramowanie lub to, co teraz nazywamy
maszyna gospodarza
i system operacyjny wraz z nim
aplikacje umieszczone w kontenerach logicznych
znane jako maszyny wirtualne lub goście
system operacyjny zostanie zainstalowany
gospodarz, który zawierał dodatkowe
możliwości zwane hiperwizorem i
pozwoliło mu dokonać niezbędnego
uprzywilejowane wywołania do sprzętu
mając pełny dostęp do hosta
hypervisor odsłonił interfejs
urządzenie sprzętowe, które jest dostępne na
gospodarz
i zezwolił na zmapowanie go do
maszynę wirtualną i emulować
zachowanie tego urządzenia i to było dozwolone
maszynę wirtualną za pomocą pliku Operating
sterowniki systemowe, do których zostały zaprojektowane
wchodzić w interakcję z emulowanym urządzeniem
bez instalowania specjalnych sterowników
lub narzędzia
jak również utrzymanie systemu operacyjnego
niezmodyfikowany problem polega na tym, że to
wszystko było emulowane i tak za każdym razem
maszyny wirtualne wykonały połączenia zwrotne do
hostować każdą instrukcję, która była potrzebna
przetłumaczone przez hiperwizora
używając tak zwanego tłumaczenia binarnego
teraz bez tego tłumaczenia
emulacja nie zadziałałaby i spowodowałaby
awarie systemu powodujące wyłączenie wszystkich wirtualnych
maszyny w procesie teraz problem
z tym procesem jest to, że stworzył
system boleśnie powolny i to było to
kary za wydajność, która to spowodowała
proces nie został tak powszechnie przyjęty, ale
potem pojawił się inny rodzaj wirtualizacji
na scenie zwanej para wirtualizacją
teraz w tym modelu zmodyfikowany gość
system operacyjny może mówić
bezpośrednio do hiperwizora i to
wiąże się z posiadaniem systemu operacyjnego
jądro do modyfikacji i ponownej kompilacji
przed instalacją na virtual
maszynie, co pozwoliłoby na działanie
system do bezpośredniej rozmowy z
hypervisor bez żadnych spadków wydajności
ponieważ nie ma tłumaczenia
emulacja do wirtualizacji
zastępuje instrukcje, które nie mogą być
zwirtualizowany z hiper wywołaniami
komunikować się bezpośrednio z hiperwizorem
więc hiperwezwanie opiera się na tym samym
koncepcja jako uprzywilejowane wywołanie systemowe
instrukcje
które akceptują zamiast dzwonić
kernel bezpośrednio wywołuje hiperwizora
i ze względu na modyfikację w tym
wydajność systemu operacyjnego gościa jest
ulepszony jako zmodyfikowany gość
system komunikuje się bezpośrednio z
hiperwizor i narzut na emulację
usunięto system operacyjny gościa
staje się jeszcze prawie świadomy wirtualizacji
nadal istnieje proces, w którym
oprogramowanie było używane do rozmowy z
sprzętu, jaki mogły maszyny wirtualne
nadal nie ma bezpośredniego dostępu do sprzętu
Chociaż
rzeczy się zmieniły w świecie
wirtualizacja, gdy fizyczna
stał się sprzęt na hoście
świadomy wirtualizacji i oto gdzie
pojawiła się wirtualizacja wspomagana sprzętowo
do gry teraz wspomagane sprzętowo
wirtualizacja to podejście, które
umożliwia sprawne
pełna wirtualizacja z pomocą
możliwości sprzętowe
na procesorze hosta przy użyciu tego modelu
system operacyjny ma bezpośredni dostęp do
zasobów bez hiperwizora
emulacja lub system operacyjny
modyfikacją staje się sam sprzęt
obsługujący wirtualizację, który zawiera procesor
konkretne instrukcje i możliwości
aby hiperwizor mógł bezpośrednio
kontrolować i konfigurować to wsparcie
zapewnia również lepszą wydajność
ponieważ uprzywilejowane instrukcje od
maszyny wirtualne są teraz uwięzione i
emulowane w sprzęcie bezpośrednio to
oznacza, że ​​jądra systemu operacyjnego
nie trzeba już modyfikować i
ponownie skompilowany jak w wirtualizacji para
i może działać tak, jak jest w tym samym czasie
hypervisor również nie musi być
uczestniczy w niezwykle powolnym procesie
translacji binarnej jest teraz jedna
więcej iteracji, które chciałem omówić
jeśli chodzi o wirtualizację i nie tylko
jest wirtualizacja na poziomie jądra
teraz zamiast używać hiperwizora
wirtualizacja na poziomie jądra działa a
oddzielna wersja jądra Linuksa i
widzi powiązaną maszynę wirtualną jako
proces przestrzeni użytkownika na hoście fizycznym
ułatwia to uruchamianie wielu
maszyny wirtualne na jednym hoście a
do komunikacji używany jest sterownik urządzenia
między głównym jądrem Linuksa a
zaimplementowana jest każda maszyna wirtualna
jako zwykły proces linuksowy
zaplanowane przez standardowego Linuksa
planista
z dedykowanym sprzętem wirtualnym, takim jak
karta sieciowa
karta graficzna
obsługa pamięci procesora i sprzętu dyskowego przez
procesor jest wymagany do wirtualizacji a
jest nieco zmodyfikowany proces emulacji
używany jako wyświetlacz i wykonanie
kontenery dla maszyn wirtualnych w
na wiele sposobów wirtualizacja na poziomie jądra
wyspecjalizowana forma serwera
wirtualizacja i to jest rodzaj
platforma wirtualizacji, która jest używana w
cała chmura Google teraz z tym typem
wirtualizacji z powodu jądra
działając jako hiperwizor umożliwia a
specyficzna funkcja zwana zagnieżdżoną
wirtualizacja teraz z zagnieżdżonymi
wirtualizacja jest możliwa
zainstaluj hypervisor na górze
już działająca maszyna wirtualna
i to właśnie ma chmura Google
zrobione teraz, prawdopodobnie zastanawiasz się później
przejść przez wszystkie zawiłości
związany z poprzednią wirtualizacją
modele
co sprawia, że ​​ten scenariusz jest wart zachodu
dzięki zagnieżdżonej wirtualizacji to robi
użytkownikom łatwiej przenieść swoje
lokalnie
zwirtualizowane obciążenia do chmury
bez konieczności importowania i konwertowania vm
obrazy tak w istocie
ułatwia użytkowanie podczas migracji do chmury
świetny przypadek użycia dla wielu, ale nie
być możliwe w chmurze Google bez
korzyść z uruchamiania na poziomie jądra
wirtualizacja teraz jest zaawansowana
koncepcja, która nie pojawia się na
egzamin, ale chciałem, żebyś zrozumiał
wirtualizacja na wysokim poziomie
abyś mógł zrozumieć zagnieżdżone
wirtualizacja w chmurze Google
ponieważ jest częścią zestawu funkcji
silnik obliczeniowy i to w zasadzie tyle
wszystko, co chciałem omówić, jeśli chodzi o
wirtualizacja
więc możesz teraz oznaczyć tę lekcję jako
zakończyć i przejść do następnego
jeden
[Muzyka]
Witamy z powrotem teraz wcześniej w
oczywiście omówiłem silnik obliczeniowy w a
wysoki poziom, aby zrozumieć, co to jest i
jaki jest cel tej sekcji
jest głębsze zanurzenie się w silniku obliczeniowym jako
pojawia się mocno na egzaminie, więc ja
chcę się upewnić, że ujawnię wszystkie
niuanse
jest to również oferta usług typu „go-to”.
z Google Cloud, gdy szukasz rozwiązania
wszelkie ogólne potrzeby związane z przetwarzaniem
lekcja, do której konkretnie się odniosę
co składa się na instancję i
różne dostępne opcje
podczas tworzenia instancji, więc z tym
mówiąc, zanurzmy się
teraz Compute Engine pozwala tworzyć i
uruchamiać maszyny wirtualne zwane instancjami
i hostować je w infrastrukturze Google
silnik obliczeniowy należy do Google
infrastruktura jako usługa wirtualna
oferta maszyn, więc jest
serwis google dba o
platforma wirtualizacji fizyczna
serwery wraz z siecią i pamięcią masową
z zarządzaniem data center i nie tylko
instancje są dostępne w różnych
rozmiary w zależności od ilości procesora i
pamięć, której możesz potrzebować, jak również obliczyć
silnik oferuje różne typy rodzin dla
rodzaj obciążenia, do którego jest potrzebny
każda instancja jest naliczana przez drugą
po pierwszej minucie, ponieważ jest to a
model oparty na konsumpcji, a także
te instancje są uruchamiane w vpc
sieć w określonej strefie i te
instancje faktycznie będą znajdować się na hostach w
tych stref, a otrzymasz
możliwość korzystania z hosta wielodostępnego
gdzie serwer, który hostuje twoje
maszyna jest udostępniana innym osobom
ale pamiętaj, że każda instancja jest
całkowicie odizolowany od innych, więc nie
można zobaczyć swoje instancje
teraz masz również możliwość
uruchamianie instancji na wyłącznym dzierżawie
node, w którym twoja instancja działa sama
dedykowane hosty, które są zarezerwowane tylko
dla ciebie i tylko dla ciebie nie podzielasz tego
z kimkolwiek innym i jest to ściśle określone
dla ciebie tylko teraz chociaż ta opcja
może brzmieć naprawdę świetnie, to przychodzi w
stromy koszt
więc tylko wtedy, gdy wymaga tego twój przypadek użycia
użyj pojedynczego węzła dzierżawy dla bezpieczeństwa lub
celów zgodności polecam
trzymaj się hosta z wieloma dzierżawcami, kiedy
uruchamianie instancji i to jest
zwykle najczęstszym wyborem dla
bardzo
teraz mogą być instancje silnika obliczeniowego
konfigurowane na wiele różnych sposobów i
pozwalają na elastyczność w spełnieniu
prośby o konkretny scenariusz i
jak widać tutaj są cztery
różne opcje podstawowe, jeśli chodzi o
konfiguracja instancji, którą ty
przygotowują się do uruchomienia i tak chciałem
poświęcić trochę czasu, aby przejść przez nie w zaledwie
trochę szczegółów na temat uruchamiania kontekstu
najpierw z typem maszyny, która obejmuje
vcpu i pamięci teraz jest ich wiele
różne predefiniowane typy maszyn, które
omówię dogłębnie w
inna lekcja, ale na razie po prostu wiedz
że są dostępne w różnych
rodzin w zależności od Twoich potrzeb i możliwości
zostać wybrany spośród generała
optymalizacja obliczeń i optymalizacja pamięci
typów maszyn, w których są dostępne
smaki intel lub amd, a jeśli
predefiniowane opcje nie pasują do twojego
potrzebujesz mieć możliwość tworzenia
niestandardowa maszyna, która będzie pasować do Ciebie
określone obciążenie teraz podczas tworzenia maszyny wirtualnej
instancja w silniku obliczeniowym każdego wirtualnego
cpu lub vcpu jest zaimplementowany jako pojedynczy
sprzętowy hiperwątek na jednym z
dostępnych procesorów, które działają
gospodarz teraz przy wyborze kwoty
vcpus na instancji
musisz wziąć pod uwagę
żądaną przepustowość sieci jako ilość
vcpus określi tę przepustowość
ponieważ przepustowość jest określana na maszynę wirtualną
instancja nie na interfejs sieciowy lub
na adres IP, a więc sieć
przepustowość jest określana przez obliczenia
2 gigabity na sekundę dla każdego włączonego vcpu
twoja instancja, więc jeśli szukasz
większą przepustowość sieci niż możesz
chcesz wybrać instancję z większą liczbą
vcpus i tak po ustaleniu a
typ maszyny dla twojego silnika obliczeniowego
na przykład będziesz musiał go podać
obraz z systemem operacyjnym do uruchomienia
się teraz podczas tworzenia maszyny wirtualnej
przypadkach musisz użyć pliku Operating
obraz systemu, dla którego mają zostać utworzone dyski rozruchowe
Twoje instancje są teraz oferowane przez silnik obliczeniowy
wiele wstępnie skonfigurowanych obrazów publicznych, które
mieć kompatybilny system Linux lub Windows
systemy operacyjne i te operacyjne
obrazów systemowych można używać do tworzenia i
uruchom instancje, silnik obliczeniowy używa twojego
wybrany obraz, aby utworzyć trwałe
dysk rozruchowy dla każdej instancji domyślnie
dysk rozruchowy dla twojej instancji to
taki sam rozmiar jak wybrany obraz
i możesz użyć większości publicznych obrazów pod nr
za dodatkową opłatą, ale należy o tym pamiętać
jest kilka obrazów premium, które to robią
dodaj dodatkowe koszty do swoich instancji
teraz przechodząc do niestandardowych obrazów, to jest
obraz dysku rozruchowego, którego jesteś właścicielem i który kontrolujesz
dostęp do prywatnego obrazu, jeśli chcesz
niestandardowe obrazy są dostępne tylko dla Ciebie
projekt w chmurze, chyba że specjalnie
zdecydować się na udostępnienie ich innym
projekt lub inną organizację, którą możesz
utwórz niestandardowy obraz z dysków rozruchowych lub
inne obrazy, a następnie użyj niestandardowego obrazu
aby utworzyć niestandardowe obrazy instancji, które
importujesz do silnika obliczeniowego, nie ponoszą żadnych kosztów
do twoich instancji, ale powodują powstanie obrazu
opłata za przechowywanie
podczas gdy zachowujesz swój niestandardowy obraz w swoim
zaprojektuj teraz trzecią opcję, którą ty
mieć, to użycie obrazu z rynku teraz
Google Cloud Marketplace na to pozwala
szybko wdrożyć
funkcjonalne pakiety oprogramowania, które działają na
Google Cloud możesz uruchomić oprogramowanie
pakiet bez konieczności ręcznego
skonfiguruj oprogramowanie instancji vm
pamięć, a nawet ustawienia sieciowe
to jest uniwersalny szablon instancji
w tym system operacyjny i
wstępnie skonfigurowane oprogramowanie i możesz
wdrażać pakiet oprogramowania w dowolnym momencie
lubić i jest to zdecydowanie najłatwiejszy sposób
uruchom pakiet oprogramowania i będę
dając ci szansę na zapoznanie się z nimi
obrazy marketplace w późniejszej wersji demonstracyjnej
po wybraniu typu maszyny
a także rodzaj obrazu, który ty
chciał użyć przejścia do typu
pamięć masowa, którą chcesz, będzie następną
krok teraz podczas konfigurowania nowej instancji
konieczne będzie utworzenie nowego dysku rozruchowego
za to i tutaj jest wydajność
kontra koszt wchodzi w grę, tak jak ty
możliwość płacenia mniej i mieć wolniejszy
prędkość dysku lub mniej operacji we/wy lub możesz
wybierz dużą szybkość dysku z
wyższe liczby operacji we/wy, ale zapłacić wyższy koszt i tak dalej
najwolniejszy i najtańszy z
te opcje to standardowe trwałe
dysku, które są wspierane przez standardowy dysk twardy
dyski twarde równoważą dyski trwałe
są wspierane przez dyski półprzewodnikowe i są
szybciej i może zapewnić wyższą liczbę operacji we/wy niż
opcja standardowa i wreszcie ssd
najszybsza opcja, która również przynosi
z tym najwyższy dostępny dla
dyski trwałe teraz poza nimi
trzy opcje dla dysków trwałych
mają również możliwość wyboru lokalnego
ssd i są to dyski półprzewodnikowe
które są fizycznie dołączone do
serwer, który hostuje Twoje instancje maszyn wirtualnych i
dlatego mają najwyższe
przepustowość i najniższe opóźnienia niż jakiekolwiek inne
dostępnych dysków trwałych
jako uwaga dane, które przechowujesz na
lokalny ssd utrzymuje się tylko do momentu
instancja jest zatrzymana lub usunięta
dlaczego lokalne dyski ssd nadają się tylko do
tymczasowe przechowywanie, takie jak pamięci podręczne lub wymiana
dysk i tak w końcu się do niego przenoszę
tworzenie sieci
każdy interfejs sieciowy komputera
instancja silnika jest powiązana z a
podsieć unikalnej sieci vpc, tak jak ty
widać w ostatniej sekcji można to zrobić
z auto domyślnym lub niestandardowym
sieć, w której każda sieć jest dostępna
w wielu różnych regionach i strefach
ten region, którego również doświadczyliśmy
kierowanie ruchu dla naszej instancji zarówno w
i poza siecią vpc
przy użyciu reguł zapory ukierunkowanych na adres IP
zakresy
określone tagi sieciowe lub instancje
w sieci teraz równoważenia obciążenia
są odpowiedzialni za pomoc w dystrybucji
ruch użytkowników
w wielu instancjach albo w obrębie
sieci lub zewnętrznie za pomocą a
regionalny lub globalny system równoważenia obciążenia
i będę wchodzić w niskie balansowanie
w innej części kursu, ale ja
chciałem podkreślić, że systemy równoważenia obciążenia są
część sieci instancji, która pomaga
wyznaczać trasy i zarządzać ruchem przychodzącym i
wychodzenie z sieci
a więc jest to przegląd na wysokim poziomie
różne typy konfiguracji, które
przejdź do składania instancji i
będę nurkować głębiej w każdym z nich
w tym dziale też będę
praktyczne podejście do tego przez
tworzenie instancji w następnej lekcji
i skupiając się na różnych dostępnych
funkcje, których możesz użyć dla swojego
konkretny przypadek użycia, więc to wszystko i
chciałem pokryć tę lekcję, więc ty
może teraz oznaczyć tę lekcję jako ukończoną i
przejdźmy do następnego
[Muzyka]
witaj z powrotem teraz wiem w poprzednim
demonstracji, które zbudowaliśmy całkiem sporo
instancje silnika obliczeniowego i mieć
odpowiednio je w tym skonfigurować
demonstracja, przez którą będziemy przechodzić
kompilacja innej instancji, ale chciałem
zagłębić się w specyfikę
konfiguracje, które są dostępne dla
silnik obliczeniowy, więc to powiedziawszy
zanurzmy się, więc jestem teraz zalogowany
pod tonym muszką gmail.com oraz ja
jestem zalogowany pod Bowtie Inc
projekt, aby to rozpocząć
demo mam zamiar udać się do
Compute Engine Console, więc zamierzam to zrobić
przejdź do menu nawigacji i jestem
przewiń w dół do silnika obliczeniowego
i tak oto jestem poproszony
aby utworzyć lub zaimportować instancję maszyny wirtualnej
jak również szybki start i tak dalej
nie zamierzam importować ani brać
szybki start, więc po prostu kliknę
na tworzeniu
i dlatego chcę tu poświęcić chwilę
skoncentruj się na menu po lewej stronie, gdzie tam jest
to kilka różnych opcji
utwórz dowolną instancję, więc pierwszą
a domyślna opcja pozwala mi tworzyć
instancję od podstaw wybierając
nowa instancja maszyny wirtualnej z opcji szablonu
pozwala mi utworzyć nową instancję z
szablon instancji i ponieważ ja tego nie robię
mam jakieś szablony instancji
monit tutaj z opcją tworzenia
jeden i tak dla tych z was, którzy są
nieznajomość szablonów instancji
szablony są używane w wystąpieniu zarządzanym
grupy i zdefiniuj właściwości instancji
gdy instancje są uruchamiane w ramach
tę zarządzaną grupę instancji, ale nie
martw się, zajmę się grupami instancji
i szablony błyskawiczne w późniejszej lekcji
następna dostępna opcja jest nowa
instancja vm z obrazu maszyny i
obraz jest klonem lub kopią
przykład i znowu będę osłaniał
to w osobnej lekcji i idziemy
przez wszystkie szczegóły maszyny
obrazy, ale gdybym miał jakąkolwiek maszynę
obrazy, które mógłbym stworzyć
przykład stąd, ale ponieważ nie ja
pojawia się monit z opcją utworzenia pliku
nowy obraz maszyny teraz ostatnia opcja
to, co chciałem ci pokazać, to
rynek
i tak rynek istnieje
obrazy maszyn, które są wszystkim
wstępnie skonfigurowany z prawidłowym działaniem
systemu, jak również oprogramowania
towarzyszyć mu, więc na przykład, jeśli jestem
chce stworzyć vm z wordpress
instalacji na nim mogę po prostu przejść do
u góry do paska wyszukiwania wpisz
wordpress i ja zostaną przedstawione
wiele różnych opcji i jestem po prostu
zamierzam wybrać ten tutaj na górze
i przedstawiono mi 49 wyników
maszyny wirtualne z różnymi typami
instalacje wordpress na nich i
to wszystko są różne przypadki
zostały skonfigurowane specjalnie dla
wordpress przez różne firmy, takie jak
Lightspeed analogowa innowacja i
cognosis inc i tak dalej
demonstrację, którą wybiorę
wordpress na centos 7
a tutaj przedstawiam przegląd nt
samo oprogramowanie jest mi również dane
informacje o firmie, która
skonfigurowałem to również na górze jestem
podano miesięczny szacunkowy koszt tego
konkretna instancja i jeśli przewinę w dół
strona, na której mogę uzyskać trochę więcej
informacje dotyczące tego zdjęcia
i jak pokazano tutaj po prawej stronie, widzę
moja cena opłata za użytkowanie będzie mnie kosztować
109 miesięcznie wraz z instancją vm
typu, dla którego oprogramowanie jest skonfigurowane
ilość miejsca na dysku i
zniżka na trwałe użytkowanie, w której też byłem
podano tutaj kilka linków do samouczków i
dokumentacja
i otrzymałem również instrukcje
za konserwację i wsparcie, w jakim byłem
otrzymał zarówno e-mail, jak i link do transmisji na żywo
wsparcie i oczywiście na dole my
mieć warunki korzystania z usługi i to jest
typowy pakiet oprogramowania spośród wielu
inne dostępne w google
rynek w chmurze, teraz mogę iść dalej i
uruchom to, jeśli wybiorę, ale zamierzam to zrobić
wybierz, aby tego nie uruchamiać i idę
wycofać się i po prostu dać ci trochę
kontekście w odniesieniu do przedsiębiorstwa
oprogramowanie
pakiety oprogramowania, takie jak f5 i jenkins
są również dostępne w chmurze Google
marketplace i ponownie, kiedy klikam
pierwsza opcja da mi mnóstwo
dostępnych opcji na jenkins i jego
dostępność z różnych firm na
różne platformy teraz tylko jako uwaga
aby zaktualizować istniejące wdrożenie aplikacji a
pakiet oprogramowania
musisz ponownie zainstalować oprogramowanie
pakiet z rynku, aby
zaktualizuj go, ale poza tym zastrzeżeniem
najłatwiejszy sposób na wdrożenie pakietu oprogramowania
jest zdecydowanie przez rynek
a więc teraz, kiedy przeszliśmy przez wszystko
różne opcje tworzenia
instancja, do której wrócę i wybiorę
nowa instancja maszyny wirtualnej, abym mógł utworzyć nową maszynę wirtualną
od zera i dlatego zostałem poproszony tutaj
u góry z notatką o tym informującą
istniała wersja robocza, z której została zapisana
kiedy zacząłem tworzyć w moim nowym
przykład, ale odszedłem od niego
i mam możliwość przywrócenia
konfiguracja, nad którą pracowałem i tak dalej
po prostu wiedz o tym, kiedy jesteś w środku
tworzenia instancji
Google Cloud automatycznie zapisze plik
szkic twojej kompilacji, abyś był w stanie
kontynuować pracę nad tym później teraz ja
naprawdę nie potrzebuję tego szkicu, ale będę
po prostu naciśnij przycisk przywracania
a dla nazwy mam zamiar ją zachować
instancja 1 i ze względu na to demo
Dodam etykietę
kluczem będzie środowisko i
wartość będzie testować, do którego zamierzam
zejdź na dół kliknij zapisz teraz
jeśli chodzi o położenie geograficzne
instancji przy użyciu regionów, które mogę
po prostu kliknij menu rozwijane, a ja to zrobię
mieć dostęp do wdrożenia tej instancji w
dowolny aktualnie dostępny region jako
regiony zostaną dodane, zostaną dodane
tutaj również, więc zamierzam to zachować
jak my wschodni
a pod strefą mam dostępność
umieszczenia go w dowolnej strefie w tym zakresie
region, więc zamierzam go zachować jako my
wschód 1b i tak jak inna nuta raz
wdrożyłeś instancję w
w określonym regionie nie będziesz w stanie
przenieś tę instancję do innego regionu
będziesz musiał odtworzyć go za pomocą
migawka w innym regionie i będę
omówię to teraz na późniejszej lekcji
przewijając w dół do konfiguracji maszyny
istnieją trzy różne rodzaje
rodziny, z których możesz wybierać, kiedy
chodzi o typy maszyn ogólne
w celu zoptymalizowania obliczeń i
pamięć zoptymalizowana ogólnego przeznaczenia
Rodzina maszyn ma świetne dostępne
wybór różnych typów serii, które
możesz wybierać i zwykle jest to
przejdź do rodziny maszyn, jeśli nie jesteś pewien
o tym, jaki typ maszyny wybrać
dla tego demo zamierzam zachować mój
wybór typu serii jako e2 i
pod typem maszyny dostaję bardzo
duży wybór różnych rozmiarów kiedy
chodzi o vcpu i pamięć, więc mogę
wybrać ze wspólnego rdzenia standard
wpisz wysoki typ pamięci lub wysoki procesor
wpisz, a ja omówię to w
więcej szczegółów w innej lekcji na temat
typy maszyn teraz w przypadku predefiniowanych
typy maszyn nie odpowiadają moim potrzebom
lub zakres ilości vcpus i
pamięć, której potrzebuję
wpaść między te predefiniowane maszyny
typy mogę po prostu wybrać niestandardowy
opcja, a to wywoła zestaw
suwaki
gdzie mogę wybrać oba
ilość vcpus i ilość pamięci
którego potrzebuję dla instancji, którą jestem
Tworzę teraz, gdy zmieniam kurs
suwak do więcej vcpus lub mniej my
stosunek liczby rdzeni do pamięci dla tej serii
pozostanie taki sam i dlatego mój
pamięć zostanie dostosowana automatycznie i
mają również możliwość zmiany
pamięć, jak uważam za stosowne, aby dodać więcej
pamięci lub usunąć ją i tak jest
idealne, gdy jesteś pomiędzy rozmiarami
i czegoś szukasz
specyficzne, które pasuje do twojego obciążenia pracą i tak dalej
zamierzam zmienić maszynę
wpisz do e2 micro
i jak widać w prawym górnym rogu
znajdę miesięczne oszacowanie, w jaki sposób
wiele instancja będzie mnie kosztować
i mogę kliknąć to menu rozwijane i to
przedstawi mi zestawienie kosztów
vcpu w pamięci koszt moich dysków jako
jak również moją zniżkę za przedłużone użytkowanie i jeśli
miałem inne zasoby, którymi byłem
zużywa jak statyczny adres IP lub dodatek
dołączony dysk, te koszty się pojawią
tutaj również, więc gdybym poszedł do
zoptymalizowany pod kątem obliczeń, możesz zobaczyć, jak
cena się zmieniła, ale dostaję
awaria, żebym wiedział dokładnie co
Płacę, więc zmienię
z powrotem do ogólnego przeznaczenia
i chciałem tutaj zwrócić uwagę na procesor
platformę i gpu, do których możesz dodać gpu
specyficzna konfiguracja maszyny i
więc jako kolejna uwaga
GPU można dodać tylko do maszyny n1
wpisz, ponieważ każdy inny typ pokaże gpu
zaznaczenie jako wyszarzone, a więc tutaj i
może dodać typ gpu, a także dodać
liczba procesorów graficznych, których potrzebuję, ale dla
ze względu na tę demonstrację nie jestem
dołożę jakieś gpu
i mam zamiar wybrać serię e2
i zmień go z powrotem na e2 micro scrolling
trochę niżej
jeśli chodzi o zależność od platformy procesora
na typie maszyny, który możesz wybrać
między intel lub amd, jeśli szukasz
dla konkretnego procesora, ale po prostu to wiedz
Twoja konfiguracja jest teraz stała
przesuwając się trochę w dół, będziesz
zobacz tutaj urządzenie wyświetlające teraz wyświetla
device to funkcja silnika obliczeniowego
który umożliwia dodanie wirtualnego wyświetlacza
do maszyny wirtualnej dla narzędzi do zarządzania systemem
oprogramowanie do zdalnego pulpitu i wszelkie inne
aplikacja, która wymaga połączenia
do urządzenia wyświetlającego na zdalnym serwerze
jest to szczególnie świetna funkcja
masz na wypadek, gdyby Twój serwer utknął
łatanie rozruchu lub awaria sprzętu i
nie możesz się zalogować, a sterowniki są
już uwzględnione dla obu okien i
linux vms ta funkcja działa z
domyślny sterownik vga zaraz po wyjęciu z pudełka
więc będę to sprawdzać
wyłączam, bo nie jest mi potrzebny i zamierzam
przejdź teraz do poufnej usługi vm
poufne przetwarzanie danych jest zabezpieczeniem
funkcja szyfrowania wrażliwego kodu i
dane, które są w pamięci, więc nawet wtedy, gdy są
podczas przetwarzania jest nadal zaszyfrowany
i jest świetnym przypadkiem użycia, gdy jesteś
radzenie sobie z bardzo wrażliwymi informacjami
wymaga to teraz surowych wymagań
Compute Engine również daje taką możliwość
rozmieszczenia na nim kontenerów i to
to świetny sposób na przetestowanie kontenerów
zamiast wdrażać całe kubernetes
klastra i może nawet wystarczyć
konkretne przypadki użycia, ale po prostu zauważ to
można wdrożyć tylko jeden kontener na maszynę wirtualną
przykład, a więc teraz, kiedy to omówiliśmy
większość ogólnej konfiguracji
opcje dla silnika obliczeniowego, które chciałem
poświęć chwilę na zapoznanie się z opcjami
które są dostępne dla dysku rozruchowego, więc jestem
iść dalej i kliknąć na zmianę
i tutaj mam możliwość wyboru
z wielu różnych obrazów publicznych
z różnymi systemami operacyjnymi, tj
mogę użyć do mojego dysku rozruchowego, więc gdybym chciał
aby załadować Ubuntu, mogę po prostu wybrać
ubuntu i ja możemy wybrać z każdego
inna dostępna wersja
jak również pokazano mi tutaj dysk rozruchowy
typ, który jest aktualnie wybrany jako
standardowy dysk trwały, ale ja też mam
możliwość wyboru albo a
zrównoważony dysk trwały lub ssd
trwały dysk i zamierzam go zatrzymać
jako standardowy dysk trwały i jeśli i
chciałem, abym mógł zwiększyć dysk rozruchowy
rozmiar, więc gdybym chciał 100 koncertów, mogę
po prostu dodaj go, a jeśli go wybiorę i ja
wróć do prawego górnego rogu
widzę, że moja cena za instancję
zmienił się teraz nie jestem obciążony za
system operacyjny, ponieważ jest otwarty
obraz źródłowy, ale za to płacę więcej
standardowy dysk trwały, ponieważ jestem
nie używam już 10 koncertów, ale używam
100 gigabajtów
teraz powiedzmy, że chciałem wrócić i ja
chciałem zmienić ten obraz na okno
obraz, do którego zejdę tutaj
serwer Windows i chcę wybrać
Windows Server 2016 zamierzam załadować
wersja data center i zamierzam
trzymaj przy sobie standardowy dysk stały
ze 100 gigabajtami mam zamiar wybrać
jeśli przewinę wstecz, zobaczę to
pobierana jest opłata licencyjna za system Windows
serwer i te obrazy z tymi
opłaty licencyjne są znane jako premium
obrazy, więc upewnij się, że tak
świadomy tych opłat licencyjnych, kiedy
uruchamiając swoje instancje i ponieważ ja
chcę zaoszczędzić na pieniądzach tylko na razie jestem
zamierzam przewinąć z powrotem do mojego buta
disk i zmień go z powrotem na ubuntu
i zamierzam zmienić rozmiar z powrotem
do 10 gigabajtów również przed tobą
przejdź dalej, chciałem dotknąć niestandardowego
obrazy, a więc gdybym miał jakieś niestandardowe
obrazy, które mógłbym zobaczyć tutaj i chciałbym
móc tworzyć instancje z my
niestandardowe obrazy przy użyciu tej metody ja również
mają możliwość utworzenia instancji
z migawki i ponieważ nie mam
nic się nie pojawia i na koniec mam
możliwość wykorzystania istniejących dysków tzw
powiedzmy na przykład, że miałem vm
instance i usunąłem go, ale ja
postanowił zachować dołączony dysk rozruchowy
pojawi się jako nieprzywiązany, a ja jestem
w stanie dołączyć to do nowej instancji
a więc teraz, kiedy pokazałem ci wszystko
dostępne opcje, jeśli chodzi o rozruch
dysk, który zamierzam wybrać
system operacyjny ubuntu i przejdź dalej
do następnej opcji tutaj mamy tożsamość
i dostęp do interfejsu API, przez który przeszliśmy
dogłębnie w poprzednim demo jako
cóż, mam opcję utworzenia pliku
reguły zapory automatycznie dla http i
Ruch https i jeśli chodzi o sieć jako
omówiliśmy to bardzo szczegółowo w ostatnim
Sekcja
pominę tę część
konfiguracji i po prostu uruchom go
domyślny vpc i tak samo szybko
zauważ, że chciałem ci przypomnieć, że o godz
na dole strony można znaleźć
skrót wiersza poleceń i kliknięcie
na nim da ci gcloud
polecenie do uruchomienia, którego możesz użyć w kolejności
stworzyć twoją instancję i tak chcę
wdrożyć to tak, jak jest, więc zamierzam kliknąć
tutaj na zamknięciu i mam zamiar kliknąć
tworzyć
i tak po prostu dam
minutę, więc instancja może być
utworzone i zajęło to kilka sekund, ale
instancja jest tworzona i to jest
uważana za stronę inwentarza do wyświetlenia
swój inwentarz instancji i wyszukać
wszelkie korelujące informacje na temat któregokolwiek z nich
twoje instancje i tak prawdopodobnie
wygląda znajomo z poprzedniego
instancje, które uruchomiłeś, więc tutaj
mamy nazwę instancji
strefa
wewnętrzny ip wraz z zewnętrznym
ip i wybór, aby połączyć się z
instancja, jak również dostaję również
opcja połączenia z tą instancją w
różne sposoby masz również opcję
dodawania większej ilości informacji o kolumnach
pulpit nawigacyjny inwentarza w odniesieniu do
Twoja instancja
i możesz to zrobić, po prostu klikając
na przycisku kolumn tutaj powyżej
listę instancji i możesz wybrać
od czasu stworzenia
stan zachowania typu maszyny, a nawet
sieci, a to może przynieść ci więcej
wgląd w informacje dostępne dla
ta instancja lub nawet grupa
instancje o typowych konfiguracjach
to również pomoże ci zidentyfikować twoje
instancje wizualnie w konsoli i tak dalej
Po prostu włożę kolumny z powrotem
Do
dokładnie, co to było
więc teraz chcę poświęcić chwilę
zanurz się bezpośrednio w instancji i uzyskaj
spójrz na szczegóły instancji, tak jak Ty
pamiętaj, że wybraliśmy typ maszyny
e2 micro, który ma dwa vcpus i jeden
gigabajt pamięci tutaj mamy
identyfikator instancji, a także przewijanie w dół we
mieć platformę procesora, którą mamy
urządzenie wyświetlające, o którym wspominałem
wcześniej wraz ze strefą etykiety
czas utworzenia, jak również sieć
interfejs i przewijanie w dół, które widzę
tutaj dysk rozruchowy z obrazem ubuntu
a także nazwę dysku rozruchowego tzw
jest sporo konfiguracji
tutaj i jeśli kliknę edytuj, mogę edytować
niektóre z tych konfiguracji w locie
a przy niektórych konfiguracjach muszę
zatrzymaj instancję przed ich edycją
i jest kilka konfiguracji, takich jak
interfejs sieciowy, w którym bym to zrobił
aby usunąć instancję
odtworzyć go na przykład, gdybym chciał
aby zmienić typ maszyny, którego potrzebuję
zatrzymaj instancję, aby ją zmienić
i to samo dotyczy mojego wyświetlacza
urządzenie, jak również interfejs sieciowy w
kazać mi zmienić go z jego
bieżąca sieć lub podsieć, do której się wybieram
aby zatrzymać instancję
też to zmień i mam taką nadzieję
ogólny opis konfiguracji pliku
przykład dał ci poczucie tego, co
można skonfigurować podczas uruchamiania
i pozwoliły ci uzyskać pewien wgląd w temat
edytowanie funkcji instancji po
uruchom wiele z tego, co tu widziałeś
to demo pojawi się na egzaminie i
więc polecam to przed wyjazdem
na egzamin, żeby spędzić trochę czasu
uruchamianie instancji, wiedząc dokładnie, jak to zrobić
będą się zachowywać i co można edytować
po utworzeniu, które można wykonać na
fly edycje, które wymagają instancji
zamknij i edytuj, które wymagają
instancja do odtworzenia i tak to jest
prawie wszystko, co chciałem omówić, kiedy
chodzi o tworzenie instancji, więc ty
może teraz oznaczyć to jako ukończone i chodźmy
przejść do następnego
witam z powrotem teraz w tej lekcji jestem
będziemy omawiać silnik obliczeniowy
typy maszyn teraz typem maszyny jest a
zestaw zwirtualizowanych zasobów sprzętowych
który jest dostępny dla instancji maszyny wirtualnej
w tym rozmiar pamięci systemowej
liczba procesorów wirtualnych
i dyski trwałe w silniku obliczeniowym
typy maszyn są pogrupowane i wybrane według
rodziny dla różnych obciążeń ty
zawsze musi wybrać typ maszyny, kiedy
tworzysz instancję i możesz
wybrać z kilku predefiniowanych
typy maszyn w każdym typie maszyny
rodzina, jeśli predefiniowane typy maszyn
nie spełnia twoich potrzeb, to możesz
tworzyć własne niestandardowe typy maszyn w
tę lekcję przejdę przez wszystko
różne typy maszyn ich
rodziny i ich przypadki użycia
to powiedziawszy, zanurzmy się
teraz wyświetlana jest każda rodzina typów maszyn
tutaj obejmuje różne typy maszyn
każda rodzina jest kuratorem dla konkretnego
typy obciążeń następujące podstawowe
typy maszyn są oferowane na komputerze
silnik, który jest obliczeniami ogólnego przeznaczenia
zoptymalizowany i zoptymalizowany pod kątem pamięci, więc ja
chciał przejść przez każdy z nich
rodziny w trochę szczegółach teraz
przed nurkowaniem w nim
definiowanie, jakiego typu maszyną jesteś
bieganie może być dla niektórych przytłaczające
ale można je podzielić, aby je zrozumieć
nieco lepiej, że są podzielone
trzy części i oddzielone myślnikami
pierwsza część tego przykładu pokazana tutaj
jest serią, więc dla tego przykładu
seria to e2, a liczba po
litera jest typem generacji w tym
przypadku byłaby to druga generacja
teraz seria jest w wielu różnych
odmian i każda jest przeznaczona dla
określone obciążenia przechodzą teraz do
to jest środkowa część typu maszyny
rzeczywisty typ i typy również mogą
są w wielu różnych smakach i
zwykle łączy się z konkretną
series, więc w tym przykładzie typ tutaj
jest standardem, więc przechodzimy do
to jest trzecia część typu maszyny
ilość użycia vcp
w typie maszyny i tak z vcpus
mogą być oferowane w dowolnym miejscu z jednego
vcpu do 416 vcpus i tak dla
pokazany tutaj przykład ma ten typ maszyny
32 vcpus, więc jest jeszcze jeden aspekt
typu maszynowego
który to gpu
ale należy pamiętać, że gpus są tylko
dostępne dla serii n1 i tak dalej
łącząc serię typu i
vcpu
otrzymasz swój typ maszyny i tak dalej
teraz, kiedy zepsuliśmy maszynę
typów w celu ich właściwego zdefiniowania
Chciałem dostać się do predefiniowanych
rodziny typów maszyn
konkretnie zaczynając od
predefiniowany typ maszyny ogólnego przeznaczenia
i cała maszyna ogólnego przeznaczenia
typy są dostępne w typie standardowym
wysoki typ pamięci i wysoki procesor
wpisz więc typ standardowy
to równowaga procesora i pamięci oraz
jest to najczęstszy cel ogólny
pojawia się również typ maszyny ogólnego przeznaczenia
w wysokiej pamięci i jest to wysoka pamięć
do współczynnika procesora, więc bardzo wysoka pamięć jest niższa
procesor
i wreszcie mamy maszynę o wysokim procesorze
type i jest to wysoki procesor do pamięci
stosunek, więc byłoby to przeciwieństwo
wysoka pamięć, więc bardzo wysoki procesor
niższa pamięć, więc teraz zagłębiam się w
rodzina maszyn ogólnego przeznaczenia, którą chciałem
zacząć od serii e2 i tego
jest przeznaczony do codziennej pracy na komputerze
niski koszt, więc jeśli chcesz to zrobić
takie jak udostępnianie sieci
obsługa aplikacji
aplikacje zaplecza
mikroserwisy małych i średnich baz danych
wirtualne pulpity, a nawet programowanie
środowiskach, w których obsługiwałaby seria e2
cel doskonale
teraz typy maszyn e2 są drogie
zoptymalizowane typy maszyn, które oferują
rozmiar od 2 do 32 vcpus i pół a
gigabajt do 128 gigabajtów pamięci tzw
małe i średnie obciążenia, które tego nie robią
wymagają jak największej liczby vcpus i aplikacji
które nie wymagają lokalnych dysków ssd ani gpus
idealnie pasują do maszyn e2 e2
typy maszyn nie zapewniają trwałego użytkowania
zniżki jednak zapewniają
konsekwentnie
niskie ceny za użytkowanie na żądanie i zaangażowanie
innymi słowy oferują najniższe
ustalanie cen na żądanie w ramach ogólnych
typy maszyn celu, jak również e2
maszyny seryjne są dostępne w obu
wstępnie zdefiniowane i niestandardowe typy maszyn
Idąc dalej, chciałem dotknąć wszystkich
typów maszyn dostępnych w serii n
i są to zrównoważone typy maszyn
z ceną i wydajnością w szerokim zakresie
zakres smaków vm i tych maszyn
są przeznaczone do aplikacji serwerów WWW
serwery, aplikacje back office
do dużych baz danych, jak również do buforowania
i strumieniowego przesyłania multimediów i są one oferowane
w standardzie high memory i high cpu
typy
teraz typy maszyn n1 są obliczeniowe
silniki pierwszej generacji ogólnego przeznaczenia
typy maszyn teraz ten typ maszyny
oferuje do 96 procesorów wirtualnych i 624 gigabajtów
pamięci i znowu, jak wspomniałem
wcześniej jest to jedyny typ maszyny
który oferuje zarówno obsługę gpu, jak i tpu
wsparcie typu n1 jest dostępne jako oba
wstępnie zdefiniowane typy maszyn i niestandardowe
typów maszyn, a seria n1 oferuje m.in
większy rabat za trwałe użytkowanie niż n2
typy maszyn, o których mowa
typy maszyn n2 są drugie
generacja typów maszyn ogólnego przeznaczenia
a te oferują elastyczne rozmiary pomiędzy
dwa 280 vcpus i pół gigabajta
pamięci do 640 gigabajtów pamięci i
te typy maszyn oferują również
ogólna poprawa wydajności w stosunku do
n1 typów maszyn, które mogą przyjąć obciążenia robocze
zaletą wyższej częstotliwości taktowania
procesora
są dobrym wyborem dla typów maszyn n2
a te obciążenia mogą wzrosnąć na
wydajność gwintu przy jednoczesnym korzystaniu z
całą elastyczność generała
oferty typu maszyny celu i dwa
typy maszyn oferują również rozszerzone
funkcja pamięci, a to pomaga kontrolować
obecnie koszty licencji na oprogramowanie na procesor
wsiadanie do ostatniej maszyny serii n
type typ maszyny n2d jest największy
Typ maszyny ogólnego przeznaczenia z maks
224 vcpus i
896 gigabajtów pamięci tej maszyny
typ jest dostępny w predefiniowanych i
niestandardowe typy maszyn i ta maszyna
typ ma również rozszerzoną pamięć
funkcja, którą omówiłem wcześniej
pomaga uniknąć oprogramowania na procesor
licencjonowania obsługiwanego przez typ maszyny n2d
zadeklarowane użycie i trwałe użytkowanie
rabaty teraz przechodzą od ogólnych
rodzina typów maszyn, którą chciałem
przejdź do maszyny do optymalizacji obliczeń
rodzina teraz ta seria
oferuje ultra wysoką wydajność dla
obliczać intensywne obciążenia, takie jak wysokie
obliczenia wydajnościowe
automatyzacja projektowania elektronicznego
gier i aplikacji jednowątkowych
więc wszystko, co jest przeznaczone do obliczeń
intensywne obciążenia, to na pewno
być najlepszym wyborem
teraz oblicz maszynę zoptymalizowaną pod kątem silnika
typy są idealne, jak powiedziałem wcześniej
oblicz intensywne obciążenia i te
typy maszyn oferują najwyższą
wydajność na rdzeń
na silniku obliczeniowym zoptymalizowanym pod kątem obliczeń
typy są dostępne tylko jako predefiniowane
typów maszyn i tak nie jest
dostępne dla dowolnych niestandardowych typów maszyn
Typy maszyn c2 oferują maksimum
60 vcpus i maksymalnie 240 gigabajtów
pamięci teraz, chociaż maszyna c2
type działa świetnie w przypadku intensywnych obliczeń
obciążeń roboczych wiąże się z pewnymi zastrzeżeniami
więc nie możesz używać regionalnych
dyski trwałe ze zoptymalizowanymi obliczeniami
typy maszyn i będę się do nich odnosił
szczegóły dotyczące dysków trwałych w pliku a
późniejsza lekcja i są one dostępne tylko
w wybranych strefach i regionach na wybrane
platformy procesorów, więc teraz przechodzimy do
ostatnia rodzina to optymalizacja pamięci
rodzina maszyn, a to dla ultra
ta rodzina jest obciążona dużymi obciążeniami pamięci
przeznaczony do dużych baz danych w pamięci
jak sap hana, jak również w pamięci
analityka
teraz seria m jest dostępna w dwóch osobnych wersjach
pokolenia
m1 i m2 m1 oferuje maksimum
160 vcpus i maksymalna pamięć
3844 gigabajtów natomiast oferta m2
znowu maksymalnie 160 vcpus ale
oferując solidną 11
776 gigabajtów maksymalnej pamięci i jako i
powiedział przed tymi typami maszyn, że są
idealny do zadań wymagających intensywnej pracy
wykorzystanie pamięci, więc są odpowiednie
bazy danych w pamięci i w pamięci
obciążenia hurtowni danych analitycznych
analiza genomiki i analiza sql
typy maszyn zoptymalizowane pod kątem pamięci usług
są dostępne tylko jako wstępnie zdefiniowana maszyna
typy i zastrzeżenia tutaj to ty
nie może używać regionalnych dysków trwałych
z typami maszyn zoptymalizowanymi pod kątem pamięci, takimi jak
Cóż, są dostępne tylko w określonych
strefy, którym teraz chciałem poświęcić chwilę
Wróć
do maszyny ogólnego przeznaczenia typu tzw
że mogę kopać we wspólnym przewodzie
typu maszyny i jest to rozpowszechniane wśród
serie e2 i n1 oraz te wspólne
używane są podstawowe typy maszyn
obciążenia awaryjne są bardzo kosztowne
skuteczne, jak również są świetne
aplikacje niewymagające dużej ilości zasobów
współdzielone podstawowe typy maszyn używają kontekstu
przełączanie w celu współdzielenia fizycznego rdzenia
między vcpus w celu
wielozadaniowość inny współdzielony rdzeń
typy maszyn wytrzymują różne ilości
czasu na fizyczny rdzeń, który pozwala
Google Cloud, aby ogólnie obniżyć cenę
udostępnianie instancji podstawowych może wiązać się z większymi kosztami
skuteczny do biegania na małą skalę
aplikacje niewymagające dużej ilości zasobów niż
standardowa maszyna o dużej pamięci lub dużej mocy procesora
typy teraz, jeśli chodzi o pękanie procesora
oferują te współdzielone podstawowe typy maszyn
możliwości pękania, które pozwalają
instancje, aby użyć dodatkowego procesora fizycznego
na krótkie okresy rozrywania
dzieje się automatycznie, gdy twoja instancja
wymaga więcej fizycznego procesora niż
pierwotnie przydzielone podczas tych skoków
Twoja instancja skorzysta
dostępny procesor fizyczny w seriach i
Oferowany jest typ maszyny ze współdzielonym rdzeniem e2
w mikro małych i średnich, podczas gdy n1
Seria jest oferowana w f1 micro i
g1 mały i obie te serie
mieć maksymalnie dwa vcpus z
teraz maksymalnie cztery gigabajty pamięci
chciałem poświęcić chwilę na dotknięcie
niestandardowe typy maszyn i to są
dostępne w dowolnym celu ogólnym
maszyna, więc jest to zdefiniowane przez klienta
Procesor i pamięć zaprojektowane na zamówienie
obciążenia pracą
teraz, jeśli żaden z ogólnego celu
predefiniowane typy maszyn spełniają Twoje wymagania
wymagania
możesz utworzyć niestandardowy typ maszyny
z określoną liczbą vcpus i
ilość pamięci potrzebnej do
na przykład te typy maszyn są idealne
dla obciążeń, które nie są dobrze dopasowane
dla predefiniowanych typów maszyn, które
są dostępne, dla których są również świetne
gdy potrzebujesz więcej pamięci lub więcej procesora
ale predefiniowane typy maszyn nie
całkiem pasuje dokładnie do tego, czego potrzebujesz
obciążenie pracą, tak jak uwaga, że ​​to kosztuje
nieco więcej, aby użyć niestandardowej maszyny
typ niż predefiniowany typ maszyny i
są ograniczenia ilościowe
memory i vcpu możesz wybrać i jako i
podano wcześniej podczas tworzenia niestandardowego
Typ maszyny, który możesz wybrać z e2
n2
oraz typy maszyn 2d i n1, a więc
ostatnią częścią, którą chciałem poruszyć, są
gpus, które są dostępne, a to są
zaprojektowany z myślą o intensywnych grafikach
obciążenia i ponownie są dostępne tylko
dla typu maszyny n1 i gpu wchodzą
pięć różnych smaków od nvidii
pokazując tutaj jako teslę k80 teslę
p4 tesla t4 tesla v100 i
tesla p100 i tak to wszystko
rodziny i typy maszyn, które są
dostępne dla Ciebie w chmurze Google i
pozwoli ci być trochę więcej
elastyczny z rodzajem obciążenia pracą
potrzebujesz ich do i tak na egzamin
nie będziesz musiał zapamiętywać każdej maszyny
wpisz, ale musisz znać an
przegląd tego, co robi każdy typ maszyny
Teraz wiem, że było dużo teorii
przedstawione tutaj w tej lekcji, ale mam nadzieję
to daje ci lepsze
zrozumienia wszystkich dostępnych
predefiniowane typy maszyn w google
cloud i to właściwie wszystko
chciałem omówić w tej lekcji
obliczyć typy maszyn z silnikami, abyś mógł
teraz zaznacz tę lekcję jako ukończoną i
przejdźmy do następnego
[Muzyka]
witam ponownie na tej lekcji, na którą idę
przeglądaj teraz zarządzanie swoimi instancjami
sposób zarządzania instancjami jest duży
temat na egzaminie
jak również jest to bardzo przydatne wiedzieć
swoją pracę jako inżynier chmury w
środowisk, za które jesteś odpowiedzialny
znając obie cechy, które są
dostępne, jak również najlepsze praktyki
pozwoli Ci podejmować lepsze decyzje
w odniesieniu do twoich instancji i pozwól
dbasz o zdrowe środowisko
ta lekcja będzie zagłębiać się w wiele
funkcje, które są dostępne w celu
lepiej zarządzaj swoimi instancjami za pomocą
określone funkcje w chmurze Google, tzw
powiedziawszy to, zanurzmy się
teraz chciałem rozpocząć tę lekcję
omawianie cyklu życia instancji
w chmurze Google każda instancja ma plik
z góry określony cykl życia od momentu jego rozpoczęcia
stan udostępniania do jego usunięcia an
instancja może przechodzić przez wiele
stany natychmiastowe jako część jego cyklu życia
kiedy po raz pierwszy tworzysz instancję
zasobów udostępnianych przez silnik obliczeniowy
uruchom instancję obok instancji
przechodzi do inscenizacji, gdzie przygotowuje
najpierw uruchamia się, a potem w końcu się uruchamia
i jest uważany za bieg podczas jego trwania
czas życia uruchomionej instancji
wielokrotnie zatrzymywany i uruchamiany ponownie lub
zawieszone i wznowione, więc teraz chciałem
poświęcić kilka minut na przejście
cykl życia instancji w szczegółach
zaczynając od stanu udostępniania
teraz to jest miejsce, w którym znajdują się zasoby
przydzielone dla instancji instancja
nie jest jeszcze uruchomiony, a instancja jest
przydzielono jej żądaną kwotę w wysokości
procesor i pamięć wraz z dyskiem głównym
dołączone dodatkowe dyski
do tego, a także kilka dodatkowych
zestawy funkcji, które są do tego przypisane
przypadku i jeśli chodzi o koszty
będąc w stanie udostępniania
nie są ponoszone żadne koszty
przechodząc prosto do stanu przejściowego
po zakończeniu stanu aprowizacji
cykl życia trwa z
stan przejściowy i oto gdzie
środki zostały pozyskane i
instancja jest przygotowywana jako pierwsza
rozruchowe są zarówno wewnętrzne, jak i zewnętrzne adresy IP
przydzielony i może być statyczny lub
efemeryczny w obrazie systemu, który był
pierwotnie wybrany dla tej instancji
służy do uruchamiania instancji i tego
może być obrazem publicznym lub niestandardowym
koszty wizerunku w państwie nadal nie są
poniesione, ponieważ instancja nadal znajduje się w
stan przed uruchomieniem
teraz, gdy instancja opuści etap przejściowy
przejdzie do stanu pracy i
w tym miejscu uruchamia się instancja
lub uruchomiony i powinien umożliwiać logowanie
do instancji za pomocą ssh lub
rdp w krótkim okresie oczekiwania ze względu na
żadnych skryptów startowych ani żadnego rozruchu
zadania konserwacyjne dla obsługi
system teraz, gdy jesteś uruchomiony
może zresetować twoją instancję i to jest
gdzie chcesz wyczyścić zawartość pamięci
instancji vm i zresetuj virtual
resetowanie maszyny do stanu początkowego
instancja
powoduje natychmiastowy twardy reset maszyny wirtualnej
i dlatego vm nie robi a
wdzięczne zamknięcie dla gościa
jednak system operacyjny
maszyna wirtualna zachowuje wszystkie dane dysku trwałego
i żadna z właściwości instancji
zmienić instancję pozostaje uruchomiona
stan poprzez reset teraz również w
stanie roboczym może nastąpić naprawa
z powodu napotkania przez instancję pliku
błąd wewnętrzny lub maszyna bazowa
jest niedostępny z powodu prac konserwacyjnych w trakcie
tym razem instancja jest bezużyteczna i
jeśli naprawa zakończy się pomyślnie instancja
powraca do stanu uruchomionego, płacąc
uwagę na koszty
w tym stanie rozpoczyna się instancja
do ich wystąpienia i jest związany z
zasoby przypisane do instancji, takie jak
procesor i pamięć wszelkie statyczne ips i
wszystkie dyski dołączone do
przykład i wchodzę w to trochę
szczegółów w trochę w odniesieniu do
ten stan
i ostatecznie kończymy cykl życia z
zatrzymanie zawieszone i zakończone
stany teraz, kiedy zawieszasz an
na przykład jest to jak zamknięcie pokrywy
twój laptop zawiesi instancję
zachować system operacyjny gościa
stan pamięci i aplikacji
instancja, w przeciwnym razie zostanie odrzucona
iz tego stanu możesz wybrać
wznowić lub usunąć, gdy się pojawi
dochodzi do zatrzymania wykonanego przez użytkownika
żądanie zatrzymania instancji lub tam
była porażką, a to jest tymczasowe
status, a instancja zostanie przeniesiona do
zakończony dotykając kosztów tylko za
sekunda przy zawieszaniu lub zatrzymywaniu
na przykład płacisz za zasoby, które są
nadal dołączony do instancji vm
takie jak statyczne adresy IP i dysk trwały
danych nie ponosisz kosztów
działająca efemeryczna zewnętrzna instancja vm
adresy ip są zwalniane z
instancja i zostanie przypisana nowa
kiedy instancja jest teraz uruchamiana, kiedy it
dochodzi do zatrzymania zawieszenia lub
resetując instancję, którą możesz zatrzymać lub
zawiesić instancję, jeśli już nie
potrzebujesz go, ale chcesz zachować instancję
wokół do wykorzystania w przyszłości silnika obliczeniowego
czeka, aż gość zakończy zamykanie
w dół, a następnie przenosi instancję
do stanu zakończonego, więc dotykając
stan zakończony, w którym a
użytkownik albo zamyka instancję, albo
instancja napotka awarię
może wybrać ponowne uruchomienie instancji lub
usuń go, a także przytrzymaj reset
opcje w ramach polityki dostępności
w tym stanie nadal płacisz za statyczne
IP i dyski
ale jak zawieszenie lub zatrzymanie
oświadcz, że nie płacisz za procesor i
zasoby pamięci przydzielone do
instancja
a więc obejmuje to ogólny przegląd
cyklu życia instancji w google
chmura i wszystkie stany, które ją tworzą
ten cykl życia teraz, aby dostać się do niektórych
szczegółowe informacje dotyczące niektórych zestawów funkcji
dla silnika obliczeniowego, do którego chciałem wrócić
stany, w których te funkcje mają zastosowanie
teraz, gdy tworzysz swoją instancję
możliwość korzystania z ekranowanych maszyn wirtualnych dla
dodatkowe bezpieczeństwo i podczas korzystania z nich
instancja utworzyłaby ich instancję jako
instancja uruchamia się i wchodzi do pliku
stan biegu
więc czym dokładnie jest ekranowana maszyna wirtualna
dobrze ekranowana oferta vms możliwa do zweryfikowania
integralność maszyny obliczeniowej vm
instancjach, dzięki czemu możesz mieć pewność, że twój
instancje nie zostały naruszone przez
złośliwe oprogramowanie lub rootkity na poziomie rozruchu lub jądra
i osiąga się to w czterech krokach
proces
który jest objęty bezpiecznym rozruchem wirtualnym
zaufany moduł platformy znany również jako
vtpm mierzy uruchomiony rozruch
vtpm i monitorowanie integralności, więc i
chciałem zagłębić się w to tylko na sekundę
aby dać ci trochę więcej kontekstu
teraz proces rozruchu dla ekranowanych maszyn wirtualnych
zacznij od bezpiecznego rozruchu i to pomaga
upewnić się, że system tylko działa
autentycznego oprogramowania poprzez weryfikację
podpis cyfrowy dla wszystkich rozruchów
komponenty i zatrzymanie procesu rozruchu
jeśli weryfikacja podpisu nie powiedzie się
ekranowane instancje maszyny wirtualnej uruchamiają oprogramowanie układowe
to jest podpisane i zweryfikowane przy użyciu
urząd certyfikacji Google i nie tylko
przy każdym rozruchu dowolny składnik rozruchowy
który nie jest prawidłowo podpisany lub nie jest
podpisany w ogóle nie może działać i
więc przy pierwszym uruchomieniu instancji vm
pomiar rozruchu tworzy integralność
punkt odniesienia polityki z pierwszego zestawu
te pomiary, a następnie bezpiecznie
przechowuje te dane za każdym razem, gdy vm
instancja uruchamia po tym te
pomiary są wykonywane ponownie i zapisywane
w bezpiecznej pamięci do następnego ponownego uruchomienia
mając te dwa zestawy pomiarów
umożliwia monitorowanie integralności, które jest
następny krok i pozwala mu określić
jeśli nastąpiły zmiany w pliku vm
sekwencję rozruchową instancji i te zasady
jest ładowany do zwirtualizowanego zaufanego
moduł platformy ponownie znany jako vtpm
w skrócie, który jest wyspecjalizowany
chip komputerowy, którego możesz użyć
chronić przedmioty, takie jak klucze i
certyfikaty, których używasz
uwierzytelnić dostęp do systemu za pomocą
ekranowany vms vtpm umożliwia rozruch mierzony
wykonując niezbędne pomiary
utwórz znaną dobrą linię bazową rozruchu i
nazywa się to polityką integralności
punkt odniesienia punkt odniesienia polityki integralności
służy do porównania
z pomiarami z kolejnych vm
buty, aby ustalić, czy coś ma
na którym opiera się monitorowanie zmienionej integralności
pomiary tworzone przez mierzone
boot dla obu zasad integralności
linia bazowa i najnowszy rozruch
porównanie monitorowania integralności sekwencji
najnowsze pomiary butów
do linii bazowej polityki uczciwości i
zwraca parę wyników pomyślnych lub nieudanych
w zależności od tego, czy pasują, czy nie
jeden dla wczesnej sekwencji startowej i jeden
dla późnej sekwencji rozruchowej i tak dalej
podsumowanie w ten sposób pomagają ekranowane maszyny wirtualne
zapobiegać eksfiltracji danych, tak wzruszająca
teraz w stanie uruchomionym podczas uruchamiania
instancja VM przy użyciu dostarczonego przez Google
obrazy publiczne, jakim jest środowisko gościa
automatycznie instalowany na maszynie wirtualnej
instancja środowiska gościa jest zbiorem
demony skryptów i pliki binarne, które czytają
zawartość serwera metadanych do
sprawić, by maszyna wirtualna działała poprawnie
Compute Engine serwerem metadanych jest
kanał komunikacyjny do przesyłania
informacje od klienta do gościa
utworzone instancje maszyny wirtualnej systemu operacyjnego
korzystając z udostępnionych przez Google obrazów publicznych
obejmują środowisko gościa, tj
instalowany domyślnie, tworząc vm
instancje
użycie niestandardowego obrazu będzie tego wymagać
ręcznie zainstaluj środowisko gościa
to środowisko gościa jest dostępne
zarówno Linux, jak i Windows i każdy z nich
obsługiwany system operacyjny, tj
dostępne w Compute Engine wymaga
określone pakiety środowiska gościnnego
Google lub właściciel
system operacyjny buduje te pakiety
teraz, jeśli chodzi o gościa Linuksa
środowisko jest albo zbudowane przez Google
lub właściciela systemu operacyjnego
i jest kilka kluczowych elementów
mają zastosowanie do wszystkich kompilacji, które mogą
znaleźć w linku, który mam
zawarte w tekście lekcji podstawa
komponenty środowiska gościa linuxa
to pakiet Pythona, który zawiera
demony skryptów i pakiety dla
obsługiwane dystrybucje Linuksa, gdy to
przychodzi do systemu Windows podobne podejście
obowiązuje w przypadku dostępności pakietu
z głównymi skryptami i plikami binarnymi jako częścią
tego gościnnego środowiska
teraz wracając do serwera metadanych
silnik obliczeniowy zapewnia metodę dla
przechowywanie i pobieranie metadanych w formacie
postaci serwera metadanych tej usługi
zapewnia centralny punkt do ustawiania metadanych
w postaci par klucz-wartość, tj
następnie dostarczane do maszyn wirtualnych w
runtime i możesz zapytać o te metadane
serwer programowo z poziomu
instancji i z interfejsu API silnika obliczeniowego
jest to świetne do użytku z uruchamianiem i
skrypty zamykające lub uzyskać więcej informacji
z metadanymi Twojej instancji może być
przypisane do projektów, jak również
instancje i metadane projektu
propaguje się do wszystkich instancji w ramach
projekt, podczas gdy tylko metadane instancji
wpływa na tę instancję i masz do niej dostęp
metadane przy użyciu następującego adresu URL
za pomocą polecenia curl, które widzisz tutaj
na ekranie, więc jeśli szukasz
metadane dla projektu, którego chcesz użyć
pierwszy adres URL, który kończy się na project i for
wszelkie metadane instancji, których możesz użyć
drugi adres URL, który kończy się teraz instancją
należy o tym pamiętać, składając wniosek
aby uzyskać informacje z metadanych
serwer żądania i kolejnych
odpowiedź metadanych nigdy nie opuszcza
fizyczny host z uruchomionym wirtualnym
instancja maszyny teraz po instancji
uruchomił się i przeszedł przez
skrypty startowe, które będziesz mieć
możliwość zalogowania się do Twojej instancji za pomocą
ssh lub rdp teraz jest kilka różnych
metody, których można użyć do połączenia i
uzyskać dostęp zarówno do instancji Linuksa, jak i
Twoje instancje Windows, którymi będę
przejść
teraz, jeśli chodzi o instancje Linuksa
dostęp już przeszliśmy
tego typu przypadki w poprzednich
lekcje i pokazy, ale tylko jako
odświeżacz, z którym zazwyczaj się łączysz
twoja instancja VM przez dostęp ssh na porcie
22. pamiętaj, że będziesz potrzebować
reguły zapory sieciowej, tak jak to zrobiliśmy w
poprzednie wersje demonstracyjne, aby umożliwić ten dostęp i
możesz połączyć się z instancjami Linuksa
przez Google Cloud Console lub
powłoka w chmurze przy użyciu zestawu SDK w chmurze teraz i
wiedz, że użycie kluczy ssh jest
defacto, jeśli chodzi o logowanie
instancje linux teraz w większości scenariuszy na
google cloud google zaleca używanie os
zaloguj się za pomocą kluczy ssh podczas logowania do systemu operacyjnego
Funkcja umożliwia korzystanie z oprogramowania Compute Engine IAM
role do zarządzania dostępem ssh do systemu Linux
instancjach, a następnie, jeśli chcesz, możesz
dodać dodatkową warstwę bezpieczeństwa przez
konfigurowanie logowania do systemu operacyjnego za pomocą dwuetapowego
weryfikacja i zarządzanie dostępem w
poziom organizacji poprzez założenie
zasady organizacyjne dotyczące logowania
upraszcza zarządzanie dostępem ssh przez
łączenie konta użytkownika systemu Linux z kontem
administratorzy tożsamości Google mogą
łatwo zarządzaj dostępem do instancji
na poziomie instancji lub projektu
ustawiając teraz uprawnienia iam, jeśli jesteś
prowadzenie własnej usługi katalogowej dla
zarządzanie dostępem lub nie można skonfigurować
os, możesz ręcznie zarządzać ssh
klucze i lokalne konta użytkowników w metadanych
ręcznie tworząc klucze ssh i
edytuję teraz publiczne metadane klucza ssh
jeśli chodzi o instancje systemu Windows ty
zwykle łączyłby się z twoją maszyną wirtualną
instancja za pośrednictwem dostępu rdp na porcie 3389 i
pamiętaj, że będziesz również potrzebować a
regułę zapory, jak pokazano tutaj, aby zezwolić
ten dostęp możesz połączyć ze swoim
instancje systemu Windows za pośrednictwem rdp
protokołu lub przez PowerShell
terminal teraz podczas logowania do systemu Windows
wymaga to ustawienia hasła do systemu Windows
i można to zrobić za pośrednictwem
konsoli lub narzędziu wiersza poleceń gcloud
a następnie po ustawieniu hasła
może wtedy zalogować się z zalecanego rdp
rozszerzenie chrome lub korzystanie z oprogramowania innej firmy
rdp i podam link do
to rozszerzenie rdp chrome w lekcji
tekst teraz po uruchomieniu instancji
a Twoja instancja jest gotowa do zalogowania
do ciebie zawsze masz możliwość
modyfikując swoją instancję i możesz to zrobić
go ręcznie, modyfikując go na
w locie lub możesz wziąć niezbędne
kroki, aby edytować instancję, na przykład i
pokazał ci w poprzedniej lekcji przez
zatrzymując go, edytując go, a następnie
ponowne uruchomienie, chociaż jeśli chodzi o
google musi przeprowadzać konserwację maszyny wirtualnej
lub po prostu chcesz przenieść swoją instancję
do innej strefy w tym samym regionie
to wszystko stało się możliwe bez
zamykanie Twojej instancji
przy użyciu funkcji zwanej migracją na żywo
teraz, jeśli chodzi o migrację na żywo
Compute Engine migruje twoje bieganie
instancji do innego hosta
w tej samej strefie zamiast wymagać
pozwala to na ponowne uruchomienie maszyn wirtualnych
google, aby niezawodnie przeprowadzać konserwację
bez przerywania żadnego z twoich vms
kiedy maszyna wirtualna ma być aktywna
migrowane Google wyświetla powiadomienie
gościowi, że nadchodzi migracja
wkrótce migracja na żywo zachowa Twoje instancje
działa podczas hostowania silnika obliczeniowego, który
potrzebują stałej infrastruktury
konserwacja i modernizacja wymiana
nieudana konfiguracja sprzętu i systemu
zmienia się, gdy Google przeprowadza migrację działającego
vm z jednego hosta na inny
przenosi cały stan instancji
od źródła do celu w a
sposób, który jest przejrzysty dla systemu-gościa
i każdy, kto się z nim komunikuje, google
daje również możliwość grania na żywo
migracja ręczna z jednej strefy do
inny w tym samym regionie
używając konsoli lub uruchamiając polecenie
linia, którą widzisz tutaj gcloud compute
instancje przenoszą nazwę maszyny wirtualnej za pomocą
flagę strefy i strefę, do której należy
obecnie w, a następnie miejsce docelowe
flagę strefy ze strefą, którą chciałeś
iść do i tylko jako notatkę z niektórymi
zastrzega instancje z dołączonym GPU
nie można przeprowadzić migracji na żywo i nie można
skonfiguruj aktywną instancję z możliwością wywłaszczania
migrate i taki jest cykl życia instancji
pełen różnych opcji i
zrozumienie ich może pomóc lepiej
koordynować przenoszenie edycji i naprawy
vm bez względu na to, gdzie mogą
leżeć w tym cyklu życia, teraz mam taką nadzieję
lekcja dała ci niezbędne
teorię, która pomoże lepiej wykorzystać
omówić zestawy funkcji i dać ci kilka
pomysłów, jak lepiej zarządzać swoimi
przypadkach teraz jest o wiele więcej
wiedzieć, niż to, co ci tu pokazałem
zarządzaj swoimi instancjami, ale wyświetlane są tematy
Oto, co pojawia się na egzaminie jako
Cóż, niektóre są naprawdę świetne na początek
punktów, aby rozpocząć zarządzanie instancjami
i to właściwie wszystko, czego chciałem
pokryć, jeśli chodzi o zarządzanie
instancje, abyś mógł teraz to zaznaczyć
lekcję jako zakończoną i dołącz do mnie
następny, w którym scementuję teorię
w tej lekcji z praktyczną demonstracją
[Muzyka]
witam z powrotem w tej demonstracji jestem
będzie cementować część teorii
których nauczyliśmy się na ostatniej lekcji
w odniesieniu do różnych metod logowania
dla instancji Windows i Linux, jak to zrobić
wdrożenie tych metod jest niezwykle
przydatne zarówno do egzaminu, jak i do
zarządzanie wieloma instancjami w różnych
środowisk, teraz jest wiele do omówienia
tutaj, więc powiedzmy, że nurkujemy
tak jak widzisz jestem tu zalogowany
pod Tony Bowtie Ace
gmail.com również jestem w projekcie
Bowtie Inc i tak pierwszą rzeczą, że ja
chcesz zrobić, to stworzyć zarówno linux
instancja i instancja systemu Windows i this
jest pokazanie różnych opcji
masz do logowania się do instancji
więc abym mógł to zrobić, potrzebuję
udać się do silnika obliczeniowego, więc jestem
przejść do menu nawigacji
i zamierzam przewinąć w dół, aby obliczyć
silnik i tak jak uwaga wcześniej
upewnij się, że tworzysz swoje instancje
że masz utworzony domyślny vpc
przed kontynuowaniem i tworzeniem tych
przypadkach, jeśli zapomniałeś, jak to zrobić
utwórz domyślny vpc, wróć do
sekcja usług sieciowych i
obejrzyj lekcję vpc dla odświeżenia i
więc pójdę dalej i stworzę swój
pierwsza instancja i zaczynam
z instancją Windows, więc idę
aby po prostu kliknąć opcję Utwórz
i tak dla nazwy tej instancji ty
można po prostu nazwać ten myślnik systemu Windows
instancja
i nie zamierzam dodawać żadnych etykiet i
dla regionu powinieneś nas wybrać
east1 i możesz zachować strefę jako
domyślnie dla nas wschód 1b i przewijanie
aż do konfiguracji maszyny dla
typ maszyny, który zamierzam zachować
jest tak, jak jest to instancja systemu Windows i jestem
będzie potrzebował trochę więcej mocy
przewijając w dół do dysku rozruchowego, którego potrzebujemy
zmień to z debiana na windows
więc po prostu kliknę na
przycisk zmiany i pod systemem operacyjnym
zamierzam kliknąć menu rozwijane i
wybierz serwer Windows dla wersji
Wybieram najnowszą wersję
serwera Windows, czyli Windows
server 2019 centrum danych i możesz je zachować
typ dysku rozruchowego i jego rozmiar
default i po prostu skieruj się w dół i
kliknij wybierz i wychodzimy
wszystko inne jako domyślne i
po prostu kliknij utwórz
i sukces, jaki odniosła nasza instancja Windows
zostały stworzone, a więc pierwszą rzeczą, która
chcesz zrobić, to chcesz ustawić
hasło systemu Windows dla tej instancji i
więc przejdę do RDP
przycisk i zamierzam kliknąć na
rozwijane i tutaj mam zamiar wybrać
ustaw hasło do systemu Windows i zaczynam
aby uzyskać wyskakujące okienko, aby ustawić nowe okna
hasło, którym była nazwa użytkownika
propagowane dla mnie jako tony muszki jestem
zostawię tak jak jest i tak zrobię
kliknij zestaw
i zostanę poproszony o nowy
hasło systemu Windows, które zostało ustawione dla
ja, więc skopiuję to i jestem
zamierzam wkleić to do mojego notatnika, niech tak będzie
koniecznie nagraj to gdzieś albo napisz
to w dół
lub skopiuj i wklej do edytora tekstu
według twojego wyboru, kliknę
blisko, więc teraz muszę się zalogować
Muszę się upewnić co do kilku rzeczy
po pierwsze muszę się upewnić
dla którego mam otwartą regułę zapory
port 3389 drugi to muszę zrobić
upewnij się, że mam klienta rdp i tak dalej
aby spełnić moje pierwsze ograniczenie, jakim jestem
idę przejść do nawigacji
menu i przejdź do sieci vpc
tutaj mam zamiar wybrać zaporę ogniową i jako
oczekiwano, że reguła zapory rdp była
już utworzony z tego powodu
po utworzeniu domyślnej sieci vpc
ta domyślna reguła zapory to zawsze
stworzony i teraz, kiedy to mam
z drogi mam zamiar wrócić
przejdź do silnika obliczeniowego
i co zamierzam zrobić, to zrobię
nagraj zewnętrzne ip tak, że będę
w stanie się zalogować, teraz będę
logowanie do tej instancji
zarówno z klienta systemu Windows, jak i komputera Mac
klient, więc zaczynając od systemu Windows, jestem
ide do moich okien
maszyna wirtualna i ponieważ wiem
Windows ma już domyślnego klienta rdp
wbudowany, po prostu go przywołam
naciskając klawisz Windows i wpisując
połączenie z pulpitem zdalnym
zamierzam kliknąć, że zamierzam
wklej publiczny adres IP instancji
że właśnie nagrałem i zamierzam to zrobić
kliknij połącz, powinno pojawić się wyskakujące okienko
prosząc o twoje dane uwierzytelniające, zamierzam to zrobić
wpisz moją nazwę użytkownika jako Tony Bowtie Ace
również zamierzam wkleić
hasło i zamierzam kliknąć OK
pojawia się monit o zaakceptowanie zabezpieczenia
certyfikat i zamierzam wybrać tak
i sukces
Jestem teraz połączony z moim serwerem Windows
instancja i uruchomi wszystkie swoje
niezbędne skrypty startowe, które możesz otrzymać
pojawi się kilka monitów
z pytaniem, czy chcesz się połączyć
Twoja sieć
absolutnie zamykam
menedżer serwera na razie
i jeszcze jedna rzecz, na którą chciałem zwrócić uwagę
jest to, że kiedy tworzysz plik windows
instancja pojawi się automatycznie
udostępnił Google Cloud Shell
sdk jest wstępnie zainstalowany i tak będzie
w stanie uruchomić wszystkie zwykłe polecenia
bezpośrednio z tej powłoki bez konieczności
zainstaluj go, a to zasługa gościa
środowisko, które było automatycznie
zainstalowany na instancji vm na
stworzenia i to jest doskonały przykład
niektórych skryptów, które są
zainstalowany ze środowiskiem gościa i'm
iść do przodu i zamknąć to
i zamierzam iść dalej i zamknąć
mojego egzemplarza
uderz ok, a więc będąc tutaj w systemie Windows i
chciałem pokazać ci alternatywną drogę
logowanie do Twojej instancji przez
powershell, więc dla tych z was, którzy są
dość zorientowany w systemie Windows i obsłudze
powershell w Twojej codziennej pracy
łatwy sposób na zalogowanie się do Twojej instancji
używając teraz PowerShell, abym mógł
zrób to, muszę otworzyć inną zaporę ogniową
reguła obejmująca port tcp 5986, więc idę
aby przejść z powrotem do chmury Google
konsola, do której przejdę
menu nawigacyjne i zamierzam przewinąć
do sieci vpc
zamierzam wejść do zapory i jestem
zamierza utworzyć nową regułę zapory i
pod nazwą mam zamiar nazwać to jako
umożliwić
powershell, do którego zamierzam użyć tego samego
opis zamierzam przewinąć w dół
do celów i zamierzam wybrać wszystkie
instancji w sieci i pod
źródłowe zakresy adresów IP dla tej demonstracji
zamierzam użyć
0.0.0.0 ukośnik 0. i znowu to
nie powinien być używany w produkcji
środowisku, ale służy tylko do tego
demo zostawię wszystko inne
jak jest i zamierzam zejść do
protokoły i porty, które zamierzam kliknąć
na tcp i zamierzam wpisać 5986 dla
port i zamierzam kliknąć
stwórz, dam mu chwilę
po prostu stworzyć i zajęło to parę
sekund, ale nasza reguła zapory jest teraz
utworzone, więc teraz przejdę
do mojego Windows VM i otworzę plik
wiersz polecenia powershell i naciśnij
klawisz Windows i wpisz w PowerShell
i tak żebym nie dostał
ciągle pytany o moją nazwę użytkownika i
hasło zamierzam użyć zmiennej
który zachowa moje hasło dla mnie i tak dalej
za każdym razem, gdy łączę się z moimi oknami
na przykład nie będę musiał wpisywać go w całości
czas i tak brzmi polecenie
poświadczenia w postaci znaku dolara są równe uzyskaniu myślnika
credential, nacisnę enter i
pojawi się monit o wpisanie my
nazwę użytkownika i hasło, więc zamierzam to zrobić
po prostu wpisz to teraz wraz z my
hasło i naciśnij ok, a jeśli nie dostaniesz
monit z wszelkimi błędami, a następnie szanse
w których odniosłeś sukces
wprowadzając swoje dane uwierzytelniające i tak teraz
aby połączyć się z instancją, w której jesteś
będzie potrzebował publicznego adresu IP
znowu tak ja jadę ogłowić na nad nazad
do konsoli, którą zamierzam przejść
do menu nawigacji i z powrotem do
Compute Engine tutaj mam zamiar nagrać
zewnętrzny adres IP i idę dalej
z powrotem do mojej maszyny wirtualnej z systemem Windows
i tak zamierzasz to wprowadzić
polecenie, które dołączę do pliku
tekst lekcji, a ty też będziesz w stanie
znajdź go w repozytorium github obok
nazwa komputera, którą zamierzasz wprowadzić
twój publiczny adres IP twoich okien
instance i upewnij się, że na końcu ty
mam zmienną poświadczeń, którą idę
aby po prostu kliknąć Enter i odnieść sukces
teraz podłączony do mojej instancji systemu Windows w
Google Cloud, tak jak widać tutaj
lewo
to publiczny adres IP mojej instancji systemu Windows
a więc są to różne sposoby
możesz połączyć się z instancją systemu Windows
z komputera z systemem Windows i tak teraz dla mnie
aby połączyć się z moją instancją systemu Windows na a
mac, idę tam teraz
i jak powiedziałem wcześniej, muszę zaspokoić
ograniczenie posiadania klienta RDP
niestety mac nie jest dostarczany z
rdp, a więc zalecane narzędzie
do użycia jest rozszerzenie chrome, ale i
osobiście lubię rdp firmy Microsoft dla komputerów Mac
wniosek, więc idę dalej
i zrób przegląd instalacji
więc zacznę od otwarcia
safari i zamierzam to wkleić
url, który dołączę do lekcji
tekst
a firma Microsoft udostępniła a
dostępna aplikacja zdalnego pulpitu firmy Microsoft
w sklepie z aplikacjami idę dalej
i zobacz go w sklepie z aplikacjami, a ja
po prostu kliknij get, a następnie
install i po wprowadzeniu swojego
poświadczenia i pobrałeś i
zainstalowałeś, możesz po prostu kliknąć
otwórz zamierzam kliknąć nie teraz i
kontynuuj i zamknę wszystko
te inne okna dla lepszego oglądania
zamierzam kliknąć dodaj komputer idę
wkleić publiczny adres IP mojego
instancja systemu Windows i konto użytkownika
zamierzam dodać typ mojego konta użytkownika
moja nazwa użytkownika wklej moje hasło, możesz
dodaj przyjazną nazwę tutaj zamierzam
wpisz Windows Dash gc dla Google Cloud
i zamierzam kliknąć dodaj, a następnie
po wklejeniu wszystkich
poświadczenia i informacje, które możesz
następnie kliknij dodaj i powinienem być w stanie
aby połączyć się z moją instancją systemu Windows przez
podwójne kliknięcie na to okno to jest
pytając mnie o moje certyfikaty, jadę
nacisnąć kontynuuj
i sukces Jestem podłączony do moich okien
przykład i tak właśnie byś zrobił
połącz się z instancją systemu Windows z a
z komputera z systemem Windows, a także z komputera Mac jako
cóż, jest jeszcze kilka innych opcji
które chciałem wam tu pokazać
lista rozwijana obok rdp, którą mogę pobrać
plik rdp, który będzie zawierał
publiczny adres IP systemu Windows
instancja wraz z nazwą użytkownika, jeśli i
muszę zresetować hasło, aby wyświetlić
gcloud polecenie, aby to zrobić, lub mogę ustawić a
nowe hasło do systemu Windows, jeśli zapomniałem mojego
stary i to wszystko, co miałem
aby ci pokazać w odniesieniu do łączenia
do instancji systemu Windows i tak dalej
demo robiło się trochę długie, zdecydowałem
aby podzielić go na dwie części
i to jest koniec pierwszej części
to demo i byłoby świetnie
możliwość wstawania i rozciągania się
weź sobie herbatę lub kawę i
kiedy tylko będziesz gotowy, możesz do mnie dołączyć
część druga, od której zaczniemy
bezpośrednio od końca części 1 tzw
możesz ukończyć ten film, a ja zobaczę
ty w części 2.
[Muzyka]
Witamy z powrotem to jest część 2
łączenie się z demonstracją Twoich instancji i my
rozpocznie się dokładnie tam, gdzie wyruszyliśmy
w części pierwszej, więc to powiedziawszy
zanurzmy się i teraz, kiedy już to zrobiliśmy
stworzyliśmy naszą instancję Windows i poszliśmy
wszystkimi metodami, jak to zrobić
połącz się z nim, chodźmy dalej i twórzmy
instancja Linuksa, do której zamierzam przejść
górne menu tutaj i kliknij utwórz
instancja i zamierzam to nazwać
instancja
instancja Linuksa, której nie podam
wszelkie etykiety w regionie, do którego się wybieram
wybierz jeden region usa wschodni i
zone zamierzam zostawić go tak, jak jest ustawiony
domyślnie jako my na wschód 1b maszyna
konfiguracja zostawię tak jak jest
jest pod dyskiem rozruchowym, który zamierzam opuścić
tak samo jest z dystrybucją debian
i pójdę dalej i kliknę dalej
tworzyć
w porządku, a nasza instancja Linuksa była
utworzone i abym mógł się połączyć
do tego
zamierzam do niego wejść przez ssh, ale najpierw ja
potrzeba spełnienia ograniczenia posiadania
reguła zapory z otwartym portem tcp 22 tak
wybieram sie do
Menu nawigacji
i zamierzam przewinąć w dół do vpc
sieć, do której się udam
firewall i zgodnie z oczekiwaniami zezwól na ssh
została utworzona reguła zapory sieciowej
domyślna sieć vpc i tak dalej
Zaspokoiłem to ograniczenie, które mogę
wróć do obliczeń silnika i
więc tutaj mam kilka różnych opcji
które mogę wybrać, aby się zalogować
moja instancja Linuksa, którą mogę otworzyć w pliku
okno przeglądarki, gdybym zdecydował, że chcę
umieść go na niestandardowym porcie, którego mogę użyć
opcja tutaj, jeśli podałem prywatny ssh
klucz do połączenia z tą instancją Linuksa i
mogę użyć tej opcji tutaj mam
opcja przeglądania polecenia gcloud w
aby się z nim połączyć
i zostało mi przedstawione wyskakujące okienko
z poleceniem użycia w ramach
wiersz poleceń gcloud, aby się połączyć
do mojej instancji mogę teraz uruchomić ją w chmurze
shell, ale po prostu go zamknę
a więc niezależnie od tego, czy jesteś na komputerze Mac a
maszyna z systemem Windows lub maszyna z systemem Linux
możesz po prostu kliknąć ssh i otworzy się
nowe okno przeglądarki, z którym się łączysz
Twoja instancja
teraz, gdy łączysz się z linuksem
przykład po raz pierwszy
Compute Engine generuje parę kluczy ssh
dla ciebie ta para kluczy jest domyślnie
dodane do projektu lub instancji
metadane, a to da ci
wolność, o którą nie trzeba się martwić
zarządzanie kluczami teraz, jeśli Twoje konto jest
skonfigurowany do korzystania z obliczeń logowania do systemu operacyjnego
silnik przechowuje wygenerowaną parę kluczy
z Twoim kontem użytkownika
teraz podczas łączenia się z linuksem
przykład w większości scenariuszy google
zaleca korzystanie z tej funkcji logowania do systemu operacyjnego
pozwala używać ról iam do zarządzania ssh
dostęp do instancji Linuksa i to
łagodzi złożoność konieczności
zarządzać wieloma parami kluczy i jest
zalecany sposób zarządzania wieloma użytkownikami
w wielu instancjach lub projektach
więc teraz idę dalej
pokażę, jak skonfigurować logowanie do systemu operacyjnego
twoja instancja Linuksa i sposób na to
będzie to bardzo podobne we wszystkich
platformy, więc idę dalej i
wróć do mojego mac vm i zamierzam
otwórz mój terminal
powiększ to dla lepszego oglądania
i zamierzam zacząć od uruchomienia
polecenie gcloud init, aby utworzyć
upewnij się, że używam właściwego użytkownika i dla
ze względu na tę demonstrację idę
aby ponownie zainicjować tę konfigurację tak
Zamierzam kliknąć na jedno trafienie Enter
numer dwa dla Tony'ego Bowtie Ace i ja
zamierzam użyć atramentu muszki projektowej, więc 1
i nie zamierzam konfigurować domyślnego
obszar obliczeniowy w strefie, więc jeśli uruchomię
polecenie gcloud config list, które widzę
że konto, którego używam, to Tony
muszki gmail.com w projekcie bowtie inc
a więc ponieważ logowanie do systemu operacyjnego wymaga klucza
pair, będę musiał to wygenerować
sobie, więc idę dalej i
wyczyść ekran i zamierzam użyć
polecenie ssh keygen i to jest
polecenie utworzenia publicznego i prywatnego
para kluczy zamierzam użyć wartości domyślnej
path, aby zapisać mój klucz i zamierzam to zrobić
wprowadź hasło
Wchodzę ponownie i ja
radzę spisać swoje
hasło, aby go nie zapomnieć
ponieważ kiedy ją stracisz, nie będziesz mógł
użyć twojej pary kluczy, więc jeśli się zmienię
katalog do kropki ssh i wykonaj ls for
lista widzę, że mam teraz swoją publiczność
i klucz prywatny sparuj klucz prywatny
leżące w id podkreślenie rsa i
klucz publiczny leżący w podkreśleniu identyfikatora
rsa.pub, a więc kolejne ograniczenie, które ja
mam, czy muszę włączyć logowanie do systemu operacyjnego dla mojego
instancja Linuksa, więc idę dalej
i wracam do konsoli i idę
iść dalej i przejść do mojego Linuksa
instancja
zamierzam kliknąć edytuj i jeśli ty
przewiń w dół, dojdziesz do niektórych pól
oznaczone jako niestandardowe metadane i pod kluczem
wpiszesz enable dash os login
i pod wartością wpisujesz wszystko
caps true teraz chciałem poświęcić chwilę
tutaj, aby omówić tę funkcję poniżej
klucze ssh dla kluczy ssh obejmujących cały projekt blokowy
teraz dostępne są publiczne klucze ssh w całym projekcie
ma na celu zapewnienie użytkownikom dostępu do wszystkich
instancje linux w projekcie, które pozwalają
projektowe publiczne klucze ssh obejmujące cały projekt, tzw
jeśli instancja blokuje cały projekt
publiczne klucze ssh, jak widać tutaj
użytkownik nie może używać swojego projektu w całym projekcie
publiczny klucz ssh, aby połączyć się z
instancja
chyba że ten sam publiczny klucz ssh jest również
dodano do metadanych instancji this
zezwala tylko użytkownikom, których publiczny klucz ssh
jest przechowywany w metadanych na poziomie instancji do
uzyskać dostęp do instancji
i dlatego jest to ważna cecha
notatka na egzamin i tak jedziemy
na razie pozostaw tę funkcję zaznaczoną
a potem możesz zejść na dół i
kliknij Zapisz teraz, jeśli chcę włączyć
os login dla wszystkich instancji w moim projekcie
mogę po prostu przejść do menu na
w lewo i kliknij metadane i dodaj
metadane tutaj z tymi samymi wartościami tak
pod klawiszem i wpisz enable dash os login
i pod wartością wpisz wielkimi literami
prawda, ale nie chcę tego włączać
wszystkie moje okazy
tylko dla tego jednego konkretnego przypadku tak
w odniesieniu do kluczy publicznych całego projektu
za pomocą tych kluczy można zarządzać
metadanych i powinny być używane wyłącznie jako
ostateczność, jeśli nie możesz skorzystać z drugiej
narzędzia takie jak ssh z konsoli lub os
zaloguj się tam są klucze
przechowywane, dzięki czemu zawsze możesz je znaleźć
tutaj, gdy szukasz ich tutaj, jak ty
widać, że jest kilka kluczy
Tony Bowtie Ace, którego używałem
poprzednie przypadki, więc zamierzam to zrobić
wróć do metadanych, aby się upewnić
którą ma moja para klucz-wartość dla logowania do systemu operacyjnego
nie został zbawiony i nie jest i jestem
wracając do mojego
instancje, a więc teraz moje ograniczenie
zostało spełnione tam, gdzie je włączyłem
funkcję logowania systemu operacyjnego, dodając plik
niepotrzebne metadane, do których zmierzam
na powrót do mojego mac vm
idę dalej i wyczyszczę
ekran, więc teraz idę dalej i
zaloguj się do mojej instancji za pomocą os login by
za pomocą polecenia gcloud compute os dash
login ssh klawisze kresek dodają, a następnie
oznacz plik key dash, a następnie ścieżkę do
mój klucz publiczny, który jest kropką ssh do przodu
ukośnik id podkreślenie rsa.pub zamierzam
wciśnij Enter
i tak mój klucz został pomyślnie
przechowywane z moim kontem użytkownika idę
do przodu i zrób to trochę większe dla
lepsze przeglądanie i tak w celu zalogowania
do mojej instancji będę potrzebować my
nazwa użytkownika, która jest tutaj, pod
nazwa użytkownika zamierzam to skopiować i jestem
po prostu wyczyszczę ekran na jakiś czas
drugie tutaj dla lepszego oglądania i tak dalej
zamów mi ssh do mojej instancji jestem
zamierzam wpisać polecenie ssh minus i
będę musiał podać swoje prywatne
klucz, który znajduje się w kropce ssh id ukośnika
podkreśl rsa, a następnie moją nazwę użytkownika
nagrałem wcześniej o a potem jestem
będę potrzebować mojego publicznego adresu IP mojego
Linux, więc wracam
na chwilę do konsoli
zamierzam skopiować nagłówek adresu IP
z powrotem do mojego mac vm wklej go i
naciśnij enter, pyta, czy chcę
kontynuuj tak
wprowadź hasło do mojego klucza
i sukces jestem podłączony i tak tam
jest jedno zastrzeżenie, które chciałem ci pokazać
w zakresie uprawnień do logowania do systemu operacyjnego
więc wracam do tzw
konsola i zamierzam przejść do
menu nawigacyjne i przejdź do sekcji Jestem an
admin teraz, jak widać tutaj tony
muszki gmail.com pełni rolę właściciela
i dlatego nie potrzebuję żadnego granulatu
określone uprawnienia mam dostęp
zrobić absolutnie wszystko teraz w przypadku i
był innym użytkownikiem i nie trzymałem
rola właściciela, której bym szukał
określone uprawnienia
to byłoby poniżej obliczeń
os login i to by mi dało
uprawnienia jako standardowy użytkownik teraz, jeśli i
chciał dostępu superużytkownika lub dostępu roota
musiałbym otrzymać system operacyjny obliczeniowy
rola logowania administratora i jak to widzisz
pozwoli mi na administratora
uprawnienia, więc podczas korzystania z logowania do systemu operacyjnego i
członek nie jest właścicielem jednego z nich
potrzebne są dwie role, więc zamierzam to zrobić
wyjdź stąd, nacisnę anuluj
i tak to o obejmuje wszystko, co
chciałem ci pokazać w odniesieniu do wszystkich
różne metody, których możesz użyć
do łączenia się z instancjami vm dla obu
instancje Windows i Linux teraz już wiem
dla niektórych mogło to być odświeżenie
ale dla innych
znając wszystkie różne metody
łączenie się z instancjami może być bardzo trudne
przydatne zwłaszcza przy koordynowaniu wielu
instancje w większych środowiskach, które chcę
pogratulować ci dostania się do
koniec tego demo i zyskać trochę więcej
wiedzę na temat tej kluczowej części
zarządzanie instancjami przed wyjazdem
pamiętaj, aby usunąć wszelkie zasoby, które
które stworzyłeś i jeszcze raz gratuluję
świetna robota, więc możesz teraz oznaczyć to jako
skończ i do zobaczenia w następnym
jeden
witam z powrotem w tej demonstracji
dyskutować o metadanych i o tym, jak to możliwe
odnoszą się zarówno do projektu, jak i do
przykład, jak również mam zamiar dotknąć
skrypty uruchamiania i zamykania i to wszystko
rzeczywistych przypadków użycia w ostatniej lekcji
kiedy dotknęliśmy wierzchołka góry lodowej
przyszedł do metadanych i chciał iść
nieco głębiej na ten temat, jak ja osobiście
czuć, że ma tak wielką wartość
i dać kilka pomysłów, jak możesz
użyj go, zamierzam również połączyć
metadane przy użyciu zmiennych w startupie
scenariusz i mam zamiar ożywić
coś, co ma charakter dynamiczny
powiedziawszy to, zanurzmy się, więc ja
jestem obecnie zalogowany jako tony w bowtie
ace gmail.com
w ramach projektu muszka inc i tak dalej
aby przejść bezpośrednio do metadanych
idę do swojego
menu nawigacji i przejdź bezpośrednio do
Compute Engine i tutaj po lewej stronie
menu strony zobaczysz metadane i Ciebie
mogę się tam teraz zagłębić jako i
wyjaśnione na poprzedniej lekcji
metadane mogą być przypisane do obu
projekty i instancje podczas gdy instance
metadane
wpływa tylko na konkretną instancję, więc tutaj
mogę dodawać i przechowywać metadane, które będą
być również używany w całym projekcie
jak wspomniano wcześniej, metadane są przechowywane
w parach klucz-wartość i można je dodać w
w każdej chwili jest to sposób na dodanie niestandardowego
metadane, ale istnieje domyślny zestaw
wpisy metadanych, które ma każda instancja
dostęp do i ponownie dotyczy to
zarówno metadane projektu, jak i instancji so
tutaj mam możliwość ustawienia mojego
niestandardowe metadane dla całego projektu
i tak mam zamiar zagłębić się w to, dokąd
przechowywać niestandardowe metadane w instancji i
więc abym mógł ci pokazać, że jestem
najpierw przejdź do instancji vm
i utwórz moją instancję, a więc tak jak a
uwaga przed utworzeniem instancji make
upewnij się, że masz domyślny vpc
stworzony i tak, bo lubię dublować
sprawdź rzeczy, do których zamierzam się udać
menu nawigacyjne, które zamierzam przewinąć
do sieci vpc i zgodnie z oczekiwaniami i
mieć już utworzony domyślny vpc i
więc to oznacza, że ​​mogę iść do przodu i tworzyć
moja instancja, więc zamierzam wrócić
przejdź do silnika obliczeniowego
i zamierzam utworzyć moją instancję i
Nazwę tę instancję
serwer WWW Bowtie Dash, na który nie zamierzam
dodaj dowolne etykiety i pod regionem, w którym jestem
zamierzasz wybrać nas na wschód i możesz
pozostaw strefę jako domyślną, tak jak my na wschód
1b pod typem maszyny, którą chcę zachować
rzeczy opłacalne, więc zamierzam
wybierz e2 micro, które zamierzam przewinąć
w dół i pod tożsamością i dostępem do interfejsu API i
chcesz ustawić dostęp dla każdego interfejsu API
i przewiń w dół do silnika obliczeniowego, który chcę
aby go wybrać i chcę go wybrać
czytaj pisz i mam zamiar opuścić
odpocznij tak jak jest i przewiń w dół do
na dole chcę kliknąć zarządzanie
dyski bezpieczeństwa sieci i sprzedawane
dzierżawa
a poniżej tutaj znajdziesz opcję
aby dodać dowolne niestandardowe metadane i możesz
podaj go tutaj pod metadanymi jako
para klucz-wartość, ale nie będziemy tego robić
dodaj teraz dowolne metadane, więc jestem po prostu
zamierzam przewinąć w dół do samego dołu
zostawie wszystko inne tak jak jest i
po prostu kliknij utwórz
i powinno mi to zająć kilka chwil
instancja, która ma zostać utworzona w porządku, a teraz to
moja instancja się skończyła, chcę iść dalej i
zacznij teraz wysyłać zapytania do metadanych, tak jak
należy wyszukać metadane notatki z pliku
sama instancja i nie można tego zrobić
innej instancji lub nawet z chmury
sdk na twoim komputerze, więc idę
naprzód i zaloguj się do instancji za pomocą
ssh
dobrze, a teraz, gdy jestem zalogowany do mojego
instancja, którą chcę rozpocząć odpytywanie
metadane, których normalnie byś użył
narzędzia takie jak wget lub curl, aby je wykonać
zapytania
w tym demo użyję curl i for
ci, którzy nie wiedzą, że curl to komenda
narzędzie linii do przesyłania danych do lub z
serwer przy użyciu obsługiwanych protokołów, takich jak
http ftp scp i wiele innych to narzędzie
fantastyczne do automatyzacji, ponieważ jest
zaprojektowany do pracy bez użytkownika
interakcji, więc wkleję
adres URL, którego użyję do zapytania
metadane instancji i to jest
domyślny adres URL, którego użyjesz do zapytania
wszelkie metadane w dowolnej instancji otrzymującej a
trochę głębiej w to ukośnik końcowy
pokazany tutaj pokazuje, że wartość instancji
jest w rzeczywistości katalogiem i będzie miał
inne wartości dołączane do tego adresu URL
czy są to inne katalogi lub
tylko wartości punktów końcowych teraz podczas zapytania
w przypadku metadanych należy podać plik
następujący nagłówek we wszystkich twoich żądaniach
metadane kreska smak dwukropek google i
należy umieścić w cudzysłowie, jeśli nie
podaj ten nagłówek serwer metadanych
odrzucę twoją prośbę, więc to zrobię
śmiało i naciśnij enter i jak możesz
Widzisz, dużo się wychowałem
różne wartości, z których mogę wybierać
w celu odzyskania różnych typów
metadane i jak stwierdzono przed czymkolwiek
z końcowym ukośnikiem to tak naprawdę a
katalog i będą miały inne wartości
pod nim, więc gdybym chciał zapytać
interfejsy sieciowe
a ponieważ jest to katalog, którego potrzebuję
upewnij się, że dodaję końcowy ukośnik
na koniec i jak widać tutaj i
mam interfejs sieciowy równy 0 i jestem
iść do przodu i zapytać o to
i tutaj będę miał dostęp do wszystkich
informacje o interfejsie sieciowym
w tym przypadku, więc idę
naprzód i zapytaj o to sieć
interfejs i zgodnie z oczekiwaniami domyślny
wyświetlana jest sieć, do której idę
szybko idź naprzód i wyczyść mój ekran i
mam zamiar iść dalej i zapytać niektórych
tym razem zrobię więcej metadanych
nazwa serwera i zgodnie z oczekiwaniami
pojawił się serwer WWW Bowtie Dash i
ponieważ jest to punkt końcowy, którego nie potrzebuję
końcowy ukośnik na końcu idę
iść naprzód i tym razem zrobić jeszcze jedną
wybieram typ maszyny
i znowu zgodnie z oczekiwaniami e2 micro
wyświetlany jest typ maszyny i tak samo
uwaga dla tych, którzy nie zauważyli
kiedy zapytasz o metadane, tak się stanie
pokaż się na lewo od twojego dowództwa
podpowiedz teraz, co ci tu pokazałem
co można zrobić z metadanymi instancji
a co powiesz na to, jeśli chcesz zapytać
wszelkie metadane projektu dobrze zamiast
instancja na końcu, której byś użył
projekt z końcowym ukośnikiem i'm
po prostu kliknij enter i as
widać tutaj projekt mi nie daje
wiele opcji, ale daje
mi kilka ważnych wartości, takich jak identyfikator projektu
więc po prostu zapytam o to dobrze
teraz i zgodnie z oczekiwaniami jest Bowtie Inc
wyświetlany, więc jest to świetny przykład
jak wyszukiwać dowolne domyślne metadane dla
instancji i projektów teraz jesteś
prawdopodobnie zastanawiasz się, jak zapytać my
niestandardowe metadane oraz niestandardowe
metadane zostały ustawione, możesz następnie zapytać
go z katalogu atrybutów w pliku
katalog atrybutów można znaleźć w
metadane instancji i projektu
więc pójdę dalej i ci pokażę
że teraz, ale najpierw chciałem dodać trochę
niestandardowe metadane i można to ustawić
albo konsola polecenie gcloud
narzędzie linii lub używając api, więc jestem
zamierzam uruchomić polecenie tutaj gcloud
instancje obliczeniowe dodają metadane kreski
nazwa twojej instancji i kiedy jesteś
dodając niestandardowe metadane, dodałbyś plik
oznacz metadane kreski myślnikiem za pomocą klucza
para wartości, którą w tym przykładzie jest
environment równa się dev, a potem ja też
zamierzam dodać strefę instancji
czyli nas na wschód 1a i zamierzam uderzyć
Wchodzić
a ponieważ miałem tam literówkę, idę
iść dalej i spróbować ponownie, używając nas
wschód 1b
wciskam enter
i sukces, a więc aby to zweryfikować
polecenie zadziałało
idę dalej i pytam
instancja i idę na dno
atrybuty
wciskam enter i jak możesz
zobacz tutaj punkt końcowy środowiska
zostało wypełnione, więc zamierzam zapytać
że i zgodnie z oczekiwaniami wyświetla się dev
jako wartość środowiska teraz, gdybym chciał
aby dokładnie sprawdzić to w konsoli i
mogę przejść do konsoli, mogę wiercić
w dół do serwera WWW Bowtie
a jeśli przewinę w dół do dołu poniżej
niestandardowe metadane, możesz zobaczyć klucz
para wartości ma tutaj m jako klucz i dev
będąc wartością, a więc to są
wiele różnych sposobów, na które możesz wysyłać zapytania
metadane dla dowolnych instancji lub projektów
teraz chciałem poświęcić krótką chwilę
przełączać biegi i rozmawiać o starcie i
skrypty zamykające teraz obliczają pozwolenia silnika
tworzysz i prowadzisz własny startup i
skrypty zamykania w instancji maszyny wirtualnej i
pozwala to na wykonanie automatyzacji
które mogą wykonywać akcje podczas uruchamiania
takie jak instalowanie oprogramowania
przeprowadzania aktualizacji lub innych zadań
które są zdefiniowane w skrypcie i kiedy
zamykając, możesz zezwolić instancjom
czas posprzątać po wykonaniu zadań np
jak eksportowanie dzienników do magazynu w chmurze lub
bigquery lub synchronizacja z innymi systemami
więc chciałem iść naprzód i pokazać ci
jak to będzie działać podczas łączenia
metadane do skryptu, więc zamierzam to zrobić
śmiało i przejdź do sieci muszki
serwer
klikam edytuj i ide
aby przewinąć w dół tutaj
do niestandardowych metadanych, które zamierzam kliknąć
dodaj element i pod kluczem zamierzam wpisać
W
uruchamianie skryptu kreski i pod wartością i'm
zamierzam wkleić w moim skrypcie
po prostu powiększ to tutaj na sekundę i
Dostarczę skrypt w
repozytorium github teraz tylko po to, aby je złamać
w dół, to jest skrypt bash, który ściągam
w zmiennej o nazwie nazwa, która będzie
zapytaj o nazwę instancji, a także mam
zmienna o nazwie zone, która wykona zapytanie
strefa instancji, w której będę
instalowanie serwera WWW Apache i gotowe
będzie wyświetlać w przeglądarce internetowej oba
nazwę serwera i strefę, do której należy
w i tak, żebym to zobaczył
strona internetowa, którą również muszę otworzyć
reguły zapory ogniowej, a więc łatwy sposób na zrobienie tego
oznaczałoby to przewinięcie w górę do zapór ogniowych
i po prostu kliknij zezwalaj na http i zezwalaj
Ruch HTTPS oznacza to instancję
z niektórymi tagami sieciowymi jako serwer http
i serwer https i utworzyć dwa oddzielne
reguły zapory, które zezwolą na ruch
dla portu 80 i portu 443, więc zamierzam
zostaw wszystko inne tak jak ja
przewiń w dół i kliknij
zapisz OK i zajęło to kilka sekund
tam, ale skończyło się zapisywanie, idę
iść przed siebie i iść na górę i
kliknij reset, a to wykona a
twardy reset na instancji i will
zezwól na działanie skryptu startowego
więc zamierzam kliknąć reset
zapyta mnie, czy naprawdę chcę to zrobić
tego i w tym celu
demonstrację, którą zamierzam kliknąć
zresetuj, pamiętaj, że nigdy nie powinieneś tego robić
to w produkcji, ponieważ nie robi a
czyste zamknięcie systemu operacyjnego
ale ponieważ jest to instancja z niczym
na nim zamierzam po prostu kliknąć reset
teraz mam zamiar wrócić do
konsola główna dla moich instancji vm i jestem
zamierzam nagrać mój zewnętrzny adres IP idę
aby otworzyć nową przeglądarkę, którą zamierzam otworzyć
powiększ dla lepszego oglądania i idę
aby wkleić mój adres IP i nacisnąć enter
i jak widać tutaj
użyłem mojego skryptu startowego do wyświetlenia
nie tylko ta strona, ale ja mogłem
wprowadź metadane, które pobrałem za pomocą
zmiennych i był w stanie je wyświetlić
tutaj w przeglądarce i tak zanim zakończę
tę demonstrację, którą chciałem ci pokazać
inny sposób użycia skryptu startowego
ale jest w stanie wyciągnąć go z chmury
przechowywania, więc zamierzam wrócić do
menu nawigacyjne i zamierzam przewinąć
aż do przechowywania
tutaj utworzę nowe wiadro
a na razie znajdź unikalną na całym świecie nazwę
nazwać swoje wiadro i zamierzam to zrobić
Zadzwoń do mojej witryny serwera sieci web Bucktie Bowtie
a resztę zostawię jak jest
default i zamierzam po prostu kliknąć
tworzyć
i jeśli masz globalnie unikalną nazwę
dla twojego wiadra zostaniesz poproszony
z tą stroną bez żadnych błędów i
idę dalej i ładuję
scenariusz
i możesz znaleźć ten skrypt w
repozytorium github, więc idę
do mojego repo i będę szukać
muszka rozpocznij final sh mam zamiar
Otwórz to
a teraz, gdy mam przesłany skrypt
zamierzam zagłębić się w ten plik, więc i
może uzyskać więcej informacji, które ja
potrzeba dla instancji i czego potrzebuję
stąd jest skopiowanie uri, więc jestem
zamierzam skopiować to do mojego schowka i
Zamierzam wrócić do
Compute Engine, który zamierzam zgłębić
do mojej instancji
zamierzam kliknąć edytuj u góry
i zamierzam przewinąć w dół do miejsca, w którym to się znajduje
mówi niestandardowe metadane i oto idę
aby usunąć metadane skryptu startowego
i zamierzam dodać nowy element i jestem
będzie dodawanie skryptu kreski startowej
myślnik url i wartość, do której zamierzam
wklej uri, który właśnie skopiowałem
over iw ten sposób podczas uruchamiania mojej instancji
użyje tego skryptu startowego, który jest w
przechowywanie w chmurze, więc zamierzam przewinąć
w dół kliknij zapisz
a teraz zamierzam kliknąć reset, jestem
zamierzam zresetować tutaj, zamierzam wrócić
do strony głównej dla moich instancji vm i
Widzę, że mój zewnętrzny adres IP nie
zmieniłem, więc wracam do swojego
otwórz przeglądarkę internetową i zamierzam kliknąć
na odświeżenie i sukces i jak możesz
zobacz tutaj wziąłem całą masę
różne zmienne, m.in
nazwa maszyny
zmienna środowiskowa strefa jako
jak również projekt i mam wyświetlane
to tutaj na prostej stronie internetowej i chociaż
możesz nie znaleźć tej witryny
szczególnie przydatne w Twojej produkcji
środowisko to tylko pomysł na zdobycie
kreacja przy użyciu domyślnych i niestandardowych
metadane wraz ze skryptem startowym
Widziałem w niektórych środowiskach, gdzie
ludzie mają wiele serwerów WWW i
utwórz stronę internetową, aby wyświetlić wszystkie
określone serwery sieciowe w ich różnych
środowiska wraz z ich adresami IP ich
dane i ich konfiguracje i tak dalej
jako podsumowanie, przez które przeszliśmy
domyślne i niestandardowe metadane oraz instrukcje
zapytaj go w instancji, w której również poszliśmy
poprzez skrypty startowe i jak aplikować
je zarówno lokalnie, jak i za pomocą chmury
przechowywania i mam nadzieję, że ci się podobało
zabawy z metadanymi i korzystania z nich
w skryptach startowych, takich jak ten i
mam również nadzieję, że znajdziesz jakieś fascynujące zastosowanie
przypadkach w obecnych środowiskach i
więc zanim pójdziesz, tylko krótkie przypomnienie
aby usunąć wszelkie posiadane zasoby
stworzony, aby nie ponosić żadnych dodatkowych kosztów i
więc to prawie wszystko, co chciałem
przykryj tą demonstracją, abyś mógł
teraz zaznacz to jako zakończone i przejdźmy
Przechodząc do następnego
[Muzyka]
witaj z powrotem i jestem na tej lekcji
będziemy omawiać silnik obliczeniowy
rozliczenia teraz, jeśli chodzi o ceny
jeśli chodzi o silnik obliczeniowy, mam tylko
pominięto fakt, że przypadki są
ładowany przez drugi po pierwszym
minutę, ale nigdy nie wszedłem w głębiny
rozliczeń i różnych sposobów oszczędzania
pieniądze przy użyciu silnika obliczeniowego w tym
lekcja, którą ujawnię, jak oba
koszty i rabaty są podzielone na
Google Cloud, ponieważ odnosi się do
model rozliczeń oparty na zasobach i
różne oszczędności, które można mieć kiedy
przy użyciu silnika obliczeniowego, więc z tą istotą
powiedział, zanurkujmy
teraz każdy vcpu i każdy gigabajt
budowana jest pamięć na silniku obliczeniowym
oddzielnie, a nie jako część a
nadal jesteś jednym typem maszyny
tworzenie instancji przy użyciu predefiniowanych
typy maszyn, ale pokazuje je twój rachunek
jako indywidualny procesor i pamięć używana na
godzina i do tego odnosi się Google
jako rozliczanie oparte na zasobach, które zrobię
zapoznaj się z modelem rozliczeń
dotyczy wszystkich procesorów graficznych i pamięci vcpus
zasobów i są naliczane w wysokości min
jedną minutę, na przykład, jeśli uruchomisz swój
maszynę wirtualną przez 30 sekund
zostanie naliczona opłata za jedną minutę użytkowania po
instancje jednominutowe są naliczane w jednej
drugi przyrost czasu działania instancji wynosi
kolejny czynnik decydujący o kosztach i
jest mierzony jako liczba sekund
między momentem uruchomienia instancji a
innymi słowy, kiedy zatrzymasz instancję
kiedy twoja instancja jest w stanie zakończonym
stan, jeśli instancja jest bezczynna, ale nadal
ma stan działania, tak będzie
opłata za czas pracy, ale znowu
nie zostaniesz obciążony, jeśli twoja instancja
jest w stanie zakończonym
teraz wchodząc w rezerwacje, to są
zaprojektowany, aby zarezerwować instancje maszyny wirtualnej
potrzebujesz tego po utworzeniu rezerwacji
rezerwacja zapewnia, że ​​te
zasoby są zawsze dostępne dla Ciebie
do wykorzystania podczas procesu tworzenia
może wybrać, jak ma wyglądać rezerwacja
używany na przykład możesz wybrać dla
rezerwacja, która ma zostać zastosowana automatycznie
do wszelkich nowych lub istniejących instancji, które
pasują do właściwości rezerwacji które
jest zachowaniem domyślnym lub możesz
określ tę rezerwację do wykorzystania
przez określoną instancję we wszystkich przypadkach vm
instancja może korzystać z rezerwacji tylko wtedy, gdy
jego właściwości dokładnie odpowiadają
właściwości rezerwacji po tobie
utwórz rezerwację, za którą zaczniesz płacić
za zarezerwowane zasoby natychmiast
i pozostają dostępne dla Ciebie
projekt do wykorzystania w nieskończoność do godz
rezerwacja jest usunięta rezerwacje są
wspaniale jest upewnić się, że Twój projekt ma
zasoby na przyszły wzrost popytu
w tym planowane lub nieplanowane skoki
tworzenie kopii zapasowych i odzyskiwanie danych po awarii lub np
bufor kiedy planujesz wzrost kiedy
nie potrzebujesz już rezerwacji, możesz
po prostu usuń rezerwację, aby zatrzymać
ponoszenia opłat za każdą rezerwację jak
normalne maszyny wirtualne są naliczane na podstawie istniejących
stawki na żądanie, które obejmują stałe
korzystać ze zniżek i kwalifikują się do nich
zobowiązałem się korzystać ze zniżek, które będę
wchodzić teraz tylko trochę
rezerwacje zakupu pochodzą z
pewne zastrzeżenia
zastrzeżenia dotyczą tylko obliczeń
dane silnika proc
a także Google Kubernetes Engine
rezerwacje nie dotyczą udostępnionego rdzenia
typy maszyn z możliwością wywłaszczania podeszwy vms
węzły najemców
cloud sql i przepływ danych teraz jako i
wyjaśnione przed każdym vcpu i każdym
gigabajt pamięci na silniku obliczeniowym to
zbudowany oddzielnie, a nie jako część
jednego typu maszyny i jest rozliczana
jako indywidualny procesor i pamięć używana na
godzinowa wycena oparta na zasobach pozwala
Compute Engine, aby zastosować trwałe użytkowanie
zniżki
do wszystkich predefiniowanych typów maszyn
użytkowania w regionie zbiorczo
a nie do poszczególnych typów maszyn
iw ten sposób użycie vcpu i pamięci dla
każdy typ maszyny może otrzymać dowolny z
następujące rabaty trwałego użytkowania
rabaty zobowiązane do korzystania rabaty i
maszyny wirtualne z możliwością wywłaszczania i chciałbym wziąć
chwilę, aby zagłębić się w szczegóły
rozpoczyna się każdy z tych rodzajów rabatów
ze zniżkami za przedłużone użytkowanie
teraz są zniżki za trwałe użytkowanie
automatyczne rabaty na konkretne biegi
zasoby silnika obliczeniowego są znaczne
część miesiąca rozliczeniowego np
po uruchomieniu jednego z tych zasobów dla
ponad 25 procent miesięcznych obliczeń
silnik automatycznie daje ci
rabat za każdą kolejną minutę
którego używasz w tej instancji teraz
poniższe tabele przedstawiają rabaty
złożył wniosek o przyznanie określonych środków
opisane tutaj teraz dla tabeli na
pozostawione dla ogólnego przeznaczenia n2 i n2d
predefiniowane i niestandardowe typy maszyn oraz
dla typów maszyn zoptymalizowanych pod kątem obliczeń
może otrzymać zniżkę do 20
procent pokazuje tabela po prawej stronie
że dla celów ogólnych n1 predefiniowany
i niestandardowe typy maszyn, a także podeszwy
węzły najemców i gpus, które możesz uzyskać
utrzymujący się rabat do 30 procent
rabaty na korzystanie naliczane są automatycznie
do użytku w ramach projektu oddzielnie dla
w każdym regionie, więc nie ma akcji
wymagane z Twojej strony, aby je włączyć
rabaty teraz kilka notatek, które chciałem
do omówienia tutaj jest to trwałe użytkowanie
rabaty są automatycznie stosowane do vms
stworzony przez oba silniki google kubernetes
i silnik obliczeniowy również nie
stosuje się do maszyn wirtualnych utworzonych za pomocą aplikacji
elastyczne środowisko silnika, jak również
przepływ danych i typy maszyn e-2
stosowane są zniżki za przedłużone użytkowanie
przyrostowe użycie po osiągnięciu pewnego
progów użytkowania oznacza to, że płacisz
tylko przez określoną liczbę minut
użyj instancji i silnika obliczeniowego
automatycznie oferuje najlepszą cenę
Google naprawdę wierzy, że nie ma
powód, aby uruchomić instancję na dłużej
niż potrzebujesz
teraz stosowane są zniżki za przedłużone użytkowanie
na przyrostowym użyciu po osiągnięciu
pewnych progów użytkowania oznacza to, że
płacisz tylko za liczbę minut
że używasz instancji i obliczasz
Silnik automatycznie daje Ci to, co najlepsze
cena teraz rozważ scenariusz, w którym ty
mieć dwie instancje lub pojedyncze węzły dzierżawy
w tym samym regionie, które mają różne
typów maszyn i uruchamiać w różnych momentach
miesiąca
silnik obliczeniowy
rozkłada liczbę vcpus i
ilość pamięci używanej we wszystkich
instancje korzystające z predefiniowanej maszyny
typy i łączy zasoby do
kwalifikują się do największego trwałego użytkowania
rabaty możliwe teraz w tym przykładzie
załóżmy, że uruchamiasz następujące dwa
instancje
w jednym regionie usa wschodnim w ciągu miesiąca
przez pierwszą połowę prowadzisz n1
standardowe cztery instancje z czterema vcpus
i 15 gigabajtów pamięci dla
druga połowa miesiąca, w którym prowadzisz
większa i jedna standardowa instancja 16 z
16 procesorów wirtualnych i 60 gigabajtów pamięci
w tym scenariuszu mechanizm obliczeniowy reorganizuje się
te typy maszyn na indywidualne vcpu
i zasobów pamięci oraz łączy je
użycia do tworzenia następujących zasobów
dla vcpus tak, ponieważ były cztery vcpus
używany przez cały miesiąc
zniżka wynosiłaby tutaj trzydzieści procent
dodano dodatkowe dwanaście vcpus
w drugim tygodniu miesiąca i tak dalej
te 12 vcpus otrzymaliby 10
rabat i tak to jest z rabatami
stosowane, jeśli chodzi o trwałe użytkowanie
rabaty teraz przechodzą do następnego
typ rabatu to zobowiązanie do korzystania ze zniżek
więc silnik obliczeniowy umożliwia zakup
umowy o zobowiązanie do korzystania w zamian za
głęboko obniżone ceny za użycie maszyny wirtualnej, więc
przy zakupie zobowiązania
w ramach umowy kupujesz zasoby obliczeniowe
który składa się z pamięci vcpus
gpus i lokalne dyski ssd i kupujesz
te zasoby po obniżonej cenie w
zwrot za zobowiązanie się do płacenia za
tych zasobów przez rok lub trzy
rabaty za wieloletnie użytkowanie są idealne
dla obciążeń z przewidywalnymi zasobami
potrzebuje, więc jeśli dokładnie wiesz, kim jesteś
zamierza korzystać ze zniżek za zaplanowane użytkowanie
byłby świetną opcją dla tego i
rabat do 57
dla większości zasobów, takich jak typy maszyn lub
gpus, jeśli chodzi o zoptymalizowaną pamięć
typów maszyn rabat wynosi do 70
procent teraz przy zakupie
umowę o zobowiązaniu użytkowania, którą możesz kupić
dla jednego projektu i dotyczy a
domyślnie jeden projekt lub możesz
zakup wielu umów, które ty
można udostępniać w wielu projektach według
umożliwienie wspólnych rabatów po zakupie
Twoje miesięczne rachunki za zasoby
kupiłeś na czas trwania
termin, który wybrałeś, czy używasz
usługi lub nie, jeśli masz wiele
projektów korzystających z tej samej chmury
konto rozliczeniowe, które możesz włączyć
korzystaj z udostępniania rabatów, aby wszystkie Twoje
projektów w ramach rozliczeń w chmurze
konto udostępnia całe twoje zobowiązanie do użycia
umowy rabatowe dotyczące stałego użytkowania
rabaty są również łączone w tym samym czasie
czas teraz pewne zastrzeżenia, jeśli chodzi o
zadeklarowane wykorzystanie rabaty wspólny rdzeń
maszyny są również z tego wykluczone
możesz kupować zobowiązania tylko na a
według regionu, jeśli rezerwacja jest
dołączony do zobowiązanego użytkowania zniżki
rezerwacji nie można usunąć dla
czas trwania zobowiązania, więc proszę
świadomy teraz zakupu zobowiązania
gpus lub lokalne dyski ssd, które musisz kupić
cel ogólny i jedno zobowiązanie oraz
wreszcie po utworzeniu zobowiązania ty
nie możesz go anulować, musisz zapłacić ustaloną kwotę
od kwoty miesięcznej przez okres
zobowiązanie teraz zobowiązało się do użycia
rekomendacje rabatowe dają
możliwości optymalizacji obliczeń
kosztów, analizując wydatki na wirtualną maszynę
trendy z zaangażowaniem i bez zaangażowania
umowę rabatową, porównując je
numery, możesz zobaczyć, ile możesz
oszczędzaj każdy miesiąc dzięki zaangażowaniu
umowy i można to znaleźć pod
zakładka rekomendacje na stronie głównej w
konsoli, więc chciałem przejść dalej
do ostatniego typu rabatu jakim są
wirtualne maszyny wirtualne z możliwością wywłaszczania są teraz dostępne w maszynach wirtualnych z możliwością wywłaszczania
nawet o osiemdziesiąt procent taniej niż
ceny zwykłych instancji są stałe i
nigdy nie musisz się martwić o zmienną
ceny te ceny można znaleźć na stronie
link do cen instancji, które mam
zawarte w tekście lekcji a
maszyna wirtualna z możliwością wywłaszczania to instancja, którą ty
może tworzyć i działać po znacznie niższej cenie
niż normalne instancje, jednak obliczają
silnik może je zatrzymać lub uprzedzić
przypadkach, jeśli wymaga dostępu do nich
zasobów na inne zadania jako możliwe do wywłaszczenia
instancjach nasz silnik obliczeniowy dostępu
pojemności, więc ich dostępność jest różna
z użyciem teraz ogólnie silnik obliczeniowy
unika wywłaszczania instancji
ale silnik obliczeniowy nie używa pliku
natychmiastowe użycie procesora lub inne zachowanie
zdecydować, czy go uprzedzić, czy nie
teraz kluczowa cecha, którą należy znać
o maszynach wirtualnych z możliwością wywłaszczania jest to obliczenie
silnik zawsze zatrzymuje je po uruchomieniu
przez 24 godziny i to jest coś, co ma być
świadomy do egzaminu z możliwością wywłaszczania
instancje są skończonym silnikiem obliczeniowym
zasobów, więc nie zawsze tak jest
dostępne i jeśli tak się stanie
przypadkowo uruchomić maszynę wirtualną z możliwością wywłaszczania
i chcesz go zamknąć, nie ma
ładuj, jeśli działa krócej niż 10
minut teraz kolejną rzeczą do odnotowania jest
że instancje, które można wywłaszczać, nie mogą żyć
migruj do zwykłej instancji vm lub be
ustawione na automatyczne ponowne uruchamianie, gdy tam jest
jest zdarzeniem konserwacyjnym ze względu na
ograniczenia, które można wywłaszczać
nieobjęte żadnym poziomem usług
porozumienie i jeśli chodzi o
darmowe kredyty warstwy Google Cloud dla
Compute Engine to nie dotyczy
możliwe do wywłaszczenia przypadki, więc prawdopodobnie jesteś
pytając, kiedy jest świetny czas na użycie
maszyny wirtualne z możliwością wywłaszczania, jeśli są to Twoje aplikacje
odporny na uszkodzenia i może wytrzymać
wtedy możliwe wywłaszczanie instancji
instancje z możliwością wywłaszczania mogą zmniejszyć twój
znacznie obniżyć koszty silnika obliczeniowego
przykładowe zadania przetwarzania wsadowego mogą być uruchamiane
możliwe do wywłaszczenia przypadki, jeśli niektóre z nich
instancje zatrzymują się podczas przetwarzania zadania
zwalnia, ale nie zatrzymuje się całkowicie
instancje z możliwością wywłaszczania tworzą partię
zadania przetwarzania bez umieszczania żadnych
dodatkowe obciążenie pracą dla Twojego obecnego
przypadkach i bez wymagania dla Ciebie
zapłacić pełną cenę za dodatkowe normalne
instancje i ponieważ kontenery są
naturalnie bezstanowe i odporne na błędy
to sprawia, że ​​pojemniki świetnie się do tego nadają
maszyny wirtualne z możliwością wywłaszczania, więc działa z możliwością wywłaszczania
vms dla silnika google kubernetes jest
kolejny fantastyczny przypadek użycia
naprawdę krytyczne, że masz
zrozumienie dla każdego innego
rodzaj rabatu i kiedy jest na to dobry czas
użyj każdego, jak możesz być przedstawiony
różne opłacalne rozwiązania w
egzamin i zrozumienie ich
rodzaje zniżek przygotują Cię do
odpowiedz im rozumiejąc teorię
za tym modelem wyceny opartym na zasobach
wszystkie dostępne rodzaje rabatów
z rodzajami obciążeń
dobre dla każdego zagwarantuje, że ty
zapozna się z rodzajami
pytania są zadawane na egzaminie
a także sprawi, że będziesz lepszą chmurą
inżyniera, jak będziesz w stanie zauważyć
gdzie można zaoszczędzić pieniądze i być w stanie
dokonaj odpowiednich zmian i tak dalej
to właściwie wszystko, co chciałem zawrzeć
jeśli chodzi o rozliczanie silnika obliczeniowego
i jego rodzaje rabatów, więc teraz możesz
zaznacz tę lekcję jako zakończoną i przejdźmy do rzeczy
przejść do następnego
witam ponownie na tej lekcji, na którą idę
być obejmujące podstawy, jak to
dotyczy przechowywania tych pojęć
trzeba wiedzieć, aby w pełni
zrozumieć inną chmurę Google
opcje przechowywania, w których będę nurkować
później egzamin tego oczekuje
znasz różne rodzaje pamięci masowej
to jest dostępne dla wszystkich różnych
usługi
i tak zanim przejdę do innego
rodzaje pamięci, które chciałem uwzględnić
podstawowa teoria, która za tym stoi, więc z tym
mówiąc, zanurzmy się
więc chciałem zacząć od pójścia
przez trzy rodzaje przechowywania i
w jaki sposób dane są prezentowane użytkownikowi lub
na serwerze znajduje się plik pamięci blokowej
storage i obiekt storage tego typu
przechowywania powiązać z dostępnymi
usługi dostępne w google
cloud i oferują różne opcje
dla różnych rodzajów obciążeń i
omówię każdy z nich w a
trochę głębi, a więc pierwszy i
chciałem dotknąć, to pamięć blokowa
teraz czasami określa się pamięć blokową
do przechowywania na poziomie bloku i jest a
technologia służąca do przechowywania danych
plików w systemach pamięci masowej lub w chmurze
środowiska pamięci masowej to pamięć blokowa
najszybszy dostępny typ pamięci i
jest również wydajny i niezawodny
pliki pamięci blokowej są podzielone na
równej wielkości bloki danych, z których każdy zawiera
jest to jego własny unikalny identyfikator
przedstawiony systemowi operacyjnemu jako
bezstrukturalne surowe dane w postaci a
wolumin logiczny lub dysk twardy i
system operacyjny tworzy go za pomocą a
system plików, taki jak ext3 lub ext4 w systemie Linux
i ntfs dla systemu Windows, który następnie by się zamontował
ten wolumin lub dysk jako wolumin główny
w systemie Linux lub dysk ac lub d w systemie Windows
pamięć blokowa jest zwykle dostarczana
nośnik fizyczny w przypadku Google
chmura jest dostarczana jako wirująca
dyski twarde lub dyski półprzewodnikowe
google cloud, z którym jesteś prezentowany blok
magazyn, który składa się z jednego z nich
dyski trwałe lub lokalny dysk ssd
które można zarówno montować, jak i uruchamiać
wtedy można użyć woluminów pamięci blokowej
jako woluminy rozruchowe do obliczeń
instancje w chmurze Google
zainstalowany z systemem operacyjnym
wyboru i zorganizowane tak, że Twoje
baza danych lub aplikacja systemu operacyjnego
będzie mógł go teraz spożywać
przejście do drugiego rodzaju pamięci
jest przechowywanie plików
teraz przechowywanie plików jest również określane jako
poziom pliku lub przechowywanie oparte na plikach i jest
zwykle pamięć, która jest prezentowana
użytkowników i aplikacji w sposób tradycyjny
sieciowy system plików, innymi słowy
użytkownik lub aplikacja otrzymuje dane
przez foldery drzew katalogów i
pliki umożliwia również przechowywanie plików
to samo działa podobnie do a
lokalny dysk twardy, jednak ma strukturę
już zastosowano i nie może być
dostosowane po fakcie tego typu
struktura ma tylko możliwości
być montowalnym, ale nie bootowalnym
nie można zainstalować systemu operacyjnego na
przechowywanie plików, jak powiedziałem wcześniej
struktura została już zbudowana
dla Ciebie i jest gotowy dla Ciebie lub Twojego
aplikacja do konsumpcji z tego powodu
ustrukturyzować usługę, która służy
system plików ma pewne podstawy
oprogramowanie obsługujące prawa dostępu
udostępnianie plików blokowanie plików i inne
kontrole związane z przechowywaniem plików w
google cloud ta usługa, która służy
ten typ przechowywania jest znany jako chmura
magazyn plików i jest zwykle prezentowany
sieci użytkownikom w Twojej sieci vpc
przy użyciu protokołu nfs lub w tym przypadku
nfs wersja 3. ale będę nurkować
że trochę później i ostatni
typ przechowywania, który chciałem omówić, to
przechowywanie obiektów
teraz obiektowa pamięć masowa jest również nazywana
przechowywanie obiektowe
to ogólny termin odnoszący się do drogi
w którym organizujemy i współpracujemy z jednostkami
przechowywania zwanych obiektami, a to jest a
typ magazynu, który jest kolekcją płaską
danych nieustrukturyzowanych i tego typu
magazyn nie ma takiej struktury jak
pozostałe dwa rodzaje przechowywania i jest tworzony
z trzech cech pierwszy
jednym są same dane i to może być
wszystko z piosenek filmowych, a nawet
zdjęcia mężczyzn w fantazyjnych muszkach dane
mogą to być również dane binarne
drugą cechą są metadane
i jest to zwykle związane z dowolnym
informacje kontekstowe o tym, co
dane są lub cokolwiek, co jest istotne
dane, a trzecią cechą jest
globalnie unikalny identyfikator i to
sposób można znaleźć dane
bez znajomości fizyczności
lokalizacja danych i oto co
umożliwia przechowywanie obiektów w nieskończoność
skalowalny, ponieważ nie ma znaczenia, gdzie
obiekt jest przechowywany w tym typie przechowywania
można znaleźć w chmurze Google i jest
znany jako przechowywanie w chmurze przechowywanie w chmurze
składowanie płaskie z kontenerem logicznym
zwane wiadrem, w którym umieszczasz przedmioty
do teraz, chociaż tego typu pamięci
nie można go uruchomić przy użyciu oprogramowania typu open source
narzędzie o nazwie bezpiecznik ten typ pamięci może
być zamontowanym w chmurze Google i będę
opisując to trochę później w
lekcja przechowywania w chmurze, ale w większości przypadków
Składnica obiektów jest zaprojektowana jako typ
pamięci masowej, która nie jest bootowalna lub
montowalny i ze względu na
cechy tego magazynu
umożliwia ponowne przechowywanie obiektów
nieskończenie skalowalne i dlatego są to
trzy główne rodzaje pamięci, które ty
będzie musiał znać i rozumieć jako każdy
ma swoje przypadki użycia, więc jeśli szukasz
dla wydajnej pamięci masowej
zawsze staraj się blokować pamięć masową, aby zaspokoić
Twoje potrzeby, jeśli chcesz się dzielić
plików w wielu systemach lub mieć
wiele aplikacji
które potrzebują dostępu do tych samych plików i
katalogi, to może być przechowywanie plików
najlepszy wybór, jeśli szukasz sklepu
terabajtów zdjęć do sieci
aplikację i nie chcesz się martwić
o skalowaniu obiektowej pamięci masowej pozwoli
czytać i pisać nieskończoną ilość
zdjęć, które spełnią Twoje
wymagania, więc teraz, gdy to omówiliśmy
tych typów pamięci masowej, weźmy kilka
chwilę na omówienie wydajności pamięci masowej
warunki teraz podczas omawiania przechowywania
wydajności istnieje kilka kluczowych terminów
zrozumieć, że używane razem
zdefiniuj wydajność swojej pamięci masowej
najpierw jest io, które oznacza wejście
wyjście
i jest pojedynczym żądaniem odczytu i zapisu oraz
można zmierzyć wielkością bloku i tym
rozmiar bloku może różnić się od jednego
kilobajtów do czterech megabajtów i więcej
w zależności od obciążenia pracą teraz q głębokość
jeśli chodzi o przechowywanie, to liczba
oczekujących żądań wejścia i wyjścia
oczekujące na wykonanie na dysku we/wy
żądania ustawiają się w kolejce, gdy odczytuje lub
zapisy są wymagane szybciej niż oni
mogą być przetwarzane przez dysk, gdy io
żądań jest umieszczanych w kolejce na łączną kwotę
czas potrzebny na odczyt lub zapis danych
dysk staje się znacznie wyższy
gdzie może wystąpić spadek wydajności
wystąpić, a głębokość kolejki musi zostać dostosowana
odpowiednio teraz następny wyraz to a
wspólny punkt kontaktowy, jeśli chodzi o
omawianie wydajności pamięci w gcp
a na egzaminie który jest iops i to
jest metryką oznaczającą dane wejściowe i wyjściowe
operacji na sekundę tej wartości
wskazuje, ile różnych wejść lub
operacje wyjściowe urządzenia lub grupy
urządzenia mogą działać o sekundę więcej
wartość w iops oznacza
możliwość wykonania większej liczby operacji
na sekundę i znowu jest to powszechne
punkt dotykowy, w który będę nurkować
trochę później, teraz następny jest
przepustowość i jest to prędkość w
w którym dane są przekazywane w
drugi i jest najczęściej mierzony w
megabajtów na sekundę to będzie
pojawia się kolejny wspólny temat
często podczas omawiania przechowywania na
gcp również
latencja jest miarą opóźnienia
pomiędzy momentem żądania danych kiedy
dane zaczynają być zwracane i jest
mierzony w milisekundach, więc czas
każde żądanie io zajmie ukończenie
skutkuje średnią latencją
i ostatnie dwa warunki, które chciałem przynieść
up to dostęp sekwencyjny i losowy
sekwencyjny byłby dużym pojedynczym plikiem
jak wideo i swobodny dostęp
ładowanie aplikacji lub operacji
system, więc jest wiele małych plików
wszędzie to widać
losowy dostęp do danych jest znacznie wolniejszy
i mniej wydajny niż dostęp do niego
sekwencyjnie i to też może mieć wpływ
wydajność teraz, dlaczego przywołuję to wszystko
warunki nie polegają na obliczaniu
średnią przepustowość, ale aby dać ci a
holistyczne spojrzenie na wydajność pamięci masowej
ponieważ wszystkie te cechy odgrywają rolę
w określaniu wydajności twojego
składowanie
nie ma jednej konkretnej cechy
który odpowiada za wydajność dysku
ale wszystkie odgrywają rolę w osiągnięciu
najwyższą możliwą wydajność
dla wybranej pamięci teraz już wiem
to dużo teorii do przyjęcia, ale
to wszystko zacznie mieć więcej sensu
kiedy zanurzamy się w inne części
kurs, na którym omówimy dysk
wydajność z tym wszystkim
właściwości związane z obliczeniami
silnik i inne usługi, z których korzysta
przechowywanie jest bardzo ważne, aby wiedzieć
typy pamięci masowej, a także wydajność
właściwości, ponieważ zapewni to przejrzystość
na pytania na egzaminie, a także dać
masz lepsze wyczucie, jak zwiększyć
wydajność pamięci masowej w pracy
środowisko i to całkiem sporo
wszystko, co chciałem omówić, jeśli chodzi o
typy pamięci masowej i wydajność pamięci masowej jako
dotyczy to przechowywania jako całości, więc ty
może teraz oznaczyć tę lekcję jako ukończoną i
przejdźmy do następnego
[Muzyka]
witaj z powrotem i jestem na tej lekcji
będzie obejmować dyski trwałe
i lokalne ssd, które zamierzam zdobyć
w szczegóły z najczęściej
używane typy pamięci masowej dla instancji, które
są zarówno dyskami trwałymi, jak i lokalnymi dyskami ssd
ta lekcja przesieje wszystkie
różne typy dysków trwałych i
lokalne ssds wraz z wydajnością
każdy wie, jakiego typu dysku użyć
dla twojej instancji i jak zwiększyć
wydajność dysku pojawia się na egzaminie
i dlatego chcę się upewnić, że to zakryję
szczegółowo i nie pozostawiaj kamienia na kamieniu
powiedziawszy to, przejdźmy teraz do rzeczy
dyski trwałe i lokalne dyski ssd
dwa dostępne rodzaje pamięci blokowej
urządzenia
dostępne w chmurze Google i
czynnik decydujący o tym, czego będziesz używać
dla twojego konkretnego scenariusza będzie zależeć
na twoim przypadku użycia i specyfice
cechy, od których wymagasz
każdy nośnik pamięci teraz domyślnie każdy
instancja silnika obliczeniowego ma pojedynczą
rozruchowy dysk trwały zawierający plik
system operacyjny, kiedy potrzebujesz
dodatkowe miejsce do przechowywania, które możesz dodać
lub więcej dodatkowych dysków trwałych lub
lokalne ssds do twojej instancji i zrobię to
przejrzyj te opcje przechowywania
wraz z ich charakterystyką obecnie jako
możesz zobaczyć tutaj dyski trwałe i
lokalne dyski ssd są dostępne w wielu różnych wersjach
typy, jak również z dyskami trwałymi
są dostępne zarówno w strefie, jak i w regionie
opcje, więc zacznij od trwałego
dyski masz trzy różne typy
możesz wybierać, jak również masz
elastyczność wyboru spośród dwóch
różne opcje geograficzne, kiedy to
dochodzi do zwolnienia twojego
dyski trwałe i będę je omawiał
szczegółowo opcje strefowe i regionalne
za chwilę dyski trwałe są już dostępne
trwałe sieciowe urządzenia pamięci masowej
do których Twoje instancje mają dostęp, np
dyski fizyczne w komputerze, więc te
nie są fizycznie dołączonymi dyskami, ale
dyski sieciowe, które są połączone
wewnętrzna sieć Google jest trwała
dyski są niezależne od Twojej instancji
i może utrzymywać się po tym, jak twoja instancja ma
została rozwiązana i można to zrobić przez
włączenie tej flagi po stworzeniu ciebie
może nawet odłączyć dysk i przenieść go do
inne przypadki, gdy trzeba skalować
trwałe dyski można zrobić
automatycznie i w locie za pomocą
funkcja zmiany rozmiaru dysku i to daje
elastyczność zmiany rozmiaru
bieżące dyski trwałe z nr
przestojów, a nawet dodać dodatkowe dyski
do Twojej instancji, aby uzyskać dodatkowe
dyski trwałe wydajności i pamięci masowej
są również domyślnie szyfrowane i google
daje również możliwość korzystania z
własne klucze niestandardowe, które może mieć każdy dysk trwały
mieć rozmiar do 64 terabajtów i większość
instancje mogą mieć do 128 trwałych
dysków i łącznie do 257 terabajtów
trwałe miejsce na dysku dołączone i po prostu
jako uwaga, podstawowe typy maszyn są wspólne
ograniczona do 16 dysków trwałych i 3
terabajtów całkowitej trwałej przestrzeni dyskowej
a więc teraz, kiedy przeszedłem przez
szczegóły dotyczące dysków trwałych, które chciałem
zanurz się w dwóch opcjach geograficznych
dostępne dla dysków trwałych
najpierw zaczynając od strefowego, teraz strefowego
dyski trwałe to dyski, które są
dostępne w jednej strefie w jednym regionie
te dyski są najczęściej używane
dyski trwałe do użytku codziennego
użytkowania i używane dla tych, których obciążenia pracą
nie są wrażliwe na określoną strefę
przerwy w dostawie są zbędne w ramach
strefa, w której je utworzyłeś, ale nie możesz
przetrwać awarię tej strefy i może
zostać narażony na utratę danych, jeśli tak się stanie
dotknięta jest konkretna strefa i tak jest
gdzie migawki powinny być częścią twojego
strategia wysokiej dostępności podczas używania
Strefowe migawki dysków trwałych są
przyrostowe i mogą być podjęte, nawet jeśli ty
dyski migawek, które są dołączone do
uruchomione instancje i będę wchodził
szczegóły dotyczące migawek w późniejszej lekcji
można również używać strefowych dysków trwałych
z dowolnym typem maszyny, w tym
wstępnie zdefiniowany wspólny rdzeń i niestandardowy
typy maszyn teraz, jeśli chodzi o
regionalnych dysków trwałych, które mają
właściwości przechowywania, które są podobne do
strefowe dyski trwałe, jednak regionalne
dyski trwałe zapewniają trwałe przechowywanie
i replikacja danych między dwoma
strefy w tym samym regionie, jeśli jesteś
projektowanie systemów wymagających wysokich
dostępność w silniku obliczeniowym
powinien używać regionalnych dysków trwałych
w połączeniu z migawkami dla trwałości
regionalne dyski trwałe są również
zaprojektowany do pracy z regionalnymi zarządzanymi
grup instancji w mało prawdopodobnym przypadku
awaria strefowa, którą zwykle można przełączyć w tryb awaryjny
Twoje obciążenie działa w trybie regionalnym
dyski trwałe do innej strefy przez
po prostu za pomocą flagi przyczepionej na siłę
regionalne dyski trwałe są wolniejsze
niż strefowe dyski trwałe i powinny
wziąć pod uwagę przy pisaniu
wydajność jest mniej krytyczna niż dane
nadmiarowość w wielu strefach
zwracając uwagę na kilka zastrzeżeń tutaj, kiedy to
dochodzi do limitów dysku regionalnego trwałego
dyski są podobne do strefowych trwałych
dyski jednak w standardzie regionalnym
dyski trwałe mają 200 gigabajtów
minimalny rozmiar i może być głównym czynnikiem
jeśli chodzi o koszty, więc bądź świadomy
jak również nie możesz użyć regionalnego
dyski trwałe ze zoptymalizowaną pamięcią
typy maszyn lub zoptymalizowane pod kątem obliczeń
typy maszyn teraz te dwa geograficzne
opcje są dostępne dla wszystkich trzech
typy dysków trwałych, których
cechy, w które teraz się zagłębię
zaczynając od standardu
trwały typ dysku znany również w
Chmura google jako standard pd teraz te
dyski trwałe są obsługiwane przez standard
dyski twarde, a to są twoje
standardowe obracające się dyski twarde i
pozwala chmurze Google podać koszt
skuteczne rozwiązanie dla Twoich potrzeb
potrzebuje standardowych dysków trwałych
doskonale nadaje się do przetwarzania dużych ilości danych
obciążenia, które używają głównie sekwencyjnego
ios teraz, jak wyjaśniono wcześniej sekwencyjnie
dostęp oznaczałby dostęp do większych plików
i wymagałoby mniej ciężkiej pracy
dysk zmniejszając w ten sposób opóźnienie, jak tam
są fizycznymi częściami ruchomymi w tym twardym
dysk, co umożliwiłoby dyskowi zrobienie tego
jak najmniej pracy i
dzięki czemu jest najbardziej wydajny
jak to możliwe, a zatem sekwencyjne ios
najlepiej nadają się do tego typu
trwały dysk i znowu to jest
spośród wszystkich dysków trwałych o najniższej cenie
typy dysków trwałych są teraz krokowe
w wykonanie standardu
dyski trwałe tylko na sekundę
proszę pamiętać, że iops i przepustowość
wydajność zależy od rozmiaru dysku
liczba instancji vcpu i rozmiar bloku we/wy
między innymi i tak ta tabela
tutaj wraz z kolejnymi tabelami
zobaczysz później, są to średnie prędkości
które Google uznało za optymalne dla nich
określone typy dysków, które obejmują
maksymalne trwałe iops, jak również
maksymalna trwała przepustowość wraz z
szczegółowy podział każdego tutaj ciebie
widać różnice między obydwoma
strefowy i regionalny standard pd i as
możesz zobaczyć tutaj w tabeli strefę
standardowy pd i regionalny standardowy pd
są prawie takie same, jeśli chodzi
do większości tych wskaźników, ale kiedy ty
przyjrzyj się uważnie odczytowi iops na
na przykład w tym miejscu różnią się
strefa standardowa pd ma wyższy odczyt
iops na instancję niż regionalna
standard pd, a to dlatego, że
regionalny standard pd uzyskuje dostęp do dwóch
różne dyski w dwóch oddzielnych strefach
a więc opóźnienie będzie wyższe
to samo dotyczy właściwej przepustowości na
przypadku, więc to byłaby decyzja
między wysoką dostępnością a szybkością
przejście do następnego typu trwałych
disk jest zrównoważonym dyskiem trwałym w
Chmura Google znana jako pd równoważy to
typ dysku jest alternatywą dla ssd
dyski trwałe, które równoważą oba
wydajność i koszt jak ten typ dysku
ma taką samą maksymalną liczbę operacji we/wy jak dysk ssd
trwały typ dysku, ale ma niższy
iops na gigabajt i taki jest ten dysk
przeznaczony do ogólnego użytku
Cena za ten dysk również spada
między standardowym a ssd
dyski trwałe, więc to w zasadzie
Twój środek tarczy drogowej, kiedy jesteś
próbując zdecydować między ceną a szybkością
przechodząc prosto do wydajności, którą umieściłem
standardową metrykę pd tutaj, abyś ty
można zobaczyć porównanie side-by-side
między równowagą pd a standardem
pd i jak widać tutaj, kiedy nadejdzie
do wskaźników poniżej maksimum
trwałe iops, czyli saldo pd
znacznie wyższa niż norma
pd zarówno w strefie, jak i regionie
opcje, jak również patrząc na maksimum
trwała przepustowość odczytu i zapisu
przepustowość na gigabajt jest nieco większa
dwa razy szybciej i w prawo
przepustowość na instancję jest trzykrotna
szybciej, więc całkiem spory skok od
standardowe pd do balansu pd i poruszanie się
na ostatnim trwałym typie dysku jest
znany również typ dysku trwałego ssd
w chmurze google jako pd ssd i te
to najszybsze dyski trwałe, które
są dostępne
i świetnie sprawdzają się w przedsiębiorstwach
aplikacji i wysokiej wydajności
baz danych, które wymagają mniejszych opóźnień i
więcej iopów, więc byłoby to świetne
transakcyjnych baz danych lub aplikacji
które wymagają wymagających i bliskich
Wydajność w czasie rzeczywistym, jaką mają pd ssd
jednocyfrowe milisekundowe opóźnienie i
z tego powodu wiąże się to z wyższymi kosztami
i dlatego jest najwyższą ceną
dysk trwały przenoszący się do
wydajność tego dysku trwałego this
typ dysku jest pięć razy szybszy, gdy jest
przychodzi do odczytu iops na gigabajt niż
równowagi pd, a także pięć razy szybciej
dla odpowiednich iopów na gigabajt i tak dalej
tabela tutaj po lewej pokazuje
wydajność dla pd ssd i stołu
po prawej pokazuje wydajność
zarówno standardowe pd, jak i pd równowagi
i tutaj widać różnicę
przejście ze standardowego pd na
ssd pd przepustowość odczytu i zapisu na
instancja pozostaje taka sama z
standardowy pd aż do ssd pd
ale gdzie ssd przewyższa wszystkie
inne są przez odczyt i zapis
przepustowość na gigabajt to jeden i a
pół razy szybciej niż balans pd
i czterokrotnie szybszy od standardowego
pd i znowu zauważysz spadek
w wykonaniu od opcji strefowej do
opcja regionalna i tak jest
koniec pierwszej części tej lekcji
zaczął się trochę wydłużać i tak dalej
kiedy tylko będziesz gotowy, możesz do mnie dołączyć
część druga, od której zacznę
zaraz od końca pierwszej części tzw
możesz dokończyć ten film, a ja to zrobię
do zobaczenia w następnym
[Muzyka]
Witamy z powrotem to jest druga część
lekcja dotycząca dysków trwałych i lokalnych dysków ssd
i zaczniemy dokładnie tam, gdzie my
przerwane w części pierwszej, więc z tą istotą
powiedziałem, zanurkujmy, więc teraz, kiedy to zrobiłem
obejmował wszystkie typy dysków trwałych, tj
chciał przejść do dyskusji nt
charakterystyka lokalnego ssd local
ssds są fizycznie dołączone do
server, który hostuje lokalną instancję maszyny wirtualnej
ssds mają wyższą przepustowość i niższą
opóźnienie niż jakikolwiek z dostępnych
trwałe opcje dysku i znowu to
to dlatego, że jest fizycznie przymocowany i
dane nie muszą podróżować przez
sieć teraz najważniejsza rzecz, którą należy wiedzieć
o lokalnych dyskach ssd jest to, że dane ty
store na lokalnym dysku ssd utrzymuje się tylko do
instancja zostanie zatrzymana lub usunięta jeden raz
instancja zostanie zatrzymana lub usunięta
dane znikną i nie ma na to szans
odzyskania go teraz każdy lokalny dysk ssd jest
375 gigabajtów, ale możesz dołączyć
maksymalnie 24 lokalne partycje ssd dla
łącznie 9 terabajtów na instancję
lokalne dyski ssd są zaprojektowane tak, aby oferować bardzo
wysokie iops i bardzo małe opóźnienie i to
jest świetny, gdy potrzebujesz postu
dysk magazynujący lub pamięć podręczną, a ty nie
chcesz używać lokalnych dysków ssd z pamięcią instancji
dostępne są również w dwóch smakach scuzzy
i mvme teraz dla tych z was, którzy są
nieświadomy
scuzzy jest starszym protokołem i został stworzony
specjalnie dla dysków twardych to również
posiada ograniczenie posiadania jednej kolejki
z drugiej strony również dla poleceń nvme
znany jako nieulotna pamięć ekspresowa
nowszy protokół i jest przeznaczony dla
specyficzne użycie pamięci flash i
zaprojektowane tak, aby mieć również do 64 000 qs
każda z tych kolejek z kolei może mieć górę
do 64 000 poleceń działających jednocześnie
time i tym samym tworząc nvme w nieskończoność
teraz jest szybszy, chociaż zawiera nvme
te niewiarygodne prędkości, jakie osiąga
koszt, a więc jeśli chodzi o
zastrzeżenia lokalnego dysku ssd, chociaż obliczenia
silnik automatycznie szyfruje Twoje dane
kiedy jest zapisywany na lokalnym dysku SSD
przestrzeń, z której nie można korzystać, dostarczona przez klienta
klucze szyfrujące również z lokalnymi dyskami ssd
lokalne ssd są dostępne tylko dla n1
n2 i typy maszyn zoptymalizowane pod kątem obliczeń
teraz przechodzimy do wykonania
lokalna przepustowość ssds jest taka sama
między scuzzy a nvme, ale read
write iops na instancję to miejsce, w którym nvme
wychodzi na wierzch i jak widać tutaj
odczyt iops na instancję jest ogromny
dwa miliony czterysta tysięcy przeczytanych
iops na instancję, jak również prawe iops
na instancję wynosi 1,2 miliona ponad 800
000 dla lokalnego ssd teraz, zanim to zakończę
lekcja, którą chciałem omówić kilka punktów
skalowanie wydajności
jeśli chodzi o blokowanie pamięci
silnik obliczeniowy jest teraz dyskiem trwałym
skale wydajności z wielkością
dysk i z włączoną liczbą vcpus
dysk trwały instancji maszyny wirtualnej
wydajność skaluje się liniowo do momentu
osiąga granice głośności
lub ograniczenia każdego silnika obliczeniowego
przykład, którykolwiek jest niższy teraz, może
wydają się dziwne, że wydajność twojego
dysk skaluje się z liczbą procesorów, ale masz
pamiętać, że dyski trwałe nie są
są fizycznie przywiązani do twojej maszyny wirtualnej
niezależnie zlokalizowane jako takie io na a
pd jest operacją sieciową i dlatego też
zabiera procesor do wykonania io, co oznacza, że
w mniejszych instancjach zabraknie procesora
wykonuj disk io z wyższymi szybkościami, więc w
Aby uzyskać lepszą wydajność
możesz zwiększyć liczbę operacji we/wy dla swojego dysku
zmieniając ich rozmiar do maksimum
pojemność, ale kiedyś ten rozmiar był
osiągnięty, będziesz musiał zwiększyć
liczbę procesorów w Twojej instancji w kolejności
aby zwiększyć wydajność dysku a
rekomendacją Google jest to, że ty
mieć jeden dostępny vcpu na każde 2000
Do
iops oczekiwanego ruchu, tak podsumowując
skaluje wydajność, aż osiągnie
albo ograniczenia dysku, albo
granice instancji vm, do której
dysk jest podłączony do limitów instancji maszyny wirtualnej
są określone przez typ maszyny i
liczba procesorów wirtualnych instancji w tej chwili
jeśli chcesz uzyskać bardziej szczegółowe informacje
w odniesieniu do wydajności dysku mam
zawiera kilka linków w tekście lekcji
to da ci więcej wglądu, ale
do większości ogólnych celów i do
egzamin pamiętaj o tym dysku trwałym
wydajność jest oparta na sumie
stała pojemność dysku
dołączony do instancji i numeru
vcpus, które ma instancja i tak dalej
to właściwie wszystko, co chciałem zawrzeć
jeśli chodzi o dyski trwałe i
lokalne ssds, dzięki czemu możesz to teraz zaznaczyć
lekcję za zakończoną i przejdźmy dalej
Następny
witaj ponownie w tym demo, które zamierzam obejrzeć
omawiać, jak zarządzać i wchodzić w interakcje
z dyskami w silniku obliczeniowym to
demo ma na celu zapewnienie obu
doświadczenie i zrozumienie w pracy
z dyskami trwałymi i jak byś to zrobił
wchodzić z nimi w interakcję, zaczniemy
wyłączyć demo, tworząc instancję
następnie utworzymy oddzielne
trwały dysk i dołącz go do
instancja, z którą następnie będziemy wchodzić w interakcje
z dyskiem, a następnie zmień rozmiar dysku
a potem usuniemy go i
zrobimy to wszystko, używając obu
konsola i wiersz poleceń tak
to powiedziawszy, zanurzmy się, więc tutaj
Jestem w konsoli Jestem zalogowany jako tony
muszki gmail.com i jestem w projekcie
Bowtie Inc, a więc pierwszą rzeczą, którą my
co musisz zrobić, aby uruchomić to demo, to
utwórz instancję, którą możemy dołączyć
nasz dysk, ale najpierw zawsze lubię
upewnij się, że mam vpc do wdrożenia
instancja do odpowiadającej jej
domyślne reguły zapory sieciowej, więc zamierzam to zrobić
przejdź do menu nawigacji
i zejdę do sieci vpc
i zgodnie z oczekiwaniami mój domyślny vpc był
stworzony i tylko po to, aby upewnić się, że ja
mam wszystkie niezbędne reguły zapory sieciowej
przejdziemy do szczegółów vpc i
przejdź do reguł zapory, idę
aby kliknąć reguły zapory sieciowej i
niezbędna reguła zapory, której potrzebuję
ssh jest tworzony, więc mogę iść dalej i
utwórz moją instancję, więc idę
wracam do menu nawigacji i jestem
zamierzam przejść do silnika obliczeniowego, więc
idę dalej i klikam
utwórz i zamierzam to nazwać
instancja Bowtie Dash instancja i for
ze względu na to demo dodam w
etykieta tutaj klucz będzie
środowisko i wartość będzie
testowanie mam zamiar zejść do
dolny kliknij Zapisz w odniesieniu do
region wybieram nas na wschód 1 i
Zamierzam zachować strefę jako
domyślnie dla nas na wschód 1b i pod maszyną
wpisz, aby wszystko było opłacalne i'm
zamierzam użyć współdzielonego rdzenia e2 micro
machine i zamierzam przewinąć w dół do
konto usługi i w ramach usługi
konto, z którego chcesz wybrać zestaw
dostęp dla każdego interfejsu API
chcesz przewinąć w dół, aby obliczyć
engine i tutaj chcesz wybrać odczyt
napisz, a to da nam
niezbędne uprawnienia, aby
wchodzić w interakcje z naszym dyskiem, którym będziemy
tworzenie później, więc będę przewijać
na dół tutaj i zamierzam
pozostaw wszystko inne ustawione na wartości domyślne
i tuż przed utworzeniem instancji
pamiętaj, że zawsze możesz kliknąć
na łączu wiersza poleceń, gdzie możesz
pobierz polecenie gcloud, aby to utworzyć
instancja za pomocą wiersza poleceń i'm
zamknę temat i tak zrobię
po prostu kliknij utwórz, właśnie zamierzam
poczekaj kilka sekund tutaj na moją instancję
wymyślić dobrze, a moja instancja się skończyła
więc teraz to, co chcemy zrobić, to chcemy
aby utworzyć nasz nowy dysk, więc zamierzam to zrobić
przejdź tutaj do menu po lewej stronie i
zamierzam kliknąć na dyskach i jak ty
można zobaczyć tutaj dysk dla instancji
który właśnie utworzyłem, ma 10 gigabajtów
w nas wschód 1b i chcemy to zostawić
sam i chcemy utworzyć nasz nowy dysk
więc idę na górę tutaj
i po prostu kliknij Utwórz dysk
i tak dla nazwy dysku jestem
zamierzam nazwać ten dysk nowym pd dla
trwały dysk i zamierzam go dać
ten sam opis, który zamierzam zachować
typ jako standardowy dysk trwały i
dla regionu, w którym chcę wybrać nas na wschód
jeden zamierzam zachować strefę taką, jaka jest
domyślnie u nas East 1b i jak jest z dyskiem
w nas East 1b będę mógł to dołączyć
do mojej instancji i tak tylko jako notatkę
tutaj jest wybór, gdzie możesz
zreplikuj ten dysk w regionie if
Wyłączam to. Teraz to zmieniłem
ze strefowego dysku trwałego na a
regionalny dysk trwały i tutaj
w strefach daje mi to możliwość
wybierz dowolne dwie strefy, które preferuję i
więc jeśli chcesz je utworzyć
są to regionalne dyski trwałe
kroki, które musisz podjąć, aby to zrobić
zrób to teraz w konsoli w kolejności
aby zaoszczędzić na kosztach, zamierzam to zatrzymać
jako strefowy dysk trwały, więc idę
aby kliknąć anuluj, odznaczę
opcja i upewnij się, że Twój region jest
nadal ustawiamy się na wschód 1, a twoja strefa jest
wybraliśmy jako nas wschód 1b, do którego jedziemy
zostaw harmonogram migawek w spokoju i
będę zagłębiać się w harmonogramy migawek
w późniejszej lekcji zamierzam przewinąć
tutaj do typu źródła, do którego zamierzam
zachowaj go jako pusty dysk i rozmiar tutaj
jest ustawiony na 500 gigabajtów i chcemy
ustaw go na 100 gigabajtów, ale zanim to zrobimy
na które chciałem zwrócić Twoją uwagę
szacowana wydajność tutaj możesz
zobacz limity losowych operacji iops podtrzymania jako
jak również limit przepustowości i tak dalej
w zależności od rozmiaru dysku
chcesz dodać te limity ulegną zmianie
odpowiednio, więc jeśli zmienię to na 100
mój trwały limit losowych operacji odczytu
poszedł z 375 iops do 75 iops i tak
jest to wspaniały dowód na to, że
większy dysk, tym lepszy
wydajność, więc jest to świetny sposób
dowiedzieć się, na czym polega Twoja wydajność
będzie przed utworzeniem dysku i
Zostałem również poproszony o notatkę tutaj
mówiąc to, ponieważ mój dysk ma mniej niż 200
gigabajty, które zmniejszę
wydajność i tak jest w przypadku tego demo
dobrze, zachowam moje szyfrowanie jako
klucz zarządzania google i pod etykietami i
doda środowisko jako klucz i
wartością jest testowanie
a więc teraz, kiedy wszedłem do wszystkich moich
opcje, które po prostu kliknę
tworzyć
i dam mu kilka sekund
a mój nowy dysk powinien zostać utworzony w porządku
a mój nowy dysk został utworzony i ty
można łatwo utworzyć ten dysk za pomocą
wiersz poleceń, a ja będę dostarczać
że w tekście lekcji po prostu chcę
przejdź przez konfigurację konsoli, aby
są świadomi wszystkich różnych opcji
a więc teraz, gdy utworzyłem swój dysk i
stworzyłem moją instancję, którą chcę teraz
zaloguj się do mojej instancji i dołącz ten nowy
disk, więc wrócę do vm
instancje i tutaj chcę się połączyć przez ssh
instancja muszki i zamierzam to zrobić
daj mu kilka sekund na połączenie
i zamierzam powiększyć dla lepszego
przeglądanie zamierzam wyczyścić ekran
więc pierwszą rzeczą, którą chcę zrobić, jest ja
chcę wyświetlić listę wszystkich moich urządzeń blokowych, które
są dla mnie dostępne w tej instancji i
poleceniem linuxowym jest ls blk
i jak widać mój dysk rozruchowy był
zamontowane
i jest dla mnie dostępny, więc teraz chcę
dołączyć nowy dysk, który po prostu
utworzone i tak jak notatkę mogłem jako
łatwo to zrobić w konsoli, ale
Chciałem dać ci pomysł, co to jest
wyglądałoby to jak robienie tego z
wiersz poleceń, więc zamierzam wkleić
w poleceniu, aby dołączyć dysk, który
czy instancje gcloud compute dołączają myślnik
disk nazwa instancji, która jest
instancja myślnika muszka wraz z
flag myślnik myślnik dysk nazwa dysku który
to nowy pd i strefa dysku, z którego korzysta
flaga strefy z nami na wschód 1b, więc jestem
iść dalej i nacisnąć enter
i nie pojawił się żaden błąd, więc zakładam
że to zadziałało i tak po prostu
sprawdź dwukrotnie, czy uruchomię lsblk
znowu komenda i sukces jak widać
tutaj było moje urządzenie blokowe sdb
dołączony do mojej instancji i jest dostępny
dla mnie o rozmiarze 100 gigabajtów i
więc teraz chcę spojrzeć na ten stan
to urządzenie Roblox jest dostępne, więc
poleceniem do tego będzie sudo
file myślnik s, po którym następuje ścieżka pliku
zablokuj urządzenie, które jest deweloperem ukośnika
ukośnik sdb, w które uderzę
wchodzisz i jak widzisz to się wyświetla
danych, co oznacza, że ​​jest to tylko surowy
urządzenie danych i tak, abym mógł
wejść w interakcję z nim, muszę sformatować plik
dysk z systemem plików, który
system operacyjny będzie w stanie
wchodzić w interakcje z, a więc polecenie
sformatować dysk to Sudo mkfs
czyli zrobić system plików, do którego zamierzam
użyj ext4 jako minus systemu plików
kapitał f wraz ze ścieżką nowego
disk, więc zamierzam nacisnąć enter i nie
błędy, więc zakładam, że tak
pomyślnie, więc tylko po to, by sprawdzić, czy jadę
aby uruchomić polecenie sudo file minus s i
jak widać tutaj, ponieważ dysk teraz
ma system plików, który otrzymałem
informacje dotyczące tego dysku
podczas gdy wcześniej były to po prostu surowe dane
i tak teraz, gdy stworzyliśmy nasz dysk
i sformatowaliśmy nasz dysk do pliku
systemu operacyjnego, który jest w stanie
aby przeczytać, musimy teraz zamontować dysk
więc aby to zrobić, musimy
utwórz punkt montowania, więc zamierzam to zrobić
najpierw wyczyść ekran, a ja to zrobię
uruchom polecenie Sudo mkdir i nowy
punkt montowania, nazwijmy to ukośnikiem
nowy pd, wcisnę enter i teraz
Zamierzam zamontować dysk i
polecenie to Sudo zamontuj ścieżkę
dla urządzenia blokowego, które jest do przodu
slash dev forward slash sdb a następnie
punkt montowania, który jest nowym ukośnikiem
pd zamierzam nacisnąć enter bez błędów, więc
Zakładam, że zadziałało, ale po prostu
aby sprawdzić, czy zamierzam uruchomić polecenie
lsblk
i sukces jak widać sdb ma teraz
został zamontowany jako nowy pd, więc teraz mogę
wchodzić w interakcję z tym dyskiem, więc najpierw
rzeczą, którą chcę zrobić, jest to, że chcę się zmienić
katalogi do tego punktu montowania, w którym się znajduję
teraz nowy pd zamierzam zrobić ls i tak dalej
tylko jako uwaga dla tych z was, którzy są
zastanawiam się nad zgubionym i znalezionym katalogiem
znajduje się w każdym systemie plików Linux i
ma to na celu umieszczenie osieroconych lub
uszkodzone pliki lub uszkodzone bity
dane z systemu plików, który ma zostać umieszczony
tutaj i tak to nie jest coś, co ty
będzie wchodzić w interakcje, ale zawsze dobrze
wiem, więc teraz utworzę plik
w nowym pd, więc zamierzam uruchomić
polecenie sudo nano plik kropka z muszką
tekst, więc złóż muszki to plik, który
zamierzam stworzyć nano to mój tekst
redaktor, więc wciskam enter
i tak w tym pliku mam zamiar wpisać
muszki są tak eleganckie
bo przecież po nich mam zamiar
naciśnij ctrl o, aby zapisać, zamierzam uderzyć
wprowadź, aby to zweryfikować i ctrl x, aby wyjść
jeśli zrobię kolejny ls, zobaczę plik
muszki stworzył również m.in
uruchamiając polecenie df minus k i'll be
tutaj również można zobaczyć system plików
i to jest koniec pierwszej części
to demo robiło się trochę długie, więc ja
postanowił zerwać to byłoby
świetna okazja, aby wstać
się rozciągnąć, zrób sobie kawę lub herbatę
i kiedy tylko będziesz gotowy, możesz dołączyć
mnie w następnym, w którym będzie część druga
zaczynać się natychmiast od końca
część pierwsza
[Muzyka]
witaj z powrotem to jest druga część tego
demo i będziemy kontynuować
zaraz od końca pierwszej części tzw
powiedziawszy to, zanurzmy się i
więc to, co chcę teraz zrobić, to chcieć
zrestartuj instancję, aby
zademonstrować montaż tego urządzenia
i zamierzam to zrobić za pomocą
polecenie Sudo uruchom ponownie, tak się stanie
odłącz mnie, mam zamiar kliknąć
blisko i będę czekać ok
minutę, aby się zrestartował i jest
Minęło około minuty, więc idę teraz
ssh do mojej instancji
ok i znowu jestem zalogowany
do mojej instancji zamierzam szybko
wyczyść ekran i idę biegać
polecenie lsblk teraz to, co chciałem
wykazać tutaj jest to, że chociaż i
zamontowane nowe urządzenie nie zostało
zamontowany przez ponowne uruchomienie i to jest
ponieważ istnieje plik konfiguracyjny
linux, który wskazuje, które partycje
montuje się automatycznie po uruchomieniu
które muszę edytować, aby utworzyć
upewnij się, że to urządzenie jest montowane co
czas ponownego uruchomienia instancji i tak dalej
aby to zrobić, muszę edytować plik
nazwałem fstab i będę musiał
dodaj do tego unikalny identyfikator
partycja znana również jako urządzenie sdb
a to zamontuje partycję
automatycznie za każdym razem, gdy to nastąpi
być restartem, aby to zrobić
zamierzam uruchomić polecenie sudo blk id
i ścieżka urządzenia blokowego do przodu
slash dev forward slash sdb zamierzam
naciśnij enter i oto identyfikator
znany również jako uuid, którego potrzebuję
dołącz do pliku fstab, więc zamierzam to zrobić
skopiuj uuid
i zamierzam użyć polecenia
sudo nano
itp
fs i zamierzam nacisnąć enter i
tutaj znajdziesz uuid dla swojego
inne partycje i tak zamierzasz
dołącz linię tutaj dokładnie w
koniec, więc przesunę kursor w dół
tutaj mam zamiar wpisać uuid równa się
a następnie uuid, który skopiowałem
wcześniej punkt kwoty, która się dzieje
być ukośnikiem w przód nowy pd typ
system plików, który jest ext4 wraz z
domyślne
przecinek no fail, nacisnę control o
aby zapisać, naciśnij enter, aby zweryfikować i kontrolować
x, aby wyjść, więc teraz zamierzam zamontować
to urządzenie, uruchamiając polecenie sudo
mount myślnik a i naciśnij enter i to
polecenie zamontuje wszystkie partycje
które są dostępne w pliku fstab i
więc kiedy uruchamiam lsblk
widzę tutaj, że moje urządzenie blokowe sdb
jest teraz zamontowany na ukośniku nowy pd
teraz wiem, że to może być odświeżenie
niektóre, ale jest to doskonała demonstracja
zadań, które należy wykonać, kiedy
tworzenie i dołączanie nowego dysku do pliku
przykład i jest to wspólne zadanie dla wielu osób
praca na instancjach Linuksa i praca
w chmurze można to zdecydowanie napisać w skrypcie
ale chciałem pokazać kroki, które
należy podjąć, aby uzyskać nowy
dysk w stanie zdatnym do użytku ok tak wspaniale my
utworzyliśmy nowy dysk, który mieliśmy podłączony
dysk stworzył system plików i miał
zamontowałem dysk wraz z edycją pliku
plik konfiguracyjny, aby upewnić się, że plik
urządzenie montuje się za każdym razem, gdy instancja
zaczyna się teraz, gdy zrobiliśmy wszystko
że chciałem zademonstrować zmianę rozmiaru
tego dysku ze 100 gigabajtów do 150
gigabajtów i tak tylko po to, aby pokazać ci, gdzie
jest w konsoli, do której zamierzam
szybko wróć do zakładki mojej konsoli i tak dalej
tutaj przejdę do lewej ręki
menu mam zamiar kliknąć na dyskach jestem
przejdziemy do szczegółów nowego pd i at
u góry zamierzam kliknąć edytuj i
więc tutaj mogę dostosować dysk
rozmiar miejsca i po prostu kliknij opcję nie zapisuj
dużo że ja naprawdę potrzebuję zrobić tutaj ale ja
chciałem ci pokazać, jak to zrobić w
wiersz poleceń, więc zamierzam wrócić
do zakładki mojej instancji i idę
aby szybko wyczyścić ekran i jestem
zamierzam wkleić polecenie gcloud
dyski obliczeniowe
zmień rozmiar nazwy dysku, który jest nowy
pd i nowy rozmiar w gigabajtach za pomocą
flaga rozmiaru kreski myślnika 150, która jest
nowy rozmiar dysku wraz z kreską
flaga strefy kreskowej nas wschód 1b idę
nacisnąć enter, zapyta mnie, czy i
chcesz to zrobić, bo tak nie jest
odwracalne i pamiętaj, kiedy ty
zmienić rozmiar dysku, możesz to zrobić tylko
większe i nigdy mniejsze, więc zamierzam
naciśnij y, aby kontynuować
i zajęło to kilka sekund, ale to
powiodło się, więc jeśli uruchomię df minus k
widać tutaj, że mam tylko 100
dostępnych dla mnie gigabajtów i to jest to
ponieważ muszę rozszerzyć system plików
na dysku, więc powiększyłem dysk
ale nie przydzieliłem tych surowych bloków
do systemu plików, aby plik
system plików, aby zobaczyć te nieprzydzielone
bloki, które są dla niego dostępne, muszę
uruchom inne polecenie, więc zamierzam to zrobić
szybko ponownie wyczyść ekran
i zamierzam uruchomić polecenie sudo
zmień rozmiar na fs wraz z urządzeniem blokowym
Wciskam enter i jak możesz
widać, że udało się pokazać stare
bloki jako 13, a nowe bloki jako 19.
więc jeśli uruchomię df minus ki, możesz teraz zobaczyć
moje 150 gigabajtów, które są dla mnie dostępne
i tak tylko po to, żeby zademonstrować
zmiana rozmiaru dysku wraz z montażem
a następnie ponowne zamontowanie dysku, który
plik, który utworzyłem, nadal istnieje
zamierzam uruchomić ls minus al, ale najpierw i
będzie trzeba
zmień katalogi na nowy pd wyczyść mój
ekran i uruchom muszki ls i phyla
nadal tam jest, więc to jest świetne
przykład pokazujący, w jaki sposób dane dot
dyski trwałe utrzymują się przez
żywotność dysku nawet podczas montażu
odmontowywanie, ponowne uruchamianie i zmiana rozmiaru i tak dalej
jak widać wykonaliśmy dużo pracy
tutaj i tak jako podsumowanie, gdzie mamy
utworzyliśmy nowy dysk, dołączyliśmy ten dysk
do instancji sformatowaliśmy dysk
do systemu plików ext4, który zamontowaliśmy
na tym dysku zapisaliśmy na nim plik
dodał swój unikalny identyfikator do pliku
plik konfiguracyjny, aby można go było zamontować
startup, a następnie zmieniliśmy rozmiar dysku
wraz z rozszerzeniem systemu plików na
dysk i tak to jest koniec
demo i chciałem ci pogratulować
dobrnąć do końca i mam taką nadzieję
demo było niezwykle przydatne i ponownie
fantastyczna robota z twojej strony teraz
Idź, chciałem szybko przejść
kroki usuwania wszystkich zasobów
stworzyłeś, a więc pierwszą rzeczą
co chcę zrobić, to usunąć dysk
który został stworzony dla tego demo i tak dalej
zanim będę mógł usunąć dysk, idę
aby najpierw odłączyć dysk od
instancja i najłatwiejszy sposób, aby to zrobić
jest przez wiersz poleceń, więc idę
aby szybko wyczyścić ekran i tak też robię
Pokażę ci, jak odłączyć dysk
z instancji i tak zamierzam
wklej to polecenie gcloud compute
instancje odłączają dysk nazwę instancji
która jest instancją myślnika muszki
z dyskiem z kreską flagową
disc nazwa nowego dysku
pd wraz ze strefą, w którą uderzę
Wchodzić
i został pomyślnie odłączony i
więc teraz, kiedy jest odłączony, właściwie mogę
usuń dysk i tak idę do głowy
na powrót do konsoli i jestem
zamierzam iść dalej i usunąć nowy pd
dysk, który zamierzam kliknąć usuń
pojawi się monit z pytaniem, czy jestem
na pewno tak, jeśli wrócę do głównego
menu dla moich dysków i to powinno wystarczyć
poświęć chwilę, a kiedy cię to usunie
już go tu nie zobaczę i idę
aby wrócić do instancji vm i jestem
to też usunę
więc nie ma potrzeby usuwania twojego
domyślny vpc, chyba że chcesz
odtworzyć go ponownie, ale nie martw się
ci, którzy zdecydują się go zatrzymać, ty nie
zostanie naliczona opłata za vpc, tak jak my
używając go w następnym demo i tak to jest
prawie wszystko, co chciałem omówić, kiedy
chodzi o zarządzanie dyskami za pomocą obliczeń
engine, dzięki czemu możesz teraz oznaczyć to jako
zakończyć i przejść do następnego
jeden
[Muzyka]
witaj z powrotem na tej lekcji, będę
omawiając teraz trwałe migawki dysku
migawki to świetny sposób na tworzenie kopii zapasowych danych
z uruchomionych lub zatrzymanych instancji
przed nieoczekiwaną utratą danych
migawki są również świetną strategią dla
używać w planie tworzenia kopii zapasowych dla wszystkich
przypadkach bez względu na to, gdzie się znajdują
zlokalizowani i tak jak inżynierowie chmury i
architektów, dla których jest to doskonałe narzędzie
osiągnięcie maksymalnego czasu sprawności dla Twojego
przypadkach, więc nurkowanie od razu w to
migawki, jak wspomniałem wcześniej, to a
świetny sposób zarówno na tworzenie kopii zapasowych, jak i
przywrócenia danych Twojego trwałego
dysków, z których można tworzyć migawki
dyski, nawet jeśli są do nich podłączone
migawki uruchomionych instancji są globalne
zasobów, aby każda migawka była dostępna
przez dowolny zasób w ramach tego samego projektu
możesz także udostępniać migawki w poprzek
obsługują również projekty i migawki
strefowych i regionalnych dysków trwałych
migawki są przyrostowe i
automatycznie skompresowane, więc możesz
tworzyć regularne migawki na trwałe
dysk
szybciej i po znacznie niższych kosztach niż gdyby
regularnie tworzyłeś pełny obraz a
dysku teraz, gdy tworzysz migawkę
mają możliwość wyboru magazynu
migawki lokalizacji są przechowywane w chmurze
składowanie
i może być przechowywany zarówno w a
lokalizacja wieloregionalna lub regionalna
wiadro do przechowywania w chmurze wieloregionalne
miejsce przechowywania zapewnia wyższą
dostępności, ale spowoduje wzrost kosztów
należy pamiętać, że lokalizacja a
migawka wpływa na jej dostępność i
może ponieść
koszty sieci podczas tworzenia
migawki lub przywracania jej na nowy dysk
jeśli nie określisz miejsca przechowywania
dla migawki Google Cloud używa
domyślna lokalizacja, w której przechowywane są Twoje pliki
migawka w magazynie w chmurze
wieloregionalna lokalizacja najbliżej
region dysku źródłowego, jeśli przechowujesz
twoja migawka w tym samym regionie co twoja
dysku źródłowego nie ma opłaty sieciowej
kiedy uzyskujesz dostęp do tej migawki z pliku
ten sam region, jeśli uzyskasz dostęp do migawki
z innego regionu poniesiesz a
magazyny silników obliczeniowych kosztów sieciowych
wiele kopii każdej migawki w poprzek
wielu lokalizacjach, jak również nie możesz
zmienić miejsce przechowywania pliku
istniejącą migawkę po utworzeniu migawki
został zabrany, można go użyć do stworzenia
nowy dysk w dowolnym regionie i strefie
niezależnie od miejsca przechowywania
migawka teraz, jak wyjaśniłem wcześniej
migawki są przyrostowe i chciałem
poświęcić chwilę, aby się w to zagłębić
tylko minutę, więc podczas tworzenia migawek
pierwsze udane zdjęcie a
trwały dysk to pełna migawka
zawiera wszystkie dane dotyczące trwałego
dysk, który zawiera tylko druga migawka
wszelkie nowe dane lub modyfikować dane od czasu
pierwsze dane migawki, które się nie zmieniły
ponieważ migawka 1 nie jest dołączona
migawka 2 zawiera odniesienia do
migawka 1 dla niezmienionych danych jako
pokazana tutaj migawka 3 zawiera wszelkie nowe
lub zmienione dane od migawki 2, ale
nie będzie zawierał żadnych niezmienionych danych z
migawka 1 lub 2. zamiast migawki 3
zawiera odniesienia do bloków w
migawka 1 i migawka 2 dla dowolnego
niezmienione dane powtarzają się dla wszystkich
kolejne migawki trwałego
migawki dysków są zawsze tworzone na podstawie
na ostatniej pomyślnie wykonanej migawce
więc teraz pewnie się zastanawiasz
co się stanie, gdy zdecydujesz się usunąć plik a
migawkę, czy są od siebie zależne
inne dobrze, gdy usuniesz migawkę
silnik obliczeniowy natychmiast zaznacza
migawka jako usunięta w systemie, jeśli plik
snapshot nie ma zależnych migawek
jest jednak całkowicie usuwany, jeśli plik
snapshot ma zależne migawki
potem są pewne kroki, które się zdarzają
za kulisami tak pokazanymi tutaj w tym
migawka diagramu 2 jest usuwana jako następna
migawka z pełnej migawki nr
dłużej odwołuje się do migawki dla
usunięcie w tym przykładzie migawka 1 następnie
staje się odniesieniem dla migawki 3 i
wszelkie dane wymagane do przywrócenia
inne migawki są przenoszone do następnego
migawka zwiększająca swój rozmiar pokazana tutaj
bloki, które były unikalne dla migawki 2
są przenoszone do migawki 3 i rozmiaru
migawka 3 zwiększa wszelkie dane, które są
nie jest wymagane do przywrócenia innych
migawki są usuwane, więc w tym przypadku
bloki, które są już w migawce 3
są usuwane z migawki 2 i rozmiaru
wszystkich migawek jest teraz niższa, ponieważ
mogą wymagać kolejne migawki
informacje przechowywane w poprzednim
migawka
należy pamiętać, że usuwanie migawki
niekoniecznie usuwa wszystkie dane
na migawce, jeśli szukasz
upewnij się, że Twoje dane rzeczywiście zostały
usunięte z twoich migawek, powinieneś
usuń wszystkie migawki, jeśli twój dysk ma
harmonogram migawek, który należy odłączyć
harmonogram migawek z dysku przed
możesz usunąć harmonogram
usunięcie harmonogramu migawek z pliku
disk uniemożliwia dalsze wykonywanie migawek
od wystąpienia
teraz dotykając tematu zaplanowanego
migawki zdecydowanie najlepszym sposobem tworzenia kopii zapasowych
Twoje dane w Compute Engine mają być używane
zaplanowane migawki w ten sposób
nigdy nie musisz się martwić o ręcznie
tworzenie migawek, a nawet martwienie się
używając innych narzędzi, aby je uruchomić
migawek, możesz po prostu użyć tego
wbudowane narzędzie Google, dlatego
harmonogramy migawek są uważane za najlepsze
ćwiczyć tworzenie kopii zapasowych dowolnego silnika obliczeniowego
trwałe dyski teraz w celu utworzenia
wszelkie harmonogramy migawek, które musisz utworzyć
twój harmonogram migawek w tym samym
region, w którym znajduje się dysk stały
obecnie istnieją dwa sposoby tworzenia
harmonogram migawek, do którego należy wykonać pierwszy
utwórz harmonogram migawek, a następnie
dołączyć go do istniejącego dysku trwałego
innym sposobem jest utworzenie nowego
dysk trwały z harmonogramem migawek
masz również możliwość założenia tzw
zasady przechowywania migawek, które definiują
jak długo chcesz przechowywać migawki
niektóre opcje podczas tworzenia migawki
harmonogramy są zasadami przechowywania
i zasady usuwania dysku źródłowego teraz if
zdecydujesz się skonfigurować migawkę
zasady przechowywania, musisz to zrobić jako część
harmonogramu tworzenia migawek, kiedy ty
tworzenie harmonogramu migawek jest wtedy, gdy ty
może również ustawić regułę usuwania dysku źródłowego
kontrolki reguły usuwania dysku źródłowego
co stanie się z twoimi migawkami, jeśli
Dysk źródłowy został usunięty, teraz kilka zastrzeżeń
tutaj na zaplanowanych migawkach jest to
dysk trwały może mieć tylko jeden
harmonogram migawek dołączony do niego pod adresem a
czasie również nie można usunąć migawki
harmonogram, jeśli jest dołączony do dysku
musi odłączyć harmonogram od wszystkich dysków
następnie usuń harmonogram, a także później
tworzysz harmonogram migawek
nie można go edytować, aby zaktualizować migawkę
harmonogram, musisz go usunąć i utworzyć plik
nowy teraz, zanim zakończę tę lekcję i
chciałem dotknąć zarządzania migawkami
tylko na minutę, więc kiedy zarządzasz
migawki jest kilka rzeczy
pamiętaj, aby użyć migawek do
efektywnie zarządzać swoimi danymi
migawkę dysków co najwyżej raz
10 minut nie możesz zrobić migawki
dyski w odstępach mniejszych niż 10
minut, więc proszę o tym pamiętać, kiedy
tworzenie harmonogramów również powinieneś
regularnie tworzyć migawki
aby zminimalizować utratę danych, jeśli wystąpił błąd
nieoczekiwana awaria, jeśli masz
migawki dysku trwałego
system automatycznie wykorzystuje je jako
linii bazowej dla kolejnych migawek
które tworzysz z tego samego dysku
więc w celu poprawy wydajności
może wyeliminować nadmierne migawki przez
tworzenie obrazu i ponowne wykorzystanie go za pomocą
ta metoda byłaby idealna nie tylko dla
przechowywanie i zarządzanie migawkami, ale
również pomóc obniżyć koszty i jeśli ty
zaplanuj regularne migawki dla swojego
dysków trwałych można skrócić czas
tyle potrzeba, aby ukończyć każdą migawkę
tworząc je poza godzinami szczytu
kiedy to możliwe i wreszcie dla tych z
ty, który używasz okien w większości sytuacji
możesz użyć kopii woluminu w tle
usługa robienia migawek trwałych
dyski dołączone do systemu Windows
instancje, w których możesz tworzyć migawki vss
bez konieczności zatrzymywania instancji lub
odłącz dysk trwały i tyle
prawie wszystko, co chciałem omówić, kiedy
dochodzi do teorii uporczywości
migawki dysku ich harmonogramy i sposób
zarządzać nimi na następnej lekcji
robić praktyczne demo
demonstrując migawki i umieszczając to
teorię przekuć w praktykę i poczuć
jak działają migawki i jakie mogą być
stosowane do dysków trwałych, więc możesz
teraz zaznacz tę lekcję jako ukończoną i
kiedy tylko będziesz gotowy, dołącz do mnie
konsola
[Muzyka]
Witamy spowrotem
w tej demonstracji mamy zamiar
zanurz się w migawki i migawki
harmonogramy, które to demo da ci
praktyczna wiedza, którą musisz stworzyć
i usuń migawki wraz z instrukcjami
zarządzaj harmonogramami migawek, które zamierzamy wykonać
rozpocznij demo, tworząc plik
przypadku będziemy z nim wchodzić w interakcje
a następnie zrób migawkę dysku
następnie stworzymy kolejną
instancja z migawki, a następnie
utwórz harmonogramy migawek dla obu
tych instancji, używając zarówno
konsola i wiersz poleceń, więc jest
wiele do zrobienia tutaj tak z tym jest powiedziane
zanurzmy się i tak jestem obecnie
zalogowany jako tony bowties gmail.com jako
Cóż, jestem w projekcie Bowtie Inc, więc
pierwszą rzeczą, którą musimy zrobić, aby kopnąć
wyłączenie tego demo polega na utworzeniu instancji
ale najpierw jak zawsze wolę się upewnić
że mam vpc do wdrożenia mojej instancji
z odpowiednią wartością domyślną
reguły zapory ogniowej, więc idę do głowy
przejdź do menu nawigacji i
przewiń w dół do sieci vpc
i ponieważ nie usunąłem mojego domyślnego
vpc z ostatniego demo nadal go mam
tutaj po prostu drążę i
upewnij się, że mam moje reguły zapory
przejdę do reguł zapory i
zgodnie z oczekiwaniami reguła zapory ssh, że i
potrzeba już powstała i tak jest teraz
że mam wszystko w porządku
wracam do nawigacji
menu i przejdź do silnika obliczeniowego
aby utworzyć moją instancję, o której teraz myślę
to demo, zmieniłbym to trochę
i utwórz instancję za pomocą polecenia
linii, więc mam zamiar przejść do
Cloud Shell zamierzam to otworzyć
a zaopatrzenie zajęło minutę i tak dalej
co teraz zrobię, to zrobię
otwórz go w nowej karcie, którą zamierzam
powiększ dla lepszego oglądania i idę
wkleić moje polecenie, aby utworzyć my
instancja i to polecenie gcloud do
utwórz te instancje, będą dostępne
w repozytorium github i będziesz
znaleźć wszystkie instrukcje i
polecenia
w ramach zarządzania migawkami w obliczeniach
engine, więc wciskam enter
i możesz otrzymać monit o autoryzację
to wywołanie api i zamierzam kliknąć
autoryzować
i sukcesem była nasza instancja
stworzony i działa i tak jest teraz
to, co chcę zrobić, to ssh do pliku
instancja, więc po prostu pobiegnę
polecenie stąd, którym jest gcloud
oblicz strefę ssh myślnik myślnik strefę, która
i'm, w którym jest używany 1b i instancja
którą instancję Bowtie Dash wybieram
nacisnąć enter, wyświetli się monit, jeśli
chcę kontynuować, powiem tak
i zamierzam wprowadzić moje hasło i
wprowadź go ponownie
zamierza zaktualizować moje metadane i
znowu poprosi mnie o moje
hasło i jestem w, więc zamierzam
po prostu szybko wyczyść mój ekran i tak
pierwszą rzeczą, którą chcę zrobić, jest to, że chcę
zweryfikuj nazwę mojej instancji, więc jestem
zamiar wpisać nazwę hosta polecenia
i zgodnie z oczekiwaniami instancja Bowtie Dash
pojawia się, więc teraz chcę utworzyć plik
text, więc zamierzam uruchomić plik
Komenda
sudo nano plik a
tekst, który mam zamiar nacisnąć enter i jest
zamierzam otworzyć mój edytor tekstu nano i
możesz wprowadzić wiadomość dowolnego rodzaju
chcesz dla mnie mam zamiar wejść
potrzeba więcej muszki, bo możesz
Nigdy nie mam dość muszek, mam zamiar
naciśnij ctrl o, aby zapisać, naciśnij enter, aby zweryfikować
nazwę pliku do zapisania, a następnie ctrl x
aby wyjść, uruchomię polecenie ls
spacja minus al, aby wyświetlić listę moich plików, więc mogę
sprawdź, czy mój plik został utworzony i
jak widać tutaj plik bowties.txt
został stworzony i tak teraz, że mam
stworzyłem moją instancję i napisałem a
plik na dysk, zajmę się teraz
podejdź do konsoli i zrób zrzut ekranu
tego dysku i ponieważ moja sesja była
przeniesiony do innej karty, którą teraz mogę
zamknij terminal i chcesz iść
przejdź do menu po lewej stronie i przejdź do
dyski i tak teraz chcę wam pokazać dwa
sposoby tworzenia tej migawki
pierwszy idzie na dyski i
wybierając dysk, który chcesz dla mnie
to instancja muszki i akcje
zamierzam kliknąć menu hamburgerów
i tutaj mogę utworzyć migawkę i to
przeniesie mnie prosto do mojej migawki
menu, ale dla tego demo mam zamiar iść
do lewego menu i idę
aby kliknąć migawki i oto idę
aby kliknąć utwórz migawkę i tak dalej
nazwa migawki, którą zamierzam zrobić
wpisz migawkę muszki i zamierzam to zrobić
użyj tego samego do poruszania się opisu
na dysku źródłowym jako jedyny
którą mogę wybrać, to instancja muszki
i to jest ten, którego i tak chcę
więc zamierzam kliknąć na to
lokalizację, aby obniżyć koszty
nie potrzebujemy wielu regionów, jedziemy
po prostu wybierz regionalny i jeśli ty
wybierz lokalizację, w której jestem w stanie
wybierz dowolne inne lokalizacje, takie jak tokio
i mogę utworzyć moją migawkę w Tokio
ale chcę zachować moją migawkę w
ten sam region, więc zamierzam wrócić i
wybierz nas na wschód, na którym jest oparty
lokalizację dysku źródłowego i idę
aby dodać tutaj etykietę z kluczem
środowisko i wartość testowania jestem
pozostawię mój typ szyfrowania jako
google zarządzał i zamierzam po prostu
kliknij utwórz, a to utworzy plik
migawka dysku rozruchowego na muszce
przykład i zajęło to około minuty
tam i tak tylko jako uwaga, jeśli masz
większe dyski zajmą trochę
nieco dłużej, aby zrobić migawkę, a teraz to
utworzyłem migawkę, którą zamierzam przejść
wykonaj kopię zapasową instancji vm i zamierzam to zrobić
utwórz nową instancję z tej migawki
i tak zamierzam nazwać tę instancję
muszka kreska instancja myślnik 2 i ja
zamierzam nadać temu etykietę, którą zamierzam
dodaj tutaj etykietę klucz środowiska
oraz wartość testowania i zapisywania trafień
region będzie używany 1 i ty
może opuścić strefę jako domyślną, tak jak my
East 1b i pod typem maszyny możesz
wybierz e2 micro i chcesz iść
w dół do dysku rozruchowego i wybierz zmianę
przycisk i tutaj mam zamiar wybrać
migawki zamiast publicznego
obraz, więc zamierzam kliknąć migawki
a jeśli wybiorę rozwijaną migawkę
menu, zobaczę tutaj moją migawkę z muszką
więc mam zamiar wybrać to, co zamierzam
pozostaw resztę jako domyślną i idę
zejść w dół, aby wybrać i zamierzam
pozostaw wszystko inne jako domyślne i
zamierzam kliknąć utwórz, idę
po prostu daj mu minutę, więc muszka
instancja 2 może zostać utworzona w porządku i to
zajęło mi to chwilę, więc teraz idę
ssh do tej instancji
i zamierzam powiększyć dla lepszego
oglądam i chociaż znam
instancja nosi nazwę bowtie.instance2
nadal będę uruchamiał nazwę hosta
polecenie i zgodnie z oczekiwaniami ta sama nazwa
wyskakuje, ale byłem naprawdę ciekawy
chodzi o to, czy uruchomię polecenie ls space
myślnik al widzę tutaj mój plik pliku
muszki.tekst
a jeśli zakotwiczę plik
[Muzyka]
będę mógł zobaczyć tekst, który
wprowadzony do tego pliku i tak chociaż
był to tylko jeden plik i plik tekstowy w
że byłem w stanie zweryfikować, że mój
migawka działała tak, jak będzie
razy, w których można uzyskać migawkę
uszkodzony i tak robiąc różne miejsca
sprawdzanie twoich migawek jest dobre
powszechna praktyka, więc teraz chcę
utwórz harmonogram migawek dla obu z nich
te przypadki i tak mam zamiar iść
tyłem do konsoli i lewą ręką
menu, przejdę do migawek
a jeśli przejdę do harmonogramów migawek
widać, że nie mam migawki
harmonogramy, więc przejdźmy dalej i utwórzmy plik
nowy, klikając opcję Utwórz migawkę
harmonogram i tak jak wspomniano w ostatnim
lekcja, której potrzebujemy, aby stworzyć ten harmonogram
najpierw, zanim będziemy mogli dołączyć go do dysku
i tak mam zamiar nazwać tę migawkę
zaplanuj jako harmonogram dysku z muszką
zamierzam użyć tego samego dla
opisz region, do którego jadę
wybierz to jako nas na wschód i idę
aby zachować lokalizację migawki jako
regionalny pod nami wschód, który przewijasz
tutaj iw opcjach harmonogramu
może pozostawić częstotliwość harmonogramu jako
codziennie i tylko jako notatkę dla czasu rozpoczęcia
ten czas jest mierzony w utc, więc proszę
pamiętaj o tym, gdy tworzysz swój
harmonogram w określonej strefie czasowej i
więc ustawię czas rozpoczęcia jako o
600 i będzie to 1 w nocy wschodniego
standardowym czasie, ponieważ kopie zapasowe są zawsze najlepsze
wykonane, gdy jest ich najmniej
aktywność i zamierzam zatrzymać auto
usuń migawki po 14 dniach idę
aby zachować regułę usuwania jako zachowaną
migawki, jak również mogę włączyć
usługa kopiowania woluminów w tle dla systemu Windows
ale ponieważ używamy Linuksa, ja nie
trzeba to włączyć i odkąd oznaczyliśmy
wszystko inne równie dobrze mógłbym dać
to etykieta, w której użyję klucza
środowisko oraz wartość testowania i
kiedy już wszystko wypełnisz
możesz po prostu kliknąć utwórz i to
zajęło to minutę, ale harmonogram był
stworzony i tak teraz, gdy mam swój
harmonogram migawek, do którego muszę go dołączyć
dysk, więc przejdę do niego
menu po lewej stronie i kliknij dyski
i tutaj zamierzam zagłębić się w temat
muszka, do której zamierzam się udać
u góry i kliknij edytuj i poniżej
harmonogram migawek, który zamierzam kliknąć
rozwiń i tutaj znajdę łuk
powiąż harmonogram dysku, który mam zamiar wybrać
że mam zamiar kliknąć zapisz i tak dalej
teraz, kiedy mam swój harmonogram migawek
dołączony do mojego dysku na muszkę
instancja, którą teraz chcę utworzyć
harmonogram migawek dla mojej innej instancji
i tak zamiast używać konsoli jestem
iść do przodu i zrobić to przez
wiersz poleceń, więc zamierzam przejść do
szczyt do mojej otwartej muszli i idę
aby szybko wyczyścić ekran i tak dalej
aby stworzyć mój harmonogram, do którego zamierzam
uruchom to polecenie zasób obliczeniowy gcloud
zasady tworzą harmonogram migawek
nazwa harmonogramu migawek, który jest
harmonogram dysków muszka 2 region
maksymalne dni retencji retencja
zasady i harmonogram, zgodnie z którym
miejsce przechowywania i jak powiedziałem wcześniej
te polecenia znajdziesz w
repozytorium github, więc idę
naprzód i naciśnij enter
więc chciałem zostawić ten błąd
tutaj, aby pokazać ci, że potrzebowałem
odpowiednie uprawnienia do tworzenia
ten harmonogram migawek to świetne przypomnienie
aby zawsze sprawdzić, czy masz rację
rolę dla danego zadania i tak też zrobiłem
dwie opcje, które mogę zmienić użytkowników
od użytkownika mojego konta usługi do tony'ego
muszka albo mogę po prostu przejść do
moją instancję i edytuj konto usługi
uprawnienia i tak najłatwiej to zrobić
byłoby po prostu zmienić użytkowników i tak dalej
zamierzam iść naprzód i zrobić to, więc jestem
iść dalej i uruchomić polecenie
gcloud auth zaloguj się i pamiętaj, że this
jest czymś, czego nie musisz robić
chciałem ci tylko pokazać, że ty
wymagają odpowiednich uprawnień
tworzenie określonych zasobów w porządku i
szybko przeszedłem przez
proces uwierzytelniania, po prostu to zrobię
wyczyść ekran i idę
do przodu i ponownie uruchom polecenie
i zgodnie z oczekiwaniami harmonogram migawek
został utworzony bez błędów i tak jest teraz
że mój harmonogram został utworzony, mogę
teraz dołącz go do dysku, więc idę
aby uruchomić polecenie gcloud compute disks
dodaj zasady dotyczące zasobów nazwę instancji
który jest instancją Bowtie 2 i
polityka zasobów, która jest migawką
Harmonogram o nazwie Bowtie Disk Schedule 2
w strefie nas wschód 1b jadę do
wciśnij Enter
i sukces, a więc tylko po to, aby to zweryfikować
harmonogram migawek został dołączony
na mój dysk zamierzam wrócić do
konsola, na której zamierzam wrócić
do strony głównej dysków, na które się wybieram
przejdź do instancji muszki 2 i
tutaj jest harmonogram migawki ma
został dołączony i tak chcę
gratuluję dotarcia do końca
tego demo i mam nadzieję, że to demo ma
były przydatne jako migawki w roli
inżynier to wspólne zadanie, które może
uchroni Cię przed utratą danych po ustawieniu
na miejscu i tak po prostu jako podsumowanie, które masz
utworzyłeś instancję, utworzyłeś plik
w tej instancji, a następnie utworzyłeś
migawka dysku tej instancji
i użyłem go do stworzenia kolejnej instancji
następnie zweryfikowałeś migawkę, a następnie
utworzył harmonogram migawek dla obu
dyski rozruchowe instancji korzystających z
konsola i wiersz poleceń dobrze zrobione
teraz w innej świetnej pracy, zanim odejdziesz
chciałem poświęcić chwilę na posprzątanie
zasoby, z których korzystaliśmy, więc tego nie robimy
skumulować wszelkie koszty i tak po pierwsze
rzeczą, którą chcemy zrobić, jest oderwanie się
harmonogramy migawek z dysków
a więc skoro jesteśmy w instancji muszki 2
Idę dalej i klikam edytuj
zgodnie z harmonogramem migawek zamierzam
wybierz brak harmonogramu trafienia zapisz i jestem
zrobie to samo z moim drugim
dysk
teraz ja jadę ogłowić nazad na nad do
migawki, zamierzam to usunąć
zdjęcie i wracam do tematu
do harmonogramów migawek, do których zamierzam
wybierz wszystkie harmonogramy migawek i
zamierzam kliknąć usuń
a teraz, gdy wszystko jest posprzątane
w odniesieniu do migawek i migawek
harmonogramy, które mogę teraz przejść do vm
instancje i usuń instancje
wybieram je wszystkie i po prostu
kliknij usuń
i to właściwie wszystko, czego chciałem
omówić w tym demo, jeśli chodzi o
migawki i harmonogramy migawek
więc możesz teraz oznaczyć to jako kompletne i
przejdźmy do następnego
witaj z powrotem na tej lekcji, na którą idziemy
zmienić biegi i wziąć automat
podejście do wdrażania poprzez zanurzenie się w
narzędzie Google do infrastruktury jako kodu
o nazwie menedżer wdrażania teraz wdrożenie
manager pozwala na wdrożenie
aktualizować i usuwać zasoby z
w chmurze Google przy użyciu yaml jinja i
szablony kodu Pythona, na które pozwala
zautomatyzować wdrażanie wszystkich
zasoby dostępne w google
chmurze i wdrożyć ją w szybki i łatwy sposób
powtarzalny sposób dla spójności i
efektywność w tej lekcji, którą zamierzamy przeprowadzić
poznaj architekturę wdrożenia
menedżera i zanurz się w różne
komponenty, które zapewniają jej elastyczność
oraz funkcje, które sprawiają, że to narzędzie jest
łatwe rozwiązanie do wdrażania złożonych
środowiskach, więc to powiedziawszy
zanurzmy się
teraz rozkładając komponenty, które ja
wspomniałem wcześniej, że chciałem zacząć
przy czym pierwszym składnikiem jest
konfiguracja teraz konfiguracja
definiuje strukturę Twojego wdrożenia
ponieważ musisz określić konfigurację do
utwórz wdrożenie konfiguracji
opisuje wszystkie zasoby, których potrzebujesz
pojedyncze wdrożenie i jest wpisany
składnia yaml, która zawiera listę każdego z
zasobów, które chcesz utworzyć i jego
odpowiednie właściwości zasobów
konfiguracja musi zawierać zasoby
sekcja, po której następuje lista
zasoby do utworzenia, a więc każdy zasób
musi zawierać te trzy składniki
nazwij typ i właściwości bez
te trzy komponenty będą dostępne we wdrożeniu
nie tworzyć instancji, więc chciałem wziąć
chwilę na omówienie tych trzech
komponenty w nieco głębi, więc
pierwszym elementem konfiguracji jest
nazwa i nazwa jest zdefiniowana przez użytkownika
ciąg identyfikujący ten zasób i can
bądź czymkolwiek wybierzesz spośród imion takich jak
instancja jedna my-vm
instancji bowtie dash i możesz nawet iść
tak daleko, aby użyć myślnika instancji skowronka
nie myśl kreską, a składnia może być
znaleźć tutaj i nie może ich zawierać
obok spacji lub nieprawidłowych znaków
komponent w konfiguracji to typ i
istnieje kilka różnych typów
które możesz wybrać z puszki typu
reprezentują pojedyncze źródło API znane jako a
typ bazowy
lub zestaw zasobów znany jako
typem złożonym i jednym z nich
może być użyty do stworzenia części twojego
wdrożenie typu zasobu
jest wdrażany tutaj na tym diagramie
pokazany jako typ podstawowy
compute.v1.instancja
i istnieje wiele innych zasobów interfejsu API
których można użyć, takich jak compute.v1.disk
silnik aplikacji dot v1, jak również
bigquery.v2, a składnia jest pokazana tutaj
jako api dot wersja dot zasób teraz a
typ złożony zawiera jeden lub więcej
szablony, które są wstępnie skonfigurowane
pracuj razem, aby rozszerzyć te szablony
zestaw typów podstawowych po wdrożeniu w
typy złożone wdrażania są
zasadniczo hostowane szablony, które ty
może dodać składnię do menedżera wdrażania
jest tutaj pokazany jako gcp dash typu forward
zasób dwukropka dostawcy ukośnika i do
daj przykład co to za kompozyt
typ wygląda
tutaj pokazano tworzenie zastrzeżonego
adres IP przy użyciu silnika obliczeniowego v1
api i możesz także użyć kompozytu
typy z innymi API w ten sam sposób
takie jak gcp myślnik typy aplikacja z ukośnikiem
aplikacje dwukropka silnika dash v1 lub bigquery
zestawy danych dwukropka v2 i na koniec
komponentem w konfiguracji jest
właściwości i to są parametry
dla typu zasobu obejmuje to wszystko
parametry, które widzisz tutaj w this
przykład ze strefą
typ maszyny wraz z typem dysku
jego parametry właściwie wszystko
który zawiera szczegółowe informacje na temat typu zasobu
teraz tylko jako uwaga muszą pasować do
właściwości dla tego typu, więc co zrobić i
rozumiem przez to, więc powiedzmy, że wpisałeś a
strefa, ale ta konkretna strefa nie
istnieje lub ta maszyna z silnikiem obliczeniowym
typ nie istnieje w tej strefie
kończy się błędem podczas wdrażania
menedżer nie będzie mógł tego przeanalizować
konfiguracji i tym samym kończy się niepowodzeniem
wdrożenie, więc upewnij się, kiedy dodasz
Twoje właściwości, które odpowiadają właściwościom
zasób teraz konfiguracja może
zawierają szablony, które zasadniczo są
części pliku konfiguracyjnego, który
zostały wyabstrahowane do jednostek
bloki konstrukcyjne szablon jest osobny
plik, który jest importowany i używany jako typ
w konfiguracji i możesz użyć as
wiele szablonów, jak chcesz w
konfiguracji i pozwalają na separację
Twoja konfiguracja na inną
elementy, które można wykorzystać i ponownie wykorzystać
mogą być różne szablony wdrożeń
tak ogólne lub szczegółowe, jak potrzebujesz
i pozwalają ci również wziąć
zaletą funkcji takich jak szablon
właściwości zmienne środowiskowe i
moduły do ​​tworzenia dynamicznej konfiguracji
jak pokazano tutaj, można pisać szablony
na kilka różnych sposobów mogą
być napisane w języku imbirowym 2.1 lub
python 3. przykład pokazany po lewej stronie
został napisany imbirem i jest bardzo
podobny do składni yaml, więc jeśli jesteś
zaznajomiony z yamlem, może to być lepsze
dla ciebie przykład po prawej ma
został napisany w Pythonie i jest ładny
niesamowite, jak możesz skorzystać
programowo generujące części
szablony, jeśli je znasz
python może to być lepszy format
teraz jedną z zalet używania
szablony to możliwość tworzenia i
zdefiniuj niestandardowe właściwości szablonu
właściwości szablonu są dowolne
zmienne zdefiniowane w szablonie
pliki dowolny plik konfiguracyjny lub szablon
plik, który korzysta z danego szablonu
może podać wartość dla szablonu
właściwość bez zmiany szablonu
bezpośrednio pozwala to na abstrakcję
właściwość, aby można było zmienić
wartość właściwości dla każdego unikalnego
konfiguracja bez aktualizacji
podstawowy szablon i tylko jako notatka
menedżer wdrażania tworzy predefiniowane
zmienne środowiskowe, których możesz użyć
w twoim wdrożeniu w tym przykładzie plik
zmienna projektu użyje identyfikatora projektu
dla tego konkretnego projektu i tak dalej
łącząc wszystkie te elementy razem
da ci wdrożenie i tak dalej
wdrożenie to kolekcja zasobów
które są wdrażane i zarządzane razem
za pomocą konfiguracji możesz wtedy
wdrożyć aktualizację lub usunąć to wdrożenie
po prostu zmieniając jakiś kod lub w
kliknij przycisk teraz podczas wdrażania
podajesz prawidłową konfigurację w pliku
żądanie utworzenia wdrożenia a
wdrożenie może zawierać kilka
zasobów w wielu google
usług w chmurze podczas tworzenia pliku
wdrażanie tworzy menedżer wdrażania
wszystkie opisane zasoby do wdrożenia
konfiguracja, przez którą należy to zrobić
linii poleceń i nie można tego zrobić
przez konsolę możesz po prostu użyć
pokazana tutaj składnia i wdrożenie
zostanie utworzony z
plik konfiguracyjny, który wprowadziłeś
gdzie rozmieszczenie muszki to nazwa
wdrożenie i plik po myślniku
dash config to twój plik konfiguracyjny
Google Cloud oferuje również predefiniowane
szablony, których można użyć do wdrożenia
z rynku gcp i może być
znaleźć bezpośrednio w konsoli wdrażania
zarządzaj w ten sposób całą konfiguracją
i tworzenie szablonów jest obsługiwane za Ciebie
i po prostu wdrażasz rozwiązanie
konsoli teraz po utworzeniu pliku
wdrożenie możesz aktualizować w dowolnym momencie
musisz zaktualizować wdrożenie
dodając lub usuwając zasoby z a
wdrażanie lub aktualizowanie właściwości
istniejące zasoby we wdrożeniu a
pojedyncza aktualizacja może zawierać dowolne
połączenie tych zmian, abyś mógł
wprowadzić zmiany we właściwościach
istniejące zasoby i dodawać nowe zasoby
w tym samym żądaniu aktualizujesz swoje
wdrożenia, najpierw wprowadzając zmiany w
plik konfiguracyjny lub możesz
utwórz plik konfiguracyjny z rozszerzeniem
zmiany, które chcesz, będziesz mieć
opcję wyboru zasad, których chcesz użyć
swoje aktualizacje lub możesz użyć domyślnego
zasady, a na końcu tworzysz
żądanie aktualizacji do menedżera wdrażania i
więc po uruchomieniu wdrożenia
każde wdrożenie ma odpowiedni
zamanifestować się jak w przykładzie pokazanym tutaj a
manifest jest właściwością tylko do odczytu, która
opisuje wszystkie zasoby w twoim
wdrożenia i jest tworzony automatycznie
z każdym nowym manifestem wdrożenia
nie mogą być modyfikowane po ich wykonaniu
stworzony również to nie to samo co a
plik konfiguracyjny, ale jest tworzony na podstawie
w pliku konfiguracyjnym i tak kiedy
usuniesz wdrożenie wszystkie zasoby
które są częścią wdrożenia
usunięte, jeśli chcesz usunąć określone
zasobów z wdrożenia i zachowaj
reszta usuwa te zasoby z
swój plik konfiguracyjny i zaktualizuj plik
zamiast tego wdrożenie
i tak jak widać tutaj wdrożenie
kierownik daje mnóstwo różnych
opcje wdrożenia aktualizacji lub usunięcia
zasobów jednocześnie w chmurze Google
teraz, podobnie jak większość usług w gcp, istnieje
zawsze kilka najlepszych praktyk do naśladowania
pamiętaj, że jest o wiele więcej najlepszych
praktyki dodać do tego i może być
znalezione w dokumentacji, którą zrobię
podaj link do lekcji
tekst, ale chciałem zwrócić uwagę na niektóre
ważne do zapamiętania, więc pierwsze
jeden, który chciałem poruszyć, to złamać
twoje konfiguracje na logiczne
jednostki, więc na przykład powinieneś utworzyć
oddzielne konfiguracje do pracy w sieci
usługi usługi bezpieczeństwa i informatyka
usługi, więc w ten sposób będzie każdy zespół
w stanie łatwo zadbać o swoje
domeny bez konieczności przesiewania przez a
ogromny szablon zawierający kod do
całe środowisko kolejny najlepszy
praktyką do naśladowania jest korzystanie z referencji
a odniesienia powinny być używane dla wartości
które nie są zdefiniowane, dopóki nie zostanie zasób
utworzone, takie jak zasoby self-link ip
adres lub identyfikator wygenerowany przez system bez
odniesienia tworzone przez menedżera wdrażania
wszystkie zasoby równolegle, więc nie ma
zagwarantować, że zasoby zależne są
utworzone we właściwej kolejności za pomocą
referencje wymusiłyby zamówienie w
które zasoby są tworzone jako następne
jest podgląd wdrożeń za pomocą
flaga podglądu, więc zawsze powinieneś
wyświetl podgląd wdrożeń, aby ocenić, jak to zrobić
dokonanie aktualizacji wpłynie na Twoje
menedżer wdrażania wdrażania nie
faktycznie wdrażaj zasoby, gdy ty
podgląd konfiguracji, ale uruchamia makietę
zamiast tego rozmieszczenie tych zasobów
daje to możliwość zobaczenia
zmiany we wdrożeniu przed
zobowiązując się do tego, ty też chcesz
rozważyć zautomatyzowanie tworzenia
projektów, a także automatyzację
tworzenie zasobów w nich zawartych
projektów, a to umożliwia
przyjąć podejście infrastrukturalne jako kod
pozwoli to na zasilenie projektu
możesz podać serię predefiniowanych
środowiska projektowe, które można szybko
i łatwe do zaopatrzenia, to również będzie
pozwalają używać kontroli wersji do
zarządzać podstawową konfiguracją projektu
a także pozwoli na wdrożenie
powtarzalny i spójny projekt
konfiguracje i wreszcie za pomocą a
system kontroli wersji jako część
proces rozwoju dla Twoich wdrożeń
jest świetną najlepszą praktyką do naśladowania
pozwala wrócić do poprzedniego
znana dobra konfiguracja zapewnia
ścieżkę audytu dla zmian, jak również wykorzystuje
konfiguracja jako część a
system ciągłego wdrażania teraz jako
widziałeś tutaj podczas tej lekcji
menedżer wdrażania może być potężny
narzędzie w pasku narzędzi, jeśli chodzi o
wdrażanie infrastruktury jako kodu i
ma nieskończone możliwości, które ty
może odkrywać na własną rękę, może też
zapewnić ogromny nacisk
w kierunku praktyk devops i głową w dół
ścieżka ciągłej automatyzacji
poprzez ciągłą integrację
dostawa ciągła i ciągła
wdrożenie i to właściwie wszystko
chciałem zakryć, jeśli chodzi o
menedżer wdrażania i tak zawsze
jesteś gotowy, dołącz do mnie w następnym
gdzie przejdziemy osobiście w
demonstracja wdrożenia konfiguracji
w menedżerze wdrażania, więc możesz teraz
zaznacz tę lekcję jako zakończoną i
kiedy tylko będziesz gotowy, dołącz do mnie
konsola
[Muzyka]
witamy z powrotem w tej demonstracji, w której jesteśmy
zajmę się wdrożeniem
menedżera i wdrożyć mały serwer WWW
najpierw użyjemy chmury Google
edytor do skopiowania naszego kodu i jesteśmy
potem przeprowadzę próbę i wreszcie
wdrożyć nasz kod, który następnie wykonamy
przewodnik po menedżerze wdrażania w
console i przejdź przez manifest jako
a także niektóre inne funkcje, którymi jesteśmy
następnie zamierzam zweryfikować wszystkie wdrożone
zasoby i możemy zrobić to łatwo
czyszczenie na końcu, naciskając przycisk usuwania
przycisk i dbając o usunięcie dowolnego
zasoby, które zostały utworzone, więc jest
całkiem sporo do przejścia tutaj i tak dalej
powiedziawszy to, zanurzmy się i
więc jak widać tutaj jestem zalogowany jako
tonybowties gmail.com w projekcie
Bowtie Inc teraz, ponieważ będziemy
większość naszej pracy wykonujemy najpierw w kodzie
rzeczą, którą chcemy zrobić, to udać się do
Google Cloud Editor, więc idę
tutaj na górę i otwórz chmurę
shell i zamierzam kliknąć na
przycisk Otwórz edytor, który zamierzam zrobić
ten pełny ekran dla lepszego oglądania i
więc aby uzyskać terminal w
ten sam panel podglądu, co edytor, którym jestem
po prostu przejść do górnego menu
i kliknij terminal i wybierz nowy
terminal teraz dla lepszego oglądania i to
jest dla ciebie całkowicie opcjonalne, zamierzam to zrobić
zmień motyw kolorystyczny na tryb ciemny
więc przechodzę do menu
kliknij plik, przejdź do ustawień i przejdź
do kolorowego motywu i zamierzam
wybierz ciemne studio wizualne i dla nich
z Was, którzy pracują w studio wizualnym
code, może to wyglądać bardzo znajomo
i zamierzam też zwiększyć czcionkę
rozmiar, ponownie wracając do poprzedniego pliku
do ustawień, a następnie ponad, aby otworzyć
preferencje tutaj w obszarze roboczym i
następnie przewiń w dół do terminala
a jeśli przewiniesz w dół do zintegrowanej
rozmiar czcionki zamierzam dostosować czcionkę
rozmiar do 20 dla lepszego oglądania i my
rozmiar czcionki Cloud Shell jest trochę za mały
łatwiej zobaczyć i tak po zakończeniu
aby można było zamknąć preferencje
kartę i jesteśmy teraz gotowi do tworzenia plików
w naszym edytorze w porządku, więc następny chcę
utwórz folder, w którym będą przechowywane wszystkie moje pliki
w, więc przejdę do menu
tutaj wybieram w pliku i
wybierz nowy folder i zamierzam
zmień nazwę tego folderu na szablony i kliknij
ok, a więc teraz, gdy mamy folder
że wszystkie nasze pliki będą aktywne
w następnym kroku jest otwarcie pliku
repozytorium github w edytorze tekstu
i przygotuj pliki do skopiowania
i tak tylko jako uwaga dla tych, którzy są
biegle posługiwać się git
możesz użyć tej nowej funkcji w
edytor Cloud Shell, aby sklonować kurs
repo bez konieczności ponownego tworzenia
pliki, więc przejrzę mój tekst
redaktor i upewnij się, że to zrobiłeś
ostatnio zrobiliśmy git pull, do którego zamierzamy
otwórz pliki w silniku obliczeniowym
menedżera wdrażania, a zobaczysz
szablony z zestawem trzech plików i
już je wygodnie otworzyłem
Idę do góry po muszkę
wdrożyć.yaml i to będzie
plik konfiguracyjny, którym będę
kopiowanie i kiedy skończę kopiować
skończę te wszystkie pliki
przez to trochę szczegółowo
tylko po to, abyś mógł zrozumieć format
taka konfiguracja i tak zamierzam
zaznacz wszystko, co mam zamiar skopiować
to wróć do redaktora i
tutaj mam zamiar wybrać plik nowy plik
więc zmienię nazwę tego na muszkę
myślnik rozmieścić kropkę yaml trafił w porządku i jestem
zamierzam wkleić mój kod i tak to
plik konfiguracyjny pokazuje, że jestem
będzie importować dwa szablony według
nazwa bowtie.webserver.jinja
jak również
bowtie.network.jinja, więc zamierzam
mieć szablon dla mojego serwera WWW i
szablon dla sieci i pod
resources, jak możesz zobaczyć ten kod tutaj
utworzy mój serwer WWW z muszką
typem będzie szablon
właściwości będą miały strefę
typ maszyny, jak również odniesienie do
sieć, jak również pod
serwer WWW Bowtie to sieć Bowtie
i znowu to jest wyciąganie z typu
muszka.sieć.jinja
więc to jest inny plik szablonu i
pod właściwościami mamy region
z nas na wschód i tak zamierzamy
skopiuj te dwa szablony Bowtie Web
serwer i sieć Bowtie, jak potrzebujemy
oba te szablony, aby
ukończ to wdrożenie, więc jestem
zamierzam iść dalej i zrobić to teraz głowa
wracam do mojego edytora kodu, idę
aby przejść do serwera WWW Bowtie, do którego zamierzam
skopiuj wszystko tutaj z powrotem do mojego edytora
i zamierzam utworzyć nowy plik
zwany muszka
serwer WWW to będzie kropka jinja
naciśnij enter, zamierzam wkleić kod
i po prostu zrobić szybki przegląd
szablon, do którego zmierza nazwa instancji
być witryną z muszką, takim typem jest
compute.v1.instancja
i jak widać tutaj używamy a
kilka różnych właściwości tutaj poniżej
zone mamy strefę własności, która jest
zamierzam odwołać się z powrotem do yaml
szablon tutaj pod strefą zobaczysz nas
wschód 1b i tak w ten sposób, jeśli muszę
utwórz inny serwer WWW
Mogę wejść do dowolnej strefy, w której mi się podoba
plik konfiguracyjny i wyjdź z dziobu
tie dash szablon serwera WWW tylko
sposób, w jaki mam typ maszyny
zmienne ustawione zarówno dla strefy, jak i
typ maszyny pod dyskami, do których zamierzam
mieć nazwę urządzenia jako środowisko
zmienna i będzie to a
trwały dysk i obraz źródłowy
będzie debian9, dołożyłem też trochę
metadane tutaj, które przywołają web
server i na koniec mam tag sieciowy
serwera http oraz
konfiguracja interfejsu sieciowego
sieć odnosząca się do Bowtie Dash
sieć i sieć podrzędną zwaną publiczną
które pokażę Wam już za chwilę
moment, a także konfiguracje dostępu do
typ jeden do jednego nat i to będzie
nadaj instancji publiczny adres IP
i teraz, kiedy już przez to przeszliśmy
szablon, który musimy utworzyć ostatni
szablon, który jest kreską muszki
sieć, więc zamierzam wrócić
przejdź do mojego edytora kodu i otwórz
sieć bowtie wybierz kod skopiuj go
wracam do edytora w chmurze i idę
aby utworzyć nowy plik, nazwij tę muszkę
sieć kropka jinja naciśnij enter wklej w my
kod i szybko przeprowadzić Cię przez proces
to będziemy tworzyć nowe
niestandardowa sieć o nazwie Bok tie dash
sieci, jaki będzie typ
obliczeniowa.v1.sieć
ponieważ vpc używa interfejsu API silnika obliczeniowego
będzie to niestandardowa sieć, więc
wartość automatycznie tworzonych sieci podrzędnych to
nazwa będzie fałszywa
być publicznym tutaj mamy zwyczaj
ipcider i możesz również użyć tego
jako zmienna, ale dla tego demo i
zdecydowałem się po prostu zostawić to w sieci i
mieć odniesienie do sieci muszków
wartość dla prywatnego dostępu do Google to
false, a zmienna regionu to
spełnione przez plik konfiguracyjny
poruszając się w prawo, mam dwie zapory ogniowe
zasady tutaj jeden dla dostępu ssh i
inne dla dostępu do serwera WWW jedno otwarcie
do portu 22 na świat, a także do portu
80. jak również dostęp do serwera WWW
reguła zapory ma docelowy tag http
serwer odwołujący się z powrotem do sieci
tag instancji serwera WWW Bowtie
dobrze, więc teraz zakończyliśmy tworzenie
plik konfiguracyjny wraz z
szablony, więc wracam do tematu
do menu kliknij plik i wybierz
zapisz wszystko i odkąd skończyliśmy
tworzenie wszystkich naszych plików następną rzeczą
zrobić, to wykonać próbne wdrożenie za pomocą
Konfiguracja wdrażania muszki, ale
po pierwsze wiem, że nie używaliśmy
menedżer wdrażania wcześniej, więc potrzebuję
wejść i włączyć api, więc jestem
po prostu zamierzam wejść tutaj na szczyt
pasek wyszukiwania i zamierzam wpisać
wdrożenie i powinieneś zobaczyć wdrożenie
menedżer jako pierwszy wynik i przynieść
to trochę w dół i zgodnie z oczekiwaniami
interfejs API menedżera wdrażania nie został
włączone, więc zamierzam kliknąć
włączyć i po kilku chwilach powinniśmy
być gotowym do wyjścia
ok i jak widać tutaj wdrożenie
menedżer jest dość pusty
ponieważ większość z nich odbywa się za pośrednictwem
linii poleceń, ale jeśli chcesz
wdrożyć rozwiązanie rynkowe, które możesz zrobić
to tutaj na górze i to będzie
zabierze cię prosto na rynek i
pozwoli na wdrożenie z dużej
wybór wstępnie skonfigurowanych szablonów
ale nie chcę tego robić i tak robię
tylko trochę podniosę ten temat
i wybieram się na tzw
terminal zamierzam uruchomić ls jestem
zamierzam uruchomić polecenie ls i ty
powinien być w stanie zobaczyć szablony
folder Zamierzam zmienić mój katalog
do folderu szablonów wykonaj kolejny ls
a oto wszystkie moje pliki i tak dalej
robimy próbne wdrożenie tego
konfiguracji chcemy się upewnić
wdrażamy do właściwego projektu, tj
widać tutaj, że jestem obecnie w łuku
tie inc, ale jeśli nie masz pewności
projekt, w którym jesteś, możesz
zawsze uruchamiaj listę konfiguracji gcloud
polecenie w celu potwierdzenia, więc idę
aby szybko wyczyścić ekran i idę
aby uruchomić polecenie gcloud config list
wyświetli monit o autoryzację
to wywołanie api i zamierzam autoryzować
i zgodnie z oczekiwaniami mój projekt jest ustawiony na
wdrożyć w projekcie bowtie inc i tak teraz
że zweryfikowałem to zamierzam to zrobić
szybko wyczyść mój ekran ponownie i tak
zamierzam wkleić moje polecenie gcloud
wdrożenia menedżera pulpitu wdrażania
utwórz wdrożenie muszki, która jest nazwą
rozmieszczenia wraz z
plik konfiguracyjny flag myślnik myślnik config
a następnie nazwę konfiguracji
plik, który jest muszka
wdrożyć.yaml i flagę podglądu jako
robimy tylko próbne wdrożenie, więc jeśli
są jakieś błędy, które będę mógł zobaczyć
to, zanim faktycznie wdrożę wszystkie
zasobów, więc zamierzam iść naprzód i
naciśnij enter i za minutę będziemy
dowiedzieć się, co dokładnie się dzieje
i jak widać tutaj makieta
wdrożenie zakończyło się sukcesem i są
żadnych błędów i jeśli zrobię szybkie odświeżenie
tutaj w konsoli będę mógł zobaczyć
moje wdrożenie, które mogę zgłębić
do i tutaj zobaczę mój manifest
plik z moim imieniem i nazwiskiem manifestu i mogę
wyświetl konfigurację oraz moje szablony
że zaimportował również układ
rozszerzona konfiguracja, więc jeśli kliknę
widok konfiguracji, w której mi się pokaże
prawy panel dokładnie to, co to
wdrożenie zostało użyte do konfiguracji i i
może zrobić to samo z moim szablonem
pliki, więc zamierzam otworzyć moją sieć
szablon i mogę szybko przejść
że gdybym chciał, to też mam
możliwość pobrania go i jeśli naprawdę
chcesz uzyskać szczegółowe informacje, mogę przejść tutaj
do panelu po lewej stronie mogę wybrać na vm
instancja i pokaże mi wszystko
właściwości zasobów wszystko od
dyski do typu maszyny do
metadane interfejsy sieciowe strefa
że jest, a tag sieciowy jest taki sam
rzecz, jeśli przejdę tutaj do sieci
i jeszcze raz, bo taki jest zwyczaj
sieci wartość dla automatycznego tworzenia
subnetworks jest fałszywe, mogę to sprawdzić
publicznej sieci podrzędnej, jak również
reguły zapory ogniowej, a więc ponieważ jest to plik a
podgląd, którego faktycznie nie wdrożono
cokolwiek teraz patrząc na obliczenia
instancje silnika w nowej karcie, możesz
zobacz tutaj, że nie mam instancji
wdrożone, więc to samo dotyczy każdego z nich
inne zasoby, a więc czego chcemy
teraz chcemy to wdrożyć
wdrożenie i możemy to zrobić jedno z dwóch
sposoby, w jakie możemy po prostu kliknąć przycisk
tutaj jest napisane wdrożenie lub możemy uruchomić plik
polecenie w wierszu poleceń, więc jestem
chce ci pokazać, jak to zrobić w
wiersz poleceń, więc przejdę w dół
do wiersza poleceń idę szybko
wyczyść mój ekran
zamierzam wkleić kod, który jest
Menedżer pulpitu wdrażania gcloud
wdrożenia zaktualizuj muszkę wdrażaj teraz
prawdopodobnie zastanawiasz się, po co aktualizować i
dzieje się tak, ponieważ konfiguracja ma
został wdrożony, mimo że jest to wersja zapoznawcza
menedżer wdrażania nadal widzi to jako plik
wdrożenie i stworzył to, co google
cloud wywołuje powłokę i tak za pomocą
update możesz w pełni wdrożyć
konfiguracja przy użyciu ostatniego podglądu do
wykonaj tę aktualizację, a zostanie ona wdrożona
swoje zasoby dokładnie tak, jak je widzisz
manifest i tak za każdym razem, gdy robię
dostosowanie do dowolnej konfiguracji
lub szablony, które mogę po prostu uruchomić
aktualizacja polecenia zamiast wykonywania
całe wdrożenie ponownie, więc chcę dostać
to zostało wdrożone teraz, więc zamierzam to zrobić
wciśnij Enter
i wrócę za minutę, gdy już będzie
wykorzystał wszystkie zasoby i sukces
moje wdrożenie zakończyło się sukcesem i tak jak ty
widać tutaj nie ma żadnych błędów i wszystko
zasoby są w stanie ukończonym
więc wybieram moją muszkę
site w moim manifeście i będę miał
dostęp do zasobu z linkiem w górę
tutaj na szczycie, do którego mnie zaprowadzi
instancja, jak również mogę ssh do
instance i mam te same opcje
które mam w silniku obliczeniowym
console i tak, aby to zweryfikować
wszystkie moje zasoby zostały rozmieszczone
zamierzam wrócić do zakładki, którą i
już otwarte i jak widać moje
instancja została wdrożona i chcę to zrobić
sprawdź, czy moja sieć była
rozmieszczone, więc idę do
menu nawigacyjne i ruszam dalej
aż do sieci vpc i jak widać
tutaj sieć Bowtie została wdrożona
z dwoma odpowiednimi firewallami
zasady, które zamierzam zgłębić
Bowtie network i sprawdź
reguły firewalla i jak widać tutaj
dostęp ssh i dostęp do serwera WWW mają
został utworzony wraz z odpowiadającym mu
protokoły i porty, więc teraz, gdy ja
wiedz, że wszystkie moje zasoby były
wdrożony, do którego chcę wrócić
Compute Engine, aby sprawdzić, czy moja instancja ma
został poprawnie skonfigurowany, więc zamierzam to zrobić
kliknij ssh, aby sprawdzić, czy mogę się połączyć przez ssh
instancja i sukces z ssh, więc i
wiedzieć, że to działa prawidłowo i
więc zamknę tę kartę i
Chcę również zobaczyć, czy mój plik web
serwer został poprawnie skonfigurowany
metadane, które im podałem, więc ja
może bezpośrednio otworzyć stronę internetową przez
po prostu kliknij ten link i sukces
mój, wyglądasz dziś elegancko, dlaczego dziękuję
tony muszka i tak jak widać
serwer WWW został poprawnie skonfigurowany
korzystając z metadanych, które podałem, więc ja
chciałem ci pogratulować, że ci się udało
do końca tego demo i mam nadzieję, że tak się stało
były niezwykle przydatne i dały ci
zrozumienie, jaka jest infrastruktura
kod jest używany w chmurze Google przy użyciu ich
natywne narzędzia, mam nadzieję, że to również się uruchomiło
kilka możliwych przypadków użycia dla ciebie
pozwoli Ci zautomatyzować więcej
zasoby i konfiguracje w twoim
środowisko i pozwalają rozpocząć
innowacje w zakresie fantastycznych nowych sposobów
cicd dla tych z was, którzy są zaznajomieni
z infrastrukturą jako kodem, to może
były odświeżeniem, ale dadzą ci
trochę wglądu w pytania na egzaminie
które obejmują menedżera wdrażania i tylko
jako szybka uwaga dla tych z was, którzy są
chce dowiedzieć się więcej o
infrastruktura jako kod umieściłem kilka
linki w tekście lekcji
głębokość menedżera wdrażania i inny
narzędzie polecane przez Google o nazwie
terraform i tak teraz, zanim pójdziesz my
chcesz wyczyścić wszystkie zasoby, które
wdrożyliśmy, aby zmniejszyć wszelkie poniesione
koszty i ponieważ menedżer wdrażania
ułatwia, możemy to zrobić w jednym prostym
Krok więc ja jadę ogłowić nazad na na drugą
do mojej otwartej karty, w której mam konsolę
otwarte dla menedżera wdrażania i idę
aby przejść do przycisku usuwania i
po prostu kliknij usuń teraz wdrożenie
manager daje mi możliwość usunięcia
wszystkie zasoby, które stworzył, lub po prostu
usunięcie manifestu, ale zachowanie pliku
zasobów nietkniętych i tak chcesz
wybierz usuń muszkę rozłóż ze wszystkimi
jego zasoby i po prostu kliknij usuń
wszystko, a to zainicjuje rozerwanie
wszystkich środków, które były
rozmieszczone z rozmieszczenia muszki
konfiguracji, a to zajmie kilka
minut do zburzenia, ale jeśli kiedykolwiek
mieć większą konfigurację do wdrożenia
tylko jako uwaga, może to trochę potrwać
dłużej zarówno do rozmieszczenia, jak i do zburzenia
i tak po prostu jako podsumowanie, które stworzyłeś
plik konfiguracyjny i dwa szablony w
edytor Cloud Shell, który następnie wdrożyłeś
Twoja konfiguracja za pomocą wdrożenia
menedżera za pomocą wiersza poleceń w
Cloud Shell, które następnie zweryfikowałeś
indywidualny zasób, który został wdrożony
i zweryfikowałem konfigurację każdego z nich
zasób jeszcze raz gratuluję pracy
dobrze zrobione i to właściwie wszystko
chciałem pokryć w tym demo, kiedy to
chodzi o wdrażanie zasobów za pomocą
menedżera wdrażania, dzięki czemu możesz teraz zaznaczyć
to jako kompletne i przejdźmy do
Następny
[Muzyka]
witamy z powrotem i jesteśmy na tej lekcji
zamierzam dowiedzieć się o obciążeniu chmury Google
równoważenie i jak to jest przyzwyczajone
dystrybuować ruch w google
platforma chmurowa ładowanie chmury google
równoważenie jest niezbędne podczas korzystania z niego
z klastrami kubernetes grup instancji
i jest prawie defacto, kiedy to
przychodzi do równoważenia ruchu wchodzącego jako
jak również w twoim środowisku gcp
znając różnice między
rodzaje systemów równoważenia obciążenia i który z nich
zastosowanie w określonych scenariuszach ma kluczowe znaczenie
na egzamin, ponieważ będziesz na nim testowany
a więc jest tu wiele do omówienia
powiedziawszy to, zanurzmy się teraz i
chciał zacząć od podstaw
w odniesieniu do tego, co jest niskim balansem
a więc jeśli chodzi o low balancer
sam niski balanser dystrybuuje użytkownika
ruchu w wielu instancjach
swoją aplikację, więc rozpowszechniając
obciążenia zmniejszasz ryzyko
aplikacje doświadczają wydajności
problemy z systemem równoważenia obciążenia to pojedynczy punkt
wpisu z jednym lub wieloma
zaplecza i w ramach gcp te zaplecza
może składać się z dowolnej grupy instancji
lub negów i wejdę w dowolne g
w tylko trochę niskie wyważarki włączone
gcp są w pełni dystrybuowane i oprogramowanie
zdefiniowane, więc nie ma faktycznego sprzętu
system równoważenia obciążenia zaangażowany w równoważenie niskiego poziomu
na gcp jest całkowicie zdefiniowany programowo
więc nie ma się czym martwić
dowolny sprzęt dowolny czas wstępnego nagrzewania jako
teraz wszystko odbywa się za pomocą oprogramowania
w zależności od tego, jaki low balancer masz
Wybierz Google Cloud daje Ci taką możliwość
posiadania globalnego systemu równoważenia obciążenia
lub regionalnego systemu równoważenia obciążenia
równoważniki mają służyć treści jako
jak najbliżej użytkowników, tak aby
nie doświadczają zwiększonego opóźnienia
i zapewnia użytkownikom lepsze wrażenia
a także zmniejszenie opóźnień w twoim
aplikacje w przypadku niskiego poziomu
wyważarki między usługami google
chmura oferuje również automatyczne skalowanie z
kontroli stanu w swoich systemach równoważenia obciążenia
upewnij się, że Twój ruch jest zawsze
kierowane do zdrowych instancji i przy użyciu
automatyczne skalowanie w stanie zwiększyć kwotę
liczby instancji potrzebnych do obsługi
ładunek automatycznie teraz, jak są
wiele różnych low balancerów do wyboru
z tego pomaga wiedzieć, co konkretnie
aspektów, których szukasz i jak
chcesz rozproszyć ruch i tak dalej
Google podzielił je dla nas na
te trzy kategorie jako pierwsze
kategoria jest globalna kontra regionalna
globalne równoważenie obciążenia jest świetne, kiedy
Twoje tylne końce są rozmieszczone w poprzek
wiele regionów
a Twoi użytkownicy potrzebują do nich dostępu
aplikacji i treści
używając pojedynczego adresu IP anycast
jak również, gdy szukasz ipv6
zakończenie globalnego równoważenia obciążenia
zadbaj o to teraz, jeśli chodzi o to
regionalne równoważenie obciążenia to jest, jeśli
patrzysz na obsługę zaplecza
w jednym regionie i tylko obsługa
ruch IPv4 teraz, gdy już to ustalisz
czy potrzebujesz global vs
regionalne niskie równoważenie drugiego
kategorią, w którą należy się zagłębić, jest zewnętrzna kontra
wewnętrzne zewnętrzne systemy równoważenia obciążenia są
przeznaczony do dystrybucji ruchu przychodzącego
do Twojej sieci z Internetu
i wewnętrzne systemy równoważenia obciążenia są zaprojektowane
dystrybuować ruch w ramach
sieć i wreszcie ostatnia kategoria
które pomogą Ci zdecydować, jaki rodzaj
systemu równoważenia obciążenia, którego potrzebujesz, to ruch
typu i pokazany tutaj jest cały ruch
typy, które obejmują http https tcp i udp
a więc teraz, gdy omówiliśmy
różne rodzaje równoważenia obciążenia
dostępne w chmurze Google, chciałem
zanurzyć się nieco głębiej na niżu
same wyważarki tutaj możecie zobaczyć
że istnieje pięć systemów równoważenia obciążenia
dostępne i będę przechodzić
każdy z nich szczegółowo teraz wcześniej
zanurzając się w samych low balancerach
chciałem przedstawić wam koncepcję
za pomocą gcp
dla wszystkich systemów równoważenia obciążenia zwanych zapleczem
usługi, jak nisko wyważony wie
dokładnie to, co należy zrobić, jest określone przez a
usługa backendowa i tak działa chmura
równoważenie obciążenia wie, jak dystrybuować
ruch w usłudze zaplecza
konfiguracja zawiera zestaw wartości
takie jak protokół używany do połączenia
tylne końce różne dystrybucje w
kontrole kondycji ustawień sesji i
limity czasu te ustawienia zapewniają dobrze
kontrola ziarna nad sposobem załadunku
balancer zachowuje się jak zewnętrzny http lub
System równoważenia obciążenia https musi mieć min
jedną usługę zaplecza i może mieć
wiele usług zaplecza zaplecza
usługi zaplecza może być albo
grupy instancji lub punkt końcowy sieci
grupy znane również jako negs, ale nie a
połączenie obu i tak samo jak a
zauważ, że usłyszysz, jak mówię o negatywach
przebieg tej lekcji i tak a
grupa punktów końcowych sieci znana również jako neg
jest obiektem konfiguracyjnym, który określa
grupa punktów końcowych zaplecza lub
usługi i wspólny przypadek użycia dla tego
konfiguracja wdraża usługi
pojemniki przechodzą teraz do wartości
od siebie chciałem najpierw zacząć
kontrole kondycji i chmura Google używa
ogólny stan zdrowia każdego zaplecza
określić jego kwalifikację do otrzymania
nowe żądania lub zaplecza połączeń
które pomyślnie odpowiadają na
skonfigurowana liczba razy
uważane za zdrowe back-endy, które zawodzą
pomyślnie odpowiedzieć na oddzielne
razy są uważane za niezdrowe
i kiedy back-end jest brany pod uwagę
niezdrowy ruch nie będzie kierowany
następne jest powinowactwo sesji i
koligacja sesji wysyła wszystkie żądania z
tego samego klienta do tego samego zaplecza if
tył jest zdrowy i tak jest
limit czasu usługi pojemności jest następny
wartość i jest to ilość czasu
że system równoważenia obciążenia czeka na a
backend, aby zwrócić pełną odpowiedź do pliku a
kolejnym żądaniem jest dystrybucja ruchu
a to składa się z trzech różnych
wartości pierwszy to tryb równoważenia
i to określa sposób równoważenia obciążenia
mierzy gotowość zaplecza na nowe
żądania lub połączenia z drugim
to pojemność docelowa, a to definiuje a
docelowa maksymalna liczba połączeń a
docelowa maksymalna stawka lub docelowa maksymalna stawka
wykorzystanie procesora i trzecia wartość dla
dystrybucja ruchu jest skalarna
i to dostosowuje ogólnie dostępne
pojemność bez modyfikowania celu
pojemność i ostatnia wartość dla zaplecza
usługi są back-endami, a back-end jest
grupa punktów końcowych, które otrzymują
ruch z chmury Google
Balancer i istnieje kilka rodzajów
zaplecza, ale tym, czym jesteśmy
koncentrując się na tej sekcji i
do egzaminu jest teraz grupą instancji
usługi zaplecza nie są krytyczne
Wiem na egzamin, ale chciałem
zapoznaj się z tą koncepcją, aby dodać a
trochę więcej kontekstu, kiedy jesteś
tworzenie niskich balanserów w dowolnym
środowisko
i pomoże zrozumieć innych
pojęcia w tej lekcji i tak jest
koniec pierwszej części tej lekcji to
robiło się trochę długo, więc zdecydowałem się
zerwij to by było super
okazja, aby wstać i mieć
rozciągnij się, zrób sobie kawę lub herbatę i
kiedy tylko będziesz gotowy, dołącz do mnie częściowo
dwa, od których zaczniemy
zaraz od końca pierwszej części tzw
możesz teraz dokończyć ten film i ja
do zobaczenia w części drugiej
to jest druga część obciążenia chmury
Lekcja balanserów i zaczynamy
dokładnie tam, gdzie skończyliśmy w części pierwszej
powiedziawszy to, przejdźmy teraz do rzeczy
przed przejściem od razu do pierwszego ładunku
balanser, który chciałem przedstawić
który jest niskim balanserem HTTP i https
istnieje kilka różnych koncepcji
które chciałem przedstawić i oto one
metody, jak http i https
system równoważenia obciążenia dystrybuuje ruch za pomocą
reguły przekazywania, a te są krzyżowe
region niskie wyważenie i oparte na treści
równoważenie obciążenia dotyka teraz krzyża
równoważenie obciążenia regionu podczas konfiguracji
zewnętrzny system równoważenia obciążenia http lub https
w warstwie premium używa global
zewnętrzny adres IP i can
inteligentnie kierować żądania od użytkowników
do najbliższej grupy instancji zaplecza lub
neg na podstawie bliskości, na przykład if
konfigurujesz grupy instancji na północy
ameryka i europa i dołącz je do a
low balancers użytkownik usług zaplecza
żądań na całym świecie
automatycznie wysyłane do najbliższych vms
użytkownicy zakładając, że vms przechodzą
kontroli zdrowia i mieć wystarczającą pojemność
jeśli wszystkie najbliższe maszyny wirtualne są w złej kondycji lub
jeśli najbliższa grupa instancji znajduje się w
pojemność i inna grupa instancji to
nie ma możliwości równoważenia obciążenia
automatycznie wysyła żądania do następnego
najbliższy dostępny region
pojemność i tak tutaj na tym diagramie a
użytkownik w szwajcarii osiągnął najniższy poziom
balancer wchodząc na stronę bowtieinc.co i
ponieważ istnieją maszyny wirtualne, które są w stanie
obsługiwać ten ruch w Europie Zachodniej 6
ruch jest kierowany do tego regionu i tak dalej
teraz ładowanie oparte na treści
równoważenie http i https niskie równoważenie
obsługuje równoważenie obciążenia w oparciu o zawartość
za pomocą map adresów URL do wyboru zaplecza
usługi na podstawie żądanej nazwy hosta
zażądaj ścieżki lub obu, na przykład możesz
użyj zestawu grup instancji lub negów do
obsługiwać treści wideo i inne
ustawiony do obsługi statycznej, jak również innej
ustawić do obsługi dowolnych obrazów, które możesz
użyj niskiego równoważenia HTTP lub https z
zasobniki do przechowywania w chmurze, a potem po tobie
skonfiguruj swój system równoważenia obciążenia, możesz
dodaj do niego zasobniki do przechowywania w chmurze
posuwając się naprzód, jeśli chodzi o http
i moduł równoważenia obciążenia https jest to globalny
low balancer warstwy 7 oparty na proxy, który
jest w warstwie aplikacji i tak po prostu
jako uwaga tutaj ze wszystkimi innymi niskimi
balancers, które są dostępne w gcp the
Niski balanser HTTP i https jest jedynym
równoważenie obciążenia warstwy 7, wszystkie inne niskie
balancery w gcp to warstwa 4 i will
praca w warstwie sieciowej i tak dalej
niski balanser umożliwia obsługę
aplikacji na całym świecie za jednym
zewnętrzny adres IP emisji pojedynczej zewnętrzny
Równoważenie obciążenia HTTP i https
dystrybuuje ruch http i https do
zaplecza hostowane na silniku obliczeniowym i
gke zewnętrzne ładowanie http i https
równoważenie jest realizowane na google front
kończy się lub gfes, jak pokazano tutaj w
diagram gfes są dystrybuowane na całym świecie
i działać razem za pomocą Google
globalna sieć i płaszczyzna kontroli w
oferta gfe premium poziomu międzyregionalnego
niskie balansowanie kierujące ruch do
najbliższy zdrowy backend, który ma
pojemność i zakończenie http i https
ruch jak najbliżej Twojego
użytkowników ze standardowym poziomem obciążenia
równoważenie jest obsługiwane regionalnie i to
dostępny jest moduł równoważenia obciążenia
zarówno zewnętrznie, jak i wewnętrznie
czyni ten system równoważenia obciążenia globalnym zewnętrznym
i wewnętrzny ten moduł równoważenia obciążenia również
zapewnia obsługę https i ssl, które
obejmuje tls do szyfrowania podczas przesyłania jako
cóż, ten moduł równoważenia obciążenia akceptuje wszystko
ruchu niezależnie od tego, czy jest to ipv4, czy ipv6
ruch i po prostu wiedz, że ruch IPv6
zakończy się na niskim balansie i
wtedy przekaże ruch jako ipv4
tak naprawdę nie ma znaczenia, jaki rodzaj
ruch, który wysyłasz do modułu równoważenia obciążenia
nadal będzie kierować ruch do tyłu
zakończ używanie ipv4, którym jest ten ruch
dystrybuowane według lokalizacji lub treści jako
pokazany na poprzednim schemacie przekazywania
istnieją zasady dystrybucji zdefiniowane
targets do każdej puli docelowej dla
grupy instancji ponownie zdefiniowały cele
może być oparty na treści, a zatem jako
pokazano na poprzednim schemacie wideo
zawartość może trafić do jednego celu, podczas gdy
zawartość statyczna może przejść do innej
docelowe mapy adresów URL kierują Twoje żądania
w oparciu o reguły, dzięki czemu możesz stworzyć grupę
zasad w zależności od rodzaju
ruch, który chcesz kierować, i umieść je
w mapach żądań certyfikatów ssl
są potrzebne dla https i mogą być
zarządzane przez Google lub samodzielnie zarządzane
i tak tylko jako szybka uwaga tutaj
porty używane do http to 80 i 8080
jak również na https port, który jest używany
czy port 443 przechodzi teraz do następnego najniższego poziomu
balancer to ssl proxy niski proxy ssl
równoważenie to odwrotne ładowanie proxy
balancer, który dystrybuuje ruch ssl
pochodzących z Internetu do maszyny wirtualnej
instancje podczas korzystania z ładowania proxy ssl
równoważenie ruchu SSL użytkownika ssl
połączenia są zakończone przy niskim poziomie
warstwa równoważąca, a następnie proxy do
najbliższe dostępne instancje zaplecza według
za pomocą ssl lub tcp z premią
tier ssl proxy niskie równoważenie może być
skonfigurowane jako globalne równoważenie obciążenia
usługa ze standardową warstwą ssl
moduł równoważenia obciążenia proxy obsługuje niski poziom
równoważenia regionalnego tego systemu równoważenia obciążenia
dystrybuuje również ruch według lokalizacji
pozwala na to tylko niskie równoważenie serwera proxy ssl
używać jednego adresu IP dla wszystkich użytkowników
na całym świecie i jest systemem równoważenia obciążenia warstwy 4
który działa na warstwie sieciowej this
moduł równoważenia obciążenia pokazuje wsparcie dla tcp z
odciążenie ssl i to jest coś
szczególne, aby pamiętać o tym na egzaminie
nie przypomina ładowania http lub https
balancer, w którym możemy zastosować określone reguły
lub określone konfiguracje w celu
niski balanser proxy ssl ruchu bezpośredniego
obsługuje zarówno ipv4, jak i ipv6, ale znowu to
kończy się na module równoważenia obciążenia i
przekazuje ruch do zaplecza jako
obowiązują reguły ruchu i przekierowania IPv4
miejsce do dystrybucji każdego zdefiniowanego celu
do odpowiedniej puli docelowej i szyfrowania
jest wspierany przez konfigurację back-endu
usług, aby zaakceptować cały ruch
ssl teraz tak samo jak uwaga, może to być również
używany dla innych protokołów, które używają ssl
takie jak gniazda sieciowe i imap przez ssl
i przenoszą wiele otwartych portów
wspierać ich w przejściu do następnego ładunku
balancer to proxy tcp, teraz proxy tcp
moduł równoważenia obciążenia to odwrotne ładowanie proxy
balancer, który dystrybuuje ruch tcp
pochodzących z Internetu do maszyny wirtualnej
wystąpień podczas korzystania z ładowania proxy tcp
równoważenie ruchu przechodzącego przez tcp
połączenie zostaje zakończone przy obciążeniu
warstwa równoważąca, a następnie przekazywana do
najbliższy dostępny backend używający tcp
lub ssl, więc tutaj jest niski balanser
określi, które instancje są w
pojemność i wysłać je do nich
instancje, które nie są jak proxy ssl
równoważenie obciążenia równoważenie obciążenia tcp proxy
pozwala używać jednego adresu IP dla wszystkich
użytkowników na całym świecie obciążenie proxy tcp
balancer automatycznie kieruje ruch do
tylne końce, które są najbliżej
użytkownik jest to moduł równoważenia obciążenia warstwy 4 i
ponownie może obsługiwać ruch zarówno globalnie
i zewnętrznie dystrybuuje proxy tcp
ruch tylko według lokalizacji i jest zamierzony
dla ruchu innego niż HTTP
chociaż możesz zdecydować, czy chcesz
użyj ssl między serwerem proxy a plecami
koniec i możesz to zrobić, wybierając a
certyfikat na zapleczu ponownie to
typ modułu równoważenia obciążenia obsługuje ipv4 i
ruch IPv6 i ruch IPv6 będą
zakończyć na dolnym balanserze i
przekazuje ten ruch do zaplecza jako
ruch ipv4 teraz niskie równoważenie proxy tcp
jest przeznaczony dla ruchu tcp i obsługuje
wiele znanych portów, takich jak port 25
dla prostego protokołu przesyłania poczty lub
smtp obok mamy obciążenie sieci
balancer teraz obciążenie sieci tcp udp
balancer to regionalne obciążenie tranzytowe
balancer system równoważenia obciążenia sieciowego
rozdziela ruch tcp lub udp między
instancji w tej samej sieci regionu
moduły równoważenia obciążenia nie są serwerami proxy i
dlatego odpowiedzi z zaplecza
vms trafiają bezpośrednio do klientów
nie z powrotem przez moduł równoważenia obciążenia
termin znany z tego to serwer bezpośredni
powrót, jak pokazano tutaj na schemacie this
to regionalny system równoważenia obciążenia warstwy 4 i
zewnętrzny moduł równoważenia obciążenia, jak również to
może służyć do lokalizacji regionalnych to
obsługuje tcp lub udp, ale nie oba
chociaż może obniżyć równowagę udp tcp i
ruch SSL na portach, które nie są
obsługiwane przez tcp proxy i ssl proxy
ruch ssl może być nadal odszyfrowywany przez
twój tył zamiast ładunku
Balancer sam ruch jest również
dystrybuowane przez przychodzące dane protokołu
jest to schemat i zakres protokołów
nie ma odciążania ani proxy tls
i obowiązują zasady przekazywania
dystrybuować i definiować cele dla nich
docelowe pule, a to jest dla tcp i udp
tylko teraz z innymi protokołami, których używają
instancje docelowe w przeciwieństwie do instancji
grupuje wreszcie system równoważenia obciążenia sieciowego
może też tylko wspierać
w przeciwieństwie do samozarządzanych certyfikatów SSL
do certyfikatów zarządzanych przez Google jako
no i tak ostatni low balancer do
wprowadzenie to wewnętrzny system równoważenia obciążenia
teraz wewnętrzny moduł równoważenia obciążenia tcp lub udp
to regionalny system równoważenia obciążenia warstwy 4
umożliwia dystrybucję ruchu z tyłu
wewnętrzny adres IP równoważenia obciążenia
który jest dostępny tylko dla twojego wewnętrznego
Instancje vm wewnętrzne ładowanie tcp i udp
równoważenie rozdziela ruch między vm
instancje w tym samym regionie to ładowanie
balancer obsługuje ruch tcp lub udp, ale
nie oba i jak powiedziałem przed tym typem
równoważenia obciążenia służy do równoważenia
ruch w gcp między instancjami this
low balancer nie może być używany
równoważenie ruchu internetowego w obecnej postaci
tylko ruch wewnętrzny jest automatycznie
wysyłane do zaplecza, ponieważ tak nie jest
zakończyć połączenia klienckie i dla
reguły przekazywania dla tego systemu równoważenia obciążenia
przestrzega określonych specyfikacji, gdzie
musisz określić co najmniej jeden i więcej
do pięciu portów według liczby, a także musisz
określ wszystkie, aby przekazywać ruch do wszystkich
porty teraz ponownie, podobnie jak obciążenie sieci
balancer możesz użyć tcp lub udp
i to właściwie wszystko, co musiałem
przykryj lekcją na temat niskiego balansu
pamiętaj proszę o tym na egzaminie
będzie musiał znać różnice
między nimi wszystkimi
z mojego doświadczenia wynika, że ​​jest ich kilka
pytania, które pojawiają się na egzaminie gdzie
będziesz musiał wiedzieć, jaki low balancer
używać, więc dobrym pomysłem może być
wejdź do konsoli i zobacz
opcje, jak również powrót
przez tę lekcję jako odświeżenie
zrozumieć każdy przypadek użycia, jest to również a
kluczowy element w każdym środowisku
który jest używany zwłaszcza podczas serwowania
aplikacje do internetu dla każdego
trójwarstwowa aplikacja internetowa lub kubernetes
klastra i tak to właściwie podsumowuje
tę lekcję na temat niskiego równoważenia, abyś mógł
teraz zaznacz tę lekcję jako ukończoną i
przejdźmy do następnego
witam z powrotem w tej lekcji będę
zagłębianie się w grupy instancji
wraz z instancją szablonów instancji
grupy to świetny sposób na założenie grupy
identycznych serwerów używanych w połączeniu
z szablonami instancji grup instancji
obsługuje właściwości instancji do
wdrożyć grupy instancji w swoim
środowisko, w które zagłębimy się w tej lekcji
szczegóły przypadków użycia funkcji
oraz w jaki sposób grupy instancji i instance
szablony współpracują ze sobą, tworząc plik
wysoce skalowalny i wydajny
środowisko, teraz jest wiele do omówienia
tutaj, więc powiedzmy, że nurkujemy
obecnie grupa instancji jest kolekcją
instancji vm, którymi możesz zarządzać jako
silnik obliczeniowy pojedynczej jednostki oferuje dwa
rodzaje zarządzanych grup instancji maszyn wirtualnych i
niezarządzane zarządzanie grupami instancji lub migracjami
pozwalają obsługiwać aplikacje na wielu
identyczne maszyny wirtualne, które możesz wykonać
skalowalne i wysoce dostępne, biorąc
zaletą zautomatyzowanych usług mig, takich jak
automatyczne skalowanie automatyczne leczenie regionalne i
wdrożenia strefowe i automatyczne aktualizacje
i wezmę się za te usługi
w ciągu sekundy, jeśli chodzi o
niezarządzane grupy instancji, na które również pozwalają
niskie saldo we flocie maszyn wirtualnych
ale to jest coś, czego potrzebujesz
zarządzać i będę wchodził głębiej
niezarządzane grupy instancji nieco później
teraz chciałem poświęcić trochę czasu
przejrzyj funkcje i przypadki użycia
migs bardziej szczegółowo, aby uzyskać więcej informacji
kontekst zaczynając od przypadków użycia
teraz migs świetnie nadają się do obsługi bezpaństwowców
obciążenia robocze, takie jak frontony witryn internetowych
serwery i aplikacje internetowe, jak np
aplikacja nie zachowuje swojego stanu
i nie zapisuje żadnych danych w pamięci trwałej
wszystkie dane użytkownika i sesji pozostają w
klienta i umożliwia skalowanie w górę iw dół
szybkie i łatwe migi są również świetne
bezstanowe obciążenia wsadowe i są to
wysoka wydajność lub wysoka przepustowość
obciążenia obliczeniowe, takie jak image
przetwarzanie z kolejki i wreszcie ty
może budować wysoce dostępne stanowe
obciążenia przy użyciu stanu zarządzanego
grupy instancji lub migi stanowe
obciążenia stanowe obejmują aplikacje
z danymi stanowymi lub taką konfiguracją
jako bazy danych
starsze aplikacje typu monolit i
długotrwałe obliczenia wsadowe z
punktów kontrolnych możesz poprawić dyspozycyjność i
sprężystość tego typu
aplikacje z funkcją automatycznego leczenia
kontrolowane aktualizacje i wielostrefowe
wdrożeń przy zachowaniu każdego z nich
unikalny stan instancji, w tym
nazwy instancji dyski trwałe i
metadane teraz, gdy omówiłem ten typ
obciążeń, które są używane z migs i
chciałem zagłębić się w funkcje
zaczynając od automatycznego leczenia
teraz, jeśli chodzi o automatyczne leczenie
zarządzanych grup instancji utrzymuje się na wysokim poziomie
dostępność Twoich aplikacji wg
proaktywne utrzymywanie instancji w pliku a
stan pracy mig automatycznie
odtwarza instancję, która nie jest
działające i zarządzane grupy instancji również
zadbaj o auto oparte na aplikacjach
gojenie, co poprawia aplikację
dostępność polegając na zdrowiu
sprawdź, czy wykrywa rzeczy takie jak zamrażanie
awaria lub przeciążenie, jeśli zdrowie
check określa, że ​​aplikacja ma
nie powiodło się na maszynie wirtualnej z automatycznym uzdrowieniem mig
automatycznie odtwarza tę instancję maszyny wirtualnej
kontrola stanu używana do monitorowania
migs są podobne do kontroli stanu
używany do niskiego równoważenia z kilkoma małymi
różnice niskie równoważenie kontroli zdrowia
pomóż skierować ruch z dala od
niereagujące przypadki i ku
zdrowe, te kontrole zdrowotne nie mogą
odtworzyć instancje, podczas gdy mig health
sprawdza proaktywnie sygnał do usunięcia i
odtworzyć wystąpienia, które stają się w złej kondycji
przejście do zarządzanych grup instancji
funkcja regionalna lub wielostrefowa teraz ty
mają możliwość tworzenia regionalnych
migi lub migi strefowe
regionalne migs zapewniają wyższe
dostępność w porównaniu z migami strefowymi
ponieważ instancje w regionalnym mig
są rozsiane po wielu strefach w
jeden region google zaleca regionalny
migs nad strefowymi migami, jak możesz zarządzać
dwa razy więcej migów niż migów strefowych, więc ty
może zarządzać 2 000 migs zamiast 1000
możesz również rozpowszechnić swoją aplikację
ładuj w wielu strefach zamiast a
pojedyncza strefa lub zarządzanie wieloma strefami
migs w różnych strefach i to
chroni przed awariami strefowymi i
nieprzewidziane scenariusze, w których całość
grupa instancji w jednej strefie
awarie w przypadku strefy
niepowodzenie lub jeśli grupa instancji w pliku a
strefa przestaje odpowiadać na regionalną mig
nadal wspiera Twoje instancje przez
nadal obsługuje ruch ul
instancji w pozostałych strefach
niskie równoważenie chmury może korzystać z instancji
grupy do obsługi ruchu, aby można było je dodawać
grupy instancji do puli docelowej lub do
zaplecza, którego typem jest grupa instancji
zaplecza i instancje w
grupa instancji odpowiada na ruch z
system równoważenia obciążenia usługa zaplecza
z kolei wie, jakich instancji może użyć
i jaki ruch mogą obsłużyć i
jaki jest obecnie ruch
obsługa dodatkowo zaplecza
usługa monitoruje sprawdzanie stanu i
nie wysyła nowych połączeń do
niezdrowe przypadki teraz, gdy twój
aplikacje wymagają dodatkowej mocy obliczeniowej
zasoby migs obsługują automatyczne skalowanie
dynamicznie dodawać lub usuwać instancje z
mig w odpowiedzi na wzrost lub
spadek obciążenia można włączyć auto
skalowanie i skonfigurować automatyczne skalowanie
zasady, aby określić, w jaki sposób chcesz grupę
to scale nie tylko automatycznie skaluje
skalować, aby sprostać wymaganiom obciążenia, ale
zmniejszy również i usunie instancje jako
obciążenie zmniejsza się, aby obniżyć koszty
zasady automatycznego skalowania obejmują skalowanie
w oparciu o równoważenie obciążenia procesora
metryki monitorowania pojemności i chmury
a więc jeśli chodzi o automatyczną aktualizację
możesz łatwo i bezpiecznie wdrożyć nowe
wersje oprogramowania do instancji w a
mig następuje wdrożenie aktualizacji
automatycznie na podstawie Twojego
Specyfikacje można również kontrolować
szybkość i zakres wdrożeń w
w celu zminimalizowania zakłóceń w Państwa
aplikację, którą możesz opcjonalnie wykonać
aktualizacje kroczące, jak również częściowe
rollouty do testowania kanarków i dla
ci, którzy nie znają aktualizacji kroczących
zezwalaj na aktualizacje z zerem
przestoje poprzez stopniową aktualizację
instancje z nowymi, a także kanarek
testowanie jest sposobem na zmniejszenie ryzyka i
weryfikować nowe oprogramowanie, wydając je
oprogramowanie dla niewielkiego odsetka użytkowników
z testami kanarków, do których możesz dostarczyć
określonych grup użytkowników w danym momencie i
jest to również określane jako etap
rolloutów i jest to najlepsza praktyka w
Devops i tworzenie oprogramowania teraz
jest jeszcze kilka rzeczy, które ja
chciałem zaznaczyć, że odnoszą się do migs
możesz obniżyć koszty swojej pracy
przy użyciu instancji maszyn wirtualnych z możliwością wywłaszczania w
Twoja grupa instancji i kiedy są
usunięte automatyczne leczenie przyniesie
instancje z powrotem, gdy można wywłaszczać pojemność
stanie się ponownie dostępny, ty też możesz
wdrażaj kontenery w instancjach w
zarządzane grupy instancji, gdy określisz
obraz kontenera w instancji
szablon i służy do tworzenia mig
każda maszyna wirtualna jest tworzona z kontenerem
zoptymalizowany system operacyjny, który zawiera Docker i
Twój kontener uruchamia się automatycznie
każdy vm w grupie i wreszcie kiedy
tworząc migi, musisz zdefiniować vpc
sieć, w której będzie rezydować
gdy nie zdefiniujesz sieci google
cloud spróbuje użyć wartości domyślnej
sieć przechodzi teraz w stan niezarządzany
grupy instancji tylko na minutę
mogą zawierać niezarządzane grupy instancji
heterogeniczne przypadki i takie są
instancje o różnych rozmiarach procesora
ram, a także typy instancji i ty
może dodawać i usuwać te instancje z
grupa, kiedy tylko wybierzesz, jest
poważny minus tego, choć niezarządzany
grupy instancji nie oferują auto
skalowanie aktualizacji automatycznej naprawy
obsługuje obsługę wielu stref lub korzystanie z
szablony instancji i nie są dobre
nadające się do wdrażania wysoce dostępnych i
skalowalnych obciążeń, których należy używać tylko
niezarządzane grupy instancji, jeśli potrzebujesz
zastosuj równoważenie obciążenia do ich grup
mieszane typy instancji lub jeśli potrzebujesz
tak samodzielnie zarządzać instancjami
projektowane są niezarządzane grupy instancji
do bardzo specjalnych przypadków użycia, w których ty
będzie musiał mieszać typy instancji
prawie we wszystkich przypadkach, których będziesz używać
zarządzane grupy instancji bez zmian
mający na celu uchwycenie korzyści wszystkich
jakie funkcje mają do zaoferowania
teraz, aby uruchomić grupę instancji
w dowolne środowisko, którego będziesz potrzebować
inny zasób do tego i to jest
gdzie do gry wchodzą szablony instancji
szablon instancji jest zasobem, który
możesz użyć do tworzenia instancji vm i
zarządzana instancja grup instancji
szablony definiują rozruch typu maszyny
obraz dysku lub obraz kontenera, a także
etykiety i inne właściwości instancji
może następnie użyć szablonu instancji do
utwórz instancję instancji mig lub vm
szablony to łatwy sposób na zapisanie maszyny wirtualnej
konfiguracja instancji, abyś mógł z niej korzystać
to później odtworzyć vms lub grupy
vms szablon instancji
jest globalnym zasobem, który nie jest związany
do strefy lub regionu, chociaż możesz
ograniczyć szablon do strefy przez wywołanie
obecnie dostępne są określone zasoby strefowe
jest czymś, na co warto zwrócić uwagę, kiedy jesteś
kiedykolwiek używałeś migs, jeśli chcesz utworzyć plik
musisz mieć grupę identycznych instancji
użyj szablonu instancji, aby utworzyć mig
i jest czymś, co zawsze powinieneś zachować
z przodu umysłu podczas korzystania z mig
te dwa zasoby są instancjami
szablony i zarządzane grupy instancji
ramię w ramię teraz kilka innych rzeczy
należy zauważyć, że szablony instancji są
zaprojektowany do tworzenia instancji z
identyczne konfiguracje, więc nie możesz
zaktualizować istniejący szablon instancji lub
zmienić szablon instancji po tobie
utwórz go, jeśli chcesz wprowadzić zmiany
konfiguracja
możesz utworzyć nowy szablon instancji
stworzyć szablon na podstawie istniejącego
szablon instancji lub oparty na
istniejąca instancja, aby użyć istniejącej maszyny wirtualnej
aby utworzyć szablon, który możesz zapisać
konfiguracja za pomocą polecenia gcloud
szablony myślników instancji gcloud tworzą lub
aby skorzystać z konsoli, wystarczy przejść do niej
na stronie szablonów instancji kliknij na
szablon, który chcesz zaktualizować i
kliknij utwórz podobne ostatnia rzecz
na co chciałem zwrócić uwagę, to ty
możesz używać niestandardowych lub publicznych obrazów w swoim
szablony instancji i to jest ładne
dużo wszystko, co musiałem pokryć, jeśli chodzi o
grupy instancji i szablony instancji
świetnie sprawdzają się zarządzane grupy instancji
gdy zależy Ci na wysokiej dostępności
jako priorytet i pozwolić migom robić wszystko
praca nad utrzymaniem środowiska
i działa, więc możesz to teraz zaznaczyć
lekcja jako kompletna i kiedykolwiek jesteś
gotowy, dołącz do mnie w następnym, w którym my
zapoznaj się z grupami instancji
szablony instancji i systemy równoważenia obciążenia w
demo
witamy z powrotem w tym demo, które zamierzamy zrobić
umieść wszystko, czego się nauczyliśmy
razem w praktycznym demo o nazwie
zarządzanie muszkami, które zamierzamy stworzyć
szablon instancji, a następnie jesteśmy
użyje go do utworzenia instancji
grupę, którą następnie stworzymy niski
balancer z nowym zapleczem i utwórz
jakieś kontrole zdrowia po drodze jesteśmy
następnie zamierzam sprawdzić, czy wszystkie instancje
pracują, przeglądając ładunek
balancer ip i weryfikacja strony
aplikację, którą następnie będziemy stresować
przetestuj jedną z instancji, aby zasymulować a
skaluj w poziomie za pomocą automatycznego skalowania, a następnie
będziemy symulować skalowanie
grupa instancji z powrotem, teraz jest całkiem
trochę do zrobienia tutaj, więc z tym powiedziane
zanurzmy się, więc tutaj jestem zalogowany jako
tony muszki na gmail.com w ramach projektu
Bowtie Inc i tak pierwszą rzeczą, która
chcesz zrobić, to chcesz się upewnić
że masz domyślną sieć vpc
już utworzone, a więc po prostu podwoić
sprawdź, czy pójdę do
menu nawigacji zamierzam przewinąć w dół
do sieci vpc
i tak, mam domyślną sieć vpc
więc idę dalej i zaczynam
tworzenie moich zasobów, a więc co teraz i
chcę zrobić, to chcę stworzyć mój
szablon instancji i tak, aby to zrobić
że zamierzam wrócić do
menu nawigacyjne, do którego zejdę
Compute Engine i przejdź do instancji
szablony, jak widać i obecnie
nie mają żadnych szablonów instancji i twoje
powinien wyglądać tak samo, więc możesz iść
naprzód i kliknij utwórz instancję
szablon i tak jak notatka są
żadnych miesięcznych kosztów związanych z
szablony instancji, ale to oszacowanie
tutaj po prawej stronie jest pokazanie
koszt każdej instancji, którą będziesz
tworzenie za pomocą tego szablonu w porządku, więc
dostając prawo do tego ja jadę nazwać
ten szablon instancji
szablon muszki a skoro już się kręcimy
w górę wiele vms, które chcesz być świadomy
na kosztach, a więc w ramach serii jesteś
zamierza kliknąć menu rozwijane i
zamierzasz wybrać n1 i poniżej
typ maszyny, którą zamierzasz wybrać f1
micro i jest to najmniejsza instancja
typu, a także najtańszy w obrębie
Google Cloud możesz śmiało przewijać
w dół do samego dołu tutaj poniżej
zapora sieciowa, którą chcesz zaznaczyć, zezwól
ruch http, który chcesz wybrać
zarządzanie dyskami bezpieczeństwa sieci i
sprzedany najem, przewiń trochę w dół
bit i pod skryptem startowym jesteś
zamiar wkleić w skrypcie, który jest
dostępne w repo, a znajdziesz
link do tego skryptu i repozytorium w
tekst lekcji i możesz zostawić wszystko
inne opcje jako domyślne i
po prostu kliknij na utwórz to będzie
poświęć tutaj kilka minut, dobrze i
szablon instancji jest gotowy, więc plik
następnym krokiem, który chcesz zrobić, jest utworzenie
grupa instancji i jak powiedziałem w a
poprzednią lekcję, aby stworzyć
grupa instancji potrzebujesz instancji
szablon, dlatego stworzyliśmy tę instancję
szablon najpierw w porządku i nasza instancja
szablon został utworzony i tak teraz
że utworzyłeś swoją instancję
szablon, do którego możesz przejść
grupy instancji tutaj w lewej ręce
menu i zgodnie z oczekiwaniami nie ma
grupy instancji i możesz iść dalej
i kliknij duży niebieski przycisk i
utwórz grupę instancji, do której się wybierasz
upewnij się, że nowe wystąpienie zarządzane
wybrano grupę bezpaństwowców i tutaj ty
mają możliwość wyboru stanowego
grupa instancji, jak również niezarządzana
grupa instancji i tak zrobimy
utrzymuj rzeczy bezpaństwowe i tak dla
nazwę grupy instancji, którą możesz
po prostu zadzwoń do tej grupy z muszkami, do której idę
używać tej samej nazwy w opisie
i pod lokalizacją, którą chcesz zaznaczyć
wiele stref w wybranym regionie
aby wybrać nas na wschód i jeśli klikniesz
na konfiguracji stref możesz to zobaczyć tutaj
możesz wybrać wszystkie różne strefy
który jest dostępny w tym regionie
wybierz, aby mieć swoje instancje i tak dalej
zamierzam trzymać to pod wszystkimi trzema
strefy, które przewinę tutaj w dół a
trochę i pod szablonem instancji
powinieneś zobaczyć szablon muszki, który możesz
zaznacz, że możesz trochę przewinąć w dół
nieco więcej, a tutaj pod minimalną liczbą
liczby instancji, dla których chcesz ustawić minimum
liczbę instancji do 3 i mniej
maksymalną liczbę instancji, które chcesz
ustaw to na 6 i tak będzie
podwoić liczbę minimalną
instancji, więc kiedy jesteś skalowany w poziomie
powinieneś mieć maksymalnie 6 instancji
a kiedy jesteś skalowany lub masz
bardzo mały ruch, który powinieneś mieć
trzy instancje, abyś mógł przewinąć w dół
trochę więcej i pod automatycznym leczeniem
chcesz wybrać kontrolę stanu i
zamierzasz iść naprzód i stworzyć
nowa kontrola zdrowia pod nazwą, pod którą możesz zadzwonić
te zdrowe muszki, których zamierzam użyć
to samo dotyczy opisu i jestem
pozostawi resztę jako domyślną
i zejdź w dół i kliknij zapisz i
kontynuuj, przewiń trochę w dół
więcej, a resztę zostawię bez zmian
jest i po prostu kliknij na utwórz i to
zajmie kilka minut tutaj i
więc zatrzymam wideo i zrobię to
wróć w mgnieniu oka, dobrze i moja instancja
grupa została utworzona i tak, aby uzyskać
lepiej spójrz na to, mam zamiar kliknąć
grupa muszka i tutaj to widzę
utworzono trzy instancje, jeśli i
przejdź do instancji vm, które możesz zobaczyć tutaj
że mam trzy instancje, ale poniżej
grupy instancji, ponieważ mam zdrowie
zaznacz włączone, pokazuje, że moje instancje
są niezdrowe, a to dlatego, że ja
nadal musisz utworzyć regułę zapory
co pozwoli na sprawdzenie stanu Google
sondy, aby dotrzeć do moich instancji vm i tak dalej
zamierzasz iść naprzód i stworzyć to
reguły zapory sieciowej, aby można było przenieść plik
status kontroli zdrowia do zdrowego, więc jestem
przejść do menu nawigacji
i przewiń w dół do sieci vpc i przejdź
przejdź do zapory tutaj pod zaporą ogniową jako
spodziewałem się, że masz domyślną zaporę ogniową
reguły z domyślnego utworzonego vpc
sieć i tak mam zamiar przejść do
utwórz zaporę ogniową i możesz to nazwać
reguła zapory zezwól na sprawdzenie stanu jestem
użyje tego samego dla
opis przewinę w dół
tutaj trochę i pod celami jestem
zamiar wybrać wszystkie instancje w
filtr źródła sieciowego, który zamierzam opuścić
jako zakresy ip, a więc tutaj pod źródłem i
zakresy p, które chcę wprowadzić w adresie IP
adresy dotyczące kondycji chmury Google
sprawdź sondy i możesz je znaleźć w
dokumentację i ja też będę
podanie ich w instrukcjach i
istnieją dwa zestawy adresów IP
należy wprowadzić i tylko jako notatkę
nie musisz tego wiedzieć na egzamin
ale zawsze dobrze jest wiedzieć, czy jesteś
kiedykolwiek dodawać kontrole stanu do któregokolwiek z twoich
przypadki, w których przewinę w dół a
trochę do protokołów i portów i
pod tcp zamierzam to sprawdzić i
ustaw port 80. to prawie wszystko
musisz to zrobić tutaj, więc kiedy tylko
wprowadziłeś wszystkie te informacje, które możesz
po prostu kliknij na tworzenie i tak teraz mam
reguła zapory, która zezwoli na zdrowie
kontrole do wykonania, więc może to potrwać
minuta lub dwie, ale jeśli wrócę
do moich instancji silnika obliczeniowego i gotowe
przejdź do moich grup instancji
będę mógł zobaczyć, że wszystkie moje
instancje są teraz zdrowe i tak
za każdym razem, gdy tworzysz grupy instancji
i stosujesz to sprawdzenie stanu
reguła zapory jest konieczna, więc proszę
świadomy, dobrze, więc teraz, gdy stworzyliśmy nasz
szablony instancji, które stworzyliśmy
grup instancji i utworzyliśmy plik
reguły zapory w celu zaspokojenia zdrowia
czeki, możemy teraz przejść do następnego
krok, który tworzy moduł równoważenia obciążenia
więc wracam do tzw
menu nawigacyjne i zamierzam przewinąć
do usług sieciowych i do
równoważenie obciążenia i zgodnie z oczekiwaniami są
nie utworzono równoważników obciążenia i tak dalej
kiedy będziesz gotowy, możesz kliknąć
duży niebieski przycisk i stwórz nowe minimum
Balancer tutaj masz możliwość
tworzenie modułu równoważenia obciążenia http lub https
wraz z modułem równoważenia obciążenia tcp lub udp
system równoważenia obciążenia i dlatego, że obsługujemy
ruch zewnętrzny na porcie 80 idziemy
korzystać z modułu równoważenia obciążenia http, abyś mógł
kliknij na rozpocznij konfigurację i jestem
poproszony o podjęcie decyzji pomiędzy
skierowane do Internetu lub tylko wewnętrzne i
będziesz akceptować ruch
z Internetu do Twojego bramkarza obciążenia
więc upewnij się, że z internetu do mojego
vms jest zaznaczone i po prostu kliknij
kontynuuj i tak będziesz następna
monit ze stroną z wiązką
konfiguracje, które możesz wprowadzić i tak
przejdziemy do tego za chwilę, ale
najpierw musimy nazwać nasz system równoważenia obciążenia
i tak zamierzam to nazwać
Bowtie Dash lb dla low balancera i tak dalej
następnym krokiem dla Twojego systemu równoważenia obciążenia jesteś Ty
musisz skonfigurować zaplecze, abyś mógł
kliknij konfigurację zaplecza i tutaj
masz możliwość wyboru spośród
usługi zaplecza lub zasobniki zaplecza tzw
idziesz dalej i klikasz
usługi back-end i stworzyć back-end
service i tutaj zostaniesz poproszony
z mnóstwem pól do wypełnienia
aby utworzyć usługę zaplecza
i możesz śmiało nazwać
usługa backendu jako backend bowtie
będzie typ zaplecza usługi
grupę instancji i możesz opuścić
protokół o nazwie port i limit czasu tak jak jest
będziemy używać http pod
grupa instancji w nowym zapleczu, jeśli ty
wybierz listę rozwijaną, którą powinieneś zobaczyć
dostępna grupa wystąpień grupy muszki
wybierz to
przewiń trochę w dół i poniżej portu
numery, które możesz wprowadzić w porcie 80 i ty
może pozostawić wszystkie inne opcje jako
default i po prostu kliknij gotowe i tak dalej
jeśli kiedykolwiek będziesz zainteresowany, zawsze możesz
dodaj pamięć podręczną za pomocą Cloud CDN, teraz wiem
nie przeszliśmy przez cdn w chmurze
tego kursu, ale po prostu wiedz, że tak jest
sieć dostarczania treści Google i to
korzysta z globalnej sieci brzegowej Google
serwować treści bliżej użytkowników i to
przyspiesza Twoje strony internetowe i Twoje
aplikacji i zapewnia lepszego użytkownika
doświadczenie dla użytkownika w porządku i w ruchu
tutaj pod kontrolą stanu, jeśli kliknę
na liście rozwijanej powinieneś zobaczyć zdrowy łuk
krawaty możesz wybrać to dla swojego zdrowia
sprawdzić i tak tylko jako uwaga tutaj poniżej
zaawansowane konfiguracje, które możesz ustawić
powinowactwo sesji Twoje połączenie
limit czasu opróżniania, a także żądanie i
nagłówki odpowiedzi, więc nie potrzebujemy
cokolwiek z tego dla tego demo, więc jestem
zamierzam iść naprzód i zawalić to i
po zakończeniu wypełniania wszystkich
pola, które możesz po prostu kliknąć na utwórz
w porządku, więc powinieneś teraz mieć swoje
konfiguracja zaplecza i hosta oraz
reguły ścieżki skonfigurowane i tak jedyne
rzeczą, która pozostała do skonfigurowania jest
przedni koniec, dzięki czemu możesz przejść w górę i kliknąć
konfiguracja front-end i możesz nazwać
Twoja usługa front-end z muszką
zachowam protokoły http i tutaj
to miejsce, w którym należy wybrać sieć
poziom usług wybierając opcję premium lub
standard i jeśli pamiętasz w obciążeniu
lekcja równoważenia, aby użyć tego jako
globalny system równoważenia obciążenia, którego muszę użyć
poziom premium w porządku i zamierzamy to zrobić
zachowaj to jako ipv4 z efemerycznym adresem IP
adres na porcie 80, więc kiedy już to zrobisz
zakończyłem konfigurowanie interfejsu użytkownika
możesz po prostu kliknąć gotowe i możesz iść
i kliknij recenzję i sfinalizuj oraz
to da ci podsumowanie twojego
konfiguracji i tak jestem zadowolony z
sposób, w jaki wszystko jest skonfigurowane i jeśli ty
są równie dobrze można po prostu kliknąć
utworzyć, co może zająć minutę lub dwie
ale stworzy to twój niski balans
wraz z tyłem i przodem
koniec, więc znowu zatrzymam
wideo tutaj przez minutę i będę
wróć, zanim będziesz mógł powiedzieć kot w kapeluszu
w porządku, a mój moduł równoważenia obciążenia został
stworzony i dostać trochę więcej
szczegóły, które zamierzam zgłębić
i widzę tutaj szczegóły mojego
load balancer wraz z moim monitoringiem
i wszelkie buforowanie, ale nie mam żadnego
buforowanie włączone i dlatego nic nie jest
pokazując więc wracając do szczegółów i
widać tutaj, że mam nowy ip
adres mojego modułu równoważenia obciążenia i będę
wchodzę w to za chwilę
zamierzam tu wrócić i zamierzam
sprawdź moje tylne końce kliknij na muszkę
usługa zaplecza i tutaj widzę
żądań na sekundę, a także my
konfiguracji i jeśli to widzisz
symbol ostrzegawczy tutaj pokazuje, że niektóre z
twoje instancje są niezdrowe, to tylko
ponieważ low balancer potrzebuje czasu
wykonaj pełną kontrolę stanu wszystkich
instancje w grupie instancji i tak dalej
to zajmie trochę czasu, więc jestem
Zamierzam wrócić i sprawdzić moje
przód i nie ma co wiercić
w dół do usługi front-end, ale
pokazuje mi mój zakres adresu
protokół
poziom sieci i sam low balancer
więc to już koniec części pierwszej
demo robiło się trochę długie, więc ja
postanowił zerwać to byłoby
świetna okazja, aby wstać
się rozciągnąć, zrób sobie kawę lub herbatę
a kiedy będziesz gotowy, część druga będzie
zaczynać się natychmiast od końca
część pierwsza, dzięki czemu możesz teraz oznaczyć to jako
skończ i do zobaczenia w części drugiej
to druga część łuku zarządzającego
demo krawatów i zaczynamy
dokładnie tam, gdzie skończyliśmy w części pierwszej
powiedziawszy to, zanurzmy się i
więc zanim pójdziesz do przodu, chcesz
upewnij się, że wszystkie twoje instancje są
uznane za zdrowe przez system równoważenia obciążenia
i jak widzę tutaj wszystkie moje instancje
w mojej grupie instancji są brane pod uwagę
zdrowe przez moduł równoważenia obciążenia i tak po prostu
aby to zweryfikować, pójdę dalej i
skopiuj adres IP i możesz otworzyć
nową kartę w przeglądarce i po prostu
wklej to
i sukces, jak widać tutaj zarządzanie
produkcja wielu muszek może być
zautomatyzowane, ale zarządzające użytkownikiem
oni zdecydowanie nie mogą kolejnej grzywny
wiadomość od ludzi z Bow tie Inc
teraz, chociaż jest to prosta strona internetowa i
użyłem kilku zmiennych, żeby ci pokazać
niskie wyważenie, które ma miejsce w
tło i ruch zostaną załadowane
zrównoważony pomiędzy wszystkimi instancjami
w grupie instancji, więc jeśli klikniesz
odśwież, powinieneś zobaczyć maszynę
nazwa i centrum danych zmieniają się więc co roku
kiedy kliknę odśwież, ruch będzie
kierowane do innej instancji w a
inna strefa i tak prosta
symulacja, w jaki sposób ruch jest niski bilans
między różnymi instancjami w ich
różne strefy w porządku, więc teraz, kiedy to zrobiliśmy
zweryfikowałem aplikację internetową i'm
zamierzam zamknąć tę kartę i tak teraz
że stworzyliśmy nasz szablon instancji
stworzyliśmy naszą grupę instancji i
stworzyliśmy nasz low balancer z
usługi back-end i front-end i to
wygląda na to, że wszystko wydaje się być
dobrze ze sobą współpracując zamierzamy
śmiało i symuluj skalowanie w poziomie za pomocą
automatyczne skalowanie i tak w celu symulacji
na tym zrobimy test warunków skrajnych
jeden z przypadków, więc idę
wróć do menu nawigacji
przewiń w dół do silnika obliczeniowego i tutaj
możesz ssh do dowolnego z nich
instancji i uruchom test warunków skrajnych
tam, więc wybiorę tutaj
u góry i tak zawsze, gdy jesteś zalogowany
w możesz po prostu wkleić polecenie
które zawarłem w instrukcji
który przeprowadzi test warunków skrajnych i tak dalej
jest to aplikacja do testów warunków skrajnych o nazwie
stres, który był zawarty w starcie
skrypt, a to znowu spowoduje stres
sam serwer i uruchomić skalę
na zewnątrz, aby obsłużyć ładunek i to zrobi
przez 30 sekund, abyś mógł kontynuować i
naciśnij enter i wróć do
konsoli i za około minutę lub dwie ty
powinien zobaczyć kilka nowych instancji, które to zrobią
zostać utworzony przez Twoją grupę instancji w
aby obsłużyć ładunek w porządku i po
pokazuje się tutaj przez około kilka minut
że tworzone są instancje i to
będzie skalować się do maksimum
ilość instancji, które ustawiłem
czyli sześć, które zamierzam zgłębić
zaangażowany w to
i tak, skalowanie się dzieje i
tworzone są nowe instancje
poradzić sobie z obciążeniem, więc zamierzam to dać
tylko minutę tutaj dobrze i jak możesz
zobacz tutaj wszystkie przypadki
utworzone zostały dodane do
grupa instancji i wszystkie z nich są
oznaczone jako zdrowe i tak tylko w celu weryfikacji
że wszystkie instancje działają
iść dalej i otworzyć nową kartę
zamierzam podłączyć adres IP
mój moduł równoważenia obciążenia i zamierzam po prostu
przejdź przez wszystkie te instancje do
upewnij się, że wszystkie działają i
wygląda na to, że nie mam problemów i tyle
teraz, gdy symulowałeś skalowanie w poziomie i
chciałem iść do przodu i uruchomić skalę
więc najpierw je zamknę
zakładki teraz w odniesieniu do skalowania tam
to 10-minutowy okres stabilizacji
nie można dostosować do skalowania i tego
to wbudowana funkcja chmury Google
teraz, ponieważ szanuję twój czas jako
uczniu, pokażę ci pracę
wokół, aby uruchomić wagę wcześniej
ściśle dla tego demo i ja też chciałem
ostrzec, że nigdy tak nie powinno być
wykonane w produkcji lub podobne do produkcji
środowisko, na które zawsze powinieneś czekać
skalowanie dzieje się samo i
nigdy nie używaj tej metody na siłę
wyłącznie do celów edukacyjnych, aby zapisać
ty jakiś czas, więc idę
przejdź do górnego menu i kliknij
toczący się restart i wymiana i to
wyświetli nową stronę, na której będziesz
mieć opcję ponownego uruchomienia lub
zastąp wszystkie instancje w swojej instancji
grupa i tak dla twoich celów pod
operacji upewnij się, że masz
ponowne uruchomienie zaznaczone i to będzie
zrestartuj wszystkie swoje instancje i tylko
przywołaj te, które są potrzebne, więc jestem
idź dalej i kliknij restart
wracam do mojej instancji
konsola grupowa i po prostu dam
to kilka minut na gotowanie i będę
z powrotem w mgnieniu oka, tak to wygląda
jakby grupa instancji została przeskalowana
i jesteśmy teraz w lewo do trzech
instancje minimum, które skonfigurowaliśmy
dla naszej grupy instancji i tak dalej
właściwie obejmuje zarządzanie muszkami
demo, więc chciałem ci pogratulować
przetrwanie tego demo i mam nadzieję
w którym było to niezwykle przydatne
doskonalić swoją wiedzę na temat zarządzania
zarządzana instancja szablonów instancji
grup i tworzenie systemów równoważenia obciążenia za pomocą
usługi back-end i front-end teraz to
było wypełnione po brzegi demo i było
dużo do spakowania ze wszystkim, co masz
wyciągnął wnioski z kilku ostatnich lekcji i tak dalej
tak jak podsumowanie stworzyłeś instancję
szablon ze skryptem startowym ty
następnie utworzył nową grupę instancji z a
sprawdzenie stanu, aby przejść do konfiguracji
automatyczne skalowanie dla minimum trzech
przypadkach utworzyłeś następnie zaporę ogniową
reguła, aby sondy kontroli stanu
mogli połączyć się z aplikacją
a następnie utworzyłeś moduł równoważenia obciążenia
z usługą back-end i front-end
i zweryfikowałem, że strona internetowa
aplikacja rzeczywiście działała
następnie przeprowadziłeś test warunków skrajnych, aby umożliwić
symulacja skali poza twoją
grupa instancji, a następnie symulowane a
Skaluj swoją grupę instancji świetnie
pracę i teraz, kiedy to zakończyliśmy
demo chcesz się upewnić, że jesteś
nie kumulując zbędnych kosztów
więc idę przed siebie i chodzę
Cię przez podział usuwania
wszystkie te zasoby, więc jesteś pierwszy
zamierzam iść dalej i usunąć ładunek
balancer wróć do nawigacji
menu i przewiń w dół do usług sieciowych
i przejdź do równoważenia obciążenia, więc jestem
iść do przodu i odhaczyć muszkę
lb i po prostu przejdź do góry i kliknij
przy usuwaniu zapyta mnie, czy jestem
pewnie, że chcę to zrobić, też to zrobię
wybierz usługę końcową muszki i i
może usunąć mój system równoważenia obciążenia i moje plecy
zakończ usługę naraz idę
forward i usuń moduł równoważenia obciążenia oraz plik
wybrane zasoby
i to powinno się wyjaśnić w ciągu kilku
sekund w porządku, a nasz system równoważenia obciążenia ma
został usunięty, po prostu pójdę w górę
tutaj do tyłu, upewnij się
wszystko w porządku, tak, wszyscy jesteśmy czyści
to samo z przednim końcem, więc teraz ty
mogę przejść do grup instancji, więc jestem
wracamy do nawigacji
menu przejdź w dół silnika obliczeniowego i przejdź w górę
do grup instancji i tutaj możesz po prostu
po prostu zaznacz grupę muszki i
po prostu kliknij usuń
zostanie wyświetlony monit z a
powiadomienie, aby upewnić się, że chcesz
usuń grupę muszków tak, chcę
usuń i znowu powinno to zająć około
minuta w porządku, to faktycznie zajęło parę
minut, ale moja grupa instancji była
usunięte, więc teraz przechodzę
do szablonów instancji i zamierzam to zrobić
usuń mój szablon i odhacz muszkę
szablon i po prostu kliknij usuń jesteś
pojawi się monit, aby się upewnić
chcesz usunąć szablon instancji
tak, chcesz usunąć
i sukces usunąłeś teraz wszystkie swoje
zasobów, chociaż jest jeszcze jeden
zasób, za który nie zostaniesz obciążony
ale skoro wszystko sprzątamy
równie dobrze moglibyśmy to posprzątać
i to jest reguła zapory, którą my
utworzony i przejdź do nawigacji
menu i przewiń w dół do sieci vpc
zamierzam przejść do zapory tutaj na
menu po lewej stronie i tutaj idę
zaznacz opcję Zezwalaj na kontrolę stanu
regułę zapory i po prostu kliknij usuń
otrzymam monit, aby się upewnić
że chcę to usunąć, tak, chcesz
usuń, szybko kliknę odśwież
i tak, usunęliśmy to i tak to
kończy koniec tego demo, więc ty
mogę teraz oznaczyć to jako ukończone i zrobię to
do zobaczenia w kolejnym
witamy ponownie w następnej sekcji my
skupi się na Google Cloud
najlepsza usługa orkiestracji kontenerów
zwane kubernetes, ale zanim będziemy mogli nurkować
prosto do Kubernetes i korzyści
które daje do pojemników, których będziesz potrzebować
zrozumienie, jakie pojemniki
są i jaką wartość dostarczają kontenery
ta lekcja, którą omówię
różnica między maszynami wirtualnymi a
kontenery jakie kontenery są jakie są
pracy i proponowanej wartości
przynieś tak z tym powiedziawszy, zanurkujmy
W
teraz dla tych z Was, którzy nie wiedzieli
technologia kontenerów wzięła swoją nazwę
produkty przemysłu żeglugowego otrzymują
umieszczone w standardowej wysyłce
pojemniki zaprojektowane tak, aby pasowały
na statek, który mieści
standardowy rozmiar kontenera zamiast
posiadające obecnie różne rozmiary opakowań wg
standaryzację i utrzymanie tego procesu
elementy razem pojemnik może być
przeniesiony jako jednostka i kosztuje mniej
to także w ten sposób standaryzacja
pozwala na spójność podczas pakowania i
przesuwanie kontenerów, na których są umieszczane
statki i doki oraz magazyn nr
bez względu na to, gdzie jest pojemnik, zawsze
pozostaje ten sam rozmiar i zawartość
odizolować się od wszystkich innych
pojemniki, w których są ułożone
i tak teraz, zanim przejdziemy do
szczegóły dotyczące pojemników, które chciałem omówić
jak się tu znaleźliśmy i dlaczego
więc świetnym sposobem na omówienie kontenerów jest
poprzez ich porównanie do wirtualnych
maszyny teraz, jak omówiliśmy w a
poprzednia lekcja, jeśli chodzi o vms the
systemy są zwirtualizowane przez a
hypervisor, który znajduje się na górze
podstawowa infrastruktura hosta
bazowy sprzęt jest zwirtualizowany
że wiele instancji systemu operacyjnego
może działać na sprzęcie, na którym działa każda maszyna wirtualna
własny system operacyjny i ma do niego dostęp
zwirtualizowane zasoby reprezentujące
podstawowego sprzętu z powodu tego procesu
vms wiążą się z kosztami dużych narzutów
w pamięci procesora i na dysku, jak również może być
bardzo duży ze względu na fakt, że każdy vm
potrzebuje własnej, indywidualnej obsługi
systemowi tam również brakuje standaryzacji
między każdą maszyną wirtualną, co czyni je wyjątkowymi
do konfiguracji systemu operacyjnego oprogramowania
zainstalowane i biblioteki oprogramowania
w ten sposób nie czyni go bardzo przenośnym
w stanie działać w dowolnym środowisku teraz, kiedy
do czynienia z kontenerami rzeczy są uruchamiane
bardzo różnie bazowego hosta
infrastruktura nadal istnieje, ale
zamiast po prostu używać hiperwizora i
abstrakcji podstawowego sprzętu
konteneryzacja zajmuje jeden krok
dalej i streszcza działanie
system
zatem
pozostawiając aplikację ze wszystkimi
zależności w starannie zapakowanym
znormalizowany pojemnik, za pomocą którego to się odbywa
instalacja systemu operacyjnego na wierzchu
infrastruktury hosta
a następnie oddzielną warstwę na wierzchu
system operacyjny hosta o nazwie
silnik kontenera teraz zamiast mieć
własny system operacyjny
kontenery współdzielą system operacyjny
jądro z innymi kontenerami
działając niezależnie
uruchamiając tylko kod aplikacji i
zależności potrzebne do uruchomienia tego
aplikacja pozwala na to każdy pojemnik
zużywać bardzo mało pamięci lub dysku
dzięki czemu pojemniki są bardzo lekkie
wydajne i przenośne w kontenerach
aplikacje można uruchomić w kilka sekund i
wiele innych wystąpień aplikacji
może zmieścić się na maszynie w porównaniu do
VM, którym może teraz być ten kontener
przeniesione do innych środowisk
działające okno dokowane i mogące działać bez
martwiąc się o wpadnięcie
problemy ze zgodnością teraz chociaż
istnieje kilka różnych pojemników
silniki tam ten, który ma
największą popularnością cieszy się docker
i to jest silnik, którym będziemy
odnosząc się do pozostałej części tego
oczywiście teraz obraz dokera to a
kolekcja lub stos warstw, które są
utworzone z kolejnych instrukcji na
plik dokera, więc każda linia w pliku
dockerfile jest uruchamiany linia po linii i a
unikalna warstwa tylko do odczytu jest zapisywana w pliku
image, co sprawia, że ​​obrazy dokera są wyjątkowe
że za każdym razem dodajesz kolejną
instrukcja w pliku dokera a new
warstwa jest tworzona teraz przechodząc przez a
praktyczny przykład tutaj pokazany na
right jest plikiem dokera i będziemy
w stanie odwzorować każdą linię kodu na warstwę
pokazany na obrazie okna dokowanego po lewej stronie
linia oznaczona od
pokazuje obraz bazowy, który będzie wyświetlany na obrazie
korzystać z pokazanego tutaj przykładu
że wersja obrazu ubuntu 12.04
zostanie użyty obok instrukcji run
używany, który przeprowadzi ogólną aktualizację
zainstaluj Apache 2 i wyślij wiadomość do
być wyświetlany, który jest zapisany w
plik index.html następny działa
katalogi i są to
zmienne środowiskowe ustawione za pomocą
env instrukcja, a to pomoże uruchomić
następną warstwą środowiska uruchomieniowego Apache jest
ujawnić instrukcję i jest to używane
udostępnij port kontenera na 8080 i
wreszcie warstwa poleceń to
instrukcja, która wykonuje Apache
serwer WWW z jego ścieżki wykonywalnej i
więc jest to doskonały przykład tego, jak a
plik docker jest podzielony na poszczególne elementy
linię, aby utworzyć warstwy tego obrazu
i tak tylko jako uwaga tutaj każdego okna dokowanego
obraz zaczyna się również od obrazu podstawowego
każda linia w pliku dokera tworzy nowy
warstwa, która jest dodawana do obrazu i
wreszcie wszystkie warstwy w obrazie dokera
są tylko do odczytu i nie można ich zmienić
chyba że plik dokera jest dostosowany do
odzwierciedlić tę zmianę
więc teraz, jak uzyskać z obrazu dokera
do kontenera oraz działającego okna dokowanego
container jest w rzeczywistości instancją
obrazu, więc kontenery używają tego samego
obraz są identyczne w
warunki ich kodu aplikacji i
zależności środowiska wykonawczego, więc mogłem użyć
ten sam obraz dla wielu kopii
ten sam kontener, który ma różne zadania
co sprawia, że ​​każdy pojemnik jest pojedynczy
różny
jest to, że działające kontenery obejmują a
zapisywalna warstwa na górze tylko do odczytu
zmiany środowiska uruchomieniowego zawartości, w tym wszelkie
prawa i aktualizacje danych i plików są
zapisane w tej warstwie odczytu i zapisu, więc w
ten przykład podczas używania polecenia
docker run fashionistka docker
kontener zostanie utworzony z pliku
obraz dokera i warstwa do odczytu i zapisu
zawsze dodawane na wierzchu tylko do odczytu
warstw podczas tworzenia kontenera
zapisanie wszelkich niezbędnych plików, tj
potrzebne do aplikacji i tak po prostu
jako uwaga tutaj są kontenery dokerów
zawsze tworzone z obrazów dokerów i
kontenery mogą jeszcze używać tego samego obrazu
zawsze będzie miał inny odczyt i zapis
warstwy bez względu na ilość pojemników
działa na danym hoście, więc teraz, kiedy twój
kontenery zostały utworzone, potrzebujesz a
miejsce do ich przechowywania, więc jest to miejsce
rejestr kontenerów wchodzi teraz w grę
rejestr kontenerów to pojedyncze miejsce
do przechowywania i zarządzania dokerem
obrazy teraz podczas tworzenia okna dokowanego
plik, a następnie zbuduj swój obraz
chcesz zapisać ten obraz w pliku
centralne repozytorium obrazów, czy to a
prywatny lub publiczny popularny
publicznym rejestrem kontenerów jest centrum dokowania
i jest to wspólny rejestr, w którym wiele
można znaleźć obrazy open source
łącznie z tymi stosowanymi jako warstwa podstawowa
obrazy takie jak przykład ubuntu, że i
pokazałem ci wcześniej i tak raz masz
swoje kontenery w rejestrze kontenerów
musisz umieć je uruchomić
kontenery, aby je uruchomić
kontenery, których potrzebujesz hostów dokerów i
mogą one składać się z dowolnej działającej maszyny
silnik dokera i to może być twoje
laptop
serwer lub możesz je uruchomić w dostarczonym
hostowanych środowisk chmurowych teraz może
były odświeżeniem dla niektórych, ale dla
ci z was, którzy są nowicjuszami w kontenerach i
mam nadzieję, że dało ci to dużo więcej
jasność co do tego, czym są kontenery
robić i wartość, jaką wnoszą do każdego
środowisko i to całkiem sporo
wszystko, co chciałem zawrzeć w tym krótkim
lekcja wprowadzenia do pojemników
więc możesz teraz oznaczyć tę lekcję jako
zakończyć i przejść do następnego
jeden
witaj z powrotem, więc teraz, kiedy już dostałeś
wie, czym są kontenery i
jak działają, w które chciałem się zagłębić
platforma Google Cloud jako usługa
oferta dla kontenerów o nazwie google
silnik kubernetes znany również jako krótki jako
gke teraz, chociaż egzamin przechodzi do a
bardziej operacyjna perspektywa z
pozdrowienia dla gke znającego podstawę
kubernetes i różne tematy
kubernetes jest koniecznością, aby to zrobić
zrozumieć abstrakcje, które biorą
miejsce z gke ze zwykłych kubernetes
w tej lekcji będę wchodzić
kluczowe tematy dotyczące kubernetes
i będziemy dotykać
architektura
komponenty i sposób ich działania
wspólnie osiągnąć pożądany stan
dla Twoich kontenerowych obciążeń już teraz
jest wiele do zrobienia, więc z tym
mówiąc, zanurkujmy teraz, zanim ja
mogę dostać się do gke, muszę ustawić scenę
na wyjaśnienie, co jest umieszczane w kubernetes
po prostu kubernetes to orkiestracja
platforma dla kontenerów, która była
wynaleziony przez Google i ostatecznie otwarty
source jest teraz utrzymywany przez cncf
skrót od cloud native computing
fundacji i osiągnął niesamowite
zapewnia powszechna adopcja kubernetes
platforma do automatyzacji planowania i uruchamiania
kontenery na klastrach fizycznych lub
wirtualne maszyny
eliminując w ten sposób wiele instrukcji
procesy związane z wdrażaniem i
skalowanie aplikacji kontenerowych
kubernetes zarządza kontenerami, które
uruchomić aplikacje i upewnić się, że
nie ma przestojów w sposób, w jaki ty
użytkownik może zdefiniować
na przykład, jeśli zdefiniujesz to, gdy a
kontener spada i kolejny
kontener musi uruchomić kubernetes
zająłby się tym za Ciebie
automatycznie i płynnie kubernetes
zapewnia ramy do uruchomienia
systemów rozproszonych wymaga odporności
dbanie o skalowanie i przełączanie awaryjne
aplikacja udostępnia wzorce wdrażania
i pozwala zarządzać swoimi
aplikacje z ogromną elastycznością
niezawodność i moc współpracuje z
gama narzędzi kontenerowych, w tym
docker teraz, chociaż ta adopcja była
rozpowszechniony, przyszedł z różnymi
wyzwania obejmowały skalowanie na cd
automatyczne skalowanie dostępności równoważenia obciążenia
tworzenie sieci
wycofywanie wadliwych wdrożeń i tak dalej
wiele więcej
więc teraz rozwinęła się chmura Google
zarządzana oferta dla Kubernetes
zapewnienie zarządzanego środowiska dla
wdrażanie zarządzania i skalowania
konteneryzowane aplikacje za pomocą Google
infrastruktura środowisko gke
składa się z instancji silnika obliczeniowego
zgrupowane, tworząc klaster i
zapewnia takie same korzyści jak
on-premises Kubernetes jeszcze ma
wyabstrahował złożoność konieczności
martwić się o sprzęt i na dodatek
off ma zalety zaawansowane
funkcje zarządzania klastrami, które google
zapewnia chmura
z takimi rzeczami jak równoważenie obciążenia w chmurze
i jest w stanie rozłożyć ruch między
klastry i węzły pule węzłów do
wyznaczyć podsieci węzłów w obrębie a
klaster dla dodatkowej elastyczności
automatyczne skalowanie węzła Twojego klastra
liczba instancji i automatyczne aktualizacje
również dla oprogramowania węzłów klastrów
pozwala utrzymać stan węzła i
dostępność z automatyczną naprawą węzłów i
zajmuje się logowaniem i monitoringiem
z pakietem operacyjnym Google Cloud dla
widoczność w twoim klastrze, tak jak ty
widać tutaj gke ma wiele zalet
jeśli chodzi o uruchamianie kubernetes w
Google Cloud, więc chciałem wziąć
chwila, aby zanurzyć się w klastrze
architekturę i pomóc w zapoznaniu się
ze wszystkimi składnikami wchodzącymi w skład a
klaster, więc klaster jest podstawą
Google Kubernetes Engine i
kubernetes jako całość kubernetes
przedmioty, które reprezentują twoje
wszystkie aplikacje kontenerowe działają
szczyt klastra w gke a cluster
składa się z co najmniej jednej płaszczyzny sterowania
i wiele maszyn roboczych o nazwie
węzły płaszczyzna kontrolna i węzeł
maszyny obsługują klaster Kubernetes
odpowiada samolot kontrolny
koordynować cały klaster i to
może obejmować planowanie obciążeń, takich jak
aplikacje kontenerowe i zarządzanie
skalowanie cyklu życia obciążenia i
uaktualnieniami zarządza również płaszczyzna kontroli
dla nich zasoby sieciowe i pamięci masowej
obciążenia pracą, a przede wszystkim to
zarządza stanem klastra i
upewnij się, że jest teraz w pożądanym stanie
węzły to maszyny robocze, które
uruchamiaj konteneryzowane aplikacje i
inne obciążenia, węzły są obliczeniowe
instancje maszyn wirtualnych, na których tworzy gke
w Twoim imieniu podczas tworzenia klastra
każdy węzeł jest zarządzany z kontrolki
samolot, który otrzymuje aktualizacje na każdym z nich
stan węzła zgłaszany przez samego węzła również
prowadzi usługi niezbędne do obsługi
kontenery dokerów, które składają się na twoje
obciążenia klastra obejmują m.in
środowisko uruchomieniowe dokera i węzeł kubernetes
agent znany jako sześcian, który
komunikuje się z płaszczyzną sterowania i
jest odpowiedzialny za uruchamianie i jazdę
kontenery dokerów zaplanowane w tym węźle
teraz zanurzając się głębiej w architekturę
w kontrolce znajdują się komponenty
samolot i węzły, które powinieneś
zapoznać się z takimi
elementy są tym, co łączy klaster
razem i pomaga zarządzać
orkiestracja, jak i państwo teraz
płaszczyzna kontrolna jest zunifikowana
punkt końcowy dla klastra kontrolka
elementy samolotu podejmują globalne decyzje
o klastrze, na przykład planowanie
jak również wykrywanie i reagowanie na nie
zdarzenia klastra wszystkie interakcje z
klastry są wykonywane za pośrednictwem kubernetes api
wzywa, a samolot kontrolny uruchamia
proces serwera api Kubernetes do obsługi
te żądania możesz wykonać kubernetes
api wywołań bezpośrednio przez http lub grpc lub
można to zrobić również pośrednio, biegając
polecenia z polecenia kubernetes
klient liniowy o nazwie cubectl i oczywiście
możesz wchodzić w interakcje z interfejsem użytkownika w
Konsola chmurowa to proces serwera interfejsu API
centrum całej komunikacji dla
klaster przechodzi do następnego komponentu
to program do planowania kostek to program do planowania kostek
składnik, który wykrywa i przypisuje
nowo utworzone strąki do węzła dla nich
uruchomić, więc wszystkie nowe strąki, które są tworzone
zostanie do niego automatycznie przypisany
odpowiedni węzeł przez program planujący kostki
biorąc pod uwagę wszelkie
następne są ograniczenia
menedżer kontrolera kostki i to jest to
komponent, który uruchamia kontroler
przetwarza i odpowiada za rzeczy
jak zauważanie i reagowanie na węzły
spadać
utrzymanie prawidłowej liczby strąków
wypełnianie usług i podów również
jak tworzenie domyślnych kont i api
tokeny dostępu dla nowych przestrzeni nazw
te kontrolery, które w zasadzie będą
spójrz, aby wprowadzić zmiany w klastrze kiedy
obecny stan nie spełnia
pożądany stan teraz, jeśli chodzi o
menedżer kontrolera chmury, oto co
osadza specyficzną dla chmury logikę sterowania
Menedżer kontrolera chmury umożliwia połączenie
swój klaster do dowolnych dostawców chmury
interfejs API
i oddziela elementy, które
wchodzić w interakcje z tą platformą chmurową z poziomu
komponenty, które po prostu wchodzą w interakcję z twoim
klastrować menedżera kontrolera chmury
uruchamia tylko określone kontrolery
w takim przypadku do dostawcy usług w chmurze
Google Cloud i wreszcie mamy fcd i
ten składnik jest odpowiedzialny za przechowywanie
stan klastra na cd to a
spójny i wysoce dostępny klucz
magazyn wartości, który współdziała tylko z
api serwer zapisuje wszystkie
dane konfiguracyjne wraz z jakimi węzłami
są częścią klastra i jakie strąki
jeżdżą, więc teraz kontrola
samolot potrzebuje sposobu na interakcję z
węzły klastra, a więc węzły
mając same komponenty do tego
komunikacji występuje ten składnik jest
zwany sześcianem, a to jest agent
który działa na każdym węźle w klastrze
który komunikuje się z płaszczyzną sterowania
odpowiada za uruchamianie i
uruchamianie kontenerów dokerów zaplanowanych na
ten węzeł wymaga zestawu specyfikacji pod
które są mu dostarczane i zapewnia to
pojemniki opisane w tych strąkach
specyfikacje działają i są zdrowe, a ja to zrobię
później zagłębimy się w specyfikacje strąków
następną lekcją jest proxy kostki i to jest to
komponent utrzymujący sieć
łączność z podami w klastrze
i wreszcie środowisko wykonawcze kontenera to
oprogramowanie odpowiedzialne za uruchomienie
kontenery kubernetes obsługuje kontener
środowiska wykonawcze, takie jak doker i kontener d oraz
więc to są główne składniki w a
klaster obejmujący płaszczyznę kontrolną i
węzłów w zakresie komunikacji
w klastrze teraz, zanim to zakończę
lekcja jest jeszcze jeden temat, który chciałem
dotykać w odniesieniu do
architektura klastra gke i tyle
jest abstrakcją, która się dzieje i co
dokładnie zarządza gke w odniesieniu do
kubernetes dobrze gke zarządza wszystkimi
komponenty płaszczyzny kontrolnej punkt końcowy
udostępnia serwer api kubernetes, który
cubectl używa do komunikowania się z twoimi
płaszczyzna kontroli klastra punkt końcowy
udostępnia serwer api kubernetes, który
cubectl używa do komunikowania się z twoimi
płaszczyzna sterowania klastrem, którym jest punkt końcowy ip
wyświetlany w konsoli chmury i ten adres IP
pozwoli Ci na interakcję z
cluster po uruchomieniu polecenia gcloud
klastry kontenerów uzyskują poświadczenia kreski
widzisz, że polecenie dostaje
punkt końcowy klastra w ramach aktualizacji
cubeconfig adres IP klastra
jest następnie narażony na interakcję z i jest
odpowiedzialny za zaopatrzenie i
zarządzanie całą infrastrukturą tj
potrzebne również dla płaszczyzny kontrolnej gke
automatyzuje węzły kubernetes przez
uruchamiając je jako wirtualne maszyny obliczeniowe
pod maską, ale nadal pozwala użytkownikowi
aby zmienić typ maszyny i dostęp
opcje aktualizacji domyślnie google
klastry i node
pule są aktualizowane automatycznie przez
google, ale możesz także kontrolować, kiedy
automatyczne aktualizacje mogą i nie mogą odbywać się przez
konfigurowanie okien konserwacji i
wykluczeń i tylko jako uwaga klastrów
płaszczyzna kontrolna i węzły nie
koniecznie uruchomić tę samą wersję w ogóle
razy i będę kopać dalej
że w późniejszej lekcji i tak wiem
to dużo teorii do przyjęcia, ale
jest, jak powiedziałem wcześniej, koniecznością
zrozumienie kubernetes i gke oraz as
idziemy dalej do kubernetes i
dostać się do dema, obiecuję, że tak będzie
zacznij mieć dużo więcej sensu i ty
zacznie robić się wygodniej
z gke i podstawowymi komponentami
kubernetes wiedząc, że kubernetes to a
koniecznością podczas pracy w dowolnej chmurze
środowisko, ponieważ jest popularnym i
rozwijająca się technologia, która nie zwalnia
w dół, więc znajomość gke umieści cię w
naprawdę dobra pozycja dla twojej kariery jako
inżynier w Google Cloud też to zrobi
dać ci przewagę w nurkowaniu w innych
wdrażanie przez dostawców chmury
kubernetes i to właściwie wszystko
chciałem zakryć, jeśli chodzi o
google kubernetes engine i kubernetes
więc możesz teraz oznaczyć tę lekcję jako
zakończyć i przejść do następnego
jeden
witam z powrotem w tej lekcji będę
obejmujące zarządzanie klastrami i węzłami w
gke, ponieważ odnosi się do wyboru innego
typy klastrów dla klastra obciążeń
wersje
pule węzłów, a także aktualizacje i
wiele różnych opcji do wyboru
dobrze jest się zapoznać
te opcje, jakie mogą być
czynnikiem decydującym o konieczności utrzymania
obciążenia robocze o wysokiej dostępności i Twoje
tolerancja na ryzyko w twoim
środowisko, więc to powiedziawszy
przejdźmy teraz do ostatniej lekcji my
dotknął węzłów i jak one są
pracowników dla klastra kubernetes tzw
teraz, gdy znasz już węzły i
chciałem dotknąć koncepcji, która buduje
na nim o nazwie pule węzłów, teraz pula węzłów
to grupa węzłów w klastrze
że wszystkie mają tę samą konfigurację i
używając specyfikacji konfiguracji węzła do
osiągnąć to może również pula węzłów
zawierać jeden lub wiele węzłów, gdy ty
najpierw utwórz klaster numer i
typ węzłów, które określisz, stanie się
domyślna pula węzłów, jak pokazano tutaj w
diagram, a następnie możesz dodać dodatkowe
niestandardowe pule węzłów o różnych rozmiarach i
wpisuje do klastra wszystkie węzły w dowolnym
dana pula węzłów jest identyczna z jedną
kolejne niestandardowe pule węzłów są naprawdę
przydatne, gdy trzeba zaplanować pody
które wymagają więcej zasobów niż inne
takie jak więcej pamięci więcej miejsca na dysku lub
nawet różne typy maszyn
tworzyć uaktualnienia i usuwać pule węzłów
indywidualnie bez wpływu na całość
klaster i tak jak uwaga, nie możesz
skonfigurować pojedynczy węzeł w dowolnej puli węzłów
wszelkie zmiany konfiguracji wpływają na wszystkie
węzłów w puli węzłów i domyślnie
wszystkie nowe pule węzłów uruchamiają najnowszą wersję stabilną
wersja istniejącego węzła kubernetes
pule można aktualizować ręcznie lub
automatycznie aktualizowane można również uruchomić
włączonych wiele wersji węzłów kubernetes
każdej puli węzłów w aktualizacji klastra
każdą pulę węzłów niezależnie i cel
różne pule węzłów dla konkretnych
wdrożenia w tym węźle teraz z gke
możesz stworzyć klaster dostosowany do
Twoje wymagania dotyczące dostępności i Twoje
budżetować typy dostępnych klastrów
obejmują strefowe zarówno pojedynczą strefę, jak i
wielostrefowe i regionalne klastry strefowe
mieć pojedynczą płaszczyznę sterowania w jednym
strefę w zależności od rodzaju
dostępność, którą chcesz dystrybuować
twoje węzły dla twojego klastra strefowego w a
teraz w jednej strefie lub w wielu strefach
gdy zdecydujesz się wdrożyć pojedynczą strefę
klaster ponownie ma pojedynczą kontrolkę
samolot poruszający się w jednej strefie tej kontroli
płaszczyzna zarządza obciążeniami w uruchomionych węzłach
w tej samej strefie klaster wielostrefowy
z drugiej strony ma jedną replikę
płaszczyzny kontrolnej działającej w jednym
zone i ma węzły działające w wielu
stref podczas aktualizacji klastra
lub awaria strefy, w której
samoloty kontrolne działają
obciążenia nadal działają, jednak klaster
jego węzły i obciążenia nie mogą być
skonfigurowane, dopóki płaszczyzna kontrolna nie zostanie
dostępne są klastry wielostrefowe
zaprojektowany, aby zrównoważyć dostępność i
koszt spójnych obciążeń i po prostu
jako uwaga będzie taka sama liczba węzłów
zostać rozmieszczone w każdej wybranej strefie i
może kosztować więcej niż zakładano w budżecie
proszę być świadomym i oczywiście kiedy
chcesz osiągnąć wysokie
dostępność dla Twojego klastra regionalnego
klastry są zawsze dobrym rozwiązaniem
klaster regionalny ma wiele replik
płaszczyzny kontrolnej działającej w wielu
strefy w obrębie węzłów danego regionu również
uruchomić w każdej strefie, w której znajduje się replika
samolot kontrolny działa, ponieważ regionalny
klaster replikuje płaszczyznę kontrolną i
węzłów zużywa więcej silnika obliczeniowego
zasobów niż podobna pojedyncza strefa lub
klaster wielostrefowy o tej samej liczbie
węzły zostaną wdrożone do każdego wybranego
strefę i domyślną podczas wybierania
klastrów regionalnych to teraz trzy strefy, jeśli
masz do czynienia z bardziej wrażliwymi
obciążenia, które wymagają bardziej rygorystycznych
wytyczne, które dają prywatne klastry
możliwość izolowania węzłów od posiadania
połączenia przychodzące i wychodzące do
publicznym internetem jest ta izolacja
osiągnięte, ponieważ węzły mają wewnętrzne IP
adresy tylko wtedy, gdy chcesz je podać
wychodzący dostęp do Internetu na pewno
prywatne węzły, których możesz użyć cloudnat lub
domyślnie zarządzaj własną bramą nat
prywatny dostęp do Google jest włączony w
klastry prywatne i ich obciążenia
z ograniczonym dostępem wychodzącym do Google
apis i usługi w chmurze przez Google
prywatna sieć w prywatnych klastrach
sieć vpc płaszczyzny kontrolnej jest podłączona
do sieci klastrów vpc z vpc
peering sieciowy do Twojej sieci vpc
zawiera węzły klastra i a
oddzielna sieć vpc w chmurze Google
zawiera płaszczyznę kontrolną twojego klastra
jest sieć vpc płaszczyzny kontrolnej
znajduje się w projekcie kontrolowanym przez
ruch google między węzłami a
płaszczyzna kontrolna jest kierowana w całości za pomocą
wewnętrzny adres IP odnosi się do płaszczyzny kontrolnej
dla prywatnego klastra ma private
punkt końcowy oprócz public
punkt końcowy płaszczyzna kontrolna dla a
klaster nieprywatny ma tylko grupę publiczną
punkt końcowy prywatny punkt końcowy to an
wewnętrzny adres IP w kontrolce
sieć vpc samolotu jako publiczny punkt końcowy
jest zewnętrznym adresem IP
płaszczyznę kontrolną i możesz kontrolować dostęp
do tego punktu końcowego przy użyciu autoryzowanych
sieci lub możesz wyłączyć dostęp do
publiczny punkt końcowy, jak pokazano tutaj w pliku
diagram możesz wyłączyć publiczne
punkt końcowy i połącz się z siecią
przy użyciu wewnętrznego adresu IP za pomocą chmury
połączenie lub VPN w chmurze i zawsze
mieć możliwość włączenia lub wyłączenia
ten publiczny punkt końcowy teraz podczas tworzenia
klastra, możesz wybrać klaster
konkretna wersja kubernetes lub możesz
mieszaj wersje, aby uzyskać elastyczność
funkcje tak czy inaczej jest zawsze
zalecane jest włączenie automatycznej aktualizacji
dla klastra i jego węzłów teraz kiedy
masz włączoną automatyczną aktualizację
biorąc pod uwagę możliwość wyboru spośród tego, czym są
nazywane kanałami wersji podczas rejestracji
nowy klaster w kanale wersji
Google automatycznie zarządza wersją
i ulepsz kadencję dla klastra i
jego pule węzłów oferują wszystkie kanały
obsługiwane wersje gke i are
brane pod uwagę w ogólnej dostępności
mogą wybierać spośród trzech różnych wersji
kanały do ​​automatycznego zarządzania
wersję i aktualizację klastra
kadencja, jak pokazano tutaj, jest dostępna
kanały uwalniania są szybkie i regularne
kanały o stabilnym uwalnianiu są szybkie
kanał wydania pobiera najnowsze
kubernetes zostanie wydany tak wcześnie, jak to możliwe
i móc korzystać z nowych funkcji gka
moment, w którym przechodzą do generała
dostępność w wersji regularnej
kanał, do którego masz dostęp gke i
kubernetes pojawi się wkrótce
po ich wydaniu, ale w wersji
który został zakwalifikowany od dwóch do trzech
miesięcy po uwolnieniu w szybkim tempie
kanał wydania i wreszcie mamy
stabilny kanał wydania, w którym stabilność
ma pierwszeństwo przed nową funkcjonalnością
zmiany i nowe wersje w tym kanale
są rozwijane jako ostatnie po
zatwierdzona od dwóch do trzech miesięcy w
regularny kanał dystrybucji, więc jeśli tak
poszukuje bardziej bezpośredniego zarządzania
wersja twojego klastra wybierz static
wersja podczas rejestrowania klastra w
zwolnij kanał, w którym klaster jest aktualizowany
automatycznie, gdy pojawi się nowa wersja
dostępne na tym kanale teraz, jeśli to zrobisz
nie używaj kanału wersji ani nie wybieraj
wersja klastra bieżąca wartość domyślna
wersja jest używana wersja domyślna
wybrane na podstawie użytkowania i rzeczywistego świata
wydajność i jest regularnie zmieniana
podczas gdy wersja domyślna jest najbardziej
dojrzały
dostępne są inne wersje
ogólnie dostępne wersje, które przechodzą
wewnętrzne testy i kwalifikacje
zmiany do wersji domyślnej są
ogłoszono teraz w nocie do wydania, jeśli ty
wiedz, że musisz użyć konkretnego
obsługiwana wersja kubernetes dla a
przy danym obciążeniu możesz określić kiedy
tworzenie klastra, jeśli nie potrzebujesz
kontrolować określoną wersję poprawki
którego używasz, rozważ zarejestrowanie swojego klastra
w kanale wydania zamiast zarządzania
jego wersję bezpośrednio teraz, gdy nadejdzie
do aktualizacji klastra należy pamiętać
że płaszczyzna kontrolna i węzły nie
zawsze uruchamiaj tę samą wersję
jak również płaszczyzna kontrolna jest zawsze
zaktualizowane przed jego węzłami, jeśli chodzi
do klastrów strefowych, których nie można uruchomić lub
edytuj obciążenia podczas tej aktualizacji i
z klastrami regionalnymi, z których każdy kontroluje
samolot jest również ulepszany jeden po drugim
z automatyczną aktualizacją samolotów kontrolnych
domyślnie włączone, a to jest google
najlepsze praktyki w chmurze teraz ponownie, jeśli ty
wybierz, że możesz wykonać ręczną aktualizację, ale
nie możesz ulepszyć płaszczyzny kontrolnej
więcej niż jedna wersja drugorzędna na raz, więc
należy również pamiętać o każdym klastrze
aktualizuje okna konserwacji i
dostępne są wyłączenia i tak w ten sposób
możesz wybrać najlepsze czasy dla siebie
uaktualnienia i podobne uaktualnienia klastra według
domyślnie węzły klastrów mają auto
aktualizacja jest włączona i jest zalecana
że nie wyłączysz go ponownie, to jest
najlepsze praktyki w chmurze Google i jeszcze raz
jak klaster aktualizuje instrukcję
dostępna jest aktualizacja i konserwacja
dostępne są okna i wykluczenia
wszystkie te ulepszenia teraz, gdy nie ma puli
jest uaktualniony gke aktualizuje jeden węzeł w a
czas
gdy węzeł jest aktualizowany, gke zatrzymuje się
planowanie nowych strąków na nim i próby
zaplanować swoje uruchomione kapsuły na inne
nodes węzeł jest następnie odtwarzany w
nowa wersja, ale używająca tej samej nazwy co
zanim to jest podobne do innych wydarzeń
które odtwarzają węzeł, takie jak włączanie
lub wyłączenie funkcji w puli węzłów
a aktualizacja jest zakończona tylko wtedy, gdy
wszystkie węzły zostały odtworzone, a plik
klaster jest w pożądanym stanie, gdy a
nowo zaktualizowane rejestry węzłów z rozszerzeniem
płaszczyzna kontrolna gke oznacza węzeł jako
zaplanowana aktualizacja bez puli może
zakłócać obciążenia działające w tej puli
i tak, aby tego uniknąć, możesz
utwórz nową pulę węzłów z żądanym
wersję i następnie przeprowadź migrację obciążenia
po migracji możesz usunąć stare
teraz pozwalają na to uaktualnienia puli węzłów
kontroluj liczbę węzłów, które może obsługiwać gke
aktualizuj na raz i kontroluj, w jaki sposób
destrukcyjne ulepszenia są dla Ciebie
obciążenia możesz zmienić liczbę węzłów
gke próbuje dokonać aktualizacji od razu przez
zmiana parametrów aktualizacji przepięć na
redukują ulepszenia bez przepięć puli
zakłócenia w pracy podczas
utrzymanie klastra, a także pozwalają
kontrolować liczbę uaktualnianych węzłów
w równoległych aktualizacjach przepięć również działają
z automatycznym skalowaniem klastra, aby zapobiec
zmiany w węzłach, które są aktualizowane
teraz określane jest zachowanie aktualizacji przepięć
przez dwa ustawienia maksymalnego przepięcia aktualizacji i
maksymalna niedostępna aktualizacja
teraz z ulepszeniem maksymalnego przepięcia, to jest to
liczba dodatkowych węzłów, które mogą być
dodany do puli no podczas aktualizacji
zwiększenie ulepszenia maksymalnego przepięcia podnosi
liczbę węzłów, które można zaktualizować
jednocześnie i jeśli chodzi o
maksymalna niedostępna aktualizacja to jest to
liczba węzłów, które mogą być
jednocześnie niedostępne podczas
aktualizacja zwiększająca maks. niedostępna
upgrade zwiększa liczbę węzłów, które
można aktualizować równolegle, więc z maks
uaktualnienie przepięć, im wyższa liczba
więcej równoległych aktualizacji, które się zakończą
kosztuje więcej pieniędzy z max
niedostępne uaktualnienie, im wyższy
numer, tym bardziej przeszkadza i tak dalej
tym większe ryzyko podejmujesz i tak dalej
podczas aktualizacji gke co najwyżej wyłącza
suma dodanego ulepszenia maksymalnego przepięcia
z maksymalną niedostępną aktualizacją, tak jak
możesz zobaczyć tutaj jest mnóstwo
opcji, jeśli chodzi o podjęcie decyzji
typ klastra, który chcesz, a także
rodzaj dostępnych aktualizacji
wraz z tym, kiedy chcesz, aby wystąpiły
a więc twój decydujący czynnik w końcu
będzie obciążeniem pracą, którym jesteś
bieganie i twoja tolerancja ryzyka i to
będzie odgrywać dużą rolę w nadążaniu
czas dla klastra, a także oszczędność
pieniądze w każdym środowisku i tak dalej
to właściwie wszystko, co chciałem zawrzeć
jeśli chodzi o klaster i węzeł gke
zarządzania, więc możesz to teraz zaznaczyć
lekcję za zakończoną i przejdźmy dalej
Następny
[Muzyka]
witaj z powrotem i zrobię to na tej lekcji
zanurzyć się w jakiejś większej teorii
kubernetes i gke tym razem dotykając
obiekty i sposób, w jaki obiekty są zarządzanymi zasobnikami
są tylko jednym rodzajem obiektów, ale istnieją
zaangażowanych jest wiele innych części
w zarządzaniu tymi obiektami i
temu poświęcona jest ta lekcja
nauczę cię, że jest jeszcze sporo do zrobienia
przykryj tutaj, więc powiedzmy
nurkować w
teraz obiekty kubernetes są trwałe
jednostki w kubernetes kubernetes używa
te podmioty reprezentują stan
twój klaster, na przykład, który może opisać
rzeczy takie jak to, co konteneryzowane
aplikacje są uruchomione i na których
węzły i jakie zasoby są dostępne
do tych aplikacji kubernetes
obiekt jest zapisem intencji, gdy ty
utwórz obiekt kubernetes
stale pracować, aby zapewnić ten obiekt
istnieje, tworząc obiekt, którym jesteś
skutecznie mówiąc kubernetes, co ty
chcesz, aby wyglądało obciążenie Twojego klastra
like i to jest pożądane przez twój klaster
stan i słyszałeś, jak mówiłem
to już wiele razy i oto co
Miałem na myśli teraz prawie każdy
kubernetes zawiera dwa zagnieżdżone
pola obiektu, które rządzą obiektem
konfiguracja specyfikacji obiektu i
status obiektu dla obiektów, które mają
spec musisz to ustawić, kiedy ty
utwórz obiekt dostarczający a
opis cech ciebie
chcesz, aby zasób miał swoje pożądane
stan opisuje stan obecny
stan dostarczonego i zaktualizowanego obiektu
przez kubernetes i jego komponenty
kubernetes nieustannie kontroluje płaszczyznę i
aktywnie zarządza stanem faktycznym każdego obiektu
stan, aby dopasować żądany stan
dostarczył teraz każdy obiekt w twoim klastrze
ma unikalną nazwę dla tego typu
zasobów również każdy obiekt kubernetes
ma identyfikator użytkownika, który jest unikalny w całym twoim
cały klaster tylko jeden obiekt danego
rodzaj może mieć jednocześnie imię
jednak jeśli usuniesz obiekt, możesz
utworzyć nowy obiekt o tej samej nazwie
każdy obiekt stworzony na całości
czas życia klastra kubernetes ma
odrębne uid te odrębne uid są
znane również jako uuids, o których mówiliśmy
wcześniej w trakcie teraz kiedy
tworzenie aktualizacji lub usuwanie obiektów w
kubernetes odbywa się to poprzez użycie
pliku manifestu, gdzie byś to zrobił
określić żądany stan obiektu
które kubernetes będzie utrzymywać, gdy ty
zastosuj manifest w każdej konfiguracji
plik może zawierać wiele manifestów i
jest powszechną praktyką, aby to zrobić, kiedy
możliwe plik manifestu jest zdefiniowany w
postaci pliku yaml lub pliku json
i zaleca się użycie yaml teraz w
każdy plik yaml dla obiektu kubernetes
które chcesz utworzyć, jest ich kilka
wymagane wartości, które należy ustawić
pierwsza to wersja api i to
określa, która wersja kubernetes
api, którego używasz do tworzenia tego obiektu
rodzaju opisanego w tym przykładzie jako a
pod to rodzaj obiektu, który chcesz
create next up to metadane i to
to dane, które pomagają jednoznacznie zidentyfikować
obiekt zawierający nazwę ciągu
uid i opcjonalna przestrzeń nazw oraz
ostatnia wymagana wartość to specyfikacja
i to jest stan, którego pragniesz
obiekt i specyfikacja w tym przykładzie
to pojemnik o nazwie muszka
Dash serwer WWW i ma być zbudowany z
najnowszy obraz serwera WWW nginx jako
a także mając otwarty port 80 na
teraz, jeśli chodzi o obiekty
strąki są najmniejsze i najbardziej podstawowe
wdrażalne obiekty w kubernetes pod
reprezentuje pojedynczą instancję a
uruchomiony proces w podach klastra
zawierać jeden lub więcej pojemników, np
kontenery dokerów i kiedy kapsuła jest uruchomiona
wiele pojemników, którymi są pojemniki
zarządzane jako pojedyncza jednostka i udostępniać
zasoby strąków, które również obejmują
współdzielona sieć i współdzielona pamięć masowa dla
ich pojemniki to na ogół jeden strąk
przeznaczony do uruchamiania pojedynczej instancji pliku
application w twoim klastrze, który jest
samowystarczalny i odizolowany
teraz, chociaż kapsuła ma uruchamiać plik
pojedyncza instancja Twojej aplikacji na
twój klaster
nie zaleca się tworzenia
pojedyncze strąki bezpośrednio zamiast Ciebie
ogólnie tworzą zestaw identycznych strąków
zwane replikami do uruchamiania aplikacji
tworzony jest zestaw zreplikowanych strąków i
zarządzane przez administratora, np
kontrolery wdrażania zarządzają życiem
cykl ich strąków, jak również
wykonywanie zmiany skalowania w poziomie
liczba strąków jest teraz konieczna
chociaż czasami możesz wchodzić w interakcje
z podami bezpośrednio w celu debugowania rozwiązywania problemów
lub sprawdź je, jest to zalecane
używasz kontrolera do zarządzania swoimi kapsułami
i tak po utworzeniu strąków
są następnie uruchamiane na węzłach w klastrze
które omówiliśmy wcześniej, kapsuła będzie
następnie pozostań w swoim węźle, aż do jego
proces jest zakończony pula jest usuwana
kapsuła jest eksmitowana z węzła z powodu
brak zasobów lub węzeł ulegnie awarii, jeśli a
węzeł ulegnie awarii, strąki w węźle są
automatycznie zaplanowane do usunięcia teraz
pojedynczy klaster gke powinien być w stanie to zrobić
zaspokoić potrzeby wielu użytkowników lub
grupy użytkowników i kubernetes
przestrzenie nazw pomagają różnym zespołom projektowym
lub klientów do udostępniania kubernetes
klaster, o którym możesz myśleć jako o przestrzeni nazw
wirtualny klaster wewnątrz twojego
klaster kubernetes i możesz go mieć
wiele przestrzeni nazw logicznie izolowanych
od siebie mogą ci pomóc i
Twoje zespoły z organizacją i
bezpieczeństwo teraz możesz nazwać swoje
przestrzenie nazw, co chcesz, ale
kubernetes zaczyna się od czterech początkowych
przestrzeni nazw pierwsza jest domyślna
przestrzeni nazw i dotyczy to obiektów z
żadna inna przestrzeń nazw
więc podczas tworzenia nowych obiektów bez a
namespace twój obiekt automatycznie
być przypisany do tej kreski kostki przestrzeni nazw
system jest następny, a te są dla
obiekty utworzone przez kubernetes
cube-public jest tworzony automatycznie i
jest czytelny dla wszystkich użytkowników, ale jest w większości
zarezerwowane do użycia klastra w takim przypadku
niektóre zasoby powinny być widoczne i
czytelne publicznie w całym tekście
klaster i wreszcie dzierżawa węzła kostki
przestrzeń nazw dla obiektów dzierżawy
powiązane z każdym węzłem, który się poprawia
wydajność bicia serca węzła
w miarę jak klaster się skaluje i tak jak większość
zasoby w Google Cloud Labels są kluczowe
pary wartości, które pomogą Ci zorganizować
zasoby w tym przypadku kubernetes
można dołączyć etykiety obiektów
obiektów w czasie tworzenia i może być
dodawane lub modyfikowane w dowolnym momencie
obiekt może mieć zestaw wartości klucza
zdefiniowane etykiety i każdy klucz musi być
unikalne dla danego obiektu i etykiety mogą
znaleźć w metadanych w twoim manifeście
plik, a więc jedyna rzecz do zapamiętania
o strąkach jest to, że są efemeryczne
nie są zaprojektowane do działania w nieskończoność i
kiedy kapsuła jest zakończona, nie może tak być
przywrócone w ogóle strąki nie
znikają, dopóki nie zostaną usunięte przez a
użytkownika lub przez kapsuły kontrolera nie leczą
lub naprawiają się, na przykład, jeśli a
pod jest zaplanowane w węźle, który później
nie powiedzie się, kapsuła zostanie również usunięta, jeśli a
pod jest eksmitowany z węzła dla dowolnego
powód, dla którego kapsuła nie zastępuje się sama
a oto diagram życia strąka
cykl, który pokazuje różne fazy
jego czas działania, aby dać ci coś lepszego
jasność jego efemerycznego charakteru, kiedy
najpierw tworzenie kapsuły, którą będzie kapsuła
zacznij się zbliżać, a to jest kapsuła
początkowa faza i czeka na jedno lub
więcej kontenerów do ustawienia i
gotowy do uruchomienia obejmuje czas
kapsuła spędza czekając na zaplanowanie jako
jak również czas spędzony na pobieraniu
obrazy kontenerów przez sieć jeden raz
kapsuła zakończyła fazę oczekiwania
zostaje przeniesiony do zaplanowania i raz
zaplanowano, że przeniesie się do
faza biegu i to jest ta faza
gdzie kapsuła została powiązana z węzłem
i wszystkie pojemniki zostały
utworzona faza biegu ma co najmniej
jeden kontener w uruchomionym zasobniku lub jest
w trakcie uruchamiania lub ponownego uruchamiania
a po zakończeniu obciążenia pracą
kapsuła przejdzie do zakończonej sukcesem fazy
i tutaj znajdują się wszystkie pojemniki
kapsuła zakończyła się sukcesem i
nie zostanie ponownie uruchomiony, jeśli wszystkie
pojemniki w kapsule nie
zakończone pomyślnie, kapsuła to zrobi
przejść do nieudanej fazy i to jest to
gdzie znajdują się wszystkie pojemniki w kapsule
zakończone i co najmniej jeden kontener
zakończyło się niepowodzeniem, teraz jest
jeszcze jedna faza w cyklu życia strąka
który chciałem poruszyć, który jest
nieznana faza i to jest stan
strąk, którego nie można było uzyskać
faza zwykle występuje z powodu błędu
w komunikacji z węzłem, w którym
kapsuła powinna działać, więc teraz, kiedy jesteś
tworzenie strąków przy użyciu wdrożenia to a
typowy sposób, aby to zrobić, uruchamia wdrożenie
wiele replik Twojej aplikacji
i automatycznie zastępuje wszelkie wystąpienia
które zawodzą lub przestają odpowiadać
wdrożenia pomagają zapewnić, że jeden lub więcej
wystąpienia twojej aplikacji są
dostępne do obsługi żądań użytkowników
wdrożenia używają szablonu pod, który
zawiera specyfikację swoich strąków
specyfikacja pod określa, w jaki sposób
każdy strąk powinien wyglądać na przykład
jakie aplikacje powinny w nim działać
pojemniki, jaką objętość powinny mieć strąki
zamontuj swoje etykiety i nie tylko, gdy a
szablon wdrożeń został zmieniony na nowy
strąki są tworzone automatycznie jeden na a
teraz chciałem szybko przywołać
zestawy replik za chwilę będziesz
słyszałem o zestawach replik i chciałem
upewnij się, że omówiłem to zestawy replik
zapewnia, że ​​określona liczba pod
repliki są uruchomione w dowolnym momencie
jednak wdrożenie jest na wyższym poziomie
koncepcja, która zarządza zestawami replik i
zapewnia aktualizacje podów wraz z
inne funkcje, a więc za pomocą wdrożeń
jest zalecane zamiast używania zestawów replik
chyba że wymaga tego twoje obciążenie pracą i ja
będzie zawierać link do zestawów replik
w tekście lekcji, o którym mowa
obciążenia w obciążeniach kubernetes są
obiekty, które ustawiają reguły wdrażania cztery
pods w oparciu o te zasady kubernetes
wykonuje wdrożenie i aktualizuje plik
obciążenie pracą z aktualnym stanem
obciążenia aplikacji umożliwiają zdefiniowanie
zasady skalowania harmonogramów aplikacji
i uaktualnianie teraz wdrożeń, które my
właśnie omówiony jest rodzaj obciążenia pracą i
jak widzieliśmy, wdrożenie działa wiele
repliki twojej aplikacji i
automatycznie zastępuje wszelkie wystąpienia
które zawodzą lub przestają odpowiadać
wdrożenia są najlepiej używane
dla aplikacji bezstanowych inny typ
obciążenia to zestawy stanowe i in
w przeciwieństwie do wdrożeń są świetne
kiedy Twoja aplikacja tego potrzebuje
zachowania swojej tożsamości i przechowywania danych w ten sposób
w zasadzie każda aplikacja, która tego wymaga
jakiś demon trwałej pamięci masowej
sets to kolejne typowe obciążenie
zapewnia, że ​​każdy węzeł w klastrze działa
kopia tego strąka i to jest do użytku
przypadki, w których zbierasz dzienniki lub
monitorowanie wydajności węzła teraz zadania są
obciążenie, które uruchamia jedno lub więcej
strąki i zapewnia, że ​​określona liczba
z nich pomyślnie kończy pracę
najlepiej użyć do wykonania skończonego zadania
ukończenie w przeciwieństwie do zarządzania
bieżący żądany stan aplikacji i
zadania cron są jednak podobne do zadań
zadania cron są uruchamiane do końca na a
harmonogram oparty na cronie i tak ostatni
obciążenie pracą, które chciałem pokryć, to
mapy konfiguracji i te przechowują ogólne
informacje konfiguracyjne i tak dalej
przesyłasz mapę konfiguracji, którą może wykonać każde obciążenie
odwołaj się do niego jako do środowiska
zmienna lub mocowanie woluminu i tak po prostu
jako uwaga mapy konfiguracji nie są przeznaczone
przechowuj poufne dane, jeśli planujesz
aby to zrobić, użyj sekretów, które teraz wiem
ta lekcja była wyjątkowo ciężka
teoria, ale te są fundamentalne
pojęcia, które należy znać, gdy ma się do czynienia
kubernetes i gke, a także
obiekty, które obsługuje, więc polecam
że jeśli chcesz wrócić i przejrzeć
tę lekcję, jeśli coś nie idzie
sens, abyś mógł lepiej zrozumieć
ponieważ wszystkie te koncepcje łączą się ze sobą
i wyjdzie na egzaminie i tak dalej
to właściwie wszystko, co chciałem zawrzeć
w tej lekcji na temat strąków i obiektów
management w gke, więc teraz możesz
zaznacz tę lekcję jako zakończoną
i przejdźmy do następnego
[Muzyka]
witaj z powrotem i jestem na tej lekcji
zamierza nurkować w kubernetes
usługi teraz usługi są głównym
komponent sieciowy, jeśli chodzi o
pracuje w Kubernetes i może grać w
głównym czynnikiem przy podejmowaniu decyzji
o tym, jak chcesz kierować ruchem
również w klastrze Kubernetes
z mojego doświadczenia usługi pojawiają się na
egzamin, a więc zrozumienie, w jaki sposób oni
praca i różne rodzaje do wykorzystania są
niezbędne do zrozumienia wielkiego
obraz kubernetesa, który będzie dotyczył tej lekcji
zawierają przegląd tego, czym są usługi
co robią i jakie są ich rodzaje
które są dostępne wraz z ich użytkowaniem
przypadków teraz jest tu wiele do omówienia, więc
powiedziawszy to, przejdźmy teraz do rzeczy
jak omówiłem wcześniej kubernetes
strąki są efemeryczne strąki są tworzone i
zniszczone, aby pasowały do ​​​​stanu twojego
klastra, więc te zasoby nigdy nie są
permanentny jest tego doskonałym przykładem
za pomocą obiektu wdrażania, dzięki czemu możesz
teraz dynamicznie twórz i niszcz kapsuły
jeśli chodzi o networking
kubernetes każdy strąk otrzymuje swój własny adres IP
adres jednak we wdrożeniu pod
który działa, gdy zostanie zniszczony
odtworzony z nowym adresem IP i
nie ma realnego sposobu na śledzenie
te adresy IP do komunikacji jako
zmieniają się bardzo często i to jest to
gdzie usługi wchodzą teraz w grę a
usługa jest w pewnym sensie abstrakcją
że nie jest to proces, który nasłuchuje
jakiś interfejs sieciowy
usługę można zdefiniować jako logiczną
zestaw strąków abstrakcja na górze
pod, który zapewnia jeden trwały
adres ip i nazwa dns, według których strąków
można uzyskać dostęp, umożliwia wyznaczanie tras
ruch zewnętrzny do kubernetes
cluster i używane w klastrze dla
bardziej inteligentny routing z usługami
zarządzanie obciążeniem jest również bardzo łatwe
konfiguracja równoważenia ruchu
między replikami pomaga skalować strąki
szybko i łatwo, tak jak zrobi to obsługa
automatycznie obsługiwać odtwarzanie
strąki i ich nowe adresy IP są adresami main
celem usług w kubernetes jest
zapewnić stały dostęp do swoich strąków
bez konieczności szukania
ip poda
za każdym razem, gdy kapsuła jest odtwarzana i
ponownie usługi pozwalają również na zewnętrzne
dostęp użytkowników do aplikacji
wewnątrz klastra bez konieczności
znać adres IP danej osoby
pod, aby uzyskać dostęp do tej aplikacji
teraz, aby usługa mogła zostać wyznaczona
ruch do właściwego poda w
klaster istnieje kilka pól w
plik manifestu, który pomoże ustalić
punkty końcowe tam, gdzie powinien być ruch
być trasowane pokazany tutaj po prawej stronie jest
manifest wdrożenia w celach informacyjnych i dalej
po lewej stronie manifestują się teraz usługi jako
można zobaczyć tutaj w manifeście usługi
po lewej rodzaj jest wyraźnie określony
jako usługa pod metadanymi to nazwa
service i to będzie dns
nazwę usługi podczas jej tworzenia
więc jeśli chodzi o specyfikację, jest
pole zwane tutaj selektorem i to jest
co określa, jakie powinny być strąki
zawarte w usłudze i to jest
etykiety pod selektorem, które definiują
które strąki i etykiety są tym, czym jesteśmy
omówione na ostatniej lekcji jako
dowolne pary klucz-wartość, więc dowolny kapsuła
z tymi pasującymi etykietami jest to, co będzie
zostać dodany do usługi, jak pokazano tutaj w
plik wdrażania, który będzie wykonywany przez to obciążenie
być częścią usługi i jej etykiet
pasuje do selektora w
services plik dla typu to jest typ
usługi, z której będziesz chciał skorzystać
ten przykładowy typ klastra ip jest używany, ale
w zależności od przypadku użycia masz kilka
różne do wyboru teraz w
na dole jest lista portów
protokołem konfiguracji jest
protokół sieciowy, który ma być używany z portem
port jest portem przychodzącym
ruch trafia do i wreszcie do celu
port, który jest portem na pod tym
ruch powinien być wysyłany do i tak będzie
mieć więcej sensu, gdy przechodzimy przez
nadchodzące diagramy tak wzruszające
selektory i etykiety na chwilę
kubernetes ma bardzo unikalny sposób
kierowanie ruchu i kiedy to przychodzi
usługi to nie są żadne inne usługi
wybierz teraz strąki na podstawie ich etykiet
gdy zostanie wysłane żądanie selektora do
service wybiera wszystkie strąki w
klaster pasujący do pary klucz-wartość
pod selektorem wybiera jeden z
strąki, jeśli jest ich więcej niż jeden z
tę samą parę klucz-wartość i przekazuje dalej
żądanie sieciowe do niego i tak tutaj
tym przykładzie widać, że
selektor określony dla usługi ma
pary klucz-wartość zasobów aplikacji, które możesz
zobacz kapsułę w węźle 1 po lewej stronie
etykieta spisu aplikacji oraz która
pasuje do pary klucz-wartość
selektor, więc ruch zostanie przekierowany
do tego strąka z tego powodu, jeśli na to spojrzysz
etykieta poda w węźle 2 na
prawda, że ​​etykieta nie pasuje do etykiety
selektor, więc nie będzie trasowany
ruch do tego poda i tak podsumowując
etykieta na strąku pasująca do
selektor w usłudze określa gdzie
żądanie sieciowe zostanie przekierowane do
i tak teraz będę przechodzić przez
wiele różnych rodzajów usług, które są
dostępne do kierowania ruchu sieciowego
w gke zaczynając od klastra ip
teraz usługa IP klastra jest domyślna
kubernetes usługa daje ci
usługa wewnątrz klastra, która jest inna
aplikacje wewnątrz klastra mogą uzyskiwać dostęp do
usługa nie jest narażona na zewnątrz
klastra, ale można się nim zająć od wewnątrz
klastra podczas tworzenia usługi
wpisz klaster ip kubernetes tworzy plik
stabilny adres IP, który jest dostępny
z węzłów w klientach klastra w
klaster wywołuje usługę przy użyciu
adres IP klastra i wartość portu
określony w polu portu pliku
manifest usługi, którego dotyczy żądanie
przekazany do jednego z zasobników członkowskich w dniu
port określony w porcie docelowym
pole i tylko jako uwaga ten adres IP
jest stabilny przez cały okres użytkowania
usługa, więc na przykład klient
dzwoni do serwisu pod numer 10.176
na porcie tcp 80. żądanie jest przekazywane
do jednego z zasobników członkowskich na porcie tcp
80. pamiętaj, że kapsuła członkowska musi mieć
kontener nasłuchujący na porcie tcp
80. jeśli nie ma nasłuchiwania kontenera
na porcie 80 klienci zobaczą komunikat
na przykład nie można się połączyć lub ta witryna nie może
zostać osiągnięty pomyśl o przypadku, gdy ty
mieć rekord dns, którego nie chcesz
zmienić i chcesz, aby nazwa została rozwiązana
na ten sam adres IP lub tylko na Ciebie
chcesz statyczny adres IP dla swojego
obciążenie pracą, byłby to świetny przypadek użycia
do korzystania z usługi klastra ip
teraz, chociaż usługa nie jest
dostępne przez żądania sieciowe na zewnątrz
klastra
jeśli chcesz połączyć się z usługą
nadal możesz się z nim połączyć za pomocą
Cloud SDK lub Cloud Shell przy użyciu
ujawniony adres IP klastra i tak dalej
Chciałem poświęcić chwilę, aby ci pokazać
co właściwie manifestuje klaster ip
wygląda i będę przechodzić
manifest dla każdego typu usługi dla
do zapoznania się z nami
najpierw mieć nazwę usługi, która
to usługa klastra ip dash
mamy wtedy etykietę używaną dla
selektor, który jest parą klucz-wartość
spis aplikacji, a następnie mamy
typ usługi, którym jest klaster ip i my
udostępnić numer portu wewnętrznie
w klastrze, który jest wzdłuż portu 80
z portem docelowym, którym są kontenery
nasłuchiwanie, na którym ponownie znajduje się port 80. i
więc następnym typem usługi, jaki mamy, jest node
Port
więc kiedy tworzysz usługę typu
port węzła określasz wartość portu węzła
port węzła jest portem statycznym i jest
wybrany ze wstępnie skonfigurowanego zakresu
między 30 000 a 32
760
możesz określić własną wartość w ramach
ten zakres, ale należy pamiętać, że dowolny
wartość poza tym zakresem nie będzie
akceptowane również przez kubernetes, jeśli to zrobisz
nie wybieraj wartości, w której znajduje się losowa wartość
określony zakres zostanie przydzielony
po przypisaniu tego zakresu portów
do usługi, to jest usługa
dostępne za pomocą adresu IP
dowolny węzeł wraz z wartością no port
usługa jest następnie udostępniana na porcie włączonym
każdemu węzłowi w klastrze usługę
można wtedy uzyskać dostęp z zewnątrz pod adresem
ip węzła wraz z portem węzła when
korzystając z usług portu węzła, które musisz wykonać
upewnij się, że wybrany port nie jest
już otwarte na twoich węzłach i tak po prostu
jako uwaga typ portu to an
rozszerzenie typu ip klastra, więc a
usługa typu node port ma naturalnie
adres IP klastra, a więc ta metoda
nie jest zbyt bezpieczny, ponieważ otwiera każdy
node do wpisu zewnętrznego, a także this
metoda polega na znajomości ip
adresy węzłów, które mogą
zmienić w dowolnym momencie i tak przechodzić
manifest typu usługa portu węzła
zaczynamy od imienia
service, która jest usługą kreski portu węzła
etykieta używana dla selektora, który
używa pary klucz-wartość zasobów aplikacji
typ, którym jest port węzła i uwaga
rozróżnianie wielkości liter tutaj, które chcesz
znaleźć w większości typów usług wraz z
numer portu ujawniony wewnętrznie w
klaster, który jest portem 80 i ponownie
port, w którym znajdują się kontenery
nasłuchuje, na którym porcie docelowym
który jest również portem 80 i wreszcie i
co najważniejsze, nie mamy portu
wartość, która jest oznaczona tak, jak widziałeś w
diagram wcześniej jako port
32002 kolejny typ usługi, który mamy
jest low balancer i ta usługa jest
wyeksponowany jako moduł równoważenia obciążenia w
usługi klastra o niskim równoważeniu będą
utwórz wewnętrzną usługę Kubernetes
która jest połączona z dostawcą usług w chmurze
moduł równoważenia obciążenia iw tym przypadku google
cloud spowoduje to utworzenie statycznego publicznie
adresowalny adres IP i nazwa dns
którego można użyć do uzyskania dostępu do klastra
z zewnętrznego źródła dolnego balansera
type jest rozszerzeniem typu no port
czyli usługa typu load balancer
naturalnie ma adres IP klastra if
chcesz bezpośrednio udostępnić usługę
jest to domyślna metoda całego ruchu
na wskazanym porcie
zostaną przekazane do tamtejszego serwisu
nie ma filtrowania ani routingu, a to oznacza
możesz wysłać wiele różnych rodzajów
ruch do niego, jak http https tcp lub udp
i więcej minusem jest to, że dla
każda usługa, którą wystawiasz z niskim
balancer płacisz za ten load balancer
więc naprawdę możesz podnieść swój rachunek
jeśli używasz wielu systemów równoważenia obciążenia
a tutaj pokazany jest manifest dla typu
równoważenia obciążenia pokazuje nazwę
usługa równoważenia obciążenia usługa kreska usługa
etykieta używana dla selektora
która jest parą klucz-wartość app
spis
typ usługi, który jest low balancer
ponownie zwróć uwagę na rozróżnianie wielkości liter
z portem i portem docelowym który
oba są portami 80. i to jest koniec
pierwszej części tej lekcji
robi się trochę za długo, więc postanowiłem przerwać
to będzie świetna okazja
żebyś wstał i się porozciągał
sobie kawę lub herbatę i kiedy tylko
jesteś gotowy, zacznie się część druga
zaraz od końca pierwszej części tzw
Śmiało i oznacz to jako kompletne i
do zobaczenia w następnym
[Muzyka]
Witamy z powrotem to jest druga część
lekcja usług kubernetes i jesteśmy
będzie kontynuowane natychmiast od
koniec części pierwszej, więc kiedy tylko będziesz gotowy
zanurzmy się, a więc następna usługa
rodzaj, który mamy, to usługi wieloportowe
teraz jest zapotrzebowanie na niektóre usługi
ujawnić więcej niż jeden port kubernetes
pozwala skonfigurować wiele portów
definicje na obiekcie usługi, więc kiedy
korzystanie z wielu portów dla usługi
musi podać nazwy wszystkich portów i if
masz wiele portów usług
nazwy muszą być unikalne w tym przykładzie if
klient dzwoni do usługi pod numer 10.176.1
na porcie tcp 80 żądanie jest przekazywane
do poda członkowskiego na porcie tcp 80 na dowolnym
węzeł 1 lub węzeł 2. ale jeśli dzwoni klient
usługa pod numerem 10.176.133.7
na porcie tcp 9752 żądanie jest
przekazany do poda na porcie TCP 9752
który znajduje się w węźle 1. każdego pod członka
musi mieć kontener nasłuchujący na tcp
port 80 i kontener nasłuchujący na tcp
port 9752 może to być pojedynczy
pojemnik z dwoma nitkami lub dwoma
kontenery działające w tym samym zasobniku i
oczywiście, jak pokazano tutaj, jest manifestem
pokazujące usługi wieloportowe
nazwa usługi
etykieta używana dla selektora
jak również typ usługi port
węzeł odsłonięty wewnętrznie dla każdego
oddzielne obciążenie, jak również port
których nasłuchują kontenery
każde obciążenie pracą, jak również i jak widziałeś
zanim nginx używał portu docelowego 80
gdzie aplikacja korzystała z portu 9752, przechodząc dalej
do innego typu usługi jest nazwa zewnętrzna
teraz usługa typu nazwa zewnętrzna
zapewnia wewnętrzny alias dla pliku
zewnętrzna nazwa dns tworzona przez wewnętrznych klientów
żądania przy użyciu wewnętrznej nazwy DNS i
żądania są przekierowywane do
nazwę zewnętrzną podczas tworzenia usługi
kubernetes tworzy nazwę dns, która
klienci wewnętrzni mogą używać do wywoływania
service w tym przykładzie wewnętrzne dns
nazwa to bowtie.sql, gdy wewnętrzny
klient wysyła żądanie do wewnętrznego
nazwa dns bowtie.sql, którą otrzyma żądanie
przekierowany do bowtie.sql2
muszka w kropki z kropkami na zewnątrz
rodzaj usługi nazw jest nieco inny
niż inne rodzaje usług, ponieważ tak nie jest
powiązany z zestawem podów lub adresem IP
adres jest to mapowanie z wewnętrznego
nazwa dns na zewnętrzną nazwę dns to
service wykonuje proste przekierowanie cname
i jest doskonałym przypadkiem użycia dla każdego zewnętrznego
usługi, która znajduje się poza twoim
klaster i ponownie tutaj jest widok a
manifest dla typu nazwa zewnętrzna tutaj
pokazując wewnętrzną nazwę DNS wraz z
zewnętrzne przekierowanie nazw DNS i
przejście do ostatniego typu usługi my
mieć teraz typ usługi bezgłowej
czasami nie potrzebujesz lub nie chcesz niskiego poziomu
równoważenie i pojedyncza usługa IP in
w tym przypadku możesz tworzyć bez głowy
services, określając none jako
typ usługi w pliku manifestu this
opcja pozwala również wybrać inne
mechanizmy wykrywania usług bez
jest powiązany z implementacją Kubernetes
aplikacje mogą nadal używać a
wzór samorejestracji z tym
service i dlatego jest to świetny przypadek użycia
jest wtedy, gdy nie potrzebujesz żadnego niskiego balansu
lub trasy, do której potrzebujesz tylko usługi
załatać żądanie do pod nr zaplecza
ips wymaga zazwyczaj usługi bezgłowej
używany z zestawami stanowymi, w których nazwa
strąków są naprawione, jest to przydatne
sytuacjach, takich jak konfigurowanie
mysql klaster, w którym musisz znać
imię mistrza, więc tutaj jest a
ponownie zamanifestować usługę bezgłową
typ usługi jest oznaczony jako brak i
więc podsumowując usługi kubernetes
zapewnia interfejsy, przez które
strąki mogą komunikować się ze sobą
działają również jako główna brama dla
Twoje usługi aplikacji używają selektorów
aby określić, które strąki powinny
kontroli ujawniają adres IP i a
port, który niekoniecznie jest taki sam
port, na którym nasłuchuje kapsuła i
usługi mogą udostępniać więcej niż jeden port
a także może kierować ruch do innych
usługi zewnętrzne adresy IP lub dns
usługi nazw sprawiają, że jest to naprawdę łatwe
tworzyć usługi sieciowe w kubernetes
każda usługa może być wspierana przez dowolną liczbę
strąki w razie potrzeby bez konieczności robienia
Twój kod jest świadomy tego, jaka jest każda usługa
wspierane również należy pamiętać, że istnieją
wiele innych funkcji i przypadków użycia
wymienione usługi
których nie wychowałem, też to zrobię
umieść kilka linków w tekście lekcji
dla zainteresowanych nurkowaniem
głębiej w usługi, do której była ta lekcja
jedynie podsumować różne usługi
rodzaje i znajomość tych rodzajów usług
postawi cię w świetnej pozycji na
egzamin na wszystkie pytania, które obejmują
services w gke teraz wiem, że to ma
była kolejną lekcją, która była
niezwykle ciężki w teorii i był
ogromna ilość do przyjęcia, ale nie do przyjęcia
martw się obok jest demo, które umieści
całą tę teorię w praktyce i będziemy
iść naprzód i budować klaster
wraz z dotykaniem większości
elementy omówione w ciągu ostatnich kilku
lekcje i tak to prawie wszystko ja
chciał zakryć, jeśli chodzi o
typów usług kubernetes, dzięki czemu możesz teraz
zaznacz tę lekcję jako zakończoną i
kiedy tylko będziesz gotowy, dołącz do mnie
konsola
[Muzyka]
Witamy spowrotem
w tej lekcji będę przechodzić
wejście dla gke
obiekt w gke, który definiuje reguły
do kierowania ruchu do określonych usług
Ingress to dobrze znany temat, który przychodzi
się na egzaminie
a także jest wspólnym zasobem, który
jest używany w wielu klastrach gke, które ty
będzie widoczny w większości środowisk
coś, co dostaniesz bardzo
zaznajomieni z nurkowaniem głębiej
bardziej złożone środowiska
więc kiedy tylko będziesz gotowy, zanurkujmy
teraz w gke definiuje obiekt wejściowy
zasady kierowania ruchu http i https
do aplikacji działających w klastrze
obiekt wejściowy jest powiązany z jednym
lub więcej obiektów usługowych
z których każdy jest powiązany z zestawem
strąków
podczas tworzenia obiektu wejściowego plik
kontroler ruchu przychodzącego gke
tworzy chmurę Google
moduł równoważenia obciążenia http lub https i
konfiguruje go wg
informacje w ingresie i jego
powiązane usługi
gke ingress jest wbudowane
i zarządzany kontroler ruchu przychodzącego
ten kontroler implementuje ruch przychodzący
zasoby jako moduły równoważenia obciążenia Google Cloud
dla obciążeń http i https w gke
również system równoważenia obciążenia otrzymuje stabilność
adres IP, który można powiązać z plikiem a
nazwa domeny dla każdego zewnętrznego http
i moduł równoważenia obciążenia https lub wewnętrzny http
lub moduł równoważenia obciążenia https używa pojedynczego adresu URL
mapa
który odwołuje się do jednego lub więcej zaplecza
usługi
każdej z nich odpowiada jedna usługa zaplecza
usługa, do której odwołuje się wejście w
w tym przykładzie zakładamy, że masz
powiązany adres IP modułu równoważenia obciążenia
z nazwą domeny bowtieinc.co
kiedy klient wysyła żądanie do
Bowtieinc.co
żądanie jest kierowane do kubernetes
usługi nazwane produkty na porcie 80. i
kiedy klient wysyła żądanie do
Bowtieinc.co
ukośnik przerwał żądanie
jest kierowany do usługi kubernetes o nazwie
przerwane na porcie 21337
ingress jest prawdopodobnie najpotężniejszy
sposób na wyeksponowanie swoich usług, ale może też
być bardzo złożonym
ponieważ istnieje również wiele rodzajów ingresu
kontrolery do wyboru
wraz z wtyczkami do ingresu
kontrolery
ingress jest najbardziej użyteczny i kosztowny
skuteczny, jeśli chcesz się ujawnić
wiele usług pod tym samym adresem IP
adres
jak tylko płacisz
dla jednego modułu równoważenia obciążenia, jeśli używasz
natywna integracja gcp
i jest wyposażony w mnóstwo funkcji
i tak pokazany tutaj jest ingres
manifest, który różni się nieco od
inny manifest, który widziałeś
ponieważ zawiera zasady dla różnych ścieżek
wyjaśnij na poprzednim schemacie w
Manifest pokazany tutaj jedna ścieżka kieruje wszystkimi
ruch drogowy
do nazwy usługi produktu
podczas gdy druga ścieżka przekierowuje ruch
od przerwanego do tylnego końca
nazwa usługi wycofana
i pamiętaj, że każda z tych usług
nazwy mają swoje niezależne
oczywisty
ponieważ jest to potrzebne do utworzenia usługi
i są przywoływane w ingresie
oczywisty
więc im więcej zasad masz dla różnych
ścieżek lub portów, tym więcej usług
będzie potrzebował
teraz chciałem dotknąć w sieci
grupy punktów końcowych lub dowolne g w skrócie
chwileczkę
teraz jest to obiekt konfiguracyjny, który
określa grupę punktów końcowych zaplecza
lub usługi
negatywy są przydatne
do natywnego równoważenia obciążenia kontenera
gdzie każdy kontener może być reprezentowany
jako punkt końcowy systemu równoważenia obciążenia
negs są używane do śledzenia punktów końcowych pod
dynamicznie, więc google low balancer
może skierować ruch w odpowiednie miejsce
tylne końce
więc ruch jest nisko zrównoważony z obciążenia
balancer bezpośrednio do pod ip
w przeciwieństwie do przechodzenia przez vm ip i
coupe sieci proxy w nich
warunki
usługi zostaną automatycznie opatrzone adnotacjami
wskazując, że neg
należy utworzyć, aby odzwierciedlać adresy IP podów
w ramach usługi neg jest czym
umożliwia obliczenie równoważenia obciążenia silnika
komunikować się bezpośrednio z strąkami
pokazany tutaj diagram jest wejściem do
mapowania zasobów silnika obliczeniowego
Manifest, który widziałeś wcześniej, gdzie
kontroler ruchu przychodzącego gke
wdraża niski poziom silnika obliczeniowego i zarządza nim
Balancer zasoby oparte na
zasoby przychodzące
które są wdrożone w klastrze
teraz dotykając kontroli zdrowia tylko dla
minutę, jeśli nie ma określonego zdrowia
sprawdź parametry dla odpowiedniego
praca
przy użyciu niestandardowego zasobu zaplecza
definicja
zestaw parametrów domyślnych i wywnioskowanych
są używane parametry kontroli stanu dla a
usługi zaplecza powinny być wyraźnie określone
zdefiniowane przez utworzenie konfiguracji zaplecza
niestandardowa definicja zasobu dla
usługi i należy to zrobić, jeśli
używasz anthosa
niestandardowy zasób konfiguracji zaplecza
definicji należy również użyć, jeśli ty
mieć więcej niż jeden pojemnik w
obsługując strąki, jeśli potrzebujesz kontroli
przez port, który jest używany do niskiego poziomu
kontrole stanu wyważarki teraz możesz
określ kondycję usług zaplecza
sprawdź parametry
przy użyciu parametru kontroli stanu a
zasób niestandardowy konfiguracji zaplecza
definicja, do której odwołuje się kol
odpowiednia usługa
zapewnia to większą elastyczność i
kontrola
nad kontrolami stanu chmury Google
zewnętrzny system równoważenia obciążenia http lub https lub
wewnętrzny system równoważenia obciążenia http lub https
utworzony przez ingres
i na koniec chciałem dotknąć ssl
certyfikaty i są na to trzy sposoby
dostarczyć certyfikaty ssl do http lub
Pierwszym sposobem jest moduł równoważenia obciążenia https
certyfikaty zarządzane przez Google
i są one aprowizowane wdrożone
odnowiony
i zarządzane dla Twoich domen i tak samo
notka
certyfikaty zarządzane nie są obsługiwane
domeny wieloznaczne drugą drogą do
dostarczyć certyfikaty ssl
certyfikaty samozarządzające, tj
udostępnione w Google Cloud, możesz
udostępniać własny certyfikat ssl
i utwórz zasób certyfikatu
w swoim projekcie Google Cloud możesz
następnie wyświetl zasób certyfikatu w pliku
adnotacja na wejściu, aby utworzyć plik
Używany moduł równoważenia obciążenia http lub https
certyfikat i ostatnia droga do
dostarczyć certyfikaty ssl
certyfikaty samozarządzające jako tajne
zasobów, dzięki czemu możesz udostępniać własne
certyfikat ssl i utwórz klucz tajny do
przytrzymaj go, a następnie możesz odwołać się do tajemnicy
jako specyfikację ruchu przychodzącego w celu utworzenia pliku
Używany moduł równoważenia obciążenia http lub https
ten certyfikat i tylko jako notatkę
może określić wiele certyfikatów w pliku
ingress manifest modułu równoważenia obciążenia
wybiera certyfikat, jeśli nazwa zwyczajowa
w certyfikacie
pasuje do nazwy hosta
użyte w żądaniu i tak ładne
dużo okładek
wszystkie główne tematy tej krótkiej lekcji
na wejściu dla gke
więc możesz teraz oznaczyć tę lekcję jako
kompletny
i przejdźmy do następnego
[Muzyka]
Witamy spowrotem
w tej lekcji omówię gke
opcje przechowywania teraz kubernetes obecnie
oferuje mnóstwo różnych pamięci
opcje
i jest wzmocniony tylko przez dodanie
funkcje dostępne w chmurze Google dla
gke my także będziemy trafiać do
różne abstrakcje, które kubernetes
oferuje zarządzanie pamięcią masową
i jak można je wykorzystać do różnych celów
rodzaje obciążeń
teraz jest tu całkiem sporo do przejścia
więc powiedziawszy to, zanurzmy się
teraz, jak już wspomniałem, jest ich kilka
opcje przechowywania dla uruchomionych aplikacji
na gke
wybory różnią się pod względem elastyczności
i łatwość użytkowania
Chmura Google oferuje kilka miejsc do przechowywania
opcje, które możesz wykorzystać dla siebie
określony nakład pracy
kubernetes zapewnia również przechowywanie
abstrakcje, które otrzymam
w nieco najłatwiejsze miejsce do przechowywania
opcje są zarządzane przez Google Cloud
produkty do przechowywania, jeśli chcesz się połączyć
bazy danych do klastra, możesz
rozważać
przy użyciu magazynu danych cloud sql lub chmury
klucza i jeśli chodzi o obiekt
przechowywanie w chmurze byłoby
doskonała opcja wypełnienia pliku luki
store to świetna opcja, gdy
aplikacja wymaga
zarządzana pamięć podłączona do sieci i if
Twoja aplikacja wymaga pamięci blokowej
najlepszą opcją jest użycie trwałego
dyski
i może być udostępniany ręcznie lub
udostępniane dynamicznie przez
kubernetes teraz chciałem najpierw zacząć
off z abstrakcjami pamięci Kubernetes
ale aby zrozumieć kubernetes
abstrakcje przechowywania, które chciałem wziąć
chwilę, aby wyjaśnić, w jaki sposób montowana jest pamięć masowa
w koncepcji dockera teraz docker ma
koncepcja tomów
chociaż jest nieco luźniejszy i mniej
zarządzane niż kubernetes
wolumin dokera to katalog na dysku
lub w innym pojemniku
docker zapewnia sterowniki głośności, ale
funkcjonalność jest nieco ograniczona a
kontener dokera ma zapisywalną warstwę
i to tutaj są przechowywane dane
domyślny
sprawiając, że dane są efemeryczne i takie są
nie utrwalone, gdy kontener jest
usunięto, więc przechowywanie danych w pliku a
pojemnik nie zawsze jest teraz zalecany
istnieją trzy sposoby montowania danych
wewnątrz kontenera dokera w pierwszy sposób
jest woluminem dokera i znajduje się wewnątrz
obszar dokowania w pliku hosta
systemu i mogą być udostępniane innym
pojemniki
ten wolumin jest obiektem dokera i jest
odłączony od pojemnika
można je dołączać i udostępniać
wiele pojemników również wiąże
montowanie to drugi sposób montowania danych
i pochodzi bezpośrednio od gospodarza
system plików
wiązania są świetne dla lokalnych
rozwój aplikacji
ale nie można ich udostępniać między kontenerami
a ostatnim sposobem na zamontowanie danych jest przez
używając temp-fs
i jest przechowywany w pamięci hosta this
sposób świetnie nadaje się do danych efemerycznych i
zwiększa wydajność, ponieważ już nie
leży w zapisywalnej warstwie kontenera
teraz z abstrakcjami pamięci Kubernetes
system plików i pamięć blokowa są
dostarczane do twoich strąków, ale są inne
niż docker w naturze tomy są
podstawowa jednostka pamięci w kubernetes to
oddziela magazyn od kontenera
i przywiąż go do strąka, a nie do
kontener jak w dockerze regularnym
objętość nazywana po prostu głośnością jest w zasadzie
katalog, w którym znajdują się kontenery w pod
mieć dostęp do określonego woluminu
używany typ jest tym, co go określi
zamiar
niektóre typy woluminów są obsługiwane przez
przechowywanie efemeryczne
jak pusty reż
config map i sekrety oraz te woluminy
nie utrzymują się po ustaniu strąka
istnieć
woluminy są przydatne do tymczasowego buforowania
Informacja
udostępnianie plików między kontenerami
lub załadować dane do innego woluminu
typy są wspierane przez trwałe przechowywanie i
utrzymywać się dłużej niż okres życia strąka
jak trwałe woluminy i trwałe
wolumin twierdzi, że trwały wolumin to a
zasób klastra
które strąki mogą wykorzystać do trwałego przechowywania a
trwałe żądanie wolumenu
może służyć do dynamicznego udostępniania a
stała głośność
wspierane przez trwałe dyski trwałe
roszczenia wolumenowe mogą być również wykorzystywane do
udostępnić inne typy zapasowej pamięci masowej
jak nfs
i będę się bardziej zagłębiał
woluminy trwałe i woluminy trwałe
roszczeń w ciągu zaledwie trochę
teraz, jak widziałeś w oknie dokowanym na plikach dyskowych
w pojemniku to najprostsze miejsce
dla aplikacji do zapisu danych, ale
pliki zostaną utracone, gdy kontener
ulega awarii lub zatrzymuje się z jakiegokolwiek innego powodu
jak również niedostępne dla innych
kontenery działające w tym samym zasobniku w
kubernetes źródło woluminu zadeklarowane w
Specyfikacja pod określa, w jaki sposób
tworzony jest katalog
używany nośnik pamięci
i początkowa zawartość katalogu
pod określa, jakie woluminy zawiera
i ścieżka, w której kontenery montują plik
typy woluminów efemerycznych
żyją tyle samo czasu co strąki
są one połączone z tymi woluminami
tworzony, gdy kapsuła jest tworzona i
utrzymują się tylko przez ponowne uruchomienie kontenera
gdy kapsuła zakończy działanie lub zostanie usunięta
czy tomy zakończone, jak również inne
typy woluminów są interfejsami do trwałego
przechowywania, które istnieją niezależnie od a
pod jak dane woluminów efemerycznych w pliku a
wolumin wspierany przez trwałą pamięć masową
zostaje zachowana po usunięciu strąka
wolumin jest po prostu odmontowany, a plik
dane mogą zostać przekazane do innej kapsuły
teraz tomy różnią się pod względem przechowywania
realizacja
i ich początkową zawartość możesz
wybierz najlepiej dopasowane źródło głośności
Twój przypadek użycia
i będę przechodzić przez niektóre wspólne
źródła głośności
które są używane, a zobaczysz
w wielu implementacjach gke pierwszy
wolumin, który chcę wyświetlić, jest pusty
reż
teraz pusty wolumin dir zapewnia
pusty katalog, w którym znajdują się kontenery w
pod może czytać i pisać od kiedy pod
jest usuwany z węzła z dowolnego powodu
dane w pustym katalogu zostaną usunięte
na zawsze przechowywany jest pusty wolumin dir
niezależnie od medium wspiera węzeł
który może być dyskiem
dysk ssd lub pamięć sieciowa
puste woluminy der są przydatne do podstaw
przestrzeń i udostępnianie danych między wieloma
pojemniki w kapsule
kolejny rodzaj głośności, który chciałem
przejdź do mapy konfiguracji
a mapa konfiguracji jest zasobem, który
zapewnia sposób wstrzykiwania konfiguracji
dane w strąki
dane przechowywane w obiekcie mapy konfiguracji
można odwoływać się w woluminie typu
mapa konfiguracji
a następnie konsumowane przez uruchomione pliki
w strąku następny typ woluminu jest tajny
a tajny tom służy do wykonania
wrażliwe dane, takie jak hasła oauth
tokeny i klucze ssh
dostępne dla aplikacji
dane przechowywane w tajnym obiekcie mogą
być przywoływane w woluminie tajnym typu
a następnie konsumowane przez uruchomione pliki
w poduszce
następny typ woluminu to api w dół i
ten wolumin tworzy dane API w dół
dostępne dla aplikacji
więc te dane zawierają informacje
o strąku i pojemniku, w którym
aplikacja jest uruchomiona
przykładem tego byłoby ujawnienie
informacje o przestrzeni nazw strąków i
adres ip do aplikacji i ostatni
typ woluminu, który chciałem dotknąć, to
żądanie trwałego wolumenu jest teraz trwałe
do czego można użyć wolumenu roszczenia
zapewnić trwałe przechowywanie, tak aby
może być używany przez aplikacje, z których korzysta kapsuła
trwałe żądanie wolumenu
aby zamontować wolumin, który jest przez to wspierany
trwałe przechowywanie i tak teraz, że mam
objęte tomy, do których chciałem przejść
trochę szczegółów na temat trwałych woluminów
zasoby woluminów trwałych są używane
zarządzać trwałą pamięcią masową w klastrze w
gke trwały wolumin
jest zwykle wspierany przez dysk trwały
lub magazyn plików może być używany jako nfs
rozwiązanie w przeciwieństwie do tomów trwałe
cykl życia woluminu jest zarządzany przez
kubernetes i może być dynamicznie
zaopatrzony
bez konieczności ręcznego tworzenia i
usuń trwałe przechowywanie zapasowe
zasoby woluminów to zasoby klastra
które istnieją niezależnie od strąków i
nadal istnieć jako klaster
zmiany i jak strąki są usuwane i
odtworzony, przechodząc do trwałego woluminu
twierdzi, że jest to prośba
i twierdzić, że
trwały zasób woluminu trwały
obiekty roszczeń woluminu żądają określonego
rozmiar
tryb dostępu i klasa pamięci dla
trwały wolumin, jeśli istnieje
trwała głośność może zaspokoić
zażądać lub może być udostępniony
żądanie trwałego wolumenu jest z tym związane
trwała głośność i tylko jako notatka
strąki używają roszczeń
jako woluminy, które klaster sprawdza
twierdzą, że znajdują ograniczoną objętość i
montuje ten wolumin dla poda
teraz chciałem poświęcić chwilę, aby przejść
klasy przechowywania i ich zastosowanie
ogólna pamięć w gke
teraz te implementacje objętościowe
takie jak trwałe dyski gce
skonfigurowane za pomocą klasy pamięci
zasoby
gke tworzy domyślną klasę pamięci dla
ty, który używa standardu trwałego
typ dysku ext4, jak pokazano tutaj
domyślna klasa pamięci jest używana, gdy a
żądanie trwałego woluminu nie określa
nazwa klasy pamięci
i może być również zastąpiony jednym z nich
Twój wybór, możesz nawet stworzyć swój
własne zasoby klasy pamięci masowej do opisania
różne klasy przechowywania
i jest pomocny podczas korzystania z węzła Windows
totalizator piłkarski
teraz, jak powiedziałem przed trwałą głośnością
roszczenia mogą być automatycznie udostępniane
dyski trwałe dla Ciebie
podczas tworzenia tego trwałego woluminu
przedmiot roszczenia
kubernetes dynamicznie tworzy plik
odpowiedni trwały obiekt woluminu
ze względu na domyślną klasę pamięci gke
ten trwały wolumen
jest wspierany przez nowy pusty silnik obliczeniowy
dysk stały używasz tego dysku w
pod, używając roszczenia jako woluminu when
usuwasz roszczenie odpowiadające
trwały obiekt woluminu i
udostępnić dysk trwały silnika obliczeniowego
są teraz również usuwane, aby zapobiec usunięciu
możesz ustawić zasady odzyskiwania plików
trwały zasób dysku
lub jego zasób klasy pamięci do zachowania
teraz wdrożenia, jak pokazano tutaj w this
diagram są przeznaczone dla bezpaństwowców
Aplikacje
więc wszystkie repliki wdrożenia
dzielić to samo trwałe żądanie wolumenu
dlatego zestawy stanowe są
zalecana metoda wdrażania stanowego
Aplikacje
które wymagają unikalnego woluminu na replikę
przy użyciu zestawów stanowych z trwałymi
szablony roszczeń ilościowych
możesz mieć aplikacje, które można skalować
w górę automatycznie
z unikalnymi, trwałymi roszczeniami dotyczącymi wolumenu
skojarzone z każdym zasobnikiem repliki
teraz w końcu chciałem dotknąć niektórych
tematy, które będą decydować o przechowywaniu
dostęp, który jest dostępny dla każdego gke
klaster w twoim środowisku teraz i pierwszy
chciałem zacząć od trybów dostępu
i dostępne są trzy obsługiwane tryby
twoje dyski trwałe, które umożliwiają odczyt
dostęp do zapisu i są tutaj wymienione jako przeczytane
napisz raz, gdzie może być głośność
montowany jako odczyt i zapis przez pojedynczy węzeł
tylko do odczytu wiele jest tam, gdzie tom może
być montowany jako tylko do odczytu przez wiele węzłów
i wreszcie przeczytaj napisz wiele, gdzie jest
wolumin można zamontować jako odczyt i zapis
wiele węzłów i tylko jako notatka
przeczytaj napisz raz jest najczęstszym zastosowaniem
przypadku dysków trwałych
i działa jako domyślny tryb dostępu dla
większość aplikacji obok chciałem dotknąć
od rodzaju dysków trwałych, które są
dostępne oraz korzyści i zastrzeżenia
dostępu dla każdego przechodzącego teraz przez
lekcję dotyczącą dysków trwałych w tym kursie
prawdopodobnie już wiesz o
dostępne dyski trwałe, jeśli chodzi
dostępności strefowej i regionalnej
więc dla niektórych może to być odświeżenie
teraz przechodzę do regionalnych dysków trwałych
są to zasoby wielostrefowe, które
replikować dane między dwiema strefami w
w tym samym regionie i może być używany podobnie do
strefowe dyski trwałe w przypadku a
awaria strefowa kubernetes może zostać przełączona w tryb failover
obciążenia przy użyciu woluminu do drugiego
regionalne dyski trwałe strefy są świetne
dla wysoce dostępnych rozwiązań dla
stanowe obciążenia w gke teraz strefowe
trwałe dyski
są zasobami strefowymi
i tak, chyba że strefa jest określona
gke przypisuje dysk do pojedynczej strefy
i wybiera strefę losowo raz a
udostępniany jest dysk stały
wszelkie strąki odnoszące się do dysku są
zaplanowane w tej samej strefie co dysk
i tylko jako notatkę
używając anty-powinowactwa w strefach
umożliwia rozprzestrzenianie stanowych zestawów strąków
przez strefy
wraz z odpowiednimi dyskami i
ostatni punkt, który chciałem omówić
jeśli chodzi o stałą głośność
dostęp
to szybkość dostępu
teraz, jak stwierdzono we wcześniejszej lekcji
rozmiar dysków trwałych określa
iops i przepustowość dysku gke
zazwyczaj używa dysków trwałych
jako dyski rozruchowe i do tworzenia kopii zapasowych Kubernetes
trwałe woluminy
więc jeśli to możliwe, używaj większych i
mniej dysków
aby osiągnąć wyższą liczbę operacji we/wy i przepustowość
i tak to prawie obejmuje
wszystko, co chciałem omówić
w tej lekcji na temat opcji pamięci gke
więc możesz teraz oznaczyć tę lekcję jako
kompletny
i przejdźmy do następnego
[Muzyka]
witam ponownie w tych kilku następnych demach
będzie robić pełne przejście
i umieścić całą teorię, której się nauczyliśmy
w praktyce poprzez budowanie i
interakcji z klastrami gke, a będziesz
budować i wdrażać własne
konteneryzowana aplikacja na ten temat
klaster zwany pudełkiem muszek, więc w tym
demo, które będziemy konfigurować
własny klaster gke w konsoli wzdłuż
z przejściem przez wszystkie opcje, które
są dostępne podczas wdrażania
również zamierza użyć wiersza poleceń do
skonfiguruj narzędzie wiersza poleceń cubectl
abyśmy mogli wchodzić w interakcje z klastrem
więc powiedziawszy to, zanurzmy się
i tak tutaj w konsoli jestem zalogowany
w jako tonybowties gmail.com
w ramach projektu muszka inc i tak dalej
przed uruchomieniem klastra muszę
upewnij się, że mój domyślny vpc został
utworzone, więc przejdę do
menu nawigacyjne i zamierzam przewinąć
do sieci vpc
i zgodnie z oczekiwaniami jest to domyślna sieć
tutaj, więc mogę iść dalej i tworzyć moje
klastra i tak, aby dostać się do mojego
Konsola silnika Kubernetes, do której zamierzam
przejdź do menu nawigacji i jestem
przewijanie w dół pod obliczeniami i
znajdziesz tutaj kubernetes engine i
zobaczysz kilka różnych opcji
wybierz z i tutaj po lewej stronie
menu ręczne, będę je przeglądać
opcje w nadchodzących demach, ale dla
teraz chcę się skoncentrować na tworzeniu
nasz klaster teraz gk sprawia, że ​​rzeczy są ładne
łatwy
ponieważ mam opcję utworzenia klastra
rozmieścić kontener lub nawet zabrać
szybki start i tak lecimy
dalej i kliknij utwórz nasz klaster
i tak oto jesteśmy poproszeni o nasze
podstaw klastra, gdybym naprawdę chciał
mogę po prostu wypełnić wszystkie pola
który widzisz tutaj i kliknij utwórz
i użyje wszystkich ustawień domyślnych
zbudować mój klaster, ale zamierzamy to zrobić
dostosuj go trochę, więc jedziemy
iść naprzód i przejść przez to wszystko
opcje, więc najpierw pod nazwą jedziemy
aby nazwać ten klaster muszka w desce rozdzielczej
i tak pod typem lokalizacji chcemy
utrzymuj rzeczy jako strefowe i jeśli odhaczę
określę domyślne lokalizacje węzłów
być w stanie uczynić to wielostrefowym
klaster, jak mam taką możliwość
wybieranie z wielu stref, w których i
mogę zlokalizować moje węzły, więc mogę wybrać
poza kilkoma różnymi strefami, jeśli ja
wybrać, ale chcemy zachować to jako
pojedynczy klaster strefowy, więc zamierzam to zrobić
odznacz to wszystko
i pod strefą mam zamiar kliknąć na
rozwijane menu i mam zamiar wybrać
us East 1b i tylko jako notatkę dla każdego
strefa, którą wybierzesz, to miejsce, w którym
samolot kontrolny będzie żył, więc gdybym miał
utwórz klaster wielostrefowy, jak tylko możesz
zobacz strefa główna to strefa, w której
płaszczyzna kontrolna zostanie utworzona i jest
wybrany jako nas wschód 1b, ponieważ to jest
strefę, którą wybrałem, więc jeśli ja
Zmień to
powiedzmy, że jesteśmy na wschodzie 1d, widać to
płaszczyzna kontrolna zmieni się wraz z nią
Zamierzam zmienić to z powrotem na nasz wschód
1b i masz również opcję
utworzenie klastra regionalnego i
wybór lokalizacji zmieni się ze strefy
do regionu i tutaj będziesz musiał
określ co najmniej jedną strefę do wybrania ale
proszę również pamiętać, że to samo
liczba węzłów zostanie wdrożona w każdym z nich
wybrana strefa, więc jeśli mam trzy węzły
w tym klastrze i postanawiam wybrać
trzy strefy, to będę miał dziewięć węzłów
w tym klastrze i tak coś robiąc
jak to może stać się dość drogie, kiedy
szukasz być świadomy kosztów w porządku
więc idąc dalej, odznaczę
określ domyślne lokalizacje węzłów, do których idę
, aby ponownie zmienić typ lokalizacji
strefowy i upewnij się, że moja strefa jest na
nas wschód 1b schodzimy do kapitana
wersja to jest miejsce, w którym byśmy wybrali
albo wersję statyczną, albo wyrazić zgodę na
kanał wydania dla wersji
kubernetes, które chcesz dla siebie
cluster i tak z wersją statyczną i
może wybierać spośród wielu różnych
wersje tutaj przez całą drogę powrotną
1.14.10
aż do najnowszej wersji i tak dalej
z kanałem wydania, który mam
zwolnij wybór kanału tutaj i mogę
wybierz z szybkiego kanału
zwykły kanał lub stabilny kanał
i tak zamierzam zachować rzeczy jako
domyślnie również ze zwykłym kanałem
zamierzam zachować domyślną wersję jako
wersja mojego wyboru, teraz mogę iść
naprzód i po prostu kliknij utwórz tutaj
ale ponieważ to demo jest przewodnikiem, jestem
iść do przodu i przejść przez wszystkie
dostępne opcje, więc zacznę
przechodząc do menu po lewej stronie i
klikając domyślną pulę pod brakiem pul
teraz tutaj mam już jedną pulę węzłów
z trzema węzłami i jest to ustawienie domyślne
puli węzłów dostarczanej z dowolnym klastrem
ale gdybym robił coś konkretnego, np
może dodać kolejną pulę węzłów i
skonfiguruj go stąd, ale ponieważ ja
nie potrzebuję dwóch pul węzłów, jestem
pójdę dalej i usunę nodepool1, więc
Idę tutaj, aby usunąć
nodepool i jak widać gke to robi
naprawdę łatwo mi dodać lub usunąć node
baseny, więc zamierzam wrócić do
domyślna pula i zamierzam ją zachować
Imię jak jest, zatrzymam swój numer
węzły jako trzy i gdybym chciał zmienić
liczbę węzłów, które mogę po prostu wybrać
to mogę wybrać sześć lub dowolną liczbę
węzły potrzebne do obciążenia pracą i tak dalej
ponieważ nie wdrażamy dużych
obciążenie pracą, zatrzymam tę liczbę na poziomie 3
i idąc dalej, chcemy
zaznacz włącz automatyczne skalowanie i tak dalej
w ten sposób nie musimy się martwić
skalowanie w górę lub w dół i oto jestem
zamierzam umieścić minimalną liczbę węzłów
jako jeden i zamierzam zachować maksimum
liczba węzłów na 3. i tak oto jestem
mając możliwość wyboru strefy
lokalizacja dla moich węzłów, ale znowu dla każdego
strefa, którą wybiorę, będzie działać tak samo
ilość węzłów, więc w zasadzie mam
inna opcja do wyboru
posiadanie klastra strefowego lub wielostrefowego
i dlatego, że tworzymy nasz klaster
w pojedynczej strefie zamierzam odznaczyć
to i pod automatyzacją jak widać
włącz automatyczną aktualizację i włącz automatyczną
naprawa są zaznaczone i to jest to
ze względu na fakt, że aktualizacja automatyczna
funkcja jest zawsze włączona dla
zwolnij kanał, który wybrałem, ale jako i
zwrócił na to uwagę na poprzedniej lekcji
to jest najlepsza praktyka Google
mieć automatyczną aktualizację i automatyczną naprawę
włączone, a więc przesuwając się w dół
są pola do zmiany skoku
zachowanie aktualizacji i tak samo jak a
pozwalają na to ulepszenia przypływu odświeżacza
kontroluj liczbę węzłów, które może obsługiwać gke
aktualizuj na raz i kontroluj, w jaki sposób
uciążliwe są te ulepszenia dla ciebie
obciążenia, więc maksymalny wzrost jest liczbą
dodatkowych węzłów, do których można dodać
puli węzłów podczas aktualizacji i max
niedostępne to liczba węzłów
które mogą być jednocześnie niedostępne
podczas tej aktualizacji i dlatego, że jesteśmy
nie martwiąc się o zakłócenia będziemy po prostu
pozostaw to ustawione jako domyślne i tak
idziemy dalej, cofniemy się
do menu po lewej stronie i pod żadnymi basenami
będziemy klikać na węzły i tutaj
jest gdzie mogę wybrać rodzaj
instancja, której chcę używać dla mojego
nodes, więc zatrzymam obraz
wpisz jako kontener optymalizuj os i to
jest domyślnym typem obrazu, ale ja też
mieć możliwość wyboru spośród innych
jak ubuntu czy windows i tak jadę
aby zachować go jako domyślny i poniżej
konfiguracja maszyny, którą zamierzam zachować
to w ramach ogólnego przeznaczenia
z serią e2, ale chcę to zmienić
typ maszyny do e2 micro po prostu być
świadome kosztów i poniżej rozmiaru dysku rozruchowego
chcę zachować 10 gigabajtów, tak jak my
tak naprawdę nie potrzebujesz 100 gigabajtów do czego
robimy tutaj i ty też masz
możliwość wyboru z innego buta
typ dysku, z którego możesz go zmienić
standardowy dysk trwały na ssd, ale jestem
będzie też zachowywać standard
tutaj też mam opcję do wykorzystania
klient zarządza kluczami do szyfrowania
mój dysk rozruchowy, a także wybierając z
węzły z możliwością wywłaszczania dla pewnych oszczędności
i tak mam zamiar przejść teraz do
networking i tutaj, gdybym chciał dostać
naprawdę ziarnisty, mogę dodać maksymalnie strąki
na węzeł, a także niektóre znaczniki sieciowe
ale nasze demo tego nie wymaga, więc ja
zostawię tak jak jest i tak zrobię
wróć do menu po lewej stronie i
kliknij zabezpieczenia i pod węzłem
bezpieczeństwa masz możliwość zmiany
Twoje konto usługi wraz z
zakresy dostępu i tak dla tego demo my
może zachować rzeczy jako usługę domyślną
konto i zakresy dostępu mogą być
w lewo, jak mam zamiar wrócić do
menu po lewej stronie i kliknij metadane
i tutaj mogę dodać etykiety kubernetes jako
a także metadane instancji, a więc ja
wiem, że nie dostałem się do skażeń węzłów, ale
tylko po to, żeby cię poinformować, że nie masz żadnych skaz, kiedy
przesyłasz obciążenie do uruchomienia w pliku a
klaster program planujący określa gdzie
aby umieścić strąki związane z
obciążenie pracą i tak umieści program planujący
pod na dowolnym węźle, który spełnia
wymagania dotyczące zasobów dla tego obciążenia
więc żadne skazy nie dadzą ci więcej
kontrolę nad tym, które obciążenia mogą być uruchamiane
określonej puli węzłów, więc oni
pozwala zaznaczyć węzeł tak, że
Scheduler unika go lub uniemożliwia jego użycie
w przypadku niektórych strąków, na przykład jeśli ty
miał pulę węzłów, która jest dedykowana
gpus, który chcesz zachować tę pulę węzłów
specjalnie dla takiego obciążenia pracą
wymaga tego i chociaż jest w wersji beta
jest to świetna funkcja i tak dalej
to prawie nie obejmuje żadnych basenów, tak jak my
zobacz to tutaj i tak to jest koniec
część pierwsza tego demo, które otrzymywało
trochę długi, więc postanowiłem go podzielić
byłaby to świetna okazja do
żebyś wstał i się porozciągał
sobie kawę lub herbatę i kiedy tylko
jesteś gotowy, zacznie się część druga
zaraz od końca pierwszej części tzw
możesz teraz oznaczyć to jako zakończone i
do zobaczenia w następnym
[Muzyka]
to jest druga część tworzenia gke
rozpocznie się część 2 klastra
bezpośrednio od końca części 1. tzw
powiedziawszy to, zanurzmy się i
więc wracam na lewą stronę
menu ręczne i pod klastrem zamierzam
kliknij automatyzację i tutaj mam
możliwość włączenia okna serwisowego
do wyrównywania czasów podczas automatycznych aktualizacji
są dozwolone, mam możliwość dodania
okno tutaj i mogę to zrobić w
określonych godzinach w tygodniu lub mogę
utwórz niestandardowe okno konserwacji i
więc nie potrzebujemy okna serwisowego
teraz, więc odznaczę to
a także masz możliwość zrobienia
wyłączenia dotyczące konserwacji, kiedy ty
nie chcę, aby wystąpiła konserwacja ngk
daje możliwość robienia wielu
wyjątki serwisowe na czas
ich potrzebujemy i dlatego, że ich nie potrzebujemy
wyłączenia konserwacji, do których zamierzam
usuń te i tutaj masz
opcja włączenia automatycznego poda w pionie
skalowanie i to jest miejsce, w którym zrobi to gke
automatycznie planuj strąki na inne
węzły, które spełniają zasoby
wymagane dla tego obciążenia pracą, jak również tutaj
mogę włączyć automatyczne udostępnianie mojego węzła
a włączenie tej opcji umożliwia gke
automatycznie zarządzać zestawem pul węzłów
które można tworzyć i usuwać jako
potrzebne i mam kilka pól, które
mogę wybrać typ zasobu
minimum i maksimum dla procesora i pamięci
konto usługi
a także dodanie jeszcze większej liczby zasobów
jak gpus, ale nasze obciążenie nie
potrzebuję czegoś tak fantazyjnego, więc idę
aby to usunąć i zamierzam odznaczyć
włączyć automatyczną obsługę administracyjną i wreszcie my
mam profil automatycznego skalowania i mam
możliwość wyboru salda
profile, który jest domyślny, jak również
optymalizacja wykorzystania, która jest nadal
w wersji beta, więc zamierzam zachować rzeczy
jako domyślny i zamierzam się przenieść
z powrotem do menu po lewej stronie
do sieci i tak tutaj mogę dostać
naprawdę ziarnisty z moim klastrem, kiedy to
chodzi o networking, który mam do wyboru
do wyboru publiczne lub prywatne
klaster, jak również mogę wybrać z a
inna sieć i ponieważ mamy tylko
domyślnie to, co się pojawia, ale jeśli
miałeś różne sieci tutaj możesz
wybrać spośród nich, jak również podsieci
mogę też wybrać z innych sieci
opcje takie jak maksymalny zakres adresów pod
strąków na węzeł i jest ich kilka
inne opcje, w które nie wejdę
szczegółowo z, ale zachęcam, jeśli
jesteś bardzo ciekawy, aby przejść przez
docs i sprawdzić te różne
opcje teraz jedna rzecz, której chciałem
należy zauważyć, że włączenie http jest niskie
równoważenie i to jest dodatek
wymagane do korzystania z chmury Google
równoważenie obciążenia i tak jak omówiliśmy
poprzednio w lekcji usług kiedy
włączasz system równoważenia obciążenia typu usługi a
system równoważenia obciążenia zostanie utworzony dla Ciebie przez
dostawca chmury, a więc google
wymaga zaznaczenia tego, aby a
sterownik można zainstalować w
klaster po utworzeniu i pozwoli a
moduł równoważenia obciążenia, który ma zostać utworzony, gdy
usługa jest tworzona, więc zamierzam to zrobić
pozostaw to zaznaczone, tak jak będziemy
wdrażanie modułu równoważenia obciążenia
później i tak przenosząc się z powrotem do
menu po lewej stronie, które zamierzam teraz kliknąć
bezpieczeństwo i jest tu wiele opcji
do wyboru, który ci na to pozwoli
naprawdę zablokuj swój klaster i ponownie
to wszystko zależy od twojego konkretnego
rodzaj obciążenia pracą, teraz nie zamierzam iść
przez wszystkie te opcje tutaj, ale zrobiłem to
chcę podkreślić to dla tych, którzy są
chce być bardziej skoncentrowany na bezpieczeństwie
twój klaster i przesuwając się w dół listy
w menu, które zamierzam kliknąć
metadane, więc tutaj mogę wprowadzić a
opis dla mojego klastra, jak również
dodawanie etykiet i tak ostatnia opcja włączona
menu klastra to funkcje, a tutaj i
mają opcję uruchamiania chmury dla
anthos, który umożliwi wdrożenie
bezserwerowych obciążeń roboczych do klastrów Anthos
i działa na gke i tutaj możesz
włącz monitorowanie dla gke i niech tak będzie
natywnie monitorowane przez Google Cloud
monitorowanie i gdybym prowadził
produkt innej firmy do monitorowania my
klaster mogę po prostu odznaczyć to i
korzystać z mojego zewnętrznego monitoringu i
jest cała masa innych funkcji
w które nie będę się teraz zagłębiać, ale jeśli
jesteś ciekaw, zawsze możesz najechać kursorem
znak zapytania i zdobądź więcej
informacje o tym, co robi i tak dalej
teraz już prawie wszystko omówiłem
konfiguracja, która jest do tego potrzebna
cluster i tak teraz zamierzam w końcu
zejdź na dół i kliknij
utworzyć, więc może to potrwać kilka minut
aby utworzyć ten klaster, więc zamierzam to zrobić
Śmiało i zatrzymaj ten film tutaj i
Wrócę szybciej niż możesz powiedzieć kocie
w kapeluszu ok i klaster został
stworzony, jak widać, jest w
lokalizacja nas na wschód 1b z trzema węzłami
sześć procesorów wirtualnych i trzy gigabajty pamięci
i mogę drążyć i zobaczyć dokładnie
szczegóły klastra, jak również, jeśli i
chciałem edytować którąkolwiek z tych opcji i
można po prostu przejść do góry kliknij
edytować i wprowadzać niezbędne zmiany oraz
więc teraz pewnie zastanawiasz się co
będę musiał zrobić, aby utworzyć
ten klaster za pomocą wiersza poleceń
Cóż, jest to trochę prostsze niż to, co ty
pomyśl, a pokażę ci rację
teraz po prostu przejdę do
menu po prawej stronie i aktywuj Cloud Shell
i przywołaj to dla lepszego oglądania i
zamierzam wkleić moje polecenie gcloud
klastry kontenerów tworzą kreskę z muszką
klaster z flagą num nodes i
liczba węzłów, które wybieram, która jest
trzy i tak jak powiedziałem wcześniej, jeśli i
chciałem po prostu stworzyć prosty klaster
mogę tak zrobić, ale gdybym chciał
utwórz klaster dokładnie tak, jak zbudowałem
mój ostatni klaster, to mogę go użyć
polecenie, które ma wszystkie niezbędne
flagi, które muszę dostosować
do mojego gustu niezbyt ekscytujące
pokaz, ale jednocześnie pokaz
wiesz, jak łatwe, ale potężne jest naprawdę gke
więc nie zamierzam tego uruchamiać
klaster, ponieważ już go mam i tak teraz
chciałem ci pokazać, jak wchodzić w interakcje
z twoim nowym klastrem gke, więc idę
aby po prostu wyczyścić ekran i tak teraz
nakazać mi interakcję z moim klastrem
zamierzam używać kostki ctl
narzędzie wiersza poleceń i to jest narzędzie
który jest używany do interakcji z dowolnym
klaster kubernetes bez względu na
platform teraz mogłem użyć gcloud
polecenia kontenera, ale nie pozwalają
mi się bardzo ziarnisty jak cubectl
narzędzie, a więc zastrzeżenie dotyczące tworzenia pliku your
klastra przez konsolę jest to, że ty
musisz uruchomić polecenie, aby to zrobić
pobierz poświadczenia klastra i
skonfiguruj narzędzie wiersza poleceń cubectl
i zamierzam iść dalej i wkleić to
in now, a polecenie to gcloud
klastry kontenerów uzyskują poświadczenia kreski
i nazwa mojej gromady, która jest łukiem
zawiąż klaster kresek wraz ze strefą
flaga kreska kreska strefa, po której następuje strefa
sam, który jest nami na wschód 1b, do którego jadę
śmiało i naciśnij enter i jak możesz
zobacz cubectl został teraz skonfigurowany i
więc teraz mogę wchodzić w interakcje z moim
klaster, więc tylko po to, aby sprawdzić, czy zamierzam
uruchom polecenie cubectl
getpods i oczywiście bez obciążeń
są obecnie wdrożone w klastrze
nie ma strąków, więc idę biegać
polecenie kostki ctl pobiera węzły
i jak widać polecenie cubectl
narzędzie linii jest skonfigurowane poprawnie i tak
teraz ten klaster jest gotowy
obciążenia wdrożone do niego i jest również
skonfigurowane za pomocą wiersza poleceń cubectl
narzędzie, dzięki czemu będziesz w stanie zarządzać
klaster i rozwiąż problemy, jeśli to konieczne
teraz wiem, że było ich mnóstwo
funkcje, które omówiłem, ale chciałem
dać ci pełny przewodnik, więc
jesteś w stanie zawiązać niektóre z nich
teorię z kilku ostatnich lekcji i zdobądź
wyczucie klastra gke, jakim będziemy
coraz bardziej angażować się w to przez
następne kilka demówek i tyle
prawie wszystko, co chciałem omówić, kiedy
chodzi o tworzenie i konfigurowanie
gke, dzięki czemu możesz teraz oznaczyć to jako
zakończyć i kiedy tylko będziesz gotowy, dołącz
ja w konsoli w następnym gdzie
będziesz budować swoje pudełko z muszkami
kontener do wdrożenia w nowym klastrze
ale jeśli nie planujesz iść
prosto do następnego demo, które robię
zalecamy usunięcie klastra
aby uniknąć niepotrzebnych kosztów i
odtworzyć go, gdy będziesz gotowy do pracy
do następnego demo
[Muzyka]
Witam ponownie teraz w ostatniej lekcji ty
zbudowałem niestandardowy klaster gke i
skonfigurowałem wiersz poleceń kostki ctl
narzędzie do interakcji z klastrem
ta lekcja, którą będziesz budować
obraz dokera dla pudełka z muszkami
za pomocą kompilacji w chmurze, która wtedy będzie
przeniesione do kontenera Google Cloud
rejestru, aby można go było wdrożyć
twój obecny klaster gke i tak jak ty
widzę, że jest tu wiele do zrobienia
to powiedziawszy, zanurzmy się, więc teraz
pierwszą rzeczą, którą chcesz zrobić, to zrobić
sklonuj swoje repozytorium w Cloud Shell, więc
możesz uruchomić niezbędne polecenia
buduj swój wizerunek, więc idę w górę
tutaj w prawym górnym rogu i zamierzam
otwórz chmurę, którą zamierzam zrobić
upewnij się, że jestem w moim katalogu domowym, więc
zamierzam uruchomić polecenie cd space
tylda
naciśnij enter i jestem w moim katalogu domowym
jeśli uruchomię polecenie ls, widzę, że i
mam tylko plik cloud shell.txt, więc teraz jestem
zamierzam sklonować moje repozytorium github i
będę miał link w instrukcji w
repozytorium github, jak również posiadanie go
tekst lekcji poniżej, a więc polecenie
byłby klonem git wraz z https
adres repozytorium github i idę
nacisnąć enter
i skończyło się klonowanie mojego repozytorium
zamierzam szybko wyczyścić ekran
i zamierzam uruchomić polecenie ls and
widzę moje repo tutaj i teraz idę
aby przejść do katalogu według
uruchomienie cd Google Cloud Associate Cloud
inżynier, jeśli uruchomię ls, zobaczę wszystkie moje
sklonować pliki i foldery, a więc teraz
pliki, których potrzebujemy, zostaną znalezione
w pudełku folderu z muszkami pod
kubernetes engine i kontenery, więc jestem
zamierzam zmienić katalogi na to
lokalizacja i biegnij ls i pod pudełkiem łuku
ties to folder o nazwie kontener, który
będzie miał wszystkie niezbędne pliki
których potrzebujesz, aby zbudować swój wizerunek my
mamy jpeg dla pudełka z muszkami
mamy plik dokera i mamy nasz
index.html, a więc to są trzy
pliki, które są nam potrzebne do zbudowania
obraz i tak jak powiedziałem wcześniej jesteśmy
będzie korzystać z narzędzia zwanego chmurą
build, o którym jeszcze nie rozmawialiśmy
cloudbuild to bezserwerowe ci cd
platforma, która pozwala mi pakować
kod źródłowy do kontenerów i możesz
bądź naprawdę fantazyjny dzięki kompilacji w chmurze, ale
nie będziemy zakładać żadnych ci
potoków cd używamy tylko chmury
build, aby budować nasz wizerunek i go forsować
również do rejestru kontenerów
rejestr kontenerów to Google Cloud
prywatne repozytorium dokerów, gdzie możesz
zarządzaj obrazami dockera i integruj je
z chmurą do tworzenia aplikacji gke w chmurze
Funkcje
i inne repozytoria, takie jak github lub bitbucket
i pozwala na niesamowitą konstrukcję
doświadczenie z absolutnie żadnych ciężkich
podnoszenia i dlatego, że potrafisz budować
obrazy bez konieczności opuszczania Google
cloud pomyślałem, że to będzie
świetny czas, aby wyróżnić te usługi
więc wracając do tego, sklonowaliśmy plik
repo, więc mamy tutaj nasze pliki
Cloud Shell i co chcesz zrobić
teraz chcesz się upewnić, że chmura
build api został włączony, ponieważ jest to plik
usługa, z której wcześniej nie korzystaliśmy
możemy przejść przez konsolę i włączyć
api tam, ale zamierzam go uruchomić
tutaj z Cloud Shell i zamierzam
wklej w poleceniu gcloud services
włącz cloudbuild.googleapis.com
Wcisnę enter, a ty powinieneś
pojawi się monit z prośbą o autoryzację
api call, na pewno chcesz
autoryzować
powinno zająć kilka sekund w porządku i
interfejs API został włączony do kompilacji w chmurze
więc teraz zamierzam szybko wyczyścić moje
ekran, a więc dlatego, że chcę ci pokazać
dokładnie to, co chcę robić w chmurze
udać się tam przez
konsola i tak mam zamiar przejść do
menu nawigacyjne i zamierzam
przewiń w dół do narzędzi, aż dojdziesz do
budowa chmury
i zgodnie z oczekiwaniami nic tu nie ma
historia budowy również nie jest tu zbyt duża
wchodzić w interakcje, więc teraz idziesz
aby uruchomić polecenie budujące obraz
i tak zamierzasz to wkleić
polecenie do powłoki chmury, która jest
kompilacje gcloud przesyłają myślnik myślnik tag
gcr.io, czyli chmura Google
rejestr kontenerów nasza zmienna dla naszego
projekt Google Cloud wraz z
obrazek nazwa muszki pudełkowej wersja 1.0.0
i proszę nie zapomnieć o końcowej kropce
na koniec idę do przodu i uderzam
wprowadź kompilację w chmurze, teraz skompresuje plik
pliki i przenieść je do magazynu w chmurze
wiadro, a następnie budowanie w chmurze je bierze
pliki z zasobnika i używa
docker, aby wykonać kompilację dokera
proces, więc zamierzam wstrzymać
wideo tutaj, aż do zakończenia kompilacji i
Wrócę w mgnieniu oka, dobrze i
obraz jest gotowy i teraz się wyświetla
w historii kompilacji w kompilacji w chmurze
dashboard, więc jeśli chcę przejść do szczegółów
do rzeczywistej kompilacji tuż obok
zielony znacznik wyboru, zobaczysz gorąco
link, więc możesz po prostu kliknąć
że i tutaj zobaczysz build
podsumowanie wraz z dziennikiem budowy
szczegóły wykonania wraz z
budować artefakty, a także
skompresowane pliki są przechowywane w chmurze
storage i ma tutaj gorące łącze
gdybym chciał pobrać dziennik budowy i
mogę to zrobić tutaj i wygodnie mam
gorący link do obrazu pudełka z muszkami
a to zaprowadzi mnie do mojego pojemnika
rejestru, abyś mógł śmiało kliknąć
na łączu
powinien otworzyć kolejną kartę i przynieść
bezpośrednio do strony obrazu, który
obejmuje teraz wiele szczegółów
świetna rzecz, którą kocham w kontenerze
rejestr jest znowu tak ciasny
w połączeniu z wieloma innymi
zasoby w chmurze Google, którymi jestem
w stanie po prostu wdrożyć bezpośrednio z tego miejsca
i mogę wdrożyć do uruchamiania w chmurze do gke jako
jak również silnik obliczeniowy, teraz mogłem
po prostu wdróż ten obraz bezpośrednio z tego miejsca
ale chciałem to zrobić z gke, więc jestem
zamierzam wrócić do gke w
inna karta, do której mam zamiar przejść
menu nawigacyjne zejdź do kubernetes
silnik
i zamierzam przejść do górnego menu
i kliknij na wdrożenie, zapyta
dla obrazu, który chcesz wdrożyć, i dla Ciebie
chcesz kliknąć wybierz, aby wybrać nowy
obraz kontenera i powinieneś mieć plik
wyskakujące menu z prawej strony
na ekranie i w rejestrze kontenerów
powinieneś zobaczyć pudełko z muszkami, które możesz
rozwiń węzeł tutaj i po prostu kliknij
obraz, a następnie naciśnij przycisk wyboru
i tak teraz wyglądał obraz kontenera
wypełnione w mojej ścieżce obrazu i tobie
chcę przewinąć w dół i gdybym chciał,
mógłby dodać kolejny kontener, a nawet dodać
niektóre zmienne środowiskowe i tak jesteśmy
nie chcę tego teraz robić, więc ty
możesz po prostu kliknąć kontynuuj i gotowe
zostanie wyświetlony monit z niektórymi polami
wypełnij dla swojej konfiguracji na swoim
wdrożenie, a więc nazwę aplikacji
będzie się nazywał Pudełko z muszkami
zostawię to jako domyślne
przestrzeń nazw, jak również zamierzam zachować
para klucz-wartość jako pudełko aplikacji z muszkami
dla moich etykiet i dlatego
konfiguracja utworzy wdrożenie
plik dla mnie zawsze możesz rzucić okiem
w manifeście, klikając widok
przycisk yaml przed jego wdrożeniem i
jest to zawsze dobra praktyka przed tobą
wdrożyć dowolne obciążenie, tak jak widać
tutaj na górze mam takie jak
wdrożenie nazwy, jak również
przestrzeń nazw moje etykiety
repliki trzech, a także mój selektor
a moja specyfikacja tutaj na dole jako
cóż, ten manifest zawiera również inny
Uprzejmy
poziomego automatycznego skalowania strąków i jest
w połączeniu z wdrożeniem w tym
oczywiste ze względu na odniesienie do
samo wdrożenie i tak jest zawsze
powszechną praktyką jest próba pogrupowania
manifestujcie razem kiedy tylko możecie i
więc jest to naprawdę fajna funkcja
przewaga na gke, więc zamierzam
zamknij to teraz i naprawdę zamierzam to zrobić
zamknij Cloud Shell, ponieważ go nie potrzebuję
teraz również możesz to zobaczyć tutaj
zostanie wdrożony w moim kubernetes
skupisko klastra muszki w nas na wschód 1b
a gdybym chciał, mogę go wdrożyć w
nowy klaster i gdybym miał inny
klastrów w moim środowisku
pokaż się tutaj, a będę mógł wybrać
od nich również, ale klaster muszka jest
jedyny, który mam i tak teraz
zakończyłeś konfigurację dla
swoje wdrożenie, które możesz po prostu kliknąć
wdrożenie to zajmie tylko ok
kilka minut, więc po prostu idę
zatrzymaj wideo tutaj, a ja wrócę jako
jak tylko wdrożenie zostanie zakończone, ok
obciążenie zostało wdrożone i mam
niektóre domyślne komunikaty, które pojawiły się i
może ustawić w tym celu zautomatyzowany potok
obciążenie pracą, ale nie zamierzamy tego robić
dla tego demo, ale nie krępuj się go wypróbować
własne później, jeśli chcesz, a my to zrobimy
chcemy wyeksponować naszą usługę tak, jak chcemy
zobacz, czy działa i czy jesteśmy
za chwilę się tym zajmę
więc jeśli przewinę niektóre z nich
szczegóły tutaj widzę, że mam trochę
metryki tutaj dla pamięci procesora i dysku
grupa
przestrzeń nazw
etykiety i wszystkie strąki, które to jest
działa w zasadzie na żywo
reprezentacja mojego wdrożenia, jeśli i
przewiń z powrotem do góry, mogę nurkować
w niektóre szczegóły wydarzeń
a nawet mój manifest mogę również skopiować mój
zamanifestuj i pobierz, jeśli zechcę
jak widać bardzo różne
options, więc teraz chcę zweryfikować moje
wdrożenie, więc zamierzam użyć
narzędzie wiersza poleceń kostki ctl, aby uruchomić niektóre
polecenia, aby zweryfikować informacje tzw
zamierzam otworzyć kopię zapasową mojej powłoki w chmurze
i zrób to trochę większe dla
lepsze oglądanie i zamierzam uruchomić
polecenie cubectl pobierz wszystko
i jak widać tutaj mam listę
wszystkie strąki, które uruchamiają nazwę
wdrożenia usługi
replika ustawiła wszystko na temat mojego klastra
i moje rozmieszczenie i ty powinieneś być
widząc to samo podczas uruchamiania tego
komendę i tak dalej chcesz podciągnąć
szczegóły dotyczące wdrożeń w pliku
cluster, a więc polecenie to jest
cube ctl pobierz wdrożenia i wyszło
trochę stłoczony na dole, więc jestem
zamierzam po prostu wyczyścić ekran i uruchomić
jeszcze raz to polecenie
i jak widać pudełko z muszkami
rozmieszczenie jest wyświetlane, ile
repliki, które są dostępne, ile z nich
te repliki osiągają pożądane
stan i wraz z tym, jak długo
aplikacja została uruchomiona i tak teraz
Chcę zanurzyć się w moich strąkach i uporządkować
aby to zrobić, uruchomię polecenie
cube ctl dostaje strąki i tutaj widzę wszystko
moje strąki teraz, gdybym chciał spojrzeć na
lista wydarzeń
dla konkretnego poda polecenie do tego
byłoby cubectl opisać pod, a następnie
nazwa jednego z strąków, więc idę
wybrać tę pierwszą kopię, którą jestem
wkleję to i uderzę
wejdź i tutaj mogę zobaczyć wszystkie wydarzenia
które wystąpiły również w przypadku tego strąka
Mam też dostęp do innych
informacje dotyczące wolumenów
warunki, a nawet pojemnik i
identyfikatory obrazów i jest to świetne polecenie
używać podczas rozwiązywania problemów z
strąki i próbujesz dostać się do
dno problemu, a więc teraz finał
krok, który chcesz zrobić, to chcesz
być w stanie narazić swoją aplikację tak
możesz sprawdzić, czy działa
właściwie, więc idziemy dalej
i zrób to przez konsolę, więc jestem
zamierzam zamknąć Cloud Shell i jestem
przejdź do przeglądu i przewiń w dół
na dole kliknij przycisk, który
mówi ujawnić, a gdybym chciał, mogę to zrobić
to stąd w prawym górnym rogu
róg, w którym jest napisane ujawnienie wdrożenia
więc klikam na ujawnienie i to
prawdopodobnie wygląda ci bardzo znajomo jako
jest to graficzna reprezentacja
manifest usług, a więc port
mapowanie tutaj obejmie porty
konfiguracja manifestu usług
zaczynając tutaj od portu docelowego portu jako
a także protokół dla portu docelowego i'm
zamierza otworzyć port 80. tutaj poniżej
rodzaj usługi, którą masz do wyboru
wybierając ip klastra
port węzła lub moduł równoważenia obciążenia i
rodzaj usługi, z której chcesz skorzystać
bądź low balancer i możemy utrzymać
nazwa usługi jako pole usługi muszki
i ponownie możesz wyświetlić plik manifestu
za tę usługę i możesz skopiować lub
pobierz go, jeśli potrzebujesz, ale my tego nie robimy
potrzebuję tego teraz, więc idę
zamknij go w dość prostym procesie
więc wszystko, co muszę zrobić, to kliknąć ujawnić
i w ciągu minuty lub dwóch powinieneś
mieć uruchomioną usługę
twój nowy, lśniący low balancer jest w porządku i
powstała usługa i jak możesz
zobacz, jesteśmy pod usługami i ingresem
z menu po lewej stronie i jeśli wrócę
do strony głównej usług w ingress
możesz zobaczyć to pudełko z usługą muszki
jest jedynym, który tu mam
możliwość stworzenia typu usługi
ingress, ale nie chcemy tego robić
teraz, więc wracam do
usługi i tutaj zobaczysz swoje
punkt końcowy i to jest gorący link
powinien doprowadzić Cię do wniosku tak
możesz kliknąć na to teraz dostaniesz
powiadomienie o przekierowaniu, ponieważ jest to tylko http i
nie https, więc kliknięcie go jest bezpieczne
mam zamiar kliknąć na to teraz i sukces
a oto twoje pudełko z muszkami
czego się spodziewałeś i tak chciałem
pogratulować wdrożenia
pierwsze pole aplikacji muszki na
twój klaster gke i tak tylko jako podsumowanie
sklonowałeś swoje repozytorium do swojej chmury
środowisko powłoki, które następnie zbudowałeś
obraz kontenera przy użyciu kompilacji w chmurze i
wypchnął obraz do rejestru kontenerów
następnie utworzyłeś wdrożenie przy użyciu this
image i zweryfikowałem wdrożenie za pomocą
następnie narzędzie wiersza poleceń kostki ctl
uruchomiła usługę typu low balancer
ujawnić swoją aplikację i zweryfikować
że Twoja aplikacja tak działała
fantastyczna robota z twojej strony i tyle
właściwie wszystko, co chciałem zawrzeć
ta część dema
więc możesz teraz oznaczyć to jako kompletne i
kiedy tylko będziesz gotowy, dołącz do mnie
konsoli do następnej części dema
gdzie będziesz zarządzać swoim obciążeniem pracą
klastra gke, więc proszę o tym pamiętać
opłaty ponoszone na obecnie
wdrożony klaster, jeśli planujesz to zrobić
następne demo w późniejszym terminie znowu możesz
oznacz to jako zakończone i do zobaczenia
w następnym
Witamy ponownie w kilku ostatnich democh
lekcji zbudowałeś niestandardowy klaster gke
i rozłożył pudełko z muszkami
zastosowanie w tej lekcji będziesz
interakcja z tym obciążeniem w gke przez
skalowanie aplikacji edytuj swoje
application i przebudować dockera
image, aby można było wykonać stopniową aktualizację
bieżące obciążenie w klastrze
jest tu wiele do zrobienia, więc z tym
mówiąc, zanurzmy się, więc kontynuujemy
miejsce, w którym skończyliśmy, masz obecnie
Twoje pudełko z muszkami zostało wdrożone
na twoim klastrze gke i tak pierwszy
rzeczą, którą chcesz zrobić, jest skalowanie
wdrożenie i szukasz skalowalności
w dół klastra do jednego strąka, a następnie
cofnij się ponownie do trzech i to jest po prostu
symulować skalowanie obciążenia tak
czy to dziesięć strąków, czy jedna akcja
jest nadal taki sam, więc teraz możemy łatwo
zrób to przez konsolę przez wiercenie
w dół do pudełka muszki obciążenia pracą
przechodząc do górnego menu i klikając na
akcje i kliknięcie na skalę i tutaj i
może wskazać, ile replik chciałbym
i odpowiednio skalować, więc chciałem
aby to zrobić za pomocą wiersza poleceń, więc jestem
zamierza anulować stąd, a potem jestem
zamiast tego otworzy Cloud Shell
dobrze, a teraz, gdy masz Cloud Shell
otwórz, chcesz uruchomić kostkę poleceń
ctl pobierz strąki, aby pokazać aktualnie
uruchamianie dostępnych strąków dla pudełka
obciążenie muszkami i możesz dostać
wyskakujące okienko z prośbą o autoryzację interfejsu API
zadzwonić przy użyciu Twoich danych uwierzytelniających i Ciebie
zdecydowanie chcę autoryzować i tutaj
otrzymasz listę wszystkich strąków, które
prowadzisz swoje pudełko z muszkami
obciążenie pracą i tak teraz, skoro chcesz
skaluj swoje repliki do jednej możliwej
uruchom tę skalę ctl kostki poleceń
wdrożenie i obciążenie pracą, które jest
Pudełko z replikami deski rozdzielczej muszek jest
równy jeden, możesz nacisnąć enter i tak jest
teraz skalowane
i żeby się upewnić, że zamierzam
uruchom kostkę ctl, zdobądź strąki i zauważ to
z moim działa tylko jeden kapsuła
pudełko z muszkami obciążenie pracą iw porządku
dla mnie, aby skalować moje wdrożenie z powrotem do
trzy repliki mogę po prostu uruchomić to samo
polecenie, ale zmień repliki z 1
do 3. naciśnij enter, to zostało przeskalowane, jestem
zamierzam uruchomić kostkę ctl, pobierz strąki i
zauważ, że teraz wróciłem do 3
repliki i tak jak widać
zwiększając lub zmniejszając liczbę
repliki w celu skalowania twojego
aplikacja jest dość prosta do zrobienia w porządku
więc teraz, gdy nauczyłeś się skalować
swoją aplikację, dowiesz się, jak to zrobić
wykonać aktualizację stopniową, ale w kolejności
aby to zrobić, musisz wprowadzić zmiany
Twoja aplikacja, a więc kim jesteś
zamierzasz zrobić, to edytować swoją aplikację
następnie odbuduj obraz dokera i zastosuj
aktualizacja krocząca i aby to zrobić
możemy zostać tutaj w Cloud Shell jako
zamierzasz edytować plik w chmurze
edytor powłoki, najpierw wyczyszczę mój
ekran zamierzam zmienić katalog
do mojego katalogu domowego i teraz chcesz
aby zmienić katalogi do kontenera
folder, w którym znajdują się pliki, których potrzebuję
aby edytować, uruchomię ls i oto
pliki, których potrzebuję, a więc kim jesteś
zamierza teraz zrobić, to edytować plik
index.html i najłatwiejszy sposób
zrobić to po prostu wpisać edytuj
index.html i naciśnij enter, a to się stanie
otwórz swój edytor, aby móc edytować swój
index.html i jeśli pamiętasz kiedy
uruchomiliśmy naszą aplikację, wyglądała
dokładnie tak i tak zamiast czego
spodziewałeś się, że będziemy
faktycznie zmień ten tekst na coś a
trochę inaczej, więc idę
z powrotem do edytora w mojej innej zakładce i
gdzie jest napisane czego się spodziewałeś
faktycznie zmienię to na
Cóż, zawsze przydałoby mi się coś do jedzenia
potem wracam do menu
kliknij plik i kliknij zapisz i tak dalej
teraz, abym mógł wdrożyć to i
muszę odbudować mój kontener, więc jestem
zamierzam wrócić do mojego terminala, jestem
idę wyczyścić ekran i idę
aby uruchomić to samo polecenie, które zrobiłem
ostatni raz, czyli przesłanie kompilacji gcloud
kreska kreska tag gcr kropka io z
zmienna dla twojego projektu Google Cloud
a następnie pudełko z muszkami
okrężnica
1.0.1 i tak będzie inaczej
wersja obrazu również nie zapomnij
ta końcowa kropka na końcu i możesz
naciśnij enter i znowu jest to proces
gdzie budowanie w chmurze kompresuje pliki
przenosi je do zasobnika w chmurze i
następnie pobiera pliki z wiadra i
używa pliku dokera do wykonania
proces budowania dokera i to zajmie
kilka minut, więc robię pauzę
wideo tutaj i wrócę wcześniej
możesz powiedzieć kot w kapeluszu okej i mój
powstał nowy obraz i tak chcę
aby przejść do budowania w chmurze tylko po to, aby to zrobić
pewien, że nie ma błędów, więc jestem
zamierza zamknąć Cloud Shell, ponieważ
nie potrzebuję tego teraz, zamierzam to zrobić
wróć do menu nawigacji i
przewiń w dół do budowania chmury i niżej
zbudować historię powinieneś zobaczyć swoją drugą
zbudować i jeśli się w to zagłębisz, ty
zobaczy, że budowa zakończyła się pomyślnie
i zmierzamy do budowania artefaktów
powinien teraz widzieć twój nowy obraz jako wersję
1.0.1, więc teraz przejdę do rzeczy
do rejestru i zweryfikować obraz
tam i wydaje się, że wszystko wygląda
dobrze, więc teraz wracam do tematu
do mojego klastra gke
Przejdę do menu nawigacji w dół
do kubernetes engine i oto zamierzam
kliknij pole obciążenia, które wybiorę
muszek i w górę w górnym menu
może kliknąć akcje i wybrać a
aktualizacja krocząca i tutaj pojawi się monit
z wyskakującym okienkiem, w którym możesz wejść
Twoje minimalne sekundy gotowe na maksimum
procent wyszukiwania, jak również twój
maksymalny niedostępny procent i tak dalej
tutaj pod obrazami kontenerów jestem
monit o wprowadzenie skrótu sha-256 z
ten obraz dokera jest teraz obrazem dokera
id to skrót, który zawiera sha-256
hash konfiguracji obrazu i if
wracam do otwartej karty dla
rejestr kontenerów, który możesz zobaczyć tutaj
przetrawić szczegóły, aby dać ci trochę
więcej kontekstu wraz z hashem sha 256
dla obrazu, który muszę wdrożyć i
więc możesz po prostu skopiować ten skrót
klikając przycisk kopiowania, a następnie ty
może wrócić do konsoli gke
przejdź do obrazów kontenerów
zaznacz skrót i wklej nowy
hash i tak, kiedy skopiujesz go w make
na pewno jest nadal w tym samym formacie
gcr dot io do przodu ukoś swój projekt
nazwa ukośnik pole muszki the
at symbol, po którym następuje skrót i tak dalej
kiedy to zrobisz, możesz kliknąć
przycisk aktualizacji, a to zaplanuje
aktualizacja dla Twojej aplikacji i as
możesz zobaczyć tutaj u góry, że tak jest napisane
strąki są w toku
jak również, jeśli przejdę do aktywnych wersji
tutaj widać, że jest podsumowanie
oraz status oczekujących strąków i
więc tak jako uwaga
aktualizacje stopniowe zezwalają na wdrożenia
aktualizacja odbywa się bez przestojów
poprzez stopniowe aktualizowanie instancji podów
z nowymi więc strąki będą
zaplanowane na węzłach z dostępnymi
zasobów i jeśli węzły nie mają
wystarczającej ilości zasobów, strąki pozostaną w
stan oczekiwania, ale nie sądzę, że jesteśmy
będzie miał z tym problemów
węzłów, ponieważ ta aplikacja jest bardzo lekka
w zasobach i jeśli otworzę chmurę
powłoka
i uruchom polecenie kostki ctl get strąki
zobaczysz, że zaczęły się nowe strąki
i można to stwierdzić po wieku
pod również, jeśli uruchomiłeś polecenie keep
ctl opisz pod wraz z nazwą pod
można również zobaczyć dzienniki zdarzeń when
kapsuła została utworzona i jeśli zamknę chmurę
powłoka, którą widzę tutaj na górze mojego
szczegóły wdrożenia pokazuje, że my
repliki mają jedną zaktualizowaną czwórkę gotową
trzy dostępne i jeden niedostępny i
jeśli kliknę odśwież, widzę to teraz
wszystkie moje repliki są zaktualizowane i
dostępne i tak teraz w celu sprawdzenia
swoją nową aktualizację możesz po prostu zejść
do wystawiania usług i kliknij na
link do punktów końcowych, otrzymasz to przekierowanie
zauważ, że możesz po prostu kliknąć link
oraz ponieważ stara witryna może być zapisywana w pamięci podręcznej
w przeglądarce może być konieczne odświeżenie
Twoja strona internetowa
i sukces, a teraz ukończyłeś a
aktualizacja krocząca w gke, więc chciałem
gratuluję dotarcia do końca
tego wieloczęściowego demo i mam nadzieję, że tak
było niezwykle przydatne w doskonaleniu się
swoją wiedzę w gke i tak po prostu jako
podsumuj, do jakiego skalowałeś swoją aplikację
pomieścić zarówno mniej, jak i więcej replik
edytowałeś swoją aplikację w chmurze
edytor powłoki i odbudowałeś swój kontener
obraz za pomocą kompilacji w chmurze, którą następnie zastosowałeś
nowy skrót do Twojej aktualizacji kroczącej
i zastosowałem tę kroczącą aktualizację do twojego
wdrożenie, weryfikując wszystko w pliku
zakończyć fantastyczną robotę z twojej strony w ten sposób
był dość skomplikowany i długi, wieloczęściowy
demo i możesz spodziewać się takich rzeczy jak co
których doświadczyłeś w tym demo do popu
w swojej roli bycia chmurą
inżynier w kontaktach z gke i tak dalej
to właściwie wszystko, co chciałem zawrzeć
z tym wieloczęściowym demo współpracującym z
gke, więc zanim pójdziesz, chciałem wziąć
kilka chwil, aby usunąć wszystkie zasoby
stworzyłeś jeden po drugim, więc idę
aby wejść na górę, zamykam
wszystkie moje zakładki, do których mam zamiar przejść
klastry, więc nie chcę usuwać
mój klaster jeszcze, ale pierwsza rzecz
co chcę zrobić, to usunąć mój kontener
obrazy, więc idę do góry do
górę i otwórz powłokę chmury
i zamierzam użyć polecenia gcloud
obrazy kontenerów usuń gcr dot io
ukośnik do przodu w projekcie Google Cloud
zmienny ukośnik wraz z twoim
pierwsze zdjęcie pudełka z muszkami okrężnicy
1.0.0
naciśnij enter, wyświetli się monit, jeśli
chcesz kontynuować chcesz nacisnąć y
na tak i teraz usunął obraz
jak również chcesz usunąć swój najnowszy
obraz, który jest
1.0.1, więc zamierzam zmienić zero na
jedno trafienie enter, zapyta, czy ty
chcesz kontynuować tak i tak
obrazy kontenerów zostały usunięte
i tak teraz wraz z obrazami ty
chcesz również usunąć artefakty i
są one przechowywane w chmurze, więc jestem
zamierzam zamknąć Cloud Shell
idę do nawigacji
menu i schodzę do
magazyn i chcesz wybrać swój
wiadro, które ma nazwę twojego projektu
podkreśl chmurę build wybierz źródło
folder i kliknij usuń i gotowe
pojawi się monit z prośbą o to
usuń wybrany folder, ale w kolejności
aby to zrobić, musisz wpisać nazwę
folderu, więc zamierzam go wpisać
Teraz
możesz kliknąć potwierdź, a więc teraz
folder został usunięty wraz z plikiem
artefakty i tak teraz, że wzięliśmy
opieka nad obrazami wraz z
artefakty, których potrzebujemy, aby oczyścić nasze gke
klaster więc ja jadę ogłowić nazad na górze
do menu nawigacyjnego i idę
przejdź do kubernetes engine i
pierwszą rzeczą, którą chcę usunąć, jest
niski balanser, więc idę dalej
aż do usług i ingresu i możesz
wybierz pole usługi muszki i idź w górę
do góry i kliknij usuń jesteś
dostaniesz potwierdzenie i chcesz
kliknąć usuń i tak się stanie
poświęć kilka minut, robisz to szybko
odśwież i usługa wreszcie została
usunięto Chcę teraz usunąć moje obciążenie pracą
więc przejdę na lewą stronę
menu kliknij obciążenia wybierz
załaduj pudełko muszek i idź do
top i kliknij usuń i chcesz
usuń wszystkie zasoby, w tym
poziomy automatyczny skaler strąków, dzięki czemu możesz
po prostu kliknij usuń i może to potrwać
kilka minut do usunięcia pójdzie do
top i naciśnij przycisk odświeżania, a moje obciążenie pracą ma
został usunięty i teraz wszystko, co zostało
do usunięcia jest sam klaster gke
wracam więc do klastrów
wybierasz klaster i
idź na górę i kliknij usuń i
otrzymasz monit z pytaniem
jeśli chcesz usunąć te zasobniki
i to są domyślne zasobniki do przechowywania
są również instalowane z klastrem
możesz usunąć klaster, podczas gdy
obciążenie pracą jest nadal w grze, ale mam
ten nawyk bycia dokładnym, tak chciałem
aby usunąć obciążenie przed usunięciem
klastra, więc chcesz iść dalej
i kliknij usuń, więc to jest ładne
wszystko, co mam do tego demo
i ta sekcja w google kubernetes
silnik i jeszcze raz gratulacje super
zadanie, możesz teraz oznaczyć je jako ukończone
i do zobaczenia w następnym
[Muzyka]
witaj z powrotem i zrobię to na tej lekcji
obejmować funkcje VPN w chmurze an
niezbędna usługa dla każdego inżyniera
wiedzieć, kiedy chcesz się połączyć
innej sieci do chmury Google, czy
może to być Twoja sieć lokalna inna
dostawca chmury
lub nawet podczas łączenia się z vpcs
ta usługa jest obowiązkowa dla każdego
inżyniera i do egzaminu, więc z tym
mówiąc, zanurzmy się
teraz cloudvpn bezpiecznie łączy się z Twoim peerem
network do twojej sieci vpc przez
połączenie VPN ipsec, gdy mówię o
sieć równorzędna odnosi się do
lokalne urządzenie VPN lub usługa VPN a
brama VPN hostowana przez inną chmurę
dostawca, taki jak aws, lazur lub inny
brama Google Cloud VPN i tak jest
ipsec lub zaszyfrowany tunel z twojego
sieć równorzędna do twojej sieci vpc
przemierza publiczny internet i tak dalej
ci, którzy nie wiedzą, że ipsec jest krótki
dla protokołu bezpieczeństwa internetowego i tego
jest zbiorem protokołów wykorzystujących algorytmy
umożliwiające przesyłanie bezpiecznych danych
przez sieć ip ipsec działa w
warstwa sieciowa, czyli warstwa 3 osi
model, który pozwala mu być niezależnym
jakichkolwiek aplikacji, chociaż tak jest
pochodzą z dodatkowymi kosztami ogólnymi, więc
proszę być świadomym i tak podczas tworzenia
Twoja chmura VPN
ruch odbywający się między nimi
sieci jest szyfrowane przez jedną bramę VPN
a następnie odszyfrowany przez inny VPN
Gateway przechodzi teraz do niektórych szczegółów
o vpn w chmurze to jest regionalny
usługi i proszę wziąć to pod uwagę
uwagę przy podłączaniu
lokalizacja lokalna do chmury Google
najmniejsze opóźnienie to również
oznacza, że ​​gdyby ten region miał odejść
w dół, utracisz połączenie
dopóki region nie zostanie ponownie uruchomiony
teraz VPN w chmurze jest również VPN typu site-to-site
tylko i dlatego nie obsługuje
site-to-client, co oznacza, że ​​jeśli ty
masz w domu laptopa lub komputer
nie można użyć tej opcji z klientem VPN
aby połączyć się z google cloud cloudvpn can
być również używany w połączeniu z prywatnym
dostęp Google dla hostów lokalnych
więc jeśli korzystasz z prywatnego dostępu do Google
w ramach gcp, z którym możesz po prostu się połączyć
swoje centrum danych z VPN i mieć
dostęp tak, jakbyś był już w gcp, więc
jeśli chcesz przedłużyć private
Google dostęp do danych lokalnych
centralna chmura vpn byłaby idealna
wybór, a więc jeśli chodzi o prędkości
każdy tunel VPN w chmurze może obsługiwać do
łącznie trzy gigabity na sekundę
wejście i wyjście, a także routing
dostępne są obie opcje
statyczne i dynamiczne, ale są tylko
dostępne jako dynamiczne dla aha vpn i
wreszcie cloudvpn obsługuje ik w wersji 1
i ike w wersji 2 przy użyciu wspólnego klucza tajnego
i dla tych z was, którzy nie są świadomi ike
oznacza internetową wymianę kluczy i
pomaga to w ustanowieniu zabezpieczenia
uwierzytelniony kanał komunikacji wg
za pomocą algorytmu wymiany kluczy
wygenerować wspólny tajny klucz do zaszyfrowania
komunikacji, więc wiedz o tym, kiedy ty
wybierz cloudvpn, którym jest twoje połączenie
zarówno prywatne, jak i bezpieczne, więc teraz są
dwa rodzaje opcji VPN, które są
dostępne w chmurze Google, z których jeden jest
klasyczny vpn, a drugi to ha vpn
i mam zamiar iść na chwilę
przez różnice teraz z klasyką
vpn zapewnia to poziom usług
zgoda 99,9 procent znana również jako
sla trzech dziewiątek, podczas gdy ma VPN
zapewnia cztery dziewiątki sla kiedy
skonfigurowany z dwoma interfejsami i dwoma
zewnętrzne ips teraz, jeśli chodzi o
routing klasyczny VPN obsługuje zarówno statyczne
i dynamicznego routingu, podczas gdy havpn
obsługuje tylko routing dynamiczny i to
musi być wykonane przez bgp przy użyciu chmury
Klasyczne bramy VPN routera mają
pojedynczy interfejs
oraz jeden zewnętrzny adres IP i
obsługuje tunele przy użyciu routingu statycznego jako
jak również routing dynamiczny i statyczny
routing może być oparty na trasie lub
oparte na polityce, podczas gdy z havpn jest to możliwe
być skonfigurowany dla dwóch interfejsów i dwóch
zewnętrzne adresy IP dla prawdziwych możliwości ha
i jak wspomniano wcześniej, kiedy to nastąpi
do routingu dla dynamicznego routingu havpn jest
jedyna dostępna opcja teraz ta jedyna
rzeczą w klasycznym VPN jest to, że google
chmura jest przestarzała
funkcjonalność 31 października 2021 r
i poleca wszystkim swoim klientom
przenieść się do ha vpn i tak wiedzieć, że to
nie znalazło odzwierciedlenia w egzaminie i
nie wiem czy i kiedy to będzie ale wiem
że podczas tworzenia VPN w chmurze
połączenie w twoim obecnym środowisku h
VPN jest zalecaną opcją i tak dalej
teraz chciałem zanurzyć się w niektórych
architektura konfiguracji VPN w chmurze
dla tych dwóch opcji zaczynających się od
klasyczny VPN
teraz, jak powiedziałem wcześniej, klasyczny VPN to a
rozwiązanie VPN w chmurze
który pozwala połączyć się z siecią równorzędną
do twojej sieci vpc przez ipsec vpn
połączenie w jednym regionie jest teraz inne
ha vpn classic vpn nie oferuje redundancji
po wyjęciu z pudełka, które musiałbyś stworzyć
inne połączenie VPN i jeśli
połączenie miało spaść, zrobiłbyś to
trzeba ręcznie przełączać
połączenie z jednego do drugiego teraz jako
możesz zobaczyć tutaj podczas tworzenia VPN
brama Google Cloud automatycznie
wybiera tylko jeden zewnętrzny adres IP dla
jego interfejs i schemat pokazany tutaj
pokazuje, że z klasycznej sieci VPN
podłączony z sieci Bowtie Dash
vpc w projekcie Bowtie do projektu lokalnego
sieć skonfigurowana przy użyciu trasy statycznej
aby połączyć się teraz, przechodząc do havpn
ponownie jest to chmura o wysokiej dostępności
rozwiązanie VPN, które umożliwia połączenie
sieć równorzędna do sieci vpc za pomocą
połączenie VPN ipsec w jednym
region dokładnie jak klasyczny VPN gdzie
havpn różni się tym, że zapewnia cztery
nines sla i jak widać tutaj to
obsługuje podwójne połączenia, więc kiedy
tworzysz bramę ha vpn google
cloud automatycznie wybiera dwa zewnętrzne
adresy IP
po jednym dla każdego z jego ustalonej liczby dwóch
interfejsy, którymi jest każdy adres IP
automatycznie wybierane spośród unikalnych
pula adresów do obsługi wysokich
dostępność każdego z nich ha vpn
interfejsy bramy obsługują wiele
tunele, które pozwalają tworzyć
wiele bram VPN ha i możesz
skonfiguruj bramę ha vpn za pomocą tylko
jeden aktywny interfejs i jeden publiczny adres IP
adres, jednak ta konfiguracja to robi
nie dostarczać teraz sla z czterema dziewiątkami za ha
brama VPN konfigurujesz zewnętrzną
równorzędny zasób bramy VPN, który
reprezentuje twoją fizyczną bramę równorzędną w
Google Cloud możesz to również utworzyć
zasób jako samodzielny zasób i
użyj go później w tym schemacie dwa
interfejsy bramy vpn ha w
sieć muszka vpc mieszkająca w muszce
projekt są połączone z dwoma równorzędnymi sieciami VPN
bramy w sieci lokalnej i
to połączenie używa routingu dynamicznego
z bgp łączącym się z routerem w chmurze w
Google Cloud teraz, jeśli chodzi o
razy, kiedy korzystanie z cloudvpn ma sens
jedna z pierwszych rzeczy, o których powinieneś pomyśleć
chodzi o to, czy potrzebujesz publicznego
dostęp do internetu, więc kiedy udostępniasz
pliki lub Twoja firma potrzebuje konkretnego
sas produkt, który jest dostępny tylko na
Internet VPN byłby twoją jedyną opcją
jak również wtedy, gdy chcesz użyć
połączenia i lokalizacji peeringu
nie jest dostępny, więc nie możesz
podłącz swoje centrum danych do
wybrana usługa kolokacji vpn
byłaby jedyną inną opcją, którą ty
również, jeśli pojawią się ograniczenia budżetowe
do gry przy podejmowaniu decyzji o połączeniu z
Twoja sieć VPN zawsze będzie taka sama
droga do przebycia, jaką jest połączenie w chmurze
będzie droższą opcją
i wreszcie, jeśli nie potrzebujesz haju
szybka sieć i małe opóźnienia nie są
naprawdę troska o ciebie i tylko ciebie
mieć regularny ruch wychodzący
z chmury Google, wystarczy VPN
dla twoich codziennych potrzeb i tak dalej
opcje pokazane tutaj są również decydujące
czynniki, na które należy zwrócić uwagę, jeśli chodzi o
pytania na egzaminie, które odnoszą się do
cloudvpn lub łączenie sieci i tak dalej
to właściwie wszystko co mam na ten temat
krótka lekcja na temat cloudvpn, więc możesz już teraz
zaznacz tę lekcję jako zakończoną i przejdźmy do rzeczy
przejść do następnego
[Muzyka]
witaj z powrotem i jestem na tej lekcji
przejdziemy do innego typu połączenia
który umożliwia łączność lokalną
do twojego google cloud vpcs, który jest chmurą
połączenie inne niż VPN to jest to
inny typ połączenia, który pozwala
łączność z lokalnego środowiska
środowisko do swojego vpc w chmurze Google
połączenie w chmurze jest najbardziej powszechne
połączenie dla większości większych organizacji
i są dla tych, którzy wymagają szybkiego niskiego poziomu
opóźnień połączeń, omówimy tę lekcję
obejmują funkcje połączeń międzysieciowych w chmurze
i różne rodzaje, które są
dostępne, więc powiedzmy
zanurz się, więc wejdź prosto w chmurę
interkonekt ma bardzo małe opóźnienie
dostępne połączenie między Twoim
lokalne centrum danych i chmura Google
sieci vpc również łączą się w chmurze
połączenia zapewniają wewnętrzny adres IP
połączenie, co oznacza wewnętrzny adres IP
adresy są bezpośrednio dostępne z
obie sieci i tak na hostach lokalnych
może używać wewnętrznych adresów IP i brać
zaleta prywatnego dostępu do Google
zamiast zewnętrznych adresów IP
docieraj do ruchu api i usług Google
między siecią lokalną a
twoja sieć vpc nie przechodzi przez
przez publiczny ruch internetowy a
dedykowane połączenie lub przez a
usługodawca z dedykowanym
połączenie z wewnętrzną siecią vpc
adresy IP są dostępne bezpośrednio
z sieci lokalnej, teraz w przeciwieństwie do
vpn to połączenie nie jest szyfrowane, jeśli
musisz zaszyfrować swój ruch w
ip możesz utworzyć jedną lub więcej
samodzielnie zarządzane bramy VPN w Twoim vpc
sieci i przypisać prywatny adres IP
do każdej bramy teraz, chociaż może tak być
przychodzi też bardzo szybkie połączenie
z bardzo wysoką ceną, teraz w przeciwieństwie do
vpn ten typ połączenia nie jest
zaszyfrowane, jeśli chcesz zaszyfrować swoje
ruchu w warstwie IP, którą możesz utworzyć
co najmniej jedną samodzielnie zarządzaną bramę VPN w
swoją sieć vpc i przypisz prywatny adres IP
adres do każdej bramy teraz chociaż
może to być bardzo szybkie połączenie
wiąże się również z bardzo wysoką ceną
i jest typem połączenia o najwyższej cenie
Cloud Interconnect oferuje dwie opcje
do rozszerzenia sieci lokalnej
dedykowany interkonekt, który zapewnia
bezpośrednie fizyczne połączenie między twoimi
sieć lokalna i sieć Google
jak również partnerskie połączenie międzysieciowe, które
zapewnia łączność między Twoimi
sieci lokalne i vpc za pośrednictwem a
obsługiwanego usługodawcę, więc ja
chciałem poświęcić chwilę, aby podkreślić
różne opcje łączenia w chmurze
zaczynając od dedykowanego interkonektu
dedykowany interkonekt zapewnia bezpośrednie
fizyczne połączenie między twoimi
sieć lokalna i sieć Google
dedykowany interkonekt umożliwia
przesyłać między sobą duże ilości danych
Twoja sieć i Google Cloud, które mogą
być bardziej opłacalny niż zakup
dodatkową przepustowość w przestrzeni publicznej
Internet dla dedykowanego połączenia
zapewnić dedykowane połączenie międzysieciowe
połączenie między siecią Google
i własny router we wspólnej lokalizacji
poniższy przykład pokazuje a
pojedyncze dedykowane połączenie międzysieciowe
między siecią vpc a lokalną
sieć dla tej podstawowej konfiguracji dedykowana
zapewnione jest połączenie międzysieciowe
między siecią Google a
router lokalny we wspólnym
obiekt kolokacji podczas tworzenia
załącznik vlan kojarzysz go z plikiem a
router w chmurze ten router w chmurze tworzy plik
sesja bgp dla przyłączenia vlan i
odpowiedni lokalny element równorzędny
router te trasy są dodawane jako niestandardowe
dynamiczne trasy w twojej sieci vpc i
więc dla dedykowanego połączenia międzysieciowego
pojemność jest dostarczana przez jeden lub więcej
10 gigabitów na sekundę lub 100 gigabitów
na sekundę połączeń Ethernet z
następna maksymalna obsługiwana pojemność na
połączenie międzysieciowe, więc z twoim 10
połączenia gigabitowe na sekundę, które możesz
uzyskaj do ośmiu połączeń o łącznej wartości a
prędkość 80 gigabitów na sekundę z
100 gigabitów na sekundę połączenia
można połączyć dwa z nich razem, aby mieć
łączna prędkość 200 gigabitów na sekundę
i tak dla dedykowanego interkonektu
sieć musi fizycznie spełniać Google
sieci w obsługiwanej kolokacji
obiekt zwany także interkonektem
lokalizacja połączenia tego obiektu
jest gdzie sprzedawca kolokacji
dostawca obiektu udostępnia obwód
między Twoją siecią a krawędzią Google
punkt obecności znany również jako pop
pokazana tutaj konfiguracja jest odpowiednia dla
niekrytyczne aplikacje, które mogą
tolerować pewne przestoje, ale dla wrażliwych
aplikacje produkcyjne co najmniej dwa
połączenia między sobą w dwóch
istnieją różne domeny dostępności brzegowej
zalecany teraz partnerski interkonekt
zapewnia łączność między Twoimi
sieć lokalna i twoja sieć vpc
za pośrednictwem obsługiwanego usługodawcy tzw
to nie jest bezpośrednie połączenie z
swoją sieć lokalną do Google jako
usługodawca zapewnia kanał
między siecią lokalną a
Google pop teraz jako partnerski interkonekt
połączenie jest przydatne, jeśli jest dedykowane
międzysieciowy obiekt kolokacyjny
fizycznie poza twoim zasięgiem
obciążenia nie gwarantują całej 10
połączenie Gigabit na sekundę dla
partnerski interkonekt 50 megabitów na
drugi do 50 gigabitów na sekundę vlan
załączniki są dostępne z
maksymalny obsługiwany rozmiar załącznika 50
Gigabity na sekundę teraz usługa
dostawcy mają istniejące fizyczne
połączenia z siecią Google
udostępniają swoim klientom
użyć tak w tym przykładzie pokazanym tutaj ty
zapewni partnerskie połączenie międzysieciowe
połączenie z usługodawcą i
podłączenie sieci lokalnej do
tego usługodawcy po nawiązaniu połączenia
jest ustalana z usługodawcą
jest partnerskie połączenie międzysieciowe
wymagane od usługodawcy i
dostawca usług konfiguruje twój vln
załącznik do użytku po nawiązaniu połączenia
jest zabezpieczony, możesz zacząć przechodzić
ruch między sieciami za pomocą
sieć usługodawców już tam jest
wiąże się z wieloma bardziej szczegółowymi krokami
uzyskać połączenie ustanowione wraz z
ruch płynący, ale po prostu chciałem
dać podsumowanie wysokiego poziomu, w jaki sposób
zostanie nawiązane połączenie z A
usługodawca teraz również zbudować
wysoce dostępna topologia, której możesz użyć
wielu usługodawców, jak również Ty
musi zbudować redundantne połączenia dla
każdy usługodawca w każdym
metropolita i tak teraz jest para
więcej typów połączeń, które przebiegają
usługodawcy, którzy nie są na
egzamin, ale chciałem, żebyś był tego świadomy
je, jeśli kiedykolwiek zaistnieje taka sytuacja
swoją rolę jako inżyniera chmury, więc
pierwszy to direct peering i direct
peering umożliwia ustanowienie
bezpośrednie połączenie peeringowe między twoimi
sieć biznesowa i krawędź Google
sieci i wymiany o dużej przepustowości
ruchu w chmurze, jaką jest ta funkcja
dostępne w każdym z ponad 100
lokalizacjach w 33 krajach na całym świecie
świat po ustanowieniu bezpośredniego peeringu
zapewnia bezpośrednią ścieżkę z twojego
z sieci lokalnej do usług Google
w tym produkty Google Cloud, które to potrafią
zostać ujawnione przez jeden lub więcej publicznych adresów IP
adresuje ruch z sieci Google
do sieci lokalnej również trwa
tę bezpośrednią drogę
w tym ruch z sieci vpc w
Twoje projekty teraz możesz również zapisać
pieniądze i otrzymuj bezpośrednie ceny wychodzące
dla twoich projektów po ich wykonaniu
nawiązał bezpośredni peering z Google
bezpośredni peering istnieje poza Google
cloud, chyba że potrzebujesz dostępu do Google
zalecane aplikacje obszaru roboczego
metodami dostępu do chmury Google są
dedykowany interkonekt lub partner
interkonekt ustanawiający połączenie bezpośrednie
połączenie peeringowe z Google jest bezpłatne
i nie ma żadnych kosztów na port i nie
stawek godzinowych, które po prostu musisz spełnić
techniczne wymagania Google dotyczące peeringu
i wtedy może być brane pod uwagę
usługa bezpośredniego peeringu
i przechodzimy do ostatniego połączenia
typem jest interkonekt cdn, teraz wiem, że my
nie dostałem się do cdns w trakcie
ponieważ egzamin nie wymaga wiedzy
ale cdn oznacza dostarczanie treści
network jest tym, co buforuje zawartość w
krawędzi sieci, aby szybciej dostarczać pliki
tych, którzy o to proszą, jednym z głównych sposobów
aby teraz poprawić wydajność witryny
przejście do połączenia cdn
typ połączenia umożliwia wybór
zewnętrzni dostawcy cdn, tacy jak akamai
i cloudflare wraz z innymi
ustanowić i zoptymalizować swój cdn
kosztów populacji za pomocą bezpośredniego peeringu
linki z siecią brzegową Google i
umożliwia kierowanie ruchu z
swoje sieci vpc do dostawcy
sieci, a więc ruch wychodzący z
Google Cloud za pomocą jednego z tych linków
korzysta z bezpośredniego połączenia z
dostawcy cdn i jest rozliczany
automatycznie z obniżoną ceną
typowe przypadki użycia połączenia cdn
jest, jeśli wypełniasz swój cdn
duże pliki danych z chmury Google lub
masz zapisane częste aktualizacje treści
w różnych lokalizacjach cdn i tak dalej
wchodzenie w przypadki użycia, kiedy to
korzystaj z połączenia w chmurze, aby mieć duży cel
miałoby to uniemożliwić ruch uliczny
przemierzając publiczny Internet, jest to
dedykowane połączenie fizyczne do
centra danych Google, więc kiedy potrzebujesz
rozszerzenie twojej sieci vpc do twojego
połączenie międzysieciowe w siedzibie jest
zdecydowanie sposób, aby przejść teraz w prędkości
i niskie opóźnienia o ogromnym znaczeniu
Interkonekt jest zawsze najlepszą opcją
i będzie obsługiwać do 200 gigabitów na
drugi, jak również, gdy masz ciężki
ruch wychodzący lub wychodzący
opuszczam Google Cloud Cloud Interconnect
idealnie pasuje do rachunku i wreszcie kiedy
chodzi o prywatny dostęp do Google
podróżuje po kręgosłupie Google
sieci i tak, gdy jesteś podłączony
z interkonektem jest to rozszerzenie
tego kręgosłupa, a zatem i twojego
będą w stanie przyjąć hosty lokalne
zaleta prywatnego dostępu do Google i
więc mam nadzieję, że to ci trochę dało
jasność co do różnic między
różne typy połączeń i jak to zrobić
rozszerz swoją sieć Google Cloud do
sieć równorzędna lub lokalna, więc to jest to
prawie wszystko, co musiałem pokryć, kiedy to
przychodzi do połączenia w chmurze, więc możesz
teraz zaznacz tę lekcję jako ukończoną i
przejdźmy do następnego
[Muzyka]
witam ponownie na tej lekcji, na którą idę
obejmie przegląd silnika aplikacji
teraz to nie jest lekcja głębokiego nurkowania
silnik aplikacji, ponieważ jest tak wiele do omówienia
z tą usługą, ale będę wystawiać
wiele funkcji silnika aplikacji
dać ci dobre wyczucie tego, co może zrobić
i co musisz wiedzieć o
egzamin, więc powiedzmy, że nurkujemy
w tej chwili silnik aplikacji jest w pełni zarządzany
bezserwerowa platforma do tworzenia i
hosting aplikacji internetowych na taką skalę
to platforma Google jako usługa
oferta, dla której została zaprojektowana
programistów, aby mogli się rozwijać
ich aplikacji i pozwól zrobić to silnikowi aplikacji
całe ciężkie podnoszenie, dbając o
udostępnianie serwerów i skalowanie
potrzebne instancje na podstawie aplikacji na żądanie
silnik zapewnia elastyczność
uruchamianie kodu tak, jak jest lub możesz
uruchom go jako kontener i używa
środowiska uruchomieniowe różnych
różne języki programowania, np
python java node.js go ruby ​​php lub net
aplikacje wdrożone na silniku aplikacji, który
doświadczać regularnych wahań ruchu
lub nowo wdrożonych aplikacji, gdzie
po prostu nie jesteś pewien obciążenia
automatycznie skalowane odpowiednio i
automatycznie Twoje aplikacje skalują się do
liczba uruchomionych instancji
zapewnić spójną wydajność lub skalę
w dół, aby zminimalizować bezczynne instancje i
zmniejsza koszty silnik aplikacji ma również
możliwości radzenia sobie
szybkie skalowanie dla nagłych ekstremalnych skoków
ruchu mającego wiele wersji
swoją aplikację w ramach każdej usługi
pozwala szybko przełączać się między
różne wersje tej aplikacji
do testów wycofywania lub innych tymczasowych
zdarzenia, do których możesz skierować ruch do jednego lub
bardziej szczegółowe wersje twojego
aplikacji poprzez migrację lub podział
ruchu i możesz korzystać z ruchu
podział w celu określenia wartości procentowej
rozkład ruchu na dwa lub
więcej wersji w ramach usługi
i pozwala wykonać test ab lub niebieski
zielone wdrożenie między wersjami
podczas wdrażania nowego silnika aplikacji z funkcjami
obsługuje łączenie z pamięcią zaplecza
usługi, takie jak chmura firestore cloud
sql i przechowywanie w chmurze wraz z
łączenie się z lokalnymi bazami danych i
nawet zewnętrznych baz danych, które są hostowane
w innym silniku aplikacji chmury publicznej jest
dostępne w dwóch osobnych smakach
standardowe i elastyczne środowiska oraz
każde środowisko oferuje własny zestaw
funkcje, które omówię za chwilę
sek
teraz, jak wspomniałem wcześniej, jest silnik aplikacji
dostępne w wersji standardowej i elastycznej
środowiskach i w zależności od
aplikacja wymaga jednej woli
wspieraj to, czego potrzebujesz do swojego obciążenia pracą
lub możesz nawet użyć obu
jednocześnie funkcje pokazane tutaj
daje poczucie obu typów
środowiskach i zamierzam robić
szybki przegląd podsumowania
cechy każdego zaczynające się na
standardowe środowisko teraz z
uruchamiane są standardowe aplikacje środowiska
bezpieczne środowisko piaskownicy pozwalające
standard silnika aplikacji do dystrybucji
żądania na wielu serwerach i
skalowanie serwerów w celu sprostania wymaganiom ruchu
twoja aplikacja działa z własną
bezpieczne, niezawodne środowisko
niezależny od sprzętu
system operacyjny lub fizyczna lokalizacja
serwer, na którym zapisany jest kod źródłowy
konkretne wersje
obsługiwanych języków programowania
a przy standardowym silniku aplikacji tak jest
przeznaczone do uruchomienia za darmo lub na bardzo
niski koszt, gdzie płacisz tylko za to, co ty
potrzebujesz i kiedy tego potrzebujesz z aplikacją
standard silnika, jaki może zastosować Twoja aplikacja
skaluj do zera wystąpienia, gdy nie ma
został zaprojektowany standard silnika aplikacji ruchu
na nagłe i ekstremalne skoki ruchu
które wymagają natychmiastowego skalowania i
opiera się na cenach standardowego silnika aplikacji
w godzinach instancji i tak kiedy nadejdzie
do funkcji dla elastycznego silnika aplikacji
instancje aplikacji działają w oknie dokowanym
kontenery, które zawierają plik custom
runtime lub kod źródłowy napisany w innym
języki programowania te okna dokowane
kontenery są następnie uruchamiane na komputerze
silnik aplikacji vms zostanie uruchomiony z elastycznym silnikiem
dowolny kod źródłowy napisany w
wersja dowolnego z obsługiwanych
języki programowania dla silnika aplikacji
elastyczny i odbiegający od standardu
środowisko niestety nie ma
bezpłatny limit dla elastycznego silnika aplikacji jako
dobrze zaprojektowany jest elastyczny silnik aplikacji
stały ruch lub dla aplikacji
które doświadczają regularnego ruchu
wahania i ceny są oparte na
zasobów maszyny wirtualnej, a nie godzin instancji
jak standard silnika aplikacji i tak gdzie
Elastyczny silnik aplikacji naprawdę błyszczy
standard silnika aplikacji są tym, czym są maszyny wirtualne
zarządzane, więc stan instancji jest sprawdzany
leczony w razie potrzeby i współlokowany z
inne usługi w ramach projektu
system operacyjny vm jest aktualizowany i
stosowane automatycznie, podobnie jak vms
uruchamiany ponownie co tydzień, aby się upewnić
niezbędny system operacyjny i
aktualizacje zabezpieczeń są stosowane przez ssh
z dostępem do konta root są dostępne dla maszyny wirtualnej
instancji, na których teraz działają Twoje kontenery
wdrażanie aplikacji w silniku aplikacji to
tak proste, jak użycie wdrożenia aplikacji gcloud
Komenda
to polecenie automatycznie buduje plik
obraz kontenera z Twojej konfiguracji
plik za pomocą usługi budowania w chmurze
a następnie wdraża ten obraz w aplikacji
silnik jest teraz aplikacją silnika aplikacji
składa się z pojedynczego zasobu aplikacji
który składa się z jednej lub więcej usług
każda usługa może być skonfigurowana do użycia
różnych czasów działania i obsługi
różne ustawienia wydajności
usługi i silnik aplikacji są przyzwyczajone
uwzględnij swoje duże aplikacje
elementy logiczne
które mogą bezpiecznie udostępniać silnik aplikacji
funkcje i komunikować się z jednym
stają się kolejne usługi silnika aplikacji
luźno powiązane zachowanie
mikroserwisy teraz w ramach każdej usługi
wdrażasz wersje tej usługi i
każda wersja działa następnie w ciągu jednego lub
więcej przypadków w zależności od tego, ile
ruchu skonfigurowanego do obsługi
posiadanie wielu wersji twojego
pozwala aplikacja w ramach każdej usługi
szybko przełączać się między różnymi
wersje tej aplikacji dla
testy wycofywania lub inne tymczasowe
zdarzenia, do których możesz skierować ruch do jednego lub
bardziej szczegółowe wersje twojego
aplikacji poprzez migrację ruchu do jednej
konkretna wersja
lub dzielenie ruchu między dwa
oddzielne wersje, a więc wersje
w ramach Twoich usług działają na jednym lub kilku
instancje domyślnie skalują silnik aplikacji
Twoja aplikacja będzie pasować do Twojego obciążenia
aplikacje zwiększą liczbę
instancje, które są uruchomione w celu zapewnienia
stałą wydajność lub skalowanie do
zminimalizować bezczynne instancje i obniżyć koszty
teraz, jeśli chodzi o zarządzanie instancjami
silnik aplikacji może automatycznie tworzyć i
zamykaj instancje jako ruch
waha się lub możesz określić liczbę
instancji do uruchomienia
niezależnie od natężenia ruchu
można również skonfigurować, jak i kiedy nowy
instancje są tworzone przez określenie a
typ skalowania dla Twojej aplikacji i
jak to zrobić, określasz
typ skalowania w aplikacji
app.yaml teraz są trzy
różne rodzaje skalowania wyborów do
wybrać z i pierwszym z nich jest
skalowanie automatyczne i ten typ skalowania
tworzy instancje na podstawie częstości żądań
opóźnienia odpowiedzi i inne aplikacje
metryki, dla których możesz określić progi
każdą z tych metryk, jak również a
minimalna liczba instancji do dalszego działania
przez cały czas, jeśli używasz automatycznego
skalowanie każdej instancji w twoim
aplikacja ma własną kolejkę dla
żądania przychodzące przed kolejkami
stać się wystarczająco długi, aby mieć widoczny
wpływ na silnik aplikacji z opóźnieniem
automatycznie tworzy jeden lub więcej nowych
instancje do obsługi obciążenia na sekundę
type jest podstawowym skalowaniem i to tworzy
przypadki, w których otrzymana zostanie Twoja aplikacja
żąda zamknięcia każdej instancji, kiedy
aplikacja staje się bezczynna podstawowa
skalowanie jest fantastyczne dla przerywanych
obciążenia pracą lub jeśli chcesz prowadzić
Twoja aplikacja według aktywności użytkownika
silnik postara się obniżyć Twoje koszty
nawet jeśli może to skutkować wyższymi
opóźnienie jako głośność przychodzących
żądania rosną i tak ostatnie
typ skalowania to skalowanie ręczne i to
to miejsce, w którym określasz liczbę
instancje, które działają w sposób ciągły
niezależnie od obciążenia więc takie są
stale działające instancje
a to pozwala na złożone zadania uruchamiania
przypadki już były
zakończone podczas otrzymywania wniosków i
aplikacje, które opierają się na stanie
pamięć w czasie, więc jest to idealne rozwiązanie
dla instancji, których konfiguracja
skrypty wymagają trochę czasu, aby w pełni działać
ich kurs, więc teraz, kiedy już przeszedłem
zarządzanie instancjami, które chciałem wziąć
kilka chwil, aby omówić mechanizm aplikacji
zarządza ruchem rozpoczynającym się od ruchu
migracja teraz przełączniki migracji ruchu
kierowanie żądań między wersjami
w ramach usługi Twojej aplikacji
przenoszenie ruchu z jednej lub kilku wersji
do jednej nowej wersji, więc kiedy
wdrażanie nowej wersji z tym samym
nazwa istniejącej wersji powoduje
natychmiastowa migracja ruchu wszystko
wystąpienia starej wersji są
natychmiast wyłącza się w silniku aplikacji
standard, który możesz wybrać do trasy
żądania do wersji docelowej
natychmiast lub stopniowo też możesz
wybierz opcję włączenia żądań rozgrzewki, jeśli
chcesz, aby ruch był stopniowo migrowany do a
wersja stopniowa migracja ruchu nie jest
obsługiwane w elastycznym i elastycznym silniku aplikacji
ruch jest migrowany natychmiast teraz jeden
należy zauważyć, że kiedy ty
natychmiast przenieś ruch do nowego
wersja bez żadnych uruchomionych instancji
wtedy twoja aplikacja będzie miała skok
w opóźnieniu dla żądań ładowania
podczas tworzenia instancji i tak dalej
inny sposób zarządzania ruchem w aplikacji
silnik przechodzi teraz przez podział ruchu
możesz użyć podziału ruchu, aby określić
procentowy rozkład ruchu
w dwóch lub więcej wersjach
w ramach usługi, więc w tym przykładzie if
Wdrażam nową wersję mojego
usługi mogę decydować, jak chcę
dystrybuować ruch do każdej wersji my
aplikacji i tak decyduję, że chcę
aby zachować moją obecną wersję w grze, ale
wypuścić nową wersję my
wniosek o odejście 10 moich użytkowników
stara wersja wciąż miała 90 lat
ruch przechodzący do tej wersji i tak dalej
dzielenie ruchu pozwala na prowadzenie
ab testing między twoimi wersjami i
zapewnia kontrolę nad tempem, kiedy
wdrażanie funkcji i tylko jako notatkę
po określeniu dwóch lub więcej
wersje do podziału musisz wybrać
czy podzielić ruch przez albo przez
albo plik cookie http adresu IP, albo zrób to
losowo teraz znowu to nie było
lekcja głębokiego nurkowania na silniku aplikacji, ale ja
mam nadzieję, że to dało ci przegląd
funkcje, które są dostępne jako
egzamin dotyczy również tych funkcji
chciałem dać ci trochę znajomości
sama usługa jako następna i
wejdziemy na demo, gdzie my to zrobimy
uruchamiać aplikację za pomocą app
silnik i wypróbowanie niektórych z nich
funkcje dla siebie i tyle
właściwie wszystko, co chciałem zawrzeć
jeśli chodzi o silnik aplikacji, więc możesz
teraz zaznacz tę lekcję jako ukończoną i
kiedy tylko będziesz gotowy, dołącz do mnie
konsola, na której wdrożysz plik
aplikację w silniku aplikacji i wypróbuj
niektóre z tych funkcji dla siebie
[Muzyka]
witaj z powrotem iw tym demo jesteś
zamiar zbudować kolejną aplikację do
wdrożyć na silniku aplikacji o nazwie serverless
muszki, które przeprowadzi Cię przez to demo
tajniki wdrażania strony internetowej
aplikacja na silniku aplikacji wraz z
zarządzanie nim podczas doświadczania nie
przestoje, więc pracy jest sporo
zrobić tutaj tak z tym powiedziawszy
zanurzyć się i tak oto w mojej konsoli jestem
zalogowany jako tonybowtieace gmail.com
w ramach projektu bowtie inc i tak dalej
Pierwszą rzeczą, którą chcę tutaj zrobić, jest to, że chcę
aby przejść do silnika aplikacji, więc wejdź
w tym celu udam się do
górne menu nawigacyjne po lewej stronie i jestem
zejdę do silnika aplikacji i
bo żadnego nie stworzyłem
aplikacji, do których zostanę skierowany
tę stronę powitalną teraz w celu wdrożenia
ta aplikacja nie będziemy
robiąc to przez konsolę, ale zrobimy to
robić to za pomocą wiersza poleceń i
więc na początek mam zamiar
wejdź na górę i otwórz Cloud Shell
zrobię to większe na lepsze
oglądanie i tak abym mógł dostać
kod do uruchomienia tej aplikacji jestem
zamierzam sklonować moje repozytorium github
w skorupę chmury i tak dla tych z was
z którego nie usunąłeś swojego repozytorium
ostatnie demo, które możesz przejść dalej i pominąć
krok klonowania dla tych z was, którzy
będziesz musiał sklonować swoje repozytorium
znajdź link do instrukcji w pliku
tekst lekcji i tam będziesz mógł
pobierz polecenie, którym będzie git
clone wraz z adresem repozytorium
nacisnę enter i dlatego, że tak
już sklonowałem to repozytorium, które otrzymuję
ten błąd zamierzam zrobić ls i as
możesz zobaczyć tutaj chmurę google
Associate Cloud Engineer ma repozytorium
już sklonowany, więc idę na cd
do tego katalogu i aby uzyskać
kod, który zamierzam po prostu uruchomić
polecenie git pull
aby uzyskać najnowsze i zamierzam to zrobić
po prostu wyczyść mój ekran i tak teraz
odzyskałem cały kod, którego potrzebuję
aby go wdrożyć, muszę przejść do
ten katalog i ten katalog jest
będzie 11 usług bezserwerowych
ukośnik w przód 0 1 bezserwerowe muszki i
naciśnij enter, uruchomisz ls i
tutaj znajdziesz dwie wersje
strona internetowa aplikacja strona v1 i strona v2
wraz z instrukcją, jeśli chcesz
podążać prosto stąd i tak ja
chcę iść naprzód i wdrożyć mój pierwszy
aplikacja internetowa, więc idę na cd
do serwisu v1 ls i tutaj zobaczysz
app.yaml, który jest konfiguracją
plik, który będzie potrzebny do uruchomienia
aplikacja na silniku aplikacji i tak dalej
zanim przejdę dalej i wdrożę to i
Chciałem poświęcić chwilę, aby pokazać ci
konfiguracja aplikacji, więc idę
iść dalej i otworzyć go w chmurze
edytor powłoki, więc zamierzam wpisać
edytuj app.yaml wprowadź i jak widać
tutaj moje środowisko wykonawcze to python 3.7 i jak ty
widzę, że mam domyślną datę wygaśnięcia
dwie sekundy wraz z wygaśnięciem
pod każdym handlerem i to jest spowodowane
do problemu z pamięcią podręczną, który występuje z
silnik aplikacji i tak w celu symulacji
podział ruchu między nimi
aplikacje internetowe w celu wykonania
rzeczy łatwe, których potrzebowałem, aby wygasnąć gotówka
i jest to łatwy sposób na zrobienie tego teraz
mogą istnieć aplikacje, które tam są
potrzebują tego buforowania, a więc
wygaśnięcie może być znacznie wyższe, ale dla
celów tego demo dwie sekundy
wygaśnięcie też powinno wystarczyć
najpierw wyjaśnij dwa handlery
jeden pokazujący pliki, które będą
przesłane do zasobnika pamięci masowej w chmurze jako
a także drugi stwierdzający, co jest statyczne
pliki zostaną przedstawione, więc idę
iść dalej do mojego terminala i
idę dalej i wyczyszczę swoje
ekran i zamierzam iść naprzód i biec
polecenie wdrożenie aplikacji gcloud z plikiem
flag dash dash wersja i to się dzieje
być wersją pierwszą, więc idę
naprzód i naciśnij enter, a możesz otrzymać
wyskakujące okienko z prośbą o autoryzację tego interfejsu API
zadzwoń, używając swoich poświadczeń i chcesz
kliknąć na autoryzację i idziesz
zostać poproszony o wejście do regionu, który
chcesz wdrożyć swoją witrynę
aplikacja, w której chcemy to zachować
nas na wschód, więc wpiszę 15
wciśnij Enter
i zostaniesz o to poproszony
zweryfikuj swoją konfigurację dla swojego
aplikację przed jej wdrożeniem
zostanie również wyświetlony monit, jeśli chcesz
kontynuuj zdecydowanie tak, więc zamierzam
naciśnij y enter i tak teraz, jak widziałeś
pliki zostały przesłane do chmury
pamięć masowa i silnik aplikacji zajmie
kilka minut na utworzenie usługi
wraz z wersją, więc zamierzam
niech zrobi to, co konieczne, a ja wrócę
zanim się zorientujesz, w porządku i mój
aplikacja została już wdrożona
chociaż nie widzisz tego tutaj w
konsola została wdrożona wszystko, czego potrzebuję
zrobić, to odświeżyć ekran, ale chciałem
żeby tylko zwrócić uwagę na kilka rzeczy
jest pokazany tutaj w terminalu jako pierwszy
jedna jest teraz domyślną usługą
przy pierwszym wdrożeniu wersji
aplikacja, którą zawsze będzie wdrażać w
domyślna usługa początkowo i tylko wtedy
czy będziesz w stanie wdrożyć inny nazwany
usługa do silnika aplikacji teraz tutaj, gdzie to
mówi ustawienie podziału ruchu dla usługi
odnosi się to do konfiguracji
do stosowania dzielenia ruchu
tło, które otrzymam
w trochę później i wreszcie
URL pokazany dla wdrożonej usługi will
zawsze zaczynaj od swojego imienia
projekt, a następnie .ue.r.appspot.com
dlatego w produkcji google
zaleca uruchomienie silnika aplikacji w
zupełnie odrębny projekt
przed tym demo, uruchamiając go w tym samym
projekt, którego używaliśmy will
wystarczy, więc chodźmy dalej i weźmy
spojrzenie na aplikację, więc idę
wrócić do góry tutaj do
menu nawigacyjne i zejdę do
app engine i przejdź do usług i
więc tutaj zobaczysz domyślną usługę
z wersją pierwszą i jeśli przejdę do
wersje zobaczę tutaj moją wersję the
status
przydział ruchu wraz z wszelkimi
przypadkach, że potrzebuje czasu działania
określone środowisko i będę miał trochę
narzędzia diagnostyczne, których mógłbym użyć
a więc dlatego, że jest to statyczna strona internetowa
aplikacja, z której nie będziemy korzystać
instancje, więc to zawsze pokaże a
zero, więc teraz chcę wrócić
do usług i zamierzam uruchomić mój
aplikację, po prostu klikając na to
gorący link
i sukces muszki serverless dla wszystkich
i tak wygląda na to, że moja aplikacja ma
został pomyślnie wdrożony, więc idę
aby zamknąć tę kartę, teraz jest a
kilka rzeczy, które chciałem uruchomić
przez tutaj w menu po lewej stronie po prostu
dla twojej informacji, więc tutaj mogę kliknąć
na instancjach i jeśli korzystałem z dowolnego
przypadków, które mogę zobaczyć w podsumowaniu
te instancje i mogę kliknąć
rozwiń tutaj i wybierz inny
metryka i znaleźć wszelkie informacje, które
Potrzebuję również mogę kliknąć tę kroplę
w dół i wybierz wersję, gdybym miał
wiele wersji, których nie mam
kliknięcie kolejek zadań tutaj jest miejscem, w którym i
może zarządzać moimi kolejkami zadań, ale to jest
starsza usługa, która wkrótce będzie dostępna
przestarzałe klikanie zadań cron tutaj
mogę zaplanować dowolne zadania, które potrzebuję
uruchamiać w określonym czasie w sposób cykliczny
podstawie mogę edytować lub dodać dowolny firewall
zasady, jeśli trzeba i jak widać
domyślna reguła zapory jest otwarta dla
świecie teraz prawdopodobnie zauważyłeś memcache
jako jedna z opcji tutaj w pliku
menu, ale jest to starsza usługa, która
wkrótce zostanie potępiony
memcache to rozproszone dane w pamięci
store, który jest dołączony do Pythona do
środowisko wykonawcze działające jako pamięć podręczna dla określonych
zadania i Google zaleca przejście do
magazyn pamięci dla redis, jeśli jesteś
planuje zastosować buforowanie dla twojego
aplikacja silnika aplikacji, więc nie jestem
pewien, jak długo to będzie tutaj
i wreszcie w ustawieniach tutaj jest gdzie
możesz zmienić ustawienia dla swojego
aplikacji mogę dodać dowolne niestandardowe domeny
wszelkie certyfikaty ssl, a także ustawienie
e-mail dla dowolnych aplikacji, które chcą
aby wysłać wiadomość e-mail do użytkowników w porządku i
teraz, gdy zrobiliśmy ten przewodnik i
chcę iść naprzód i wdrożyć moją drugą
wersja aplikacji i tak mam
zamierza iść naprzód z powrotem w dół do chmury
musze szybko wyczyscic moje
ekran i chcę przejść do witryny
v2, więc uderzę w cd dot
kropka, która przywróci ci jeden
katalog robisz ls i zamierzam
zmień katalogi na witrynę v2 i zrób
an ls tylko po to, aby zweryfikować i tak, zrobisz to
zobacz też muszki serverless, które zamierzam
szybko wyczyść ekran i zamierzam to zrobić
uruchom to samo polecenie, co wcześniej, które jest
wdrożenie aplikacji gcloud z flagą wersji
kreska kreska wersja i zamiast jednego jestem
zamierzam uruchomić wersję 2. więc idę
aby nacisnąć enter, zostanie wyświetlony monit, jeśli
chcę kontynuować tak robię i jak ty
widzi pliki, do których zostały przesłane
przechowywanie w chmurze dla wersji 2
aplikacja internetowa i silnik aplikacji to
utworzenie zajmie kilka minut
serwis wraz z wersją tzw
pozwolę temu gotować tutaj przez chwilę
kilka minut i wrócę wcześniej
możesz powiedzieć kot w kapeluszu okej
wersja 2 została wdrożona, więc jeśli i
idź tutaj do konsoli i kliknij
odświeżyć, powinieneś zobaczyć wersję 2 swojego
usługi i jak widać 100 z nich
ruch został przydzielony do wersji 2
automatycznie i jest to ustawienie domyślne
zachowanie za każdym razem, gdy uruchamiasz nowy
wersja usługi jest jedynym sposobem
uniknąć tego, aby wdrożyć nową wersję
z flagą bez promocji, więc jeśli pójdę
wróć do usług tutaj po lewej i ja
kliknij usługę domyślną
powinieneś zobaczyć sukces dla wersji drugiej
i tak wiem, że moja strona internetowa
aplikacja dla wersji 2 została
pomyślnie wdrożony, więc zamierzam to zrobić
zamknij ponownie tę kartę i idę
wrócić do wersji i co z tego
chcę teraz zrobić, to chcę symulować
ab test lub niebiesko-zielone wdrożenie przez
migracja mojego ruchu z powrotem do starego
wersja w tym przypadku jest wersją pierwszą
więc w produkcji powiedzmy, że ty
wyda nową wersję i
wersja nie idzie zgodnie z twoim planem
zawsze można wrócić do poprzedniego
wersja i silnik aplikacji pozwalają to zrobić
że bardzo łatwo i tak mam zamiar
kliknij na wersję 1 i idę
do górnego menu i kliknij migruj
ruchu, jeśli chcesz, zostaniesz o to poproszony
aby przenieść ruch tak, robię, więc idę
kliknąć na migrację i powinno to zająć
minuta tutaj i ruch powinien zostać przeniesiony
do wersji pierwszej i udanego ruchu
została przeniesiona i tak też chcemy
sprawdzić, czy to się stało, zamierzam to zrobić
wróć do usług, które zamierzam kliknąć
domyślna usługa i tak ruch
został przydzielony do wersji pierwszej w porządku
więc zamierzam zamknąć tę kartę
zamierzam wrócić do wersji i tak teraz
co chcę zrobić, to chcę symulować
rozdzielanie ruchu między nimi
wersje i tak, abyś mógł to zrobić
to możesz przejść do górnego menu
kliknij na podzielony ruch i będziesz
poproszony o nowe menu tutaj i tutaj i
mogą wybierać spośród różnych wersji i
bo mam tylko dwie wersje
zamierzam dodać wersję 2 i aby
alokować ruch między dwoma i
może użyć tego suwaka
i jak widać przydział
procent zmieni się lub mogę po prostu
po prostu wpisz to i tak zrobię
zostaw to na 50 procent, czyli pięćdziesiąt
procent wersji jeden pięćdziesiąt procent
wersja druga zamierzam podzielić ruch
losowo przesunę to w dół tylko o
trochę i tak właśnie jest u ciebie
chcesz przydzielić ruch i tak raz
ukończyłeś, że możesz po prostu
kliknij zapisz to zajmie
chwila na aktualizację ustawień i gotowe
odniosłem sukces, więc jeśli wrócę
przejdź do poprzedniej strony, którą możesz zobaczyć
tutaj, do którego został przydzielony ruch
obie wersje i tak teraz, aby
sprawdź to, co zamierzasz zrobić
przejdź do usług i kliknij na
domyślny gorący link, a zobaczysz wersję
jeden, ale jeśli ciągle odświeżam moje
ekran widzę, że tutaj mam
wersja druga, więc ponieważ jest losowa i
mają 50 szans na uzyskanie wersji 1
i 50 szans na uzyskanie wersji 2.
a więc jest to symulacja podziału
ruch do różnych wersji i
zwykle z ab testującym tylko małym
procent ruchu jest kierowany do
nowa wersja do czasu weryfikacji
być wykonane, że nowa wersja została wdrożona
rzeczywiście się powiodło i to może
można to zrobić, otrzymując informację zwrotną od
użytkowników, więc teraz chciałem wziąć
szybki moment na gratulacje
przebrnąć przez to demo i mieć nadzieję
w którym okazał się niezwykle użyteczny
doskonalić swoją wiedzę we wdrażaniu
i zarządzanie aplikacjami na silniku aplikacji
więc tak dla podsumowania sklonowałeś plik
repo do powłoki w chmurze, którą następnie wdrożyłeś
wersję pierwszą swojej aplikacji do app
silnik zweryfikowałeś jego uruchomienie, a następnie
wdrożyłeś wersję 2
aplikację i zweryfikował jej uruchomienie jako
następnie przeniosłeś ruch z
wersja druga do wersji pierwszej i dalej
poszedłeś naprzód i podzieliłeś ruch między
obie wersje i przydzielono 50 z nich
przydział ruchu do każdej wersji i
więc teraz, zanim pójdziesz, chcę się upewnić
byśmy wyczyścili wszelkie zasoby, które
wdrożyliśmy, abyśmy nie ponosili
wszelkie niepotrzebne koszty i tak dalej
zrobić to jest bardzo proste, więc pierwszy krok ty
chcesz przejść do menu po lewej stronie
i kliknij ustawienia i po prostu kliknij
na wyłącz aplikację, którą zamierzasz
pojawi się monit o wpisanie identyfikatora aplikacji dla
ja to Bowtie Inc, więc będę pisać
to i zamierzam kliknąć
wyłącz teraz niestety za pomocą aplikacji
engine, którego tak naprawdę nie można usunąć
aplikacji można ją tylko wyłączyć i
tak teraz tutaj ja jadę utrafić gorący
link, aby przejść do magazynu w chmurze
wiadro i jak widać tutaj nie mam
pliki, ale zamierzam wrócić do mojego
wiadra
i przechodzę do inscenizacji
wiadro, które jest dołączone do twojego
identyfikator projektu.appspot.com
i jak widać tutaj jest całość
kilka różnych plików, a także jeśli i
przejdź do katalogu oznaczonego jako
ae dla silnika aplikacji, widzę tutaj, że i
mieć więcej katalogów wraz z
manifest i tak teraz, jeśli chcesz
zachowaj swoją aplikację, aby ją uruchomić
później nie musisz tego usuwać
wiadro, ale ponieważ go nie potrzebuję, jestem
zamierzam iść dalej i usunąć wiadro
naciśnij usuń wklej w moim wiadrze nazwa hit
usuń również pod us.artifacts
znajdziesz katalog o nazwie
pojemniki i jak wyjaśniono w ostatnim
kompilacja kodu lekcji buduje kontener dla
Twojej aplikacji przed jej wdrożeniem
app engine, więc przejdę do szczegółów
na obrazy, więc oto cały kontener
trawi i nie potrzebuję żadnego z nich, więc
pójdę dalej i usunę to
wiadro, a więc to jest ostatnie
krok, aby usunąć wszystkie
katalogi i pliki, których używamy
wdrożyć naszą aplikację w silniku aplikacji
ok, więc wracam do tematu
do silnika aplikacji, a więc teraz to czyszczenie
zadbano o to, że jest ładny
wszystko, co chciałem zawrzeć w tym demo
do wdrażania i zarządzania aplikacjami
w silniku aplikacji, dzięki czemu możesz to teraz zaznaczyć
jako kompletne i do zobaczenia w następnym
jeszcze raz gratulacje za dobrze wykonaną pracę
zrobione
[Muzyka]
witam z powrotem w tej lekcji będę
zanurzyć się w inny produkt bezserwerowy
z chmury Google pod nazwą cloud
funkcje niezwykle przydatne i
zaawansowana usługa, z której można korzystać
prawie każdą usługę na platformie
jest tu sporo do omówienia, więc
powiedziawszy to, przejdźmy teraz do rzeczy
funkcje chmury, jak powiedziałem wcześniej, to a
bezserwerowe środowisko wykonawcze i
rozumiem przez to jak silnik aplikacji
nie ma potrzeby dostarczania żadnych
serwerów lub aktualizowanie vms jako
cała infrastruktura jest obsługiwana przez Google
ale w przeciwieństwie do silnika aplikacji, którego nigdy nie zobaczysz
serwery, więc udostępnianie
zasobów dzieje się, gdy kod jest
wykonywane teraz funkcje chmury to a
funkcjonować jako oferta usług i to
to miejsce, w którym przesyłasz kod
celowo napisany w obsługiwanym
język programowania i kiedy twój kod
jest wyzwalany, jest wykonywany w pełni
zarządzane środowisko i opłata
kiedy ten kod jest wykonywany w chmurze
funkcje działają w środowisku wykonawczym
i obsługują wiele różnych środowisk wykonawczych, takich jak
python java node.js go i rdzeń netto
funkcje chmury są sterowane zdarzeniami, więc kiedy
coś dzieje się w twoim otoczeniu
możesz wybrać, czy chcesz
odpowiedzieć na to wydarzenie, jeśli to zrobisz
twój kod może zostać wykonany w odpowiedzi na
zdarzenie, które wyzwalacze mogą być jednym z a
kilka różnych typów, takich jak http
przechowywanie w chmurze pubowej, a teraz firestore
i firebase, które są w wersji beta i mają
jeszcze nie do zobaczenia w chmurze egzaminacyjnej
funkcje są wyceniane w zależności od tego, jak
długo działa twoja funkcja i ile
zasoby, które zapewniasz dla swojego
funkcja, jeśli twoja funkcja tworzy
istnieją również wychodzące żądania sieciowe
dodatkowe opłaty za transfer danych chmura
funkcje obejmują również wieczystą darmową
poziom, który pozwala ci zdobyć 2 miliony
inwokacje lub egzekucje twoich
działają teraz chmura działa sama
są bardzo proste, ale wymagają kilku kroków
wykonać przed faktycznym uruchomieniem, więc ja
chciałem dać ci przewodnik
dokładnie, jak teraz działają funkcje chmury
po wybraniu nazwy i regionu
chcesz, aby twoja funkcja żyła w tobie
następnie wybierz wyzwalacz, którego chcesz użyć
i możesz wybierać spośród wielu i
wymienione wcześniej to przechowywanie w chmurze http
firestore i firebase w chmurze pubowej a
trigger to deklaracja, że ​​jesteś
zainteresowany określonym wydarzeniem lub zestawem
zdarzenia wiążące funkcję z wyzwalaczem
pozwala ci je uchwycić i działać na ich podstawie
jest konfiguracja uwierzytelniania zdarzeń
następny krok i można je wybrać za pomocą
dostęp publiczny
lub skonfigurowane przez iam teraz są
niektóre opcjonalne ustawienia, które mogą być
skonfigurowany, gdzie podasz
ilość pamięci, której będzie potrzebować funkcja
biegać
preferencje sieciowe, a nawet
wybór konta usługi teraz raz
wszystkie ustawienia zostały utrwalone
Twój napisany kod można następnie umieścić w
funkcja teraz kod funkcji
obsługuje różne języki, jak
powiedziane wcześniej, jak python java node.js
lub idź teraz, pisząc tam swój kod
to dwa różne typy chmur
funkcje, których możesz użyć http
funkcje i funkcje tła z
funkcje http, z których je wywołujesz
standardowe żądania HTTP te http
prośby czekają na odpowiedź i
obsługa obsługi typowych żądań http
metody takie jak get put
usuwanie postów i opcje podczas używania
funkcjami chmury jest certyfikat tls
automatycznie udostępniane dla ciebie, więc wszystko
Funkcje http można wywołać za pomocą a
bezpieczne połączenie teraz, jeśli chodzi o
funkcje tła
są one używane do obsługi zdarzeń z
Twojej infrastruktury gcp, takiej jak wiadomości
na temat podrzędny pubu lub zmiany w chmurze
wiadro do przechowywania teraz, gdy umieścisz wszystko
to razem jesteś gotowy do wdrożenia
twój kod teraz są dwie rzeczy
stanie się podczas wdrażania kodu
pierwszy to wiązanie twojego spustu
do swojej funkcji po powiązaniu wyzwalacza
nie możesz powiązać innego z tym samym
funkcjonować
tylko jeden wyzwalacz może być powiązany z a
funkcja na raz, teraz druga rzecz
stanie się to po wdrożeniu
kod źródłowy funkcji do chmury
funkcje polegają na tym, że przechowywany jest kod źródłowy
w pojemniku do przechowywania w chmurze jako plik ZIP
budowanie w chmurze jest następnie automatycznie budowane
swój kod do obrazu kontenera, który
wypycha ten obraz do rejestru kontenerów
funkcje chmurowe uzyskują dostęp do tego obrazu, gdy
musi uruchomić kontener, aby wykonać
Twoja funkcja proces budowania
obraz jest całkowicie automatyczny i
nie wymaga ręcznej interwencji i tak dalej
w tym momencie procesu
budowanie twojej funkcji jest teraz
zakończyć teraz, gdy funkcja została wykonana
utworzony, czekamy teraz na zdarzenie
dzieją się, a wydarzenia to rzeczy, które się dzieją
w środowisku chmurowym, które ty
może chcieć podjąć działania w stosunku do tych mocy
być zmiany danych w plikach cloud sql
dodany do magazynu w chmurze lub nowa istota wirtualna
utworzonych obecnie funkcji chmury
obsługuje
zdarzenia z tych samych usług, z których korzysta
wyzwalacze, o których właśnie wspomniałem
w tym inne usługi Google, takie jak
teraz bigquery cloud sql i cloud spanner
gdy zdarzenie wyzwala wykonanie
Twoja funkcja chmury
przekazywane są dane powiązane ze zdarzeniem
poprzez parametry funkcji typu
zdarzenie określa parametry, które są
przekazany do funkcji w chmurze funkcji
obsługuje żądania przychodzące przez przypisywanie
je teraz do instancji swojej funkcji
w zależności od ilości wniosków
jak również liczbę istniejących
instancje funkcji mogą działać w chmurze
przypisać żądanie do istniejącej instancji
lub utwórz nową, więc chmura
funkcja pobierze obraz z chmury
zarejestrować i przekazać obraz dalej
z danymi zdarzenia do instancji dla
przetwarza teraz każdą instancję a
funkcja obsługuje tylko jedno współbieżne
żądanie na raz oznacza to, że podczas
Twój kod przetwarza jedno żądanie
nie ma możliwości drugiego
żądanie jest kierowane do tego samego
przykład, więc pierwotne żądanie może
wykorzystać pełną ilość zasobów
prosiłeś i to jest wspomnienie
które przypisujesz do swojej funkcji w chmurze
podczas wdrażania go teraz, aby umożliwić Google
automatycznie zarządzać i skalować
funkcje muszą być bezstanowe
funkcje nie mają być trwałe
ani też dane przekazywane do
funkcja i tak, gdy funkcja ma
uruchomić i wszystkie dane zostały przetworzone przez
serwer, na który jest następnie przekazywany
albo vpc, albo do internetu teraz przez
domyślne funkcje mają publiczny internet
dostęp, chyba że skonfigurowano inaczej
funkcje mogą być również prywatne i używane
w twoim vpc, ale musi być skonfigurowany
przed wdrożeniem teraz jest ich tak wiele
przypadki użycia dla funkcji w chmurze i tam
jest wiele, które zostały już stworzone
przez Google do wypróbowania
i może być umieszczony w dokumentacji
które podałem w tekście lekcji
poniżej teraz egzamin też się nie wchodzi
dużo głębi w funkcjach chmury, ale tak zrobiłem
chcę dać ci trochę ekspozycji na to
fantastyczny bezserwerowy produkt od Google
ponieważ jest tak powszechnie używany w wielu
środowisk produkcyjnych w prosty i
łatwy sposób na przetwarzanie danych i
zwróć wynik z dowolnego wydarzenia, w którym jesteś
dane i nie mam wątpliwości, że kiedyś ty
opanuj ich wdrażanie
też będzie ich wielkim fanem i
więc to właściwie wszystko, co miałem do omówienia
jeśli chodzi o funkcje chmury, więc ty
może teraz oznaczyć tę lekcję jako ukończoną i
kiedy tylko będziesz gotowy, dołącz do mnie
następny, w którym wchodzimy w ręce
konsola do tworzenia i wdrażania Twojego pliku very
pierwsza funkcja
witamy z powrotem iw tym demo będziemy
zagłębiając się w tworzenie i wdrażanie naszych
pierwsza funkcja chmury, do której zamierzamy przejść
zapoznaj się ze wszystkimi opcjami w
konsoli, ale my zajmiemy się większością
praca w Cloud Shell, aby uzyskać dobre
poczuj, że robisz to w wierszu poleceń, więc
powiedziawszy to, zanurzmy się i
więc jestem zalogowany tutaj jako tony muszki
gmail.com
i jestem w projekcie Bowtie Inc i
więc pierwszą rzeczą, którą chcę zrobić, jest głowa
przejdź do funkcji chmury w
konsoli, więc idę na górę
w lewo do menu nawigacji i jestem
przewinie w dół do funkcji chmury
i jak widać tutaj funkcje chmury
przygotowuje się i to dlatego
nigdy wcześniej go nie używaliśmy, a api
jest włączany w porządku, a interfejs API ma
została włączona i możemy kontynuować i
zacznij tworzyć naszą funkcję, abyś mógł
śmiało i kliknij utwórz funkcję i
zostaniesz poproszony o podanie niektórych pól
wypełnij dla konfiguracji swojego
funkcja chmury, a więc podstawy dla
nazwa funkcji zamierzam nazwać to
witaj podkreśl światu dla regionu jestem
zamierza wybrać nas na wschód i poniżej
wyzwalacz dla typu wyzwalacza, który zamierzamy
zachowaj to jako http, chociaż jeśli kliknę
rozwijanego menu widać, że ja
będzie mieć opcje subskrypcji w chmurze
przechowywanie w chmurze i te, które ja
wspomniane wcześniej, które są w fazie beta, więc
zamierzamy zachować rzeczy jako http i
tutaj pod adresem URL jest adres URL rzeczywistego
funkcja chmury w ramach uwierzytelniania i
mieć możliwość wyboru wymagają
uwierzytelnianie lub zezwalaj na nieuwierzytelnione
inwokacje i jak widać tak jest
wyraźnie zaznaczone stwierdzenie, że sprawdź to, jeśli
tworzysz publiczne API lub stronę internetową
kim jesteśmy i tak to jest
metodę uwierzytelniania, którą chcesz
wybierz i tak teraz, gdy mamy wszystkie
pola wypełnione dla podstawowego
konfiguracja zamierzam iść dalej i
kliknij Zapisz i po prostu daj
szybki przegląd tego, co jeszcze jest
dostępne, kliknę upuść
tutaj, a to da mi dostęp
do zmiennych sieciowych i zaawansowanych
ustawienia pierwszego pola tutaj pamięci
przydzielone, mogę faktycznie dodać więcej pamięci
w zależności od tego, co robię z moją chmurą
funkcja, ale zamierzam ją zachować jako
default, jeśli masz funkcję chmury
który działa trochę dłużej i ty
potrzebują więcej czasu na uruchomienie funkcji chmury
możesz dodać dodatkowy czas na
limit czasu, a także mam opcję
wybór innego konta usługi dla
ta funkcja chmury i tak dalej
pod zmiennymi środowiskowymi, które zobaczysz
opcje dodawania środowiska kompilacji
zmienne wraz ze środowiskiem wykonawczym
zmienne i ostatnią opcją jest
połączenia tutaj możesz zmienić
różne ustawienia sieciowe dla
ruch przychodzący i wychodzący w ruchu przychodzącym
ustawienia mogę zezwolić na cały ruch, który
jest ustawieniem domyślnym, na które mogę zezwolić na wewnętrzne
ruch tylko na tyle, na ile mogę zezwolić
ruch wewnętrzny i ruch z chmury
niskie zbalansowanie również teraz, kiedy to przychodzi
do ustawień wyjścia, jak powiedziałem wcześniej
domyślnie Twoja funkcja chmury jest w stanie
wysyłać żądania do Internetu, ale nie
do zasobów w twojej sieci vpc i tak dalej
w tym miejscu utworzysz vpc
łącznik do wysyłania żądań z Twojego
cloud do zasobów w twoim vpc
więc jeśli kliknę Utwórz łącznik
otworzy nową kartę i przeniesie mnie do niej
sieć vpc, aby dodać bezserwerowy dostęp vpc
więc nie chcę tego teraz robić
więc zamknę tę kartę i
idę przed siebie i wychodzę
wszystko inne bez zmian i kliknij dalej
i tak teraz, gdy konfiguracja jest
gotowe, mogę zanurzyć się bezpośrednio w kodzie i
więc Google Cloud daje ci inline
redaktor tutaj wraz z
różne środowiska uruchomieniowe, więc jeśli i
kliknij menu rozwijane, które widzisz
mam opcje
rdzenia sieci przejdź do java node.js i python
3.7 i 3.8 i tak dla tego demo jestem
zamierzam zachować go jako node.js 10. the
punktem wejścia będzie hello world i ja
zamierza zachować kod dokładnie tak, jak jest i
jest to domyślna funkcja chmury
w pakiecie z dowolnym środowiskiem wykonawczym, kiedy tylko ty
utwórz funkcję z konsoli i
więc gdybym miał inny kod, mogę
zmień to tutaj, ale nie zamierzam tego robić
że zostawię wszystko inne
tak jak jest i kliknij wdrażanie, a to zajmie
kilka minut tutaj, aby utworzyć moją chmurę
funkcji, więc zamierzam wstrzymać
wideo tutaj przez krótką chwilę, a ja to zrobię
wróć w mgnieniu oka, dobrze i moja chmura
funkcja została wdrożona i mam
zielony znacznik wyboru, co oznacza, że ​​jestem
wszystko dobrze, więc chcę dobrze nurkować
w to tylko na sekundę, żebym mógł się dostać
trochę więcej szczegółów tutaj mam
metryki dla mojej funkcji w chmurze
wywołań na sekundę czasu wykonania
wykorzystanie pamięci i aktywne instancje
Mam swoje wersje tutaj na górze
ale ponieważ mam tylko jedną wersję tylko
jedna wersja pojawia się, jeśli kliknę
szczegóły pokaże mi generał
informacje wraz z siecią
ustawienia, które źródło pokaże mi
kod dla tej funkcji chmury, jak również
zmienne uprawnienia wyzwalacza
logi i testowanie i tutaj mogę napisać
trochę kodu i przetestuj funkcję i tak dalej
abym mógł wywołać tę funkcję
mogę po prostu przejść do spustu i to będzie
pokaż mi adres URL, ale szybki sposób
to za pomocą wiersza poleceń jest
po prostu otwórz Cloud Shell i zrób to
trochę większy dla lepszego oglądania i
zamierzam wkleić polecenie gcloud
funkcje opisują wraz z
nazwa funkcji, która jest podkreśleniem hello
świat wraz z kreską flagi regionu
region myślnika z regionem, który my
funkcja chmury została wdrożona w
który jest naszym wschodnim i zamierzam
wciśnij Enter
poprosi mnie o autoryzację mojego interfejsu API
zadzwoń tak, chcę to autoryzować i to
polecenie powinno wyświetlić pewne informacje
na ekranie i czego szukamy
ponieważ tutaj jest wyzwalacz http, który ty
znajdziesz tutaj pod wyzwalaczem https i
to jest to samo, co widzisz tutaj
konsoli, więc po prostu wiedz, jeśli chcesz
aby pobrać wyzwalacz adresu URL http, możesz
zrób to również z wiersza poleceń i tak dalej
zamierzam go teraz uruchomić, przechodząc do
ten adres URL i powinieneś zobaczyć na górze
lewa strona ekranu cześć
świat nie tak ekscytujący jak wirujący łuk
więzi, ale ten przykład daje ci pewien pomysł
tego, co może zrobić funkcja http i tak dalej
zamknę tę zakładkę i tak dalej
teraz to, co chcę zrobić, to chcę
wdrożyć inną funkcję, ale chcę to zrobić
to teraz przez wiersz poleceń i tak dalej
zamierzam teraz szybko wyczyścić ekran
i tak odkąd już przesłałem plik
kod do repozytorium, które zamierzam po prostu zrobić
sklonuj to repozytorium i uruchom je stąd
mam zamiar po prostu zrobić cd tyldę do
upewnij się, że jestem w moim katalogu domowym dla
ci z was, którzy nie usunęli
katalog, do którego możesz po prostu wejść cd
zamierzam uruchomić cd google cloud
współpracownik inżyniera chmury naciśnij enter i
zamierzam uruchomić polecenie get pull
i ściąga wszystkie pliki, które ja
potrzebne, zamierzam szybko wyczyścić moje
ekran i tak zamierzam zmienić
katalogi do katalogu, który ma
mój kod, więc go znajdziesz
poniżej 11 usług bezserwerowych poniżej zera
zadzwoniłem do ciebie, naciśnij enter i znowu to zrobię
mieć link w tekście lekcji dla
pełne instrukcje dotyczące tego demo i to
wyświetli katalog, w którym możesz
znajdź ten kod w porządku, więc idź naprzód
zamierzam uruchomić ls i powinieneś zobaczyć
trzy pliki tutaj
main.py
wymagania.txt i plik tekstowy z
instrukcje i tak teraz, że mam
wszystko gotowe do wdrożenia
mój kod, który zamierzam wkleić w
polecenie, aby faktycznie wdrożyć moją funkcję
czyli funkcje gcloud wdrażają
nazwa funkcji, którą jesteś
podkreślenie wywołało flagę dla
runtime myślnik runtime i
środowiskiem wykonawczym będzie python 3.8
flaga dla wyzwalacza, który ma zamiar
być http i ponieważ jestem miłym facetem i ja
chcę, aby każdy miał dostęp do tego, kim jestem
zamierzam oznaczyć go kreską z flagą
zezwól na nieuwierzytelnione, więc zamierzam to zrobić
naciśnij enter dobrze i ta funkcja powinna
wdrożenie zajmuje kilka minut, więc jestem
zamierzam tu usiąść i pozwolić mu się ugotować i
Wrócę, zanim zdążysz powiedzieć „wpuść kota”.
kapelusz w porządku, a nasza funkcja była
wdrożony, zrobię szybkie odświeżenie
tutaj w konsoli i został wdrożony
pomyślnie, jak widać zielony
znacznik wyboru jest tutaj w porządku, a więc teraz to
został wdrożony, który chcemy uruchomić
nasza funkcja i tak, ponieważ ja po prostu
wdrożył tę funkcję wyzwalacza adresu URL
jest dogodnie zlokalizowany tutaj w my
ekran, abyś mógł przejść dalej i kliknąć
to i witaj miłośniku muszek
o nazwie teraz, chociaż może to być podobne
do demo hello world, ale dodałem plik
mała funkcja, która może urozmaicić sprawę
a więc jeśli przejdziesz do adresu URL i ty
wpisz nazwę znaku zapytania równa się i
twoje imię i ponieważ mam na imię anthony
zamierzam wpisać anthony
naciśnij enter i witaj anthony dzwoniłeś
więc jest to doskonały przykład tzw
wiele różnych sposobów, które możesz wykorzystać
funkcje i chociaż mam tylko
podkreślił kilka bardzo prostych
demonstracje są różne
sposoby korzystania z funkcji, takich jak
uruchomione potoki uruchamiające zadania wsadowe i
teraz nawet zabezpieczenia sterowane zdarzeniami
egzamin nie wchodzi zbyt głęboko
w funkcjach chmury zawsze warto
znać jego przypadki użycia i gdzie jest
mocne strony leżą, kiedy się zdecydujesz
użyj go w roli inżyniera chmury
teraz, zanim pójdziesz, pamiętaj, aby usunąć wszystkie
zasoby utworzone przez usunięcie
funkcje i pojemniki do przechowywania
w którym znajduje się kod chmury
funkcje, a ja przeprowadzę cię przez nie
kroki teraz w porządku, więc pierwszy jestem
zamknę tę kartę i następną
wybierasz wszystkie funkcje
i po prostu klikniesz
usuń, o które zostaniesz poproszony
usuń funkcje, do których zamierzasz przejść
kliknij usuń i zajmie to ok
minuta lub dwie i funkcje są
usunięte Zamierzam zamknąć moją chmurę
powłoki i mam zamiar udać się do
magazyn w chmurze
i jak widać tutaj oba te
zasobniki zaczynające się od gcf oznaczającego
funkcje Google Cloud mogą być bezpieczne
usunięte, ponieważ w nich znajdują się pliki
które były używane do funkcji chmury tzw
zamierzam wyjść, zamierzam
wybierz oba te i zamierzam
kliknij usuń, pojawi się monit
usuń dwa segmenty, które możesz po prostu wpisać
w usuń i kliknij usuń i
zasobniki zostały teraz usunięte, a Ty tak
prawie skończyłeś sprzątanie i tak dalej
tak jak podsumowanie, które utworzyłeś jako domyślne
funkcja chmury, która była dostępna z
konsoli, a następnie zweryfikować ją przez
uruchamiając następnie adres URL http
wdrożył inną funkcję z
wiersz poleceń, pobierając kod z
repozytorium i używanie go do wdrażania i
następnie zweryfikowałeś tę funkcję przez
uruchamiając go również za pomocą adresu URL http
a następnie modyfikujesz adres URL dla a
inny wynik świetna robota na innym
udane demo, więc możesz to teraz oznaczyć
jako kompletne i przejdźmy do
Następna
[Muzyka]
witaj z powrotem na tej lekcji, na którą idziemy
aby zanurzyć się w pamięci masowej w chmurze, przejdź do
usługa przechowywania z chmury Google, jeśli
jesteś inżynierem pracującym w google
cloud, z którego prawdopodobnie korzystałeś już tyle razy
razy jako rozwiązanie do przechowywania i jeśli ty
czyż nie jest to zdecydowanie usługa
które będziesz musiał znać dla obu
egzamin i codzienną rolę chmury
inżynier teraz jest całkiem sporo do zrobienia
przykryj tutaj, więc powiedzmy
zanurzyć się teraz w chmurze jest
spójna skalowalna duża pojemność
bardzo trwała obiektowa pamięć masowa i to
to nieograniczone przechowywanie obiektów o nr
minimalny rozmiar obiektu, ale proszę pamiętać
że jest to obiektowa pamięć masowa, a nie jest
przeznaczony do przechowywania systemu operacyjnego
ale do przechowywania całych obiektów, takich jak obrazy
lub filmów w chmurze ma miejsce na całym świecie
dostępność i przechowywanie na całym świecie
lokalizacje, więc wszędzie tam, gdzie jest
przechowywania w chmurze regionu lub strefy
dostępne stamtąd i można uzyskać do nich dostęp
w dowolnym momencie przez Internet
przechowywanie w chmurze połączeń jest świetne
przechowywanie danych z zadań analizy danych
pliki tekstowe ze zdjęciami kodów
najnowsza moda z Paryża i filmy
Twój ulubiony dj w schronisku
przechowywanie w chmurze wyróżnia się zawartością
dostarczanie dużych zestawów danych i kopii zapasowych oraz
wszystkie są przechowywane jako obiekty w zasobnikach i
to jest serce przechowywania w chmurze
będę nurkować, więc zaczynam od
wiadra to podstawowe pojemniki
lub konstrukt, który przechowuje twoje dane
wszystko, co przechowujesz w chmurze
przechowywanie musi być zawarte w wiadrze
możesz użyć wiader do uporządkowania swoich
danych i kontroli dostępu do swoich danych, ale
w przeciwieństwie do katalogów i folderów ty
nie mogę zagnieżdżać wiader i wejdę do nich
że za minutę teraz, kiedy ty
utwórz wiadro, musisz określić a
globalnie unikalna nazwa jak każde wiadro
znajduje się w jednym magazynie w chmurze
przestrzeń nazw, a także nazwę, którą musisz
określić lokalizację geograficzną, w której
wiadro i jego zawartość są przechowywane i
masz trzy dostępne geografie
wybory do wyboru z regionu dual
region i wieloregion, a więc tak jak a
zwróć uwagę na wybór podwójnego regionu i
multiregion jest uważany za geograficznie nadmiarowy
w przypadku nadmiarowości geograficznej w dwóch regionach jest
osiągnąć za pomocą określonej pary
regiony dla wieloregionowej nadmiarowości geograficznej
osiąga się za pomocą kontynentu, który
zawiera dwa lub więcej miejsc geograficznych
w zasadzie im więcej regionów zawiera twoje dane
dostępne w większym
dostępność tych danych po zakończeniu
wybrana domyślna lokalizacja geograficzna
należy wybrać klasę przechowywania i to
dotyczy obiektów dodanych do zasobnika
które nie mają klasy pamięci
wyraźnie określone i będę nurkować
w klasy pamięci masowej w zaledwie chwilę i
więc po utworzeniu wiadra możesz
nadal zmieniać domyślną klasę pamięci
do dowolnej klasy obsługiwanej w zasobnikach
lokalizacja z pewnymi zastrzeżeniami
możesz zmienić tylko nazwę zasobnika
i lokalizację, usuwając i odtwarzając
wiadro, jak również po podwójnym regionie
wybrany, nie można go zmienić
w wielu regionach i podczas wybierania
w wielu regionach nie będziesz w stanie
zmień wiadro na podwójny region i
na koniec będziesz musiał wybrać co
poziom dostępu, jaki chcesz mieć dla innych
na wiaderku, czy chcesz złożyć wniosek
uprawnienia za pomocą jednolitego lub grzywny
ziarnisty dostęp do jednolitego poziomu łyżki
Access umożliwia korzystanie z iam samodzielnie
zarządzaj uprawnieniami, które stosuje
uprawnienia do wszystkich zawartych obiektów
wewnątrz wiadra lub grup obiektów
z nazwą zwyczajową poprzedzony jest zielonym kolorem wyszukiwania
Opcja umożliwia korzystanie z iam i dostępu
listy kontrolne lub acl
razem zarządzać uprawnieniami acls są
starszy system kontroli dostępu do chmury
pamięć masowa zaprojektowana z myślą o interoperacyjności
z amazon s3 dla tych z was, którzy używają
aws możesz określić dostęp i zastosować
uprawnienia zarówno na poziomie zasobnika, jak i
na pojedynczy obiekt i ja też będę
nurkowanie głębiej z dostępem
kontrola
w ciągu zaledwie trochę i tak jak etykiety notatki
są opcjonalnym elementem do tworzenia zasobników
jak każde inne tworzenie zasobów
process w gcp, który omówiliśmy
wiadra chciałem zakryć to, co jest przechowywane
w tych wiadrach, które są przedmiotami i
przedmioty są pojedynczymi częściami
dane lub fragmenty danych, które przechowujesz w pliku
wiadro do przechowywania w chmurze i nie ma
ograniczyć liczbę obiektów, które ty
możesz tworzyć w wiadrze, abyś mógł myśleć
obiektów przypominających pliki obiektów
mają dwa komponenty dane obiektowe i
metadane obiektu
dane obiektu to zazwyczaj plik, który ty
chcesz przechowywać w chmurze i w
w tym przypadku jest to zdjęcie kratki
muszka i metadane obiektu to a
zbiór par nazwa-wartość, które
opisz różne jego właściwości
obiekt nazwa obiektu jest traktowana jako
kawałek metadanych obiektu w chmurze
przechowywania i musi być unikalny w ramach
przechowywanie w chmurze wiadra używa mieszkania
przestrzeń nazw do przechowywania obiektów, co oznacza
że przechowywanie w chmurze nie jest systemem plików
hierarchii, ale widzi wszystkie obiekty w a
podane wiadro jako niezależne z nr
stosunek do siebie za
wygoda
narzędzi, takich jak konsola i gsutil
pracować z obiektami, które używają ukośnika
znak tak, jakby były przechowywane w
wirtualna hierarchia, na przykład możesz
nazwij jeden obiekt slash muszki slash
wiosna 2021 muszka w szkocką kratę.jpg kiedy
za pomocą konsoli w chmurze możesz wtedy
nawigować do tych obiektów tak, jakby one
znajdowały się w katalogu hierarchicznym
struktura pod folderami muszki i
Wiosna 2021 teraz wspomniałem wcześniej
częścią tworzenia zasobnika jest
wybór klasy pamięci masowej
klasa ustawiona dla obiektu wpływa na
model dostępności i wyceny obiektu
więc kiedy tworzysz wiadro, możesz
określ domyślną klasę pamięci dla
wiadro podczas dodawania obiektów do
Bucket dziedziczą tę klasę pamięci
chyba że wyraźnie określono inaczej teraz i
chciałem dotknąć tych czterech pamięci
zajęcia teraz, aby dać ci lepsze
zrozumienia różnic między
dla nich pierwsza to standardowa pamięć masowa
i jest uważany za najlepszy dla gorących danych lub
często używanych danych i jest dla nich najlepszy
krótkotrwałe użytkowanie, ponieważ go nie ma
określony czas przechowywania i to jest
doskonale nadaje się do zastosowań analitycznych
obciążenia pracą i transkodowaniem oraz ceną
dla tej klasy pamięci wynosi dwa
centów za gigabajt miesięcznie
w pobliżu składowania liniowego i jest to brane pod uwagę
gorące dane, jak również i jest tani
klasa pamięci do częstego przechowywania
magazyn danych typu nearline, do którego uzyskano dostęp, ma
nieco mniejsza dostępność w ciągu 30 dni
minimalny czas przechowywania i jest dostarczany z
koszt dostępu do danych nearline
przechowywanie jest idealne, jeśli szukasz
stale dodawać pliki, ale tylko planować
dostęp do nich raz w miesiącu i jest idealny
do tworzenia kopii zapasowych i archiwizacji danych
cena za tę klasę pamięci wynosi ok
grosz za gigabajt miesięcznie, teraz zimno
pamięć liniowa jest uważana za zimne dane jako
wchodzi w dłuższy okres
klas składowania i jest to bardzo niski koszt
klasa przechowywania do przechowywania i często
dostęp do danych, które zawiera
niższa dostępność niż pamięć typu nearline
minimalny okres przechowywania wynoszący 90 dni oraz
wiąże się to z kosztami dostępu do danych
jest wyższy niż koszt odzyskania dla
pamięć masowa nearline do przechowywania na zimno jest
idealny do danych, które zamierzasz przeczytać lub
modyfikować co najwyżej raz na kwartał i jest
idealny do tworzenia kopii zapasowych danych i danych
archiwizacja ceny za to miejsce do przechowywania
klasa ma mniej niż połowę
grosza za gigabajt miesięcznie i wreszcie
przechowywanie archiwów to najniższy koszt
wysoce trwała usługa przechowywania danych
archiwizacja kopii zapasowych online i awarii
odrodzenie, a nawet osiągnięcie najniższego poziomu
koszt dostępu do danych jest nadal dostępny
w ciągu milisekund przechowywania archiwum
wiąże się z wyższymi kosztami danych
odzyskanie, jak również a
dzienny minimalny czas przechowywania i jest
najlepszy wybór dla danych, które planujesz
dostęp do archiwum rzadziej niż raz w roku
przechowywanie jest również najwyższe
cena za pobieranie danych i jest idealna
do przechowywania danych archiwalnych, które są używane do
celów regulacyjnych lub odzyskiwania po awarii
dane w przypadku, gdy istnieje
upss w twoim środowisku cena
klasa przechowywania pojawia się w a
śmiesznie niska cena za gigabajt za
miesięcznie za ułamek pensa za
gigabajt miesięcznie, jeśli chodzi o
wybierając swoją lokalizację geograficzną to
określi dostępność Twojego
dane tutaj jak widać najwyższe
dostępność to standard
wieloregionowy, podczas gdy archiwum ma
najniższa dostępność, gdy jest przechowywana w
ustawienie regionalne teraz, jeśli chodzi o
trwałość Twoich danych tj
pomiar tego, jak zdrowy i odporny
Twoje dane pochodzą z utraty danych lub danych
korupcja Google Cloud może pochwalić się 11 dziewiątkami
coroczną trwałość wszystkich przechowywanych danych
w dowolnej klasie pamięci masowej w chmurze tzw
wiedzieć, że Twoje dane są bezpiecznie przechowywane i
będzie tam zachowując tę ​​samą integralność
od dnia, w którym go zapisałeś teraz, kiedy to
chodzi o nadanie uprawnień do twojego
zasobniki do przechowywania w chmurze i obiekty
w nich są cztery różne
opcje do wyboru pierwsza to iam
uprawnienia i to jest standard
uprawnienia, które kontrolują wszystkie inne
zasobów w chmurze Google i postępuj zgodnie z
tę samą odgórną hierarchię, którą my
omówione wcześniej następne dostępne
opcja to lista kontroli dostępu lub listy acl
a te określają, kto ma dostęp do twojego
wiadra i przedmioty oraz jakiego rodzaju
dostępu, jaki mają, a te mogą działać
w tandemie z uprawnieniami im
do podpisywania adresów URL są one ograniczone czasowo
adresy URL dostępu do zapisu czytnika, które mogą być
utworzone przez Ciebie w celu umożliwienia dostępu do
przedmiot na czas, który
określasz i na koniec jest to polityka podpisu
dokumenty i są to dokumenty do
określ, co można przesłać do zasobnika
i wejdę do każdego z nich
te w nieco szczegółach teraz chmura
storage oferuje dwa systemy przyznawania
uprawnienia użytkowników do uzyskiwania dostępu do zasobników
oraz obiekty iam i listy kontroli dostępu
systemy te działają równolegle w kolejności
aby użytkownik miał dostęp do magazynu w chmurze
zasobów potrzebnych tylko jednemu systemowi
aby udzielić użytkownikowi pozwolenia im jest
zawsze zalecana metoda, gdy to
chodzi o umożliwienie dostępu do wiader i
obiektów w tych zasobnikach
robi to przydzielanie ról na poziomie zasobnika
nie wpływają na żadne istniejące role, które ty
przyznawane na poziomie projektu i vice versa
odwrotnie, dając ci dwa poziomy
ziarnistość, aby dostosować swoje
uprawnienia, więc na przykład możesz dać
uprawnienia użytkownika do odczytu obiektów w dowolnym
wiadro, ale uprawnienia do tworzenia obiektów
tylko w jednym konkretnym zasobniku role
które są dostępne za pośrednictwem iam to
prymitywne standardowe role pamięci lub
starsze role, które są równoważne
acls teraz acls są tam, jeśli potrzebujesz
dostosuj dostęp i uzyskaj szczegółowe informacje
z pojedynczymi obiektami w wiadrze
i służą do określenia, kto ma do nich dostęp
twoje wiadra i przedmioty, a także co
poziom dostępu, jaki mają każdy acl
składa się z jednego lub więcej wpisów i
nadaje określonemu użytkownikowi lub grupie
zdolność do wykonywania określonych czynności każdy
wpis składa się z dwóch kawałków
informacje o pozwoleniu, które określa
jakie czynności można wykonać i a
zakres, który określa, kto może wykonać
określone akcje teraz powinny być acls
używane z ostrożnością jako role iam i listy acl
nakładające się przechowywanie w chmurze zapewni a
szersze pozwolenie, więc jeśli pozwolisz
dostęp określonych użytkowników do obiektu w pliku a
wiadro, a następnie stosuje się acl
ten obiekt, aby upublicznić to
będą publicznie dostępne, więc proszę
świadomy teraz podpisany adres URL to adres URL, który
zapewnia ograniczone pozwolenie i czas na
złóż wniosek, który zawierają adresy URL znaków
informacje uwierzytelniające pozwalające
użytkowników bez poświadczeń do wykonania
określone działania na zasobie, gdy ty
wygeneruj podpisany adres URL, który określasz jako użytkownik
lub konto usługi, które musi mieć
wystarczające zezwolenie na dokonanie ww
wniosek, że znak url zrobi
po wygenerowaniu podpisanego adresu URL przez kogokolwiek
kto go posiada, może użyć adresu URL znaku
wykonać określone czynności, np
odczytanie obiektu w określonym
teraz, jeśli chcesz
zapewnić publiczny dostęp użytkownikowi, który
nie ma konta, które możesz podać
podpisany adres URL do tego użytkownika, który daje
użytkownik ma dostęp do odczytu, zapisu lub usuwania
ten zasób przez ograniczony czas
określ datę ważności, kiedy ty
utwórz adres URL znaku, aby każdy, kto wie
adres URL może uzyskać dostęp do zasobu do
czas wygaśnięcia adresu URL to
osiągnięty lub klucz użyty do podpisania adresu URL
jest obrócony, a polecenie utworzenia
adres URL znaku jest pokazany tutaj i jak możesz
see został przydzielony na ograniczony czas
10 minut, więc jak widziałeś, kiedy to
chodzi o przechowywanie w chmurze, jest ich tak wiele
opcje konfiguracyjne do wyboru i
wiele różnych sposobów przechowywania i dawania
dostęp i to sprawia, że ​​ten zasób pochodzi
chmura Google jest tak elastyczną opcją i
pełen wielkich możliwości dla wielu
to są różne rodzaje obciążeń
także usługa, która często się pojawia
egzamin jako jeden z wielu różnych
opcje przechowywania do wyboru i tak dalej
Znajomość klas składowania funkcji
ceny i opcje dostępu będą
zdecydowanie podam ci nogę, kiedy ty
przedstawiane są pytania dot
storage i to właściwie wszystko
chciałem zakryć, jeśli o to chodzi
przegląd przechowywania w chmurze, abyś mógł teraz
zaznacz tę lekcję jako zakończoną i przejdźmy do rzeczy
przejść do następnego
[Muzyka]
witaj z powrotem i zrobię to na tej lekcji
obejmować wersjonowanie i życie obiektów
zarządzanie cyklem funkcja w chmurze
pamięć służąca do zarządzania i sortowania
przez starsze pliki, które muszą być
usunięte wraz z plikami, których nie ma w
duża potrzeba regularnego dostępu znając
możliwości tych dwóch funkcji
może naprawdę pomóc uporządkować nagromadzone
przedmioty do wiader magazynowych i ścinać
na temat kosztów, więc bez zbędnych ceregieli
zanurz się teraz, aby zrozumieć trochę więcej
o obiektach, w które chciałem się zagłębić
niezmienność i wersjonowanie są teraz obiektami
są niezmienne, co oznacza, że ​​a
przesłany obiekt nie może się zmienić w trakcie
jego czas przechowywania przechowywanie obiektu
życie to czas pomiędzy a
pomyślne utworzenie obiektu lub przesłanie i
oznacza to pomyślne usunięcie obiektu
że nie można edytować obiektów na miejscu
zamiast tego obiekty są zawsze zastępowane przez
nowa wersja, więc po przesłaniu pliku
nowy obiekt uzupełnia nową wersję
obiekt ten jest serwowany czytelnikom
wymiana oznacza koniec jednego
cykl życia obiektu i początek
teraz nowy, aby wesprzeć odzyskiwanie
obiektów, które są usuwane lub zastępowane
przechowywanie w chmurze oferuje obiekt
wersjonowanie wersjonowanie obiektów funkcji
zachowuje nieaktualną wersję obiektu
kiedy pojawi się wersja obiektu na żywo
zastąpiony lub usunięty obiekt umożliwiający
wersjonowanie zwiększa koszty przechowywania, które
można częściowo złagodzić
konfigurowanie zarządzania cyklem życia obiektów
aby usunąć starsze wersje obiektów, ale więcej
na to w zaledwie trochę zastosowań przechowywania w chmurze
dwie właściwości, które razem identyfikują
wersja obiektu generacja
który identyfikuje wersję
dane obiektu
i generacja meta, która identyfikuje
wersja metadanych obiektu
te właściwości są zawsze obecne
każdą wersję obiektu, nawet jeśli
przechowywanie wersji obiektów nie jest włączone
właściwości mogą być używane do wymuszania
zamawianie aktualizacji tak, aby
włącz wersjonowanie obiektów, które byś zrobił
że włączając go raz na wiadrze
włączone starsze wersje pozostają w twoim
wiadro podczas wymiany lub usuwania
występuje tak domyślnie, gdy zastępujesz plik
przechowywanie w chmurze obiektów usuwa stare
version i dodaje nową wersję te
starsze wersje zachowują nazwę
obiekt, ale są jednoznacznie identyfikowane przez
ich numer generacji, gdy obiekt
wersjonowanie utworzyło starszą wersję
obiektu można użyć generacji
numer odnoszący się do starszej wersji
pozwala to na przywrócenie wymienionego
obiekt w wiadrze lub na stałe
usuń starsze wersje obiektów, których nie masz
dłuższa potrzeba, a więc powrót do kosztów
przez minutę te wersje mogą
naprawdę dodaj i zacznij trochę kosztować
poważne pieniądze, jeśli masz tysiące
pliki z setkami wersji i to
tutaj pojawia się zarządzanie cyklem życia
do gry, teraz oferuje przechowywanie w chmurze
funkcja zarządzania cyklem życia obiektów w
w celu obsługi niektórych typowych przypadków użycia
jak ustawienie czasu życia lub ttl
obiekty
zachowanie nieaktualnych wersji
obiektów lub obniżenie klasy pamięci
obiektów, które pomogą zarządzać kosztami w chwili obecnej
aby zastosować tę funkcję do twojego
obiektów, którym przypisano cykl życia
konfiguracja zarządzania do wiadra
konfiguracja zawiera zestaw reguł
które dotyczą prądu i funkcji
obiekty w wiadrze, gdy obiekt
spełnia kryteria jednej z zasad
przechowywanie w chmurze automatycznie wykonuje
określoną akcję na obiekcie i tak dalej
tutaj pokazano kilka przykładowych przypadków użycia
jeśli chcesz obniżyć wersję
klasa przechowywania
obiektów starszych niż 365 dni na zimno
przechowywanie linii do celów zgodności
wraz z cyklem życia oszczędności
zarządzanie jest idealne do tego innego
przypadek użycia ma miejsce, gdy chcesz usunąć
obiekty utworzone przed 1 stycznia
2020 i jest to kolejny świetny przypadek użycia
aby zaoszczędzić pieniądze, a także zachować tylko
trzy najnowsze wersje każdego z nich
obiekt w zasobniku z wersjonowaniem
włączone, aby trzymać się z obiektów wersji
budowanie zarządzania cyklem życia obiektów
ma tak wiele innych przypadków użycia w całym a
niezliczone gałęzie przemysłu i kiedy są używane
poprawnie to świetny sposób na osiągnięcie celu
zarządzanie obiektem wraz z zapisywaniem
pieniądze, na które chciałem poświęcić chwilę
zagłębić się w zarządzanie cyklem życia
konfiguracja każdego zarządzania cyklem życia
konfiguracja zawiera zestaw
komponenty są zbiorem reguł
warunki i działanie, gdy
warunki są spełnione reguły są dowolnym zbiorem
warunki dla dowolnych warunków działania to
coś, co obiekt musi spotkać przed
akcja zdefiniowana w regule następuje na
obiekt i istnieją różne warunki
do wyboru, co pozwala ci dostać
dość ziarnisty i wreszcie akcja
gdzie miałbyś taką opcję
usunąć lub ustawić klasę pamięci teraz, kiedy
usuniesz aktualne wersje
przenieś bieżącą wersję do pliku a
stan nieaktualny i kiedy usuniesz a
nieaktualną wersję będziesz na stałe
usunąć wersję i nie można jej pobrać
z powrotem i tak po ustawieniu pamięci
class przeniesie obiekt do a
inna klasa pamięci, więc podczas definiowania
reguła, której możesz określić dowolny zestaw
warunki dla każdego działania, jeśli określisz
wiele warunków w regule obiektu
musi spełniać wszystkie warunki dot
działania, które należy podjąć, więc jeśli tak
trzy warunki i jeden z nich
warunki nie zostały spełnione, tj
akcja nie odbędzie się, jeśli ty
określ wiele reguł, które zawierają
ta sama akcja, która jest wykonywana, gdy an
obiekt pasuje do warunków w dowolnym z
te reguły teraz, jeśli istnieje wiele reguł
spełnione ich warunki
jednocześnie dla pojedynczej chmury obiektów
storage wykona usunięcie
działanie ma pierwszeństwo przed
zestaw akcji klasowych lub zestaw
akcja klasy przechowywania, która przełącza
obiekt do klasy przechowywania z
najniższa cena przechowywania w stanie spoczynku
pierwszeństwo, więc na przykład, jeśli masz
jedna reguła, która usuwa obiekt i
kolejna reguła, która zmienia obiekt
storage class, ale obie reguły używają klasy
dokładnie ten sam warunek, co akcja usuwania
występuje zawsze, gdy warunek jest spełniony
lub jeśli masz jedną regułę, która zmienia
klasa składowania obiektów do bliskiej linii
przechowywanie i kolejna reguła, która się zmienia
klasę obiektowej pamięci masowej do zimnej linii
storage, ale obie reguły używają dokładnego
ten sam warunek klasy obiektowej pamięci masowej
zawsze zmienia się na składowanie w linii zimnej, kiedy
warunek jest spełniony i tyle
uwagi, na które chciałem zwrócić uwagę
jeśli chodzi o przechowywanie w chmurze, jest
że jeśli chodzi o cykl życia obiektu
kierownictwo
zmiany są zgodne z przedmiotem
data utworzenia, a także kiedy obiekt jest
usunięty, nie można go cofnąć, więc proszę
należy zachować ostrożność podczas trwałego usuwania pliku
wersja, jak również zasady cyklu życia mogą
do 24 godzin, aby wejść w życie, więc bądź
świadomy podczas ich ustawiania i zawsze bądź
koniecznie przetestuj te zasady cyklu życia w
rozwoju przed ich wprowadzeniem
do produkcji i to jest ładne
dużo wszystko, co musiałem pokryć, jeśli chodzi o
wersjonowanie i cykl życia obiektu
zarządzanie i możesz to teraz zaznaczyć
lekcja jako kompletna i kiedykolwiek jesteś
gotowy, dołącz do mnie w konsoli, dokąd idziemy
praktyczne z wersjonowaniem życia obiektów
zarządzanie cyklem i przechowywanie w chmurze jako
cały
[Muzyka]
witamy z powrotem w tym demo, które zamierzamy zrobić
scementować wiedzę, której się nauczyliśmy
z ostatnich kilku lekcji w chmurze
przechowywania i naprawdę zanurzyć się w sedno
ziarnisty, jeśli chodzi o funkcje i
konfiguracja, do której zamierzasz przejść jako pierwsza
utwórz zasobnik do przechowywania w chmurze i prześlij
niektóre pliki do niego, a następnie wchodzić z nimi w interakcję
wiadro i pliki używające
konsola, a także dostaniesz swoją
brudzą ręce za pomocą polecenia gsutil
narzędzie linii i to jest narzędzie do
zarządzanie pamięcią masową w chmurze z poziomu polecenia
linii teraz jest sporo pracy
zrób to tutaj, mówiąc o tym
zanurkuj, więc jestem zalogowany tutaj jako
tony muszki na gmail.com wraz z
będąc w projekcie Bowtie Inc i tak
pierwszą rzeczą, którą chcę zrobić, jest to, że chcę
utwórz wiadro do przechowywania w chmurze, więc in
każ mi zrobić to, co zamierzam
przejdź do menu nawigacji i jestem
przewiń w dół do magazynu
a tutaj mam już kilka
wiadra, które utworzyłem wcześniej
lekcje i możesz mieć parę
wiadra też, ale idziesz
naprzód i utwórz nowy zasobnik, przechodząc
do góry tutaj i kliknij utwórz
wiadro teraz wiem, że poszliśmy
przez to wcześniej na poprzednich lekcjach
ale tym razem chciałem przejść przez wszystko
opcje konfiguracji, które są
dostępne i tak po pierwsze
jesteś poproszony o zrobienie tutaj, to nazwanie
swoje wiadro, jak wyjaśniono we wcześniejszej części
lekcja, że ​​musi być wyjątkowy na skalę światową
imię, więc możesz wybrać dowolne imię
wybierz i tak dla mnie zadzwonię
ta muszka wiadro inc dash 2021 jestem
zamierzam nacisnąć kontynuuj, a jeśli nie było to a
globalnie unikalna nazwa, spowoduje to błąd
i musiałbyś wprowadzić nowy
name, ale ponieważ ta nazwa wiadra jest
unikalny na skalę światową, jestem w stanie iść do przodu
dla typu lokalizacji do wyboru
region podwójny region i wiele regionów z
możesz wybrać wiele regionów w lokalizacji
wybierz z obu Ameryk Europy
lub Azji i Pacyfiku oraz w ramach podwójnego regionu
masz możliwość ponownego wyboru
z ameryki europy i azji i pacyfiku
i zostaną ci podane regiony
każdy i tak dla tego demo, do którego idziemy
Śmiało i wybierz region i jesteśmy
zamierza zachować lokalizację jako nas na wschód
jeden i kiedy już go wybierzesz
możesz iść dalej i nacisnąć Kontynuuj i jesteś
zostanie wyświetlony monit o wybranie wartości domyślnej
klasa przechowywania i tutaj masz
możliwość wyboru spośród czterech
klasy pamięci, które omówiliśmy w an
wcześniejsza lekcja i tak dla tego demo ciebie
może zachować go jako standard i po prostu kliknąć
na kontynuuj i oto pojawi się monit
wybrać kontrolę dostępu i ponieważ
będziemy nurkować w acls
może zachować to jako domyślne drobne ziarno
kontrola dostępu, którą możesz śmiało i
kliknij kontynuuj i pod szyfrowaniem
może zachować go jako domyślne zarządzanie Google
klucz, ale wiedz, że zawsze go masz
możliwość wyboru klucza zarządzania klientem
i po przesłaniu klienta
zarządzaj kluczem, możesz go wybrać tutaj
i ponieważ nie mam klienta zarządzanego
klucze żadne inne klucze się nie pojawiają, więc idę
aby kliknąć google zarządzaj kluczami i tutaj
w ramach zasad przechowywania wiem, że nie
dotknąłem tego, ale tylko po to, by ci dać
pewien kontekst podczas umieszczania retencji
Polityka dotycząca wiadra zapewnia, że ​​wszystko
obecne i przyszłe obiekty w zasobniku
nie można usunąć ani zastąpić, dopóki nie zostaną one usunięte
osiągnąć wiek, który określasz w
zasady przechowywania, więc jeśli spróbujesz usunąć
lub wymienić przedmioty, których wiek jest mniejszy
niż okres przechowywania
oczywiście zawodzi i to jest świetne
celów zgodności w obszarach, w których rejestrowane są dzienniki
muszą być co roku kontrolowane przez organy regulacyjne
roku lub gdy wymaga tego rząd
okresy przechowywania mają również zastosowanie do
polityki przechowywania, którą masz do wyboru
blokowanie tych zasad przechowywania i kiedy
blokujesz zasady przechowywania w zasobniku
uniemożliwiasz istnienie polityki
usunięte lub okres przechowywania od
jest zawsze zmniejszany, a ta funkcja jest
nieodwracalne, więc proszę być świadomym, jeśli
kiedykolwiek eksperymentowałeś z zamkiem
zasady przechowywania, więc jeśli ustawię a
zasady przechowywania tutaj mogę zachować
obiekty przez określoną liczbę sekund
dni miesięcy i lat oraz za to demo
nie będziemy ustawiać żadnej retencji
zasady, więc zamierzam to sprawdzić
i zamierzam iść dalej i dodać
etykieta z kluczem będącym środowiskiem i
wartość to test i tylko jako uwaga
zanim przejdziesz dalej i klikniesz utwórz
po prawej stronie zobaczysz
miesięczny kosztorys i będziesz
podane oszacowanie z pamięcią i
odzyskanie i ile to kosztuje
dla operacji twój sla i twój
szacowany koszt miesięczny i tak wcześniej
tworzenie dowolnych wiader, które zawsze możesz zrobić
sprawdzić cenę, aby zobaczyć, ile to będzie kosztować
do pobierania rozmiaru magazynu, aby uzyskać dobro
wyobrażenie o tym, ile będzie Cię to kosztować miesięcznie
dobrze, więc kiedy już wszystko gotowe, tutaj
można po prostu kliknąć opcję Utwórz
a to pójdzie dalej i stworzy twoje
wiadro i tak teraz, gdy twoje wiadro jest
utworzony chcemy dodać kilka plików i tak dalej
najpierw chcemy przejść do kopiowania plików
z instancji do magazynu w chmurze
wiadro i tak, aby to zrobić my
musimy utworzyć instancję, więc robimy to
wracam do nawigacji
menu, które przewiniemy w dół, aby obliczyć
silnik i stworzymy nasz
na przykład i dla tych, którzy nie mają
upewnij się, że domyślna konfiguracja vpc
aby utworzyć jeden przed kontynuowaniem i
tworzę twoją instancję idę
do przodu i kliknij utwórz, zamierzam to zrobić
nazwij tę instancję
Bowtie nada mu etykietę
testu środowiska kliknij Zapisz
region będzie
wschodni i możesz zachować wartość domyślną
strefa as us east 1b typ maszyny
zmienimy go na e2micro i
przewiniesz w dół, aby uzyskać dostęp
zakresy i tutaj idzie twoja instancja
potrzebujesz dostępu do pamięci masowej w chmurze
wiadro, więc będzie potrzebował chmury
dostęp do pamięci, więc klikniesz
przy ustawionym dostępie dla każdego przewijania interfejsu API w dół
do magazynu i zrobimy to dla tego demo
wybierz pełne, pozostawiając wszystko inne
jako domyślną i po prostu kliknij
utwórz, więc damy mu parę
minuty tutaj, na przykład, aby stworzyć OK
a moja instancja została utworzona i tak
teraz chcę utworzyć kilka plików i skopiować
je do przechowywania w chmurze, więc idę
aby najpierw przejść do przechowywania w chmurze
i do mojego wiadra i tak możesz
zobacz pliki, które przesyłasz i tak dalej
następnie otworzysz Cloud Shell
i zrób to trochę większe na lepsze
przeglądanie, więc teraz przejdziesz do ssh
do swojej instancji za pomocą polecenia
gcloud compute ssh wraz z twoim
nazwa instancji myślnik flagi strefy myślnik
strefa ze strefą nas wschód 1b jestem
pójdę dalej i wcisnę enter i ty
może zostać wyświetlony komunikat z prośbą o
autoryzować to wywołanie API i chcesz
naciśnij autoryzację i będziesz
monit o wprowadzenie hasła do Twojego
para kluczy wprowadź ją ponownie
i jeszcze raz
i sukces jesteśmy zalogowani do
na przykład zamierzam szybko wyczyścić moje
screen, więc wiem, że mogłem sshed
do instancji z komputera
konsola silnika, ale chciałem wyświetlić
zarówno konsola, jak i powłoka na
ten sam ekran, aby nieco ułatwić przeglądanie
gdy dodaję i usuwam pliki do iz
wiadro w porządku, więc teraz, kiedy jesteś
zalogowany chcesz utworzyć swój pierwszy
plik, który możesz skopiować do swojego
wiadro, abyś mógł wprowadzić polecenie
sudo nano plik trafiony tekst w kropki z muszką
wejdź, a to pozwoli ci się otworzyć
edytor nano do edycji pliku
bowties.txt i tutaj możesz wejść
jakakolwiek wiadomość, którą chcesz dla mnie, jestem
zamierzam wejść w naukę wiązania kokardki
remis wymaga czasu, dobrze, a ja uderzę
ctrl o, aby zapisać, naciśnij enter, aby zweryfikować
nazwa pliku w prawo i ctrl x, aby wyjść
więc teraz chcę skopiować ten plik
do mojego wiadra i tak oto gdzie jestem
zamierzam użyć polecenia gsutil, więc jestem
zamierzam wpisać gsutil cp, aby skopiować plik
nazwa pliku, którego jest plikiem
Muszki
tekst wraz z ukośnikiem dwukropka gs
ukośnik i imię twojego
wiadro, które w moim przypadku jest tuszem do muszki
dash 2021 i to powinno skopiować mój plik
plik bowties.txt do mojego wiadra
muszka inc
2021 wcisnę enter
dobrze i skończyło się kopiowanie i
jeśli pójdę tutaj w prawym górnym rogu i
kliknij odśwież, widzę, że mój plik
pomyślnie przesłane i to jest a
świetna i łatwa metoda przesyłania dowolnych
pliki, które możesz mieć w chmurze
dobrze, a więc teraz, gdy skopiowałeś pliki
z twojej instancji do twojego wiadra jesteś
zamierzam teraz skopiować niektóre pliki z
repozytorium do przesłania do magazynu w chmurze
nasz następny krok, więc idziesz dalej
i wyjdź z instancji przez just
po prostu wpisując wyjście, zrobię to szybko
wyczyść ekran, więc tutaj muszę
sklonuj moje repozytorium, jeśli już masz klon
repo, możesz pominąć ten krok, jestem
idę do cd tylda, aby upewnić się, że jestem w moim
katalog domowy zamierzam zrobić ls i
więc widzę tutaj, że już to zrobiłem
sklonowałem moje repozytorium, więc zamierzam wejść na cd
ten katalog i zamierzam uruchomić plik
polecenie git pull, aby pobrać najnowsze pliki
fantastycznie, zamierzam teraz wyczyścić moje
ekran i idę z powrotem do mojego
katalog domowy, więc teraz chcę skopiować
pliki, z którymi chcę pracować
moje wiadro do przechowywania w chmurze i są dwa
jpeg o nazwie pink
muszka-słoń oraz kraciasta muszka
i te pliki można znaleźć w repozytorium
oznaczył 12 usług przechowywania poniżej zera
jedno zarządzanie pamięcią masową w chmurze i tak zrobię
podać to w tekście lekcji jako
jak również można znaleźć w instrukcjach
więc zamierzam po prostu w to wejść
katalogu, wpisując cd google cloud
kojarzy pamięć masową Cloud Engineer 12
usługi i 0 1 miejsce w chmurze
zarządzanie zamierzam wymienić wszystkie
pliki w katalogu i jak możesz
zobacz tutaj różowa muszka z kreską słonia i
muszka w kratę są tutaj i ja też
zamierzam szybko wyczyścić ekran i tak dalej
teraz dla mnie skopiować te pliki idę
użyć polecenia gsutil
cp do kopiowania star.jpg, czyli wszystko
jpeg, które są dostępne wraz z gs
dwukropek ukośnik ukośnik i
nazwa wiadra, która jest muszką inc
dash 2021, wcisnę enter i to
mówi, że pomyślnie skopiował plik
pliki, po prostu przejdę do
prawym górnym rogu i wykonaj kolejny
odświeżyć i odnieść sukces w plikach
pomyślnie przesłano kolejny doskonały
przykład kopiowania plików z innego
source do swojego zasobnika za pomocą narzędzia gsutil
narzędzie wiersza poleceń i na tym koniec
pierwszej części tego demo
trochę długi, więc postanowiłem go podzielić
i byłaby to świetna okazja
żebyś wstał i się porozciągał
sobie kawę lub herbatę i kiedy tylko
jesteś gotowy, zacznie się część druga
zaraz od końca pierwszej części tzw
możesz dokończyć ten film, a ja to zrobię
do zobaczenia w części drugiej
[Muzyka]
to druga część zarządzania chmurą
demo dostępu do pamięci masowej i będziemy
zaczynając dokładnie tam, gdzie skończyliśmy
część 1. więc powiedzmy to
zanurz się i tak teraz, kiedy załadowaliśmy
wszystkie te pliki, które następnie chcemy utworzyć
ten zasobnik jest teraz publicznie dostępny
pamiętaj, że pozostawienie publicznego wiadra
nie jest powszechną praktyką i tylko powinna
być używany w rzadkich przypadkach, gdy ty
hostują statyczną witrynę internetową z Twojej witryny
wiadro i zawsze powinno być prywatne
ilekroć to możliwe, zwłaszcza w
środowisko produkcyjne, więc proszę zwrócić na to uwagę
że to tylko w celu
to demo i tak mam zamiar szybko
pokaż to ci w konsoli, więc jestem
zamierza zamknąć powłokę chmurową dla
jeszcze chwila i idę do
górne menu i kliknij uprawnienia i
pod uprawnieniami, które zamierzam kliknąć
dodaj tutaj możesz dodawać nowych członków i
ponieważ chcesz to zrobić publicznie
dostępne chcesz używać wszystkich użytkowników
Member, więc wpisujesz wszystko i powinieneś
wyskakujące okienko wyświetlające wszystkich użytkowników i
wszystkich uwierzytelnionych użytkowników, których chcesz
kliknij wszystkich użytkowników i rolę, którą ty
chcesz wybrać dla tej wersji demonstracyjnej
być przeglądarką obiektów pamięci masowej, więc zamierzam to zrobić
wpisz przeglądarkę obiektów pamięci masowej i tutaj
powinno wyskoczyć i wybrać to i
następnie możesz kliknąć zapisz, że idziesz
zostać poproszony o upewnienie się, że tak jest
co chcesz zrobić, że chcesz
upublicznij to wiadro i tak, robimy to
więc możesz po prostu kliknąć opcję Zezwól na publiczne
dostęp, a otrzymasz tutaj baner
u góry mówiąc, że to wiadro jest
publicznie do Internetu i jest wielką porażką
bezpiecznie mieć na wypadek, gdybyś kiedykolwiek
omyłkowo upublicznij swoje wiadro i
jeśli wrócę do obiektów, możesz
zobaczyć, że dostęp publiczny jest dostępny dla
wszystkie pliki w wiadrze i tak po prostu
aby to zweryfikować, skopiuję plik
publiczny adres URL muszki pink elephant dash
zamierzam otworzyć nową kartę wkleić
adres URL naciśnij Enter i jak widać i
mieć publiczny dostęp do tego zdjęcia i
zamknij tę kartę i tak teraz, gdy już to zrobiliśmy
zrobiliśmy nasze demo, aby zrobić wiadro
publicznie dostępne, powinniśmy iść dalej
i usuń publiczny dostęp, aby to zrobić
usunąć uprawnienia publiczne, które mogę po prostu
przejdź do uprawnień i po prostu kliknij
usuń uprawnienia publiczne, które zamierzam
wyświetl monit, aby upewnić się, że tak jest
dokładnie to, co chcę robić i tak jest
więc możesz kliknąć usuń publiczne
uprawnienia bardzo proste i eleganckie
rozwiązanie w celu usunięcia public
dostęp z twojego wiadra i jeśli pójdziesz
z powrotem do obiektów zobaczysz, że wszystkie
dostęp publiczny został usunięty ze wszystkich
pliki, a więc teraz, gdy już to zrobiłeś
doświadczony, jak dodać publiczny dostęp do
wiadro, które chciałem trochę zdobyć
bardziej ziarnisty i tak pójdziemy
naprzód i zastosuj uprawnienia acl dla jednego
konkretnego przedmiotu i dlatego, że lubię różowy
słonie idźmy dalej i wybierzmy różowy
muszka słoń, więc tutaj mogę
przejdź do górnego menu i kliknij edytuj
uprawnienia i zostanę poproszony o
nowe okno dla uprawnień, które są
aktualnie dostępne dla tego obiektu ty
można kliknąć dodaj wpis kliknij upuść
w dół i wybierz publiczny z
listy rozwijanej i automatycznie automatycznie
wypełnij nazwę, która jest wszystkimi użytkownikami i
dostęp, który będzie czytnikiem jestem
idź dalej i kliknij Zapisz i
zostanie wygenerowany publiczny adres URL i tak dalej
tylko po to, aby to zweryfikować, zamierzam kliknąć
na publicznym adresie URL i sukcesie, który mam teraz
publiczny dostęp do tego zdjęcia jeszcze raz
ponownie zamykam tę zakładkę
a więc teraz, gdy to skonfigurowałeś
obiekt do publicznego dostępu, który chcę pokazać
jak usunąć dostęp publiczny za pomocą
wiersz poleceń tym razem, więc jesteś
idzie w górę do prawej górnej ręki
róg i otwórz powłokę chmurową, idę
aby szybko wyczyścić ekran i idę
wkleić tutaj polecenie, które jest
gsutil acl ch dla zmiany minus d które
to usuń nazwę użytkownika, który jest
wszystkich użytkowników i czy był to zwykły użytkownik
możesz wpisać ich adres e-mail
wraz z ukośnikiem dwukropka gs
ukośnik w przód nazwy wiadra, który w
moja sprawa to muszka z atramentem 2021 i
nazwa pliku, którym jest różowy słoń
muszka w kropki jpeg zaraz wcisnę enter
i mówi, że powiodło się
zaktualizowane, więc jeśli wrócę tutaj, aby
konsola i ja wycofujemy się i wracamy
do pliku widzę tutaj, że
publiczny adres URL został usunięty w porządku, a teraz
jest jeszcze jeden ostatni krok, który musimy zrobić
przed zakończeniem tego demo i to jest do
utwórz podpisany adres URL pliku, więc in
aby najpierw utworzyć podpisany adres URL
trzeba utworzyć klucz prywatny i tak dalej
zrobimy to za pomocą usługi
konto, więc przejdę do niego
tak mam zamiar iść do
menu nawigacyjne idę do jestem
administratora i tutaj z menu na stronie
w lewo zamierzam kliknąć usługę
konta tutaj w górnym menu jesteś
zamierza kliknąć na utworzenie konta usługi
i pod nazwą konta usługi możesz
wpisać dowolną nazwę
ale dla mnie zamierzam wejść podpisany
url zostawię wszystko inne
tak jak zamierzam po prostu kliknąć
utwórz zamierzam zamknąć chmurę
shell, ponieważ tak naprawdę go nie potrzebuję
teraz po prostu wybierz rolę i jestem
zamierzam nadać mu rolę magazynu
przeglądarka obiektów
zamierzam kliknąć kontynuuj i jestem
pozostawię resztę pustą i po prostu
kliknij Gotowe i powinieneś zobaczyć
konto usługi z nazwą podpisanego
url i tak w celu utworzenia klucza jestem
po prostu przejść do działań i
mam zamiar kliknąć na trzy kropki i
wybieram utwórz klucz z pliku
rozwijane menu i tutaj będę
monit z jakim typem klucza, który ja
chcesz stworzyć i chcesz się upewnić
że json jest wybrany i po prostu kliknij
przy tworzeniu i tutaj jest twój klucz
zostanie automatycznie pobrany do twojego
folder pobierania, który zamierzam kliknąć
zamknij i tak, gdy masz swój klucz
pobrany możesz uruchomić
proces generowania podpisanego adresu URL i
więc zamierzam iść dalej i korzystać z chmury
Shell, aby wygenerować ten znak
url, więc przejdę do poprzedniej strony
górę i ponownie otwórz powłokę chmury
a następnie możesz otworzyć powłokę chmury
edytor przejdzie do górnego menu w
edytor i kliknij plik i jesteś
zamierzam wybrać przesyłanie plików i oto
skąd przesyłasz swój klucz ze swojego
folder pobierania i widzę mój klucz
został przesłany tutaj i możesz
zmień nazwę pliku klucza na coś a
trochę bardziej czytelny dla człowieka, więc jestem
zamierzam kliknąć prawym przyciskiem myszy
na zmianę nazwy i możesz zmienić nazwę tego pliku
jak privatekey.json trafił ok i tak raz
masz przesłany klucz i zmieniono jego nazwę
możesz teraz wrócić do terminala
wygeneruj podpisany adres URL, do którego idę
szybko wyczyść ekran, do którego idę
upewnij się, że klucz prywatny jest w my
path, wpisując ls i jak widać
tutaj klucz prywatny.json
jest rzeczywiście na mojej ścieżce i tak przed i
wygeneruj ten klucz, wrócę
do przechowywania w chmurze, do którego zamierzam
wiercić w moim wiadrze i jak możesz
zobacz tutaj różowa muszka słonia robi
nie mają publicznego adresu URL, więc kiedy
adres URL znaku jest generowany, otrzymasz
publiczny adres URL, który nie będzie tutaj wyświetlany
w konsoli i będą prywatne dla
tylko użytkownik, który go wygenerował, oraz plik
użytkowników, że adres URL został rozpowszechniony
do porządku i kiedy już wszystko masz
miejsce, w którym możesz iść dalej i wkleić
polecenie gsutil znak url minus d the
wyznaczony czas, który wynosi 10 minut
klucz prywatny, który jest kropką klucza prywatnego
json wraz z ukośnikiem dwukropka gs
ukośnik do przodu nazwę wiadra, który w
mój przypadek to muszka z atramentem 2021 wzdłuż
z nazwą pliku
pinkelephant-muszka.jpg Zamierzam uderzyć
enter, więc celowo zostawiłem ten błąd
tutaj, abyś mógł to zobaczyć, kiedy ty
wygeneruj podpisany adres URL, którego potrzebujesz pi open
ssl w celu wygenerowania go i tak
zastrzeżeniem jest to, że ponieważ python 2 jest
jest przestarzałe polecenie pip install
pi openssl nie będzie działać pi open ssl
musi być zainstalowany z python3 i
więc aby go zainstalować, uruchomisz plik
polecenie pip3 install pi otwórz ssl i naciśnij
wprowadź i tak po zakończeniu
instalując, możesz teraz wygenerować swój
podpisany adres URL, który zamierzam szybko wyczyścić
wklej ekran w poleceniu ponownie trafionym
wprowadź i sukces, który teraz wygenerowałeś a
adres URL znaku dla obiektu różowy słoń
bowtie.jpg i ponieważ jest to podpisane
url, który zobaczysz tam pod publicznym adresem URL
nie ma tam dostępnego adresu URL, mimo że jest
jest publicznie dostępny i tak po prostu
zweryfikuj to, zaznaczę
link tutaj, skopiuję, idę
aby otworzyć nową kartę, którą zamierzam wkleić
w tym adresie URL naciśnij enter i odnieś sukces
adres URL znaku działa i każdy, kto ma
dostęp do niego ma uprawnienia do przeglądania
plik przez 10 minut i tak ponownie
to świetny sposób na dawanie
ktoś ma dostęp do obiektu, który nie ma
mieć konto i dać im
ograniczony czas na przeglądanie lub edytowanie tego obiektu
i dlatego chciałem ci pogratulować
przebrnąć przez to demo i mieć nadzieję
w którym okazał się niezwykle użyteczny
doskonalić swoją wiedzę na temat zarządzania
Bucks i dostęp do Bucks
i pliki w chmurze i tak po prostu
w ramach podsumowania utworzyłeś magazyn w chmurze
Bucket następnie utworzyłeś instancję i
skopiował plik z tej instancji do
bucket, a następnie sklonujesz swoje repozytorium do chmury
shell i skopiuj dwa pliki jpeg do swojego
zasobnik do przechowywania w chmurze, który został następnie przypisany
a następnie usunąłem publiczny dostęp do twojego
wiadro, a następnie zastosował acl ​​do pliku
w wiadrze, co również upublicznia
jako usunięcie publicznego dostępu zaraz po
następnie utworzyłeś konto usługi
klucz prywatny i wygenerował podpisany adres URL
do obiektu w tym wiadrze
jeszcze raz gratulacje za dobrze wykonaną robotę
i to właściwie wszystko, czego chciałem
do omówienia w tym demo dotyczącym zarządzania chmurą
dostęp do pamięci, aby móc to teraz zaznaczyć
jako kompletne i przejdźmy do
Następna
[Muzyka]
witamy z powrotem w tym demo, które zamierzamy zrobić
wchodzić w chwasty z przedmiotem
zarządzanie wersjami i cyklem życia
używając zarówno konsoli, jak i polecenia
linia, przez którą będziemy przechodzić
wersjonowanie działa i co się dzieje, kiedy
przedmioty promują się wraz z tworzeniem
konfigurowanie i edytowanie tych żyć
zasady dotyczące cykli i tak dalej
powiedział, zanurkujmy, więc będziemy
zaczynając od miejsca, w którym skończyliśmy
ostatnie demo ze wszystkimi zasobami
nienaruszone, które stworzyliśmy wcześniej i jesteśmy
iść naprzód i zanurkować prosto w
wersjonowanie, a więc pierwsza rzecz
chcesz zrobić, to włączyć przechowywanie wersji dla
twoje obecne wiadro, więc w moim przypadku dla
muszka atramentowa kreska 2021 i zamierzamy
zrób to za pomocą wiersza poleceń, więc jestem
najpierw przejdź do prawego górnego rogu
róg dłoni i otwórz chmurę i
więc najpierw chcesz sprawdzić, czy wersjonowanie
jest włączony dla Twojego zasobnika i możesz
zrób to za pomocą polecenia gsutil
wersjonowanie dogadać się z dwukropkiem gs
ukośnik w przód ukośnik z twoim
nazwę wiadra i naciśnij enter, a być może
monit z komunikatem z prośbą o to
zdecydowanie autoryzuj to wywołanie interfejsu API
chcesz autoryzować i zgodnie z oczekiwaniami
wersjonowanie nie jest włączone w tym przypadku
wiadro stąd powrót zawieszonych i
więc aby włączyć przechowywanie wersji, jesteśmy
zamierza użyć podobnego polecenia gsutil
wersjonowanie i zamiast get we're
zamierza użyć zestawu na gs dwukropek do przodu
ukośnik ukośnik i nazwa zasobnika
i naciśnij enter, a wersjonowanie zostało
włączone, więc jeśli uruchomię polecenie
wersja gsutil w get ponownie, dostanę
odpowiedź włączona OK, teraz świetnie
mamy włączone wersjonowanie, możemy iść
naprzód z kolejnym krokiem, którym jest
usuń jeden z plików w zasobniku
więc możesz iść dalej i wybrać kratę
muszka.jpg
i po prostu kliknij usuń, możesz
potwierdź usunięcie, a plik ma
został usunięty teraz technicznie plik
nie został usunięty, po prostu został
przekonwertowany na nieaktualną wersję i
więc w celu sprawdzenia prądu i
nieaktualne wersje, których zamierzam używać
Komenda
gsutil
ls minus a wraz z nazwą zasobnika
gs dwukropek ukośnik ukośnik
muszka inc dash 2021 trafię
Wchodzić
i jak widać tutaj kraciastą muszkę
nadal pokazuje ls minus polecenie
polecenie linux, aby wyświetlić wszystkie pliki
w tym ukryte pliki i co z tego
inny o tych plikach ma rację
po kropce tekst lub kropka jpg będziesz
zobacz numer hashtagu i to jest
numer generacji i to określa
wersja każdego obiektu i co z tego, ja
chcesz teraz zrobić, to przywrócić
nieaktualną wersję i uczynić ją aktualną
więc zamierzam promować nieaktualne
wersja kraciastej muszki.jpg
do aktualnej wersji i tak po kolei
aby to zrobić, uruchomię polecenie
gsutil i v dla ruchu wraz z
wiadro gs dwukropek do przodu ukośnik do przodu
ukośna muszka z łącznikiem 2021 i
nazwa pliku kraciastej muszki w kropki
jpeg wraz z numerem generacji
i skopiuję to z
obecnie na liście zamierzam go wkleić
in i tak teraz musimy umieścić w
cel, który będzie taki sam
bez numeru generacji i pasty
to w następnie naciśnij enter
dobra operacja zakończona, więc jeśli pójdę
do prawego górnego rogu i
kliknij odśwież, teraz to widzę
istnieje aktualna wersja kraciastej kokardki
remis teraz po prostu wiedzieć, że za pomocą ruchu
polecenie faktycznie usuwa nieaktualne
wersję i daje nowy prąd
wersja numer nowej generacji i tak dalej
aby to zweryfikować, zamierzam to zrobić
szybko wyczyść ekran i zamierzam to zrobić
uruchom polecenie gsutil ls minus a razem
z nazwą wiadra muszka z kreską
2021
a numer generacji tutaj to
inny niż ostatni teraz, jeśli i
użyj polecenia cp lub copy
zostaw nieaktualną wersję i utwórz
do tego nowa wersja, pozostawiając dwie
obiekty z dwoma różnymi generacjami
liczby w porządku, więc z tym krokiem
gotowe, chcesz teraz zalogować się do swojego systemu Linux
przykład i będziemy robić
trochę wersjonowania dla pliku bowties.text
więc idę dalej i wyczyszczę swoje
screen ponownie i zamierzam uruchomić
polecenie gcloud oblicz muszkę ssh
instancja, która jest nazwą my
instancja wraz z myślnikiem flagi strefy
strefa kreskowa strefy usa wschód 1b jestem
zamierza nacisnąć enter
i powinieneś zostać poproszony o
hasło twojego klucza
i jestem w, więc tutaj chcesz edytować
złóż plik bowties.txt do innego
version, dzięki czemu możesz iść dalej i uruchomić
polecenie sudo nano plik kropka z muszką
tekst i naciśnij enter i powinieneś
nauka wiązania muszki wymaga czasu i
co chcesz zrobić, to dołączyć wersję 2
zaraz na końcu ctrl o, aby zapisać enter
sprawdź nazwę pliku po prawej stronie i
kontrolujemy x, aby wyjść, więc teraz chcemy
skopiuj plik muszki kropka tekst do twojego
obecna kopalnia wiadra to atrament muszki
kreska 2021, więc idę dalej i
uruchom polecenie gsutil cp nazwa
plik, który jest plikiem kropki muszki
tekst i cel, który ma być
muszka Inc
2021 i naciśnij Enter
i kopiuje plik do zasobnika
więc jeśli kliknę odświeżanie w konsoli
widać, że jest tylko jeden
wersja pliku muszki.text i tak dalej
aby sprawdzić wszystkie wersje, które mam
Zamierzam wrócić do mojej skorupy w chmurze
zamierzam szybko wyczyścić ekran i
zamierzam uruchomić polecenie gsutil ls
minus a wraz z docelowym segmentem
naciśnij enter i jak widać tutaj
są teraz dwie wersje pliku
bowties.text i jeśli szybko to otworzę
w górę
Kliknę adres URL, który widzisz
tutaj, że jest to wersja druga i tak dalej
to powinna być najnowsza generacja
plik bowties.txt, który edytowałeś
w twoim przypadku zamierzam to zamknąć
tab teraz, więc to, co chcę teraz zrobić, to
Chcę promować nieaktualne
wersja będzie aktualną wersją w
istota, czyniąc wersję 2 nieaktualną
wersja, więc zamierzam uruchomić
polecenie gsutil cp i zamierzam wziąć
numer starszej generacji i ja
skopiuje to i wkleje tutaj i
cel będzie ten sam
bez numeru generacji i pasty
go i naciśnij enter OK, a plik ma
zostało skopiowane, więc zrobię
szybkie odświeżenie w konsoli idę
aby przejść do pliku bowties.txt
a kiedy klikam link do adresu URL, to go
powinien pojawić się jako wersja 1. i tak to
to sposób na promowanie nieaktualnych wersji
do aktualnych wersji za pomocą narzędzia gsutil
polecenie kopiowania lub polecenie gsutil move
teraz zamknę tę kartę
zamierzam szybko wyczyścić ekran i jeśli
uruchamiam polecenie gsutil ls minus a
znowu widać, że mam jeszcze więcej
pliki, a więc te pliki i wersje
pliki ostatecznie się zgromadzą i
stale zajmują miejsce wraz z
kosztować cię pieniądze i tak po to
złagodzić to dobrym pomysłem byłoby
wprowadzić politykę cyklu życia i
więc teraz pójdziesz dalej i dodasz a
polityka cyklu życia do wiadra i to
pomoże zarządzać stale rosnącym
gromadzenie plików, ponieważ jest ich więcej
dodawania do wiadra i nie tylko
wersje coś produkują
to jest bardzo powszechne, co widać u wielu
różne środowiska i tak jesteśmy
iść do przodu i załatwić to
konsola, więc zamykam
Cloud Shell i mam zamiar wrócić do
strona główna wiadra i pod
menu, które możesz kliknąć na cykl życia i
tutaj będziesz mógł dodać cykl życia
zasady i tak tutaj masz zamiar kliknąć
na dodać regułę i pierwszą rzeczą, która
zostaniesz poproszony o wybranie pliku
akcja i tak pierwsza zasada jesteś
zamiar zastosowania jest usunięcie nieaktualne
obiekty po siedmiu dniach, więc zamierzasz
kliknij usuń obiekt, którym będziesz
monit z ostrzeżeniem, że uderzy
kontynuuj, a zostaniesz o to poproszony
wybierz warunki obiektu i jako
omówione we wcześniejszej lekcji
wiele warunków do wyboru i
można wybrać wiele warunków
tutaj masz zamiar wybrać dni od
staje się nieaktualny i pusty
pole, które zamierzasz wpisać 7. możesz
kliknij Kontynuuj i zanim klikniesz
podczas tworzenia chciałem tylko zauważyć, że any
Reguła cyklu życia może zająć do 24 godzin
aby wejść w życie, więc zamierzam kliknąć
utwórz i tutaj możesz zobaczyć, że reguła ma
zastosowano do usuwania obiektów po
siedem dni, kiedy przedmiot staje się
długoterminowe, więc teraz, gdy dodaliśmy a
usuń regułę, którą zamierzamy kontynuować i
dodaj kolejną regułę, aby przenieść bieżące pliki
które nie są używane do przechowywania
klasa, która może zaoszczędzić pieniądze firmy
więc chodźmy dalej i stwórzmy kolejny
reguła cyklu życia, ale tym razem użyj tego
ustaw akcję klasową dotyczącą przechowywania, a więc
pliki, które się gromadzą, które zostały
tam przez ponad 90 dni, które chcesz ustawić
klasa przechowywania zimna linia, więc to
sposób zaoszczędzisz trochę pieniędzy i tak dalej
klikniesz dodaj regułę
zamierzasz wybrać ustawioną klasę pamięci
do zimnej linii i jako uwaga tutaj jest napisane
obiekty archiwum nie zostaną zmienione
zimna linia, dzięki której możesz iść do przodu
klasa przechowywania, ale nie możesz się przenieść
do tyłu, innymi słowy, nie mogę się ruszyć
od zimnej linii do bliskiej linii lub archiwum
zimną linię mogę poruszać tylko z bliska
linia do zimnej linii lub zimna linia do
archiwum, więc idę dalej i
kliknij przycisk Kontynuuj, aby wyświetlić warunki obiektu
chcesz wybrać wiek iw terenie
chcesz wprowadzić 90 dni i oto ty
chcesz nacisnąć kontynuuj i na koniec kliknij
na tworzenie i tak, aby faktycznie
zobacz, jak te zasady wejdą w życie, tak jak powiedziałem
zanim zajmie to do 24 godzin i tak dalej
zanim zakończymy to demo, chciałem je pokazać
inny sposób edytowania cyklu życia
policy, edytując sam plik json
więc możesz udać się w górę do prawego górnego rogu
i otwórz powłokę chmurową, do której zamierzam
obniż to trochę i jesteś
zamierzam uruchomić polecenie gsutil
cykl życia dogadać się z nazwą zasobnika
i wypisz go do pliku o nazwie
lifecycle.json i naciśnij enter
i żadnych błędów, więc to dobry znak następny
zamierzam uruchomić polecenie ls i as
możesz zobaczyć tutaj plik lifecycle.json
został napisany i chciałbym go edytować
ten plik, w którym zmienia zestaw
zasada zimnej linii od 90 dni do 120 dni
tak myśli menadżer Tony'ego Bowtiego
powinni trochę zachować pliki
dłużej przed wysłaniem go do coldline i
więc aby edytować ten plik, jesteś
zamierzam uruchomić polecenie sudo nano
wraz z nazwą pliku
lifecycle.js naciskasz enter i gotowe
będzie długim ciągiem, ale jeśli użyjesz
klawisze strzałek i przejdź w dół, a następnie
z powrotem zobaczysz zestaw do zimnej linii
rządzę w wieku 90 dni więc jestem
przeniosę się tutaj i zamierzam
edytuj to na 120 i uderzę
ctrl o, aby zapisać, wprowadź, aby zweryfikować nazwę pliku
pisać i ctrl x, aby wyjść i po prostu
wiedz, że możesz także edytować ten plik w
edytor Cloud Shell i tak w celu
mnie, aby wprowadzić tę politykę cyklu życia
muszę ustawić to jako nowy cykl życia
polityki i tak, abym mógł to zrobić
zamierzam uruchomić polecenie gsutil
zestaw cyklu życia wraz z nazwą
plik json, który jest
lifecycle.json wraz z zasobnikiem
name i naciśnij enter i wygląda na to
powiedziałem to i zrobię to szybko
odśwież w konsoli tylko po to, aby zweryfikować
i powodzenia reguła została zmieniona
od 90 dni do 120 dni gratulacje
po ukończeniu tego demo teraz dużo
tego, czego tu doświadczyłeś, jest więcej
co zobaczysz na egzaminie na architekta
na czym koncentruje się egzamin na inżyniera chmury
więcej z ich teorii wysokiego poziomu
funkcje przechowywania w chmurze
ale chciałem pokazać ci prawdziwe życie
scenariuszy i jak zastosować teorię
co zostało pokazane na poprzednich lekcjach
praktyka, a więc tak samo jak podsumowanie, które ustawiłeś
wersjonowanie w bieżącym wiadrze, które
pracujesz i usunąłeś a
plik i uczynił go nieaktualnym
przywrócił go, aby był znowu aktualny
następnie edytowałem plik w twojej instancji i
skopiowałem go, aby zastąpić bieżący
wersję tego pliku w swoim zasobniku
następnie promował nieaktualną wersję jako
nowy i przeszedł do cyklu życia
reguły, w których utworzyłeś dwa oddzielne
reguły utworzyłeś regułę usuwania plików
wraz z regułą ustawiania klasy przechowywania
po pewnym wieku pliku i
ostatnim krokiem, który zrobiłeś, było skopiowanie pliku
zasady cyklu życia do powłoki w chmurze i
edytował tę politykę i ustawiał ją na nowszą
zredagowana wersja i tyle
obejmuje to demo dotyczące wersjonowania obiektów
i gratulacje zarządzania cyklem życia
ponownie za dobrze wykonaną pracę i tak wcześniej
ty idź
upewnij się, że usunąłeś wszystkie zasoby
które stworzyłeś przez ostatnie kilka lat
dema, jak chcesz się upewnić
nie gromadzisz niepotrzebnych rzeczy
koszty i tak mam zamiar zrobić szybki bieg
poprzez usunięcie tych zasobów i
więc zamierzam szybko zamknąć chmurę
shell i ja jadę ogłowić na nad do
menu nawigacyjne przejdź do silnika obliczeniowego
zamierzam usunąć moją instancję i jestem
wracając do chmury
storage i usuń wiadro tam jestem
zamierzam potwierdzić usunięcie, idę
kliknąć na usuń i tak to obejmuje
usunięcie wszystkich zasobów, więc ty
mogę teraz oznaczyć to jako ukończone i zrobię to
do zobaczenia w kolejnym
witaj z powrotem i jestem na tej lekcji
będzie obejmować cloud sql jeden z
wiele ofert baz danych Google Cloud
który oferuje niezawodne, bezpieczne i skalowalne
bazy danych sql bez obaw
o złożoności, aby to wszystko skonfigurować
teraz jest tu całkiem sporo do omówienia, więc
powiedziawszy to, przejdźmy teraz do rzeczy
cloud sql to w pełni zarządzana chmura
natywna usługa relacyjnej bazy danych, która
oferuje mysql postgres i serwer sql
silniki z wbudowaną obsługą
replikacja chmura sql jest bazą danych jako
oferta usług z google gdzie
Google zajmuje się wszystkimi podstawowymi kwestiami
infrastruktura dla bazy danych wraz
z systemem operacyjnym i
oprogramowanie bazy danych teraz, ponieważ istnieje
kilka różnych typów baz danych
oferty z Google Cloud sql były
zaprojektowany z myślą o transakcjach o niskim opóźnieniu
i obciążenia relacyjnych baz danych
dostępne również w trzech różnych
smaki baz danych mysql postgres i
najnowsza edycja to serwer sql i wszystko
z nich obsługuje standardowe API dla
oferty łączności w chmurze sql
replikacja przy użyciu różnych typów
przeczytaj repliki, do których się dostanę
trochę później i oferuje możliwości
dla wysokiej dostępności w trybie ciągłym
dostęp do sql danych w chmurze również
oferuje kopie zapasowe w dwóch różnych smakach
i pozwala przywrócić bazę danych
z tych kopii zapasowych o tej samej kwocie
teraz z łatwością wraz z kopiami zapasowymi
nadchodzi punkt w czasie odzyskiwania na kiedy
chcesz przywrócić bazę danych z pliku
określony punkt w czasie przechowywanie w chmurze sql
opiera się na podłączonych dyskach trwałych w
tej samej strefie, w której są dostępne
zwykłe dyski twarde lub dyski ssd
obecnie daje do 30 terabajtów
pojemność pamięci masowej i dlatego to samo
technologie leżą w tle
trwałe dyski
dostępne jest automatyczne zwiększanie przestrzeni dyskowej
aby zmienić rozmiar dysków, aby uzyskać więcej miejsca
cloud sql oferuje również szyfrowanie w stanie spoczynku
i w tranzycie w celu zabezpieczenia danych
wchodzenie i wychodzenie z instancji oraz
jeśli chodzi o koszty, jesteś rozliczany
dla pamięci procesora i przechowywania plików
instancja wraz z ruchem wychodzącym jako
dobrze proszę mieć świadomość, że istnieje
kosztów licencji, jeśli chodzi o system Windows
instancje są teraz instancjami cloud sql
niedostępne w tych samych typach instancji
jako silnik obliczeniowy i są dostępne tylko
we wspólnym rdzeniu
typy procesorów o standardowej i wysokiej pamięci oraz
kiedy je zobaczysz, będą jasne
oznaczone db na początku
typu procesora nie można ich dostosować
instancje, takie jak w przypadku obliczeń
silnik, więc pamięć będzie wstępnie zdefiniowana
przy wyborze typu instancji teraz
typy pamięci masowej dla cloud sql są tylko
dostępne w dyskach twardych i dyskach ssd
jesteś w stanie dopasować je do rozmiaru
Twoje potrzeby i jak wspomniano wcześniej, mogą być
o rozmiarze do 30 terabajtów i
wchodząc w niebezpieczną strefę posiadania
pełny dysk, który masz do wyboru
włączenie automatycznego zwiększania pojemności tzw
nigdy nie musisz się martwić o napełnienie
dysk przed limitem 30 terabajtów
teraz, jeśli chodzi o połączenie z twoim
instancja cloud sql, którą możesz skonfigurować
z publicznym lub prywatnym adresem IP, ale wiem
że po skonfigurowaniu instancji za pomocą
prywatny adres IP, którego nie można zmienić
chociaż łączy się z prywatnym adresem IP
jest preferowany przy połączeniu z a
klienta na zasobie z dostępem do
vpc, jak również jest to zawsze najlepsza praktyka
używać prywatnych adresów IP dla dowolnych
bazy danych w swoim środowisku w dowolnym momencie
możesz teraz przejść do uwierzytelniania
opcje zalecanej metody
połączenie z instancją cloud sql jest
przy użyciu serwera proxy cloud sql chmura sql
proxy pozwala autoryzować i zabezpieczać
połączenia za pomocą uprawnień iam
chyba że korzystasz z serwera proxy cloud sql
połączenia z publicznym adresem IP instancji
adres są dozwolone tylko wtedy, gdy
połączenie pochodzi od autoryzowanego
autoryzowane sieci to ip
adresy lub zakresy, które posiada użytkownik
określony jako posiadający pozwolenie na
połączyć się, gdy uzyskasz autoryzację, możesz
połącz się z instancją przez
zewnętrznych klientów lub aplikacji i
nawet inne usługi Google w chmurze, takie jak
silnik obliczeniowy silnik aplikacji gke chmura
funkcje i uruchamianie w chmurze teraz chciałem
skup się tutaj przez chwilę na zalecanych
metoda łączenia się z Twoją instancją
który jest teraz serwerem proxy w chmurze sql jako
wspomniane przed serwerem proxy cloud sql
pozwala autoryzować i zabezpieczać
połączenia przy użyciu uprawnień iam
proxy sprawdza połączenia za pomocą
poświadczenia dla użytkownika lub usługi
konto i zawijanie połączenia
warstwa ssl tls, dla której jest autoryzowana
instancja cloud sql używająca cloud sql
proxy jest zalecaną metodą
uwierzytelnianie połączeń z chmurą
sql, ponieważ jest najbezpieczniejsza
serwer proxy klienta jest oprogramowaniem typu open source
biblioteka dystrybuowana jako plik wykonywalny
binarny i jest dostępny dla systemów Linux macos
i Windows serwer proxy klienta działa jako
serwer pośredniczący, który nasłuchuje
połączenia przychodzące opakowują je w ssl
lub tls, a następnie przekazuje je do chmury
sql, które obsługuje proxy sql w chmurze
uwierzytelnianie z zapewnieniem cloud sql
bezpieczny dostęp do instancji cloud sql
bez konieczności zarządzania dozwolonym adresem IP
adresy lub skonfigurować połączenia ssl
jak również jest to najlepsze rozwiązanie
dla aplikacji, które są efemeryczne
okularu i podczas gdy pełnomocnik może słuchać
na dowolnym porcie
tworzy tylko połączenia wychodzące
Twoja instancja cloud sql na porcie 3307 teraz
jeśli chodzi o replikację bazy danych
to coś więcej niż tylko kopiowanie danych
z jednej bazy danych do drugiej podstawowej
powodem zastosowania replikacji jest skalowalność
wykorzystanie danych w bazie danych bez
pogorszenie wydajności z innych powodów
obejmują migrację danych między regionami
i platform oraz lokalnie
database do cloud sql, możesz również
promować replikę, jeśli oryginał
instancja zostanie uszkodzona i będę
wchodząc trochę w promowanie replik
trochę później, jeśli chodzi o chmurę
instancja sql to instancja
zreplikowana jest nazywana instancją podstawową
a kopie są nazywane replikami do odczytu
instancja podstawowa i repliki do odczytu
wszystkie znajdują się w replikach do odczytu cloud sql
są tylko do odczytu i nie można do nich pisać
im replika odczytu przetwarza zapytania
żądania odczytu i ruch analityczny
zmniejszając w ten sposób obciążenie uzwojenia pierwotnego
repliki do odczytu instancji mogą mieć więcej
procesora w pamięci niż instancja podstawowa
ale oni nie mogą mieć mniej i ciebie
może mieć do 10 replik odczytu na
instancja podstawowa i możesz się z nią połączyć
replikę bezpośrednio za pomocą swojego połączenia
nazwa i adres IP obsługiwane przez cloud sql
następujące typy replik
repliki odczytu repliki odczytu między regionami
zewnętrzne repliki do odczytu i sql w chmurze
repliki podczas replikacji z pliku
serwer zewnętrzny teraz, jeśli chodzi o
czytaj repliki, do których będziesz go używać
odciążenie pracy z instancji cloud sql
odczytana replika jest dokładną kopią pliku
podstawowa instancja i dane oraz inne
zmiany w wystąpieniu podstawowym są
aktualizowane niemal w czasie rzeczywistym podczas odczytu
replika replika do odczytu jest tworzona w pliku a
innym regionie niż główny
instancja i możesz utworzyć krzyż
region odczytuje replikę w taki sam sposób jak ty
utworzy to replikę w regionie
poprawia wydajność odczytu, czyniąc
repliki dostępne bliżej Ciebie
region aplikacji, który również zapewnia
dodatkowe możliwości odzyskiwania po awarii
aby uchronić Cię przed awarią regionalną
umożliwia także migrację danych z jednego
regionu do innego przy minimalnym przestoju
i wreszcie, jeśli chodzi o zewnętrzne
czytaj repliki są to zewnętrzne mysql
instancji replikujących się z chmury
podstawowa instancja sql
na przykład działająca instancja mysql
silnik obliczeniowy jest uważany za zewnętrzny
przykład i tak tylko jako szybka notatka
tutaj, zanim będzie można utworzyć odczyt
replika podstawowej instancji sql w chmurze
instancja musi spełniać następujące warunki
muszą być automatyczne kopie zapasowe
włączone rejestrowanie binarne musi być włączone
co wymaga odzyskiwania do punktu w czasie
być włączone i musi istnieć co najmniej jedna kopia zapasowa
zostały utworzone po logowaniu binarnym
został włączony i tak po przeczytaniu
repliki w twoim środowisku daje
elastyczność ich promowania
repliki w razie potrzeby teraz promowanie
repliki to funkcja, której można użyć
kiedy stanie się podstawowa baza danych
uszkodzony lub nieosiągalny, teraz możesz
promować replikę do odczytu w regionie lub
międzyregionalna ponowna replika w zależności od
gdzie masz hostowane repliki do odczytu
więc kiedy promujesz replikę odczytu, plik
instancja zatrzymuje replikację i konwertuje
instancję do samodzielnego sql w chmurze
podstawowa instancja z odczytem i zapisem
możliwości proszę zauważyć, że to
nie można cofnąć, a także zauważ, że kiedy
Twoja nowa podstawowa instancja została uruchomiona
twoje inne repliki do odczytu nie są
przeniesione ze starego podstawowego
przypadku konieczne będzie ponowne połączenie
inne repliki odczytu do nowego podstawowego
instancja i jak widać tutaj
promowanie repliki odbywa się ręcznie i
celowo, podczas gdy wysoka dostępność
ma instancję rezerwową, która
automatycznie staje się głównym w
przypadku awarii poziomej awarii teraz
jeśli chodzi o promocję ponadregionalną
repliki istnieją dwa typowe scenariusze
dla promocji
migracja regionalna, która wykonuje a
planowana migracja bazy danych do
inny region i odzyskiwanie po awarii
i to jest miejsce, w którym przełączyłbyś się awaryjnie na a
bazy danych do innego regionu w wydarzeniu
że główny region instancji
staje się niedostępny w obu przypadkach użycia
obejmować utworzenie międzyregionalne
replikacja, a następnie promowanie
powtórz główną różnicę między nimi
jest czy promocja repliki
jest planowane lub nieplanowane teraz, jeśli jesteś
promowanie swoich replik na regionalne
migracji możesz użyć między regionami
replika, do której ma zostać przeprowadzona migracja bazy danych
inny region z minimalnym przestojem i
dzięki temu możesz utworzyć replikę w
inny region poczekaj, aż
replikacja dogania ją promować i
następnie skieruj swoje aplikacje do
nowo promowana instancja kroki
zaangażowanych w promocję są takie same jak
za promowanie repliki w regionie i
więc kiedy promujesz repliki dla
repliki międzyregionalne do odzyskiwania po awarii
można wykorzystać jako część tej katastrofy
procedurę odzyskiwania można promować
replika międzyregionalna do przełączenia awaryjnego
inny region powinien być głównym
region instancji staje się niedostępny dla
dłuższy okres czasu, więc w tym
przykład ma cały region US East 1
upadła jeszcze replika trzciny w
region europy wciąż działa
i chociaż trochę może być
większe opóźnienia dla klientów na północy
ameryka mogę promować tę lekturę
replikę podłącz do potrzebnej
zasobów i wrócić do pracy teraz
przejście do chmury o wysokiej dostępności
sql oferuje możliwości aha poza
czasem zapakuj konfigurację aha
zwany klastrem dostarcza danych
redundancja, więc instancja cloud sql
skonfigurowany dla ha jest również nazywany a
instancja regionalna i znajduje się w
strefa pierwotna i drugorzędna w obrębie
skonfigurowany region w pliku regionalnym
instancji, z której składa się konfiguracja
instancja podstawowa i rezerwowa
instancja i przez synchronous
replikacja do trwałej każdej strefy
dysk wszystkie prawa nadane do podstawowego
instancje są również wprowadzane w stan gotowości
instancja co sekundę podstawowy
instancja zapisuje do systemowej bazy danych jako
sygnał bicia serca, jeśli jest wielokrotny
bicia serca nie są wykrywane
inicjowane jest przełączanie awaryjne, więc jeśli plik
ha-skonfigurowana instancja staje się
niereagujący cloud sql automatycznie
przełącza się na serwowanie danych z
instancja rezerwowa i nazywa się to a
przełączanie awaryjne w tym przykładzie primary
instancja lub strefa ulegnie awarii i nastąpi przełączenie awaryjne
zainicjowane, więc jeśli instancja podstawowa jest
nie reaguje na około 60
sekund lub strefa zawierająca
wystąpiła awaria instancji podstawowej
przełączanie awaryjne zainicjuje stan wstrzymania
instancja natychmiast zaczyna udostępniać dane
po ponownym połączeniu za pośrednictwem udostępnionego
statyczny adres IP z podstawowym
instancja i instancja rezerwowa teraz
obsługuje dane ze strefy dodatkowej i
teraz, gdy jest instancja podstawowa
będzie ponownie dostępny, nastąpi powrót po awarii
i wtedy będzie ruch
przekierowany z powrotem do instancji podstawowej
a instancja rezerwowa wróci
w tryb czuwania oraz regionalny
dysk stały przejmie replikację
na dysk trwały w tej samej strefie
a jeśli chodzi o rozliczanie ha
skonfigurowana instancja jest naliczana podwójnie
cena samodzielnej instancji
i obejmuje to pamięć ram procesora i pamięć masową
należy również zauważyć, że instancja rezerwowa
nie można używać do zapytań odczytu i tego
jest tam, gdzie różni się od odczytanych replik
jak również bardzo ważna uwaga tutaj
że automatyczne kopie zapasowe i punkt w czasie
odzyskiwanie musi być włączone na wysokim poziomie
dostępność i tak ostatni temat
chciałem dotknąć to kopie zapasowe
i kopie zapasowe pomagają przywrócić utracone dane
do swojej instancji sql w chmurze, możesz również
przywrócić instancję, która ma
problemy z kopii zapasowej, którą włączysz
kopie zapasowe dla każdej instancji, która zawiera
niezbędne kopie zapasowe danych chronią Twoje dane
przed utratą lub uszkodzeniem umożliwiającym zautomatyzowane
kopie zapasowe wraz z logowaniem binarnym
wymagane również w przypadku niektórych operacji, takich jak
domyślnie jako tworzenie klonów i replik
cloud sql przechowuje dane kopii zapasowej w dwóch
regionów dla nadmiarowości może być jeden region
w tym samym regionie, w którym znajduje się instancja
a drugi to inny region if
na kontynencie są dwa regiony
dane kopii zapasowej pozostają takie same
Continental cloud sql pozwala również wybrać
niestandardową lokalizację dla danych kopii zapasowej
i to jest świetne, jeśli musisz się dostosować
z przepisami dotyczącymi przechowywania danych
business now cloud sql wykonuje dwa
rodzaje kopii zapasowych kopie zapasowe na żądanie i
automatyczne tworzenie kopii zapasowych teraz na żądanie
kopie zapasowe możesz utworzyć kopię zapasową w dowolnym momencie
czas i jest to przydatne, gdy jesteś
dokonywanie ryzykownych zmian, które mogą się udać
na boki zawsze możesz tworzyć na żądanie
kopie zapasowe dla dowolnego przypadku, niezależnie od tego, czy
instancja ma włączone automatyczne tworzenie kopii zapasowych
czy nie, a te kopie zapasowe będą trwać do
je usuniesz lub do momentu ich wystąpienia
jest teraz usuwany, jeśli chodzi o
automatyczne kopie zapasowe zajmują cztery godziny
okno tworzenia kopii zapasowych, w którym rozpoczynają się te kopie zapasowe
okno kopii zapasowej i tylko jako notatkę
jeśli to możliwe, powinieneś zaplanować swój
kopie zapasowe, gdy Twoja instancja ma ich najmniej
automatyczne kopie zapasowe wykonywane są co
dzień, w którym Twoja instancja jest uruchomiona o dowolnej porze
czas w 36-godzinnym oknie i do godz
domyślnie do siedmiu najnowszych kopii zapasowych
są zachowywane, możesz także skonfigurować sposób
wiele automatycznych kopii zapasowych do zachowania z 1
Do
365. poruszyłem już ten temat wiele razy
razy na tej lekcji i chciałem
zaznacz to na sekundę i to
jest odzyskiwaniem do punktu w czasie
odzyskiwanie do punktu w czasie pomaga w odzyskaniu
instancji do określonego punktu w czasie
na przykład, jeśli błąd powoduje utratę
dane, do których można odzyskać bazę danych
stan przed wystąpieniem błędu punkt
w czasie odzyskiwania zawsze tworzy nowe
instancja i nie możesz wykonać punktu
przywracanie w czasie do istniejącej instancji
i odzyskiwanie do punktu w czasie jest włączone przez
default podczas tworzenia nowego sql w chmurze
przykład, a więc jeśli chodzi o rozliczenia
domyślnie cloud sql zachowuje siedem dni
automatycznych kopii zapasowych oraz wszystkich na żądanie
kopie zapasowe dla instancji, więc wiem
w tej lekcji jest wiele do zapamiętania
w chmurze sql, ale upewnij się, że te
pojęcia i znając różnicę
między nimi, a także kiedy używać każdego z nich
funkcja z pewnością pomoże na egzaminie
wraz z przekazaniem ci wiedzy
musisz używać cloud sql w swojej roli jako
inżynier chmury i to w zasadzie tyle
wszystko, co musiałem pokryć, jeśli chodzi o
cloud sql, abyś mógł teraz to zaznaczyć
lekcję za zakończoną i przejdźmy dalej
Następny
witaj z powrotem iw tej lekcji chciałem
dotknąć globalnej chmury Google
relacyjnej bazy danych o nazwie cloud spanner
teraz klucz do chmury jest taki sam w niektórych
sposoby jak cloud sql, jeśli chodzi o zasoby
transakcje sql zapytania i silne
spójność, ale różni się w ten sposób
dane są przetwarzane pod maską niż
cloud sql, a więc znając tę ​​bazę danych
potrzebny jest tylko wysoki poziom
egzamin, ale wejdę w coś więcej
szczegóły tylko po to, aby dać ci lepsze
zrozumienie, jak to działa
powiedziawszy, zanurzmy się teraz w chmurze
spanner to w pełni zarządzana relacja
usługa bazy danych, która jest zarówno silnie
spójne i skalowalne w poziomie
cloud spanner to kolejna baza danych jako
oferta usług od google i tak dalej
usuwa wszystkie bóle głowy związane z ustawieniem
w górę i utrzymanie infrastruktury
i oprogramowanie potrzebne do uruchomienia bazy danych
w chmurze jest teraz mocno
spójny w tym kontekście jest, gdy data
zostanie przekazany do wszystkich replik
jak tylko pojawi się żądanie zapisu
replik chmury bazy danych
spanner używa czasu rzeczywistego o wysokiej dostępności
rozproszony system zegara atomowego, tj
udostępniane aplikacjom we wszystkich google
serwery stosuje znacznik czasu do każdego
transakcja na zatwierdzenie i tak dalej
transakcje w innych regionach są zawsze
wykonywane sekwencyjnie klucz do chmury może
dystrybuować i zarządzać danymi na poziomie globalnym
Skaluj i wspieraj globalnie spójnie
czyta się razem z silnie spójnymi
transakcje rozproszone są teraz w pełni
zarządzany klucz do chmury obsługuje dowolne
potrzebne repliki
dostępność Twoich danych i optymalizuje
wydajność dzięki automatycznemu dzieleniu na fragmenty
dane na podstawie obciążenia i rozmiaru żądania
części danych, dlaczego cloud spanner's
wysoka dostępność wynika właśnie z tego
automatyczna synchroniczna replikacja danych
między wszystkimi replikami w sposób niezależny
strefy cloud spanner skaluje się poziomo
automatycznie w regionach, ale może
także skalować obciążenia między regionami
które mają wyższą dostępność
wymagania dotyczące udostępniania danych
szybciej użytkownikom w skali globalnej
z redundancją węzłów dodaną po cichu dla
każdy węzeł wdrożony w instancji i
kiedy szybko to wszystko dodasz
funkcji cloud spanner to nic dziwnego
że można osiągnąć pięć
dziewiątki dostępność w wielu regionach
instancja i cztery dziewiątki są dostępne
regionalny klucz do chmury instancji
wysoce bezpieczne i oferuje warstwę danych
rejestrowanie audytu szyfrowania i iam
zaprojektowano integracyjny klucz do chmury
do potrzeb konkretnych branż
takich jak usługi finansowe
handel detaliczny ad tech i globalny łańcuch dostaw
wraz z grami i cenami za chmurę
spanner kosztuje 90 centów za węzeł
za godzinę wraz z kosztami magazynowania
w cenie 30 centów za gigabajt miesięcznie
zdecydowanie nie tanie, ale funkcje
są obfite teraz to nie jest w egzaminie
ale chciałem poświęcić chwilę na nurkowanie
do architektury na trochę więcej
kontekście, dlaczego ta baza danych jest typu a
inna rasa niż typowy sql
Baza danych teraz, aby korzystać z usługi Cloud Spaner
musi najpierw utworzyć klucz do chmury
instancja ta instancja jest alokacją
zasobów wykorzystywanych przez chmurę
utworzone w nim bazy danych kluczy
tworzenie instancji instancji obejmuje dwa
ważne wybory instancji
konfiguracja i liczba węzłów oraz
te wybory określają lokalizację i
ilość instancji procesora i
pamięci wraz z jej zasobami pamięci masowej
Twój wybór konfiguracji jest stały
dla instancji i tylko liczby węzłów
można zmienić później w razie potrzeby
konfiguracja instancji definiuje
położenie geograficzne i replikacja
baza danych w tym przypadku
regionalny lub wieloregionowy i proszę zwrócić na to uwagę
że gdy wybierzesz multistrefę
konfiguracji pozwala na replikację
dane baz danych nie tylko w wielu
stref, ale w wielu strefach w poprzek
wielu regionach i jeśli chodzi o
liczba węzłów to określa
liczbę węzłów do przydzielenia
na przykład te węzły przydzielają kwotę
pamięci procesora i pamięci potrzebnej do
twoja instancja albo wzrośnie
przepustowość lub pojemność pamięci masowej
brak typów instancji do wyboru
cloud sql i tak, gdy potrzebujesz więcej
power po prostu dodaj teraz kolejny węzeł
dla dowolnej regionalnej chmury konfiguracyjnej
klucz zachowuje dokładnie trzy odczyty
napisz repliki, każda w innym
strefa w tym regionie każdy odczyt i zapis
replika zawiera pełną kopię twojego
operacyjna baza danych, która jest w stanie
obsługuj żądania przepisywania i tylko do odczytu
cloud spanner używa replik w różnych
strefy, tak aby w przypadku awarii pojedynczej strefy
występuje, Twoja baza danych pozostaje dostępna
w konfiguracji instancji obejmującej wiele regionów
instancja ma przydzieloną kombinację
z czterech tylko do odczytu i zapisu
repliki i tak jak uwaga, trzy węzły
minimalna konfiguracja jest tym, czym jest
zalecane do produkcji przez google i
w miarę zapełniania się klucza do chmury
dane
dzieje się sharding, który jest również znany jako
tworzy split i cloud spanner
repliki każdej podzielonej bazy danych
poprawić wydajność i dostępność wszystkich
danych w podziale jest fizycznie
przechowywane razem w replice i chmurze
klucz służy do każdej repliki z
niezależnej strefy awarii i w każdej z nich
zestaw replik
jedna replika jest wybrana do pełnienia funkcji
repliki lidera lidera są odpowiedzialne
do obsługi praw podczas dowolnego odczytu i zapisu
lub replika tylko do odczytu może służyć do odczytu
wniosek bez komunikowania się z
liderem, więc to jest wewnętrzne działanie
cloud spanner na wysokim poziomie i nie
ma na celu zmylić cię, ale dać ci
lepszy kontekst tego, w jaki sposób cloud spanner
chociaż jest to relacyjna baza danych sql
jest tak inny niż jego cloud sql
kuzyn teraz przed zakończeniem tej lekcji i
chciałem dotknąć wydajności węzła dla
szybka chwila i tak każdy klucz do chmury
węzeł może obsłużyć do 10 000 zapytań
na sekundę lub qps odczytów lub 2000 qps
zapisów każdy węzeł zapewnia do dwóch
terabajty pamięci i tak, jeśli potrzebujesz
zwiększyć skalę serwowania i przechowywania
zasobów w Twojej instancji, dodajesz więcej
węzły do ​​tej instancji
i pamiętaj, jak wspomniano wcześniej, że
dodanie węzła nie zwiększa
liczba replik, ale raczej wzrasta
zasoby, które każda replika ma w
instancja dodawania węzłów daje każdą replikę
więcej procesora i ramu, co zwiększa
replikuje przepustowość, więc jeśli jesteś
chce automatycznie zwiększać skalę
może skalować liczbę węzłów w twoim
instancja oparta na monitoringu chmury
metryki wykorzystania procesora lub pamięci masowej
w połączeniu z korzystaniem z chmury
funkcje do wyzwalania, a więc kiedy jesteś
decydując się na relacyjną bazę danych, która
zapewnia globalną dystrybucję i
skalowalny w poziomie, który obsługuje
obciążenia transakcyjne w chmurze Google
cloud spanner zawsze będzie oczywistością
wybór zamiast cloud sql i tyle
prawie wszystko, co muszę pokryć, kiedy to
przychodzi do tego przeglądu na temat klucza w chmurze
więc możesz teraz oznaczyć tę lekcję jako
zakończyć i przejść do następnego
jeden
[Muzyka]
witaj z powrotem i na tej lekcji to zrobimy
przeglądać dostępne nosql
bazy danych dostępne w chmurze Google to
lekcja ma być kolejnym przeglądem
tylko po to, aby zapoznać Cię z nosql
opcje bazy danych, które pojawiają się w pliku
egzamin ta lekcja nie jest przeznaczona do wejścia
głębokość baz danych, ale przegląd i
da ci dobre zrozumienie
jakie funkcje są dostępne dla każdego z nich
i ich przypadków użycia
powiedział, zanurkujmy, teraz jest ich czterech
zarządzane bazy danych nosql dostępne w
google cloud i będę na krótko
nad nimi i zacznę to
dyskutując o bigtable
teraz bigtable w chmurze jest w pełni zarządzany
szerokokolumnowa baza danych nosql przeznaczona dla
obciążenia w skali terabajtów i petabajtów
który oferuje niskie opóźnienia i wysokie
przepustowość, dla której zbudowano bigtable
aplikacji obsługujących obciążenia w czasie rzeczywistym
a także wielkoskalowe analizy
Workloads cloud bigtable to aplikacja regionalna
usługi, a jeśli korzystasz z replikacji, kopię
jest przechowywany w innej strefie lub regionie
dla trwałości chmura bigtable jest
przeznaczony do przechowywania bardzo dużych ilości
danych z jednym kluczem, będąc jednocześnie
w stanie zapewnić bardzo niskie opóźnienia i
ponieważ przepustowość skaluje się liniowo
może zwiększyć liczbę zapytań na sekundę o
dodawanie większej liczby węzłów bigtable, kiedy potrzebujesz
jaka może być przepustowość bigtable
dynamicznie dostosowywane przez dodanie lub
usuwanie węzłów klastra bez
ponowne uruchomienie oznacza, że ​​możesz zwiększyć
rozmiar klastra bigtable tylko dla
kilka godzin, aby obsłużyć duży ładunek i
następnie ponownie zmniejsz rozmiar klastra i
zrób to wszystko bez przestojów bigtable
jest idealnym źródłem
dla mapy zmniejsz operacje i integruje
łatwo ze wszystkimi istniejącymi dużymi danymi
narzędzia, takie jak hadoop dataproc i
przepływ danych wraz z Apache Hbase i
jeśli chodzi o cenę to bigtable
zdecydowanie nie żartuj ceny dla bigtable
zaczyna się od 65 centów za godzinę na węzeł
lub ponad 450 dolarów miesięcznie za jeden
konfiguracja węzła bez danych teraz ty
może używać bigtable do przechowywania i wyszukiwania wszystkich
z następujących typów danych, takich jak
zużycie procesora i pamięci w czasie dla
dane marketingowe z wielu serwerów, takie jak
historie zakupów i klientów
preferencje dane finansowe, takie jak
historie transakcji ceny akcji i
kursy walut IOT dane lub
internet rzeczy, takich jak raporty użytkowania
z liczników energii i sprzętu AGD
i wreszcie dane wykresu, takie jak
informacje o tym, jacy są użytkownicy
połączone ze sobą bigtable w chmurze
doskonale sprawdza się jako silnik pamięci masowej, jak tylko może
wsadowe operacje mapreduce
przetwarzanie strumieniowe lub analizy
jako używany do przechowywania maszyny
aplikacje edukacyjne, które teraz przechodzą do
następną bazą danych nosql jest chmura
magazyn danych i magazyn danych w chmurze to a
wysoce skalowalna baza danych dokumentów nosql
zbudowany do automatycznego skalowania w górę
wydajność i łatwość aplikacji
magazyn danych programistycznych jest nadmiarowy
w Twojej lokalizacji
aby zminimalizować wpływ punktów
awarie i dlatego może oferować wysokie
dostępność odczytów i chmury uprawnień
datastore może wykonywać atomic
transakcje, w których zestaw operacji
albo wszystko się powiedzie, albo żadna nie wystąpi chmura
datastore używa rozproszonego
architekturę do automatycznego zarządzania
skalowanie, więc nigdy nie musisz się martwić
skalowanie ręczne, a także co jest bardzo
wyjątkowe w przypadku przechowywania danych w chmurze jest to, że
ma język zapytań podobny do sql
dostępny o nazwie gql znany również jako gql
gql odwzorowuje z grubsza sql, jednak sql
wyszukiwanie kolumn roli jest ograniczone do a
pojedyncza wartość, podczas gdy w gql właściwość
może być właściwością o wielu wartościach this
model spójności pozwala aplikacji
obsługiwać duże ilości danych i
użytkowników, wciąż będąc w stanie dostarczać
świetne dane dotyczące doświadczenia użytkownika
automatycznie szyfrowane, zanim to nastąpi
zapisywane na dysku i automatycznie
odszyfrowywane podczas odczytu przez uprawnionego
użytkownik teraz nie odzwierciedla to w
egzamin na razie i będę aktualizować
ta lekcja, jeśli i kiedy to się stanie, ale
Firestore to najnowsza wersja
datastore i wprowadza kilka
ulepszenia w porównaniu z istniejącym magazynem danych
użytkownicy magazynu danych mogą uzyskać do nich dostęp
ulepszenia poprzez utworzenie nowego magazynu ognia
instancja bazy danych w trybie magazynu danych i
w niedalekiej przyszłości wszystkie istniejące
bazy danych datastore będą
automatycznie uaktualniony do firestore w
tryb magazynu danych jest teraz w ruchu
magazyn danych w chmurze ma naprawdę fajne
funkcja dla programistów o nazwie
emulator magazynu danych i to zapewnia
lokalna emulacja produkcji
środowisko datastore, abyś mógł
używać do rozwijania i testowania aplikacji
lokalnie jest to składnik
google cloud sdks narzędzie gcloud i może być
instalowane przy użyciu komponentów gcloud
zainstaluj polecenie, które omówiliśmy
wcześniej w trakcie i tak poruszające
na przypadki użycia dla magazynu danych
jest idealny do aplikacji, które polegają
w sprawie wysoce dostępnych danych strukturalnych pod adresem
scale możesz użyć magazynu danych do rzeczy
jak katalogi produktów, które zapewniają
inwentaryzacja i szczegóły produktu w czasie rzeczywistym
dla profili użytkowników sprzedawców detalicznych
dostarczać dostosowane doświadczenie w oparciu o
wcześniejsze działania użytkownika i
preferencje
jak również transakcje oparte na aktywach
właściwości, na przykład przenoszenie
środków z jednego konta bankowego na drugie
następnie mamy firestore dla firebase
a więc jest to elastyczny skalowalny nosql
baza danych w chmurze do przechowywania i synchronizacji danych
do rozwoju po stronie klienta i serwera
i jest dostępny dla natywnego c plus unity
node.js java go i python sdks
oprócz odpoczynku i rpc apis pretty
wiele obejmujących gamę większości głównych
języki programowania teraz z chmurą
firestore przechowujesz dane w dokumentach
które zawierają pola mapowane na wartości
w których przechowywane są te dokumenty
kolekcje, które są kontenerami dla
dokumenty, których możesz użyć
organizować dane i tworzyć zapytania
dokumenty obsługują wiele różnych danych
typy, jak również możesz także utworzyć sub
kolekcje w dokumentach i build
chmura hierarchicznych struktur danych
firestore jest absolutnie bezserwerowy
brak serwerów do zarządzania aktualizacjami lub konserwacją
oraz z automatycznym multiregionem
replikacja i silna spójność
Google jest w stanie wytrzymać
gwarancja dostępności na pięć dziewiątek i
więc jeśli chodzi o zapytania w chmurze
firestore jest wyrazisty i wydajny
elastyczny, możesz tworzyć płytkie zapytania
do pobierania danych na poziomie dokumentu
bez konieczności pobierania całości
kolekcji lub dowolnych zagnieżdżonych podkolekcji
firestore w chmurze wykorzystuje dane
synchronizacja w celu aktualizacji danych w rzeczywistości
czas dla dowolnego podłączonego urządzenia, jak również to
buforuje również dane, które twoja aplikacja
aktywnie korzysta, aby
aplikacja może pisać czytać słuchać i
zapytania o dane, nawet jeśli urządzenie jest w trybie offline
gdy urządzenie wróci do chmury online
firestore synchronizuje wszelkie lokalne zmiany
z powrotem do cloud firestore też możesz
zabezpiecz swoje dane w chmurze firestore za pomocą
Uwierzytelnianie Firebase i chmura
zasady bezpieczeństwa Firestore dla Androida iOS
i javascript lub możesz użyć iam for
języki po stronie serwera i kiedy to nastąpi
do kosztów firestore należy do zawsze
dostępny bezpłatny poziom, z którego możesz korzystać
jedna baza danych zawierająca pięć gigabajtów lub
jeśli potrzebujesz więcej, możesz się do nich wprowadzić
płatna opcja ma teraz również firebase
inna podobna baza danych
funkcje, takie jak brak serwerów
wdrażać i utrzymywać aktualizacje w czasie rzeczywistym
wraz z bezpłatnym poziomem w tym
baza danych nazywana jest bazą danych czasu rzeczywistego
i jest używany do bardziej podstawowych zapytań
prosta struktura danych i przechowywanie rzeczy
do jednej bazy danych
to coś, co lubię nazywać firestore
lite baza danych czasu rzeczywistego nie pojawia się
na egzaminie, ale chciałem to przynieść
światło, ponieważ jest częścią bazy ogniowej
rodzina po prostu wie, że możesz używać obu
baz danych w ramach tej samej bazy ogniowej
aplikacji lub projektu, ponieważ oba mogą przechowywać
te same typy bibliotek klienta danych
działają w podobny sposób i oba trzymają
aktualizacje w czasie rzeczywistym teraz, chociaż firebase
jest platformą programistyczną, a nie
usługa bazy danych, którą chciałem dać
szybka wzmianka dla tych z was, którzy są
niezaznajomiony z powiązaniem z Firestore
z firebase firebase to telefon komórkowy
platforma do tworzenia aplikacji, która
dostarcza narzędzia i usługi w chmurze
pomóc programistom w rozwoju
aplikacje szybciej i łatwiej oraz
ponieważ ładnie łączy się z firestore
staje się idealną platformą dla
tworzenie aplikacji mobilnych w porządku
przejście do naszej ostatniej bazy danych nosql to
memorystore i memorystore to w pełni
zarządzana usługa z Google Cloud dla
albo redis albo memcached w pamięci
datastore do tworzenia pamięci podręcznych aplikacji
i jest to powszechna usługa używana w
wielu środowiskach produkcyjnych
szczególnie, gdy potrzeba buforowania
powstaje magazyn pamięci automatyzuje
zadania administracyjne dla redis i
memcached jak włączenie high
łatanie przełączania awaryjnego dostępności i
monitorowanie, abyś nie musiał i kiedy
chodzi o magazyn pamięci dla redis
są to instancje w warstwie standardowej
replikowane w strefach
monitorowane pod kątem zdrowia i pościć
standardowa warstwa automatycznego przełączania awaryjnego
instancje zapewniają również sla na trzy
magazyn pamięci dostępności dziewiątek dla
redis zapewnia również możliwość skalowania
natychmiastowe rozmiary bezproblemowo, abyś mógł
zacznij od małego i zwiększ rozmiar
instancja, jak jest potrzebny magazyn pamięci
chroniony przed Internetem za pomocą vpc
sieci i prywatny adres IP, a także przychodzi
z systemami integracji iam są
monitorowane przez całą dobę, aby to zapewnić
Twoje dane są chronione przez cały czas i
wiedzieć, że wersje są zawsze zachowywane
na bieżąco z najnowszymi krytycznymi
łatki zapewniające, że twoje instancje są
bezpieczne teraz, jeśli chodzi o przypadki użycia
Oczywiście pierwszą rzeczą, którą zobaczysz, jest
buforowanie i to jest główny powód
użyj magazynu pamięci, ponieważ zapewnia on niski poziom
dostęp do opóźnień i wysoka przepustowość dla
dane, do których dostęp był intensywniejszy w porównaniu do
dostęp do danych z dysku wspólnego
przykładami buforowania jest sesja
zarządzanie często używanymi zapytaniami
skrypty lub strony, więc podczas korzystania z pamięci
sklep z tabelami wyników i grami
jest częstym przypadkiem użycia w grach
przemysł, jak również używanie go dla gracza
Magazyn pamięci profili jest również doskonały
rozwiązanie do przetwarzania strumieniowego połączone
z magazynem pamięci przepływu danych dla redis
zapewnia skalowalną szybkość w magazynie pamięci
do przechowywania danych pośrednich, które
tysiące klientów może uzyskać dostęp za pomocą
bardzo małe opóźnienie i tak jeśli chodzi o
bazy danych nosql to wszystko
dostępne opcje w chmurze google i as
Powiedziałem wcześniej, że pojawi się tylko na
egzamin tylko na wysokim poziomie i tyle
wiedząc, czym jest każda z tych baz danych
używany do
będzie ogromną korzyścią wraz z byciem
wejście do nurkowania głębiej w możliwie
korzystanie z tych usług w Twoim
na co dzień jako inżynier chmury i
więc to prawie wszystko, co chciałem
cover, jeśli chodzi o bazy danych nosql
dostępne w chmurze Google, więc możesz teraz
zaznacz tę lekcję jako zakończoną i przejdźmy do rzeczy
przejść do następnego
[Muzyka]
witaj z powrotem i na tej lekcji będziemy
omówienie ekosystemu dużych zbiorów danych w
przegląd tylko po to, aby się z tobą zapoznać
usługi dostępne w
Google Cloud i są to usługi
pojawi się na egzaminie, na którym jest ta lekcja
nie ma na celu zagłębienia się, ale jest
przegląd i daje dobre
zrozumienie tego, co te usługi mogą
robią i jak wszyscy razem pracują
nadać sens big data jako całości
więc wchodząc w to, chciałem
najpierw zadaj pytanie, czym są duże zbiory danych
mam na myśli, że wiele osób o tym mówi, ale
do czego tak naprawdę odnosi się big data
do ogromnych ilości danych, które
zwykle zbyt drogie w przechowywaniu
zarządzać i analizować przy użyciu tradycyjnych
systemy bazodanowe relacyjne lub
monolityczne, jak ilość danych, które my
widzieliśmy w ciągu ostatnich kilku lat
zaczął rozbudowywać te systemy
stały się bardzo nieefektywne z powodu
ich brak elastyczności w przechowywaniu
dane nieustrukturyzowane, takie jak obrazy tekstowe lub
wideo, a także wysokie
prędkość lub dane w czasie rzeczywistym lub skalowanie do
wsparcie bardzo duże
do tego wolumeny danych w skali petabajtów
powodu ostatnich kilku lat widziałem
przyjęcie nowych podejść do głównego nurtu
zarządzania i przetwarzania dużych zbiorów danych
w tym apache hadoop i nosql
systemy baz danych jednak te opcje
często okazują się skomplikowane do wdrożenia
zarządzać i używać w środowisku lokalnym
sytuacja
teraz zdolność do konsekwentnego uzyskiwania
wartość biznesowa z danych
szybko i skutecznie staje się obecnie
de facto organizacji odnoszących sukcesy
w każdej branży, im więcej danych a
firma ma dostęp do większej liczby przedsiębiorstw
spostrzeżenia i wartość biznesową, jaką są w stanie
osiągnąć
jak wzrost przydatnych spostrzeżeń
przychód
zdobyć lub zatrzymać klientów, a nawet poprawić
operacji i ponieważ uczenie maszynowe
modele stają się bardziej wydajne, ponieważ są
przeszkoleni z większą ilością uczenia maszynowego danych
i duże zbiory danych bardzo się uzupełniają
w sumie duże zbiory danych naprawdę przynoszą pewne korzyści
to jest wielka wartość do stołu
niemożliwe, aby jakakolwiek organizacja się odwróciła
w dół i tak teraz, kiedy przeszliśmy
ten przegląd tego, czym są duże zbiory danych, tj
chciałem zanurkować w jakimś krótszym
przegląd usług dostępnych dla
ekosystem dużych zbiorów danych w chmurze Google
a więc pierwsza usługa, którą chciałbym
na początek jest bigquery teraz bigquery
to w pełni zarządzane bezserwerowe dane
magazyn umożliwiający skalowalną analizę
ponad petabajtów danych tej usługi
obsługuje zapytania przy użyciu sql i blokad
wbudowane funkcje uczenia maszynowego
zaczynasz od przyjmowania danych do
bigquery, a następnie możesz wziąć
wykorzystać całą moc, jaką zapewnia
więc duże zbiory danych pochłonęłyby te dane
wykonując przesyłanie wsadowe lub przesyłając je strumieniowo
w czasie rzeczywistym i możesz użyć dowolnego z nich
aktualnie dostępna chmura Google
usług do ładowania danych do BigQuery
może przyjąć ręczne przetwarzanie wsadowe
zbliżać się
lub przesyłaj strumieniowo przy użyciu danych pub sub etl i
z usługą transferu danych bigquery
może automatycznie przesyłać dane z
zewnętrzne źródła danych Google i partner
aplikacje sas do bigquery na a
zaplanowane iw pełni zarządzane podstawy i
najlepsza część to partia i eksport
darmowy interfejs API szybkiego przesyłania strumieniowego BigQuery
zapewnia niesamowitą podstawę dla
analizy w czasie rzeczywistym tworzące dane biznesowe
natychmiast dostępne do analizy i
możesz także wykorzystać subskrypcje pubowe i dane
flow, aby przesyłać strumieniowo dane do BigQuery
bigquery w sposób przejrzysty i automatyczny
zapewnia bardzo trwałe powielanie
przechowywanie w wielu lokalizacjach dla wysokich
dostępność, jak również możliwość
osiągnięcie łatwego zasobu BigQuery utrzymuje a
siedmiodniowa historia zmian w przypadku
coś poszło nie tak bigquery
obsługuje standardowe zapytania sql, które
zmniejsza potrzebę przepisywania kodu
możesz po prostu użyć go tak, jakbyś chciał
wysyłanie zapytań do innych zgodnych z sql
bazy danych oraz z dataproc i dataflow
bigquery zapewnia integrację z
umożliwienie ekosystemu dużych zbiorów danych Apache
istniejące obciążenia hadoop iskrą i wiązką
bezpośrednio odczytywać lub zapisywać dane
bigquery przy użyciu bigquery interfejsu API magazynu
sprawia również, że dostęp do tego jest bardzo łatwy
dane za pomocą konsoli w chmurze za pomocą
narzędzie wiersza poleceń bq lub wykonywanie połączeń
do interfejsu API odpoczynku bigquery przy użyciu odmiany
bibliotek klienckich, takich jak java.net lub
python istnieje również wiele różnych
narzędzia innych firm, których możesz użyć
interakcja z BigQuery podczas wizualizacji
dane lub ładowanie danych bigquery
zapewnia silne bezpieczeństwo i zarządzanie
kontrole z drobnoziarnistymi kontrolami
poprzez integrację z tożsamością i
zarządzanie dostępem bigquery zapewnia
możliwość kontroli danych geograficznych
bez problemów z konfiguracją i
zarządzanie klastrami i inne przetwarzanie
zasobów w różnych strefach i regionach
bigquery zapewnia również drobne ziarno
zarządzanie tożsamością i dostępem oraz reszta
pewność, że Twoje dane są zawsze
zaszyfrowane w spoczynku iw tranzycie teraz
sposób, w jaki BigQuery oblicza rozliczenia
opłaty dotyczą zapytań i magazynu
przechowywanie danych w bigquery jest porównywalne
w cenie z przechowywaniem danych w chmurze
przechowywania, co ułatwia podjęcie decyzji
do przechowywania danych w bigquery nie ma
górny limit ilości danych, które
mogą być przechowywane w bigquery, więc jeśli tabele
nie są edytowane przez 90 dni cena
pamięć dla tego stołu spada o 50
dostępne są również procentowe koszty zapytań
jako ceny na żądanie i stawki ryczałtowe oraz
jeśli chodzi o ustalanie cen na żądanie
są naliczane tylko za nieprzeczytane bajty
bajty zwrócone na końcu bigquery
płynnie skaluje się do przechowywania i analizowania
petabajtów do eksabajtów danych z łatwością
teraz jest o wiele więcej funkcji
listę, ale jeśli jesteś zainteresowany, nie krępuj się
aby zagłębić się w inne funkcje z
podany link w tekście lekcji teraz
przejście do następnej usługi to pub sub
i pub sub to w pełni zarządzane w czasie rzeczywistym
usługa przesyłania wiadomości, która na to pozwala
wysyłać i odbierać wiadomości między
niezależne aplikacje, jak działa
oprogramowanie pośredniczące lub zdarzenie zorientowane na przesyłanie wiadomości
przetwarzanie i dostarczanie do przesyłania strumieniowego
potoki analityczne, a więc wydawca
aplikacja tworzy i wysyła wiadomości do
aplikacje subskrybentów tematu tworzą
subskrypcję tematu i otrzymuje
wiadomości z niego i tak chciałem wziąć
chwilę, aby pokazać dokładnie, jak to jest
Pracuje
więc najpierw wydawca tworzy wiadomości
i wysyła je do usługi przesyłania wiadomości
na określony temat temat jest nazwany
podmiot, który reprezentuje plik danych
komunikaty tworzone przez aplikację wydawcy
temat w usłudze podrzędnej pub i wysyła
wiadomości do tego tematu wiadomość
zawiera ładunek i opcjonalne
atrybuty opisujące zawartość
usługa jako całość zapewnia to
opublikowane wiadomości są zachowywane
w imieniu subskrypcji i tak a
opublikowana wiadomość jest przechowywana przez a
pokazana subskrypcja w kolejce komunikatów
tutaj jako przechowywanie wiadomości, dopóki nie będzie
potwierdzone przez każdego konsumującego abonenta
wiadomości z tej subskrypcji pubowej
następnie przekazuje wiadomości z tematu do
wszystkie swoje subskrypcje indywidualnie a
abonent następnie odbiera wiadomości albo
przez pub sub popychając ich do
wybranego przez abonenta punktu końcowego lub przez
abonent wyciągając je z usługi
abonent następnie wysyła
potwierdzenie usługi podrzędnej pubu
za każdą otrzymaną wiadomość usługa
następnie usuwa potwierdzone wiadomości z
kolejka komunikatów subskrypcji i niektóre
przypadków użycia pub sub to
równoważenie dystrybucji dużych kolejek zadań
powiadomienia o zdarzeniach i dane w czasie rzeczywistym
przesyłanie strumieniowe z różnych źródeł itp
następna usługa, którą chciałem uzyskać
w jest kompozytor teraz kompozytor jest
usługa orkiestracji zarządzanego przepływu pracy
to jest zbudowane na przepływie powietrza Apache
narzędzie do automatyzacji przepływu pracy dla
programistów opartych na open
źródłowy projekt przepływu powietrza Apache podobny do
lokalny kompozytor wdrażania w chmurze
wdraża wiele komponentów do uruchomienia
przepływ powietrza w chmurze przepływ powietrza to a
platforma
stworzony przez społeczność do
programowo autor harmonogramu i
monitorować przepływy pracy w harmonogramie przepływu powietrza
jak widać tutaj, wykonuje zadania na
szereg pracowników, podążając za
określone zależności i przechowywanie pliku
dane w bazie danych i posiadające interfejs użytkownika
komponent do łatwego zarządzania teraz
rozbijając te przepływy pracy tylko dla
sec w analizie danych przepływ pracy
reprezentuje serię zadań dla
połykanie przekształcanie analizowanie lub
wykorzystania danych w przepływach pracy są
utworzone przy użyciu dags, które są a
zbiór zadań, które chcesz
zaplanować i uruchomić
i organizuje te zadania, aby to zapewnić
każde zadanie jest wykonywane we właściwym czasie
we właściwej kolejności lub z prawej strony
obsługę problemu teraz, aby uruchomić plik
specjalistyczne przepływy pracy
potrzebne są środowiska zaopatrzeniowe i tak dalej
Composer wdraża te niezależne
środowiska w silniku Google kubernetes
które współpracują z inną chmurą Google
usług za pomocą wbudowanych konektorów
przepływ powietrza piękno kompozytora polega na tym
możesz utworzyć jedną lub więcej z nich
środowiska w jednej chmurze Google
projekt przy użyciu dowolnego obsługiwanego regionu
bez konieczności wykonywania wszystkich ciężkich zadań
zniesienie tworzenia pełnowymiarowego Apache
środowisko przepływu powietrza teraz, jeśli chodzi o
przepływ danych przepływ danych jest w pełni bezserwerowy
zarządzana usługa przetwarzania do wykonania
potoki wiązki Apache dla partii i
strumieniowanie danych w czasie rzeczywistym w wiązce Apache
sdk to model programowania typu open source
który umożliwia opracowanie obu partii
i potoki strumieniowe przy użyciu jednego z
apache beam sdks budujesz program
który definiuje potok, a następnie jeden z
Apache Beam obsługuje dystrybucję
backendy przetwarzania, takie jak przepływ danych
wykonuje ten potok przepływu danych
następnie serwis zajmuje się wszystkimi
szczegóły niskiego poziomu, takie jak koordynacja
poszczególni pracownicy dzielą zestawy danych na fragmenty
automatyczne skalowanie i dokładnie raz przetwarzanie
teraz w najprostszej formie Google Cloud
przepływ danych odczytuje dane ze źródła
przekształca go, a następnie zapisuje dane
z powrotem do zlewu, teraz dostaję trochę więcej
szczegółowy sposób działania tego potoku
przepływ danych odczytuje prezentowane dane
źródło danych
po odczytaniu danych są one umieszczane
razem w zbiór zestawów danych
o nazwie kolekcja aplikacji, a to pozwala
dane do odczytu i dystrybuowane
przetwarzane na wielu komputerach
na każdym etapie, w którym znajdują się dane
przekształcił nową kolekcję p
utworzony i raz ostateczna kolekcja
został utworzony, jest zapisywany jako asynchroniczny
i to jest pełny rurociąg tego, jak
dane przechodzą ze źródła, aby to zsynchronizować
potok w przepływie danych nazywa się a
praca iw końcu tutaj jest wysoki poziom
omówienie tego, czym byłoby zadanie przepływu danych
wyglądać, gdy angażujesz innych
usługi w chmurze Google i umieścić
razem w ramach kompleksowego rozwiązania od
pobieranie danych do ich wizualizacji
i wreszcie, jeśli chodzi o ceny
zadania przepływu danych są rozliczane za sekundę
przyrosty, więc płacisz tylko za
kiedy przetwarzasz teraz swoje dane
przejście do przetwarzania danych jest szybkie
i łatwy sposób na uruchomienie ula spark hadoop lub
pig w chmurze Google w środowisku lokalnym
środowisko zajmuje od 5 do 30 minut
tworzyć dane klastrów Spark i Hadoop
klastry proc zajmują 90 sekund lub mniej
średniej do zbudowania w chmurze Google
dataproc ma wbudowaną integrację z
inne usługi Google Cloud Platform i
używaj klastrów spark i hadoop bez
wszelkiej pomocy administratora, więc kiedy skończysz
z klastrem możesz go po prostu obrócić
wyłączony, aby nie wydawać pieniędzy na bezczynność
klastra, jak również nie ma powodów do zmartwień
o utracie danych, ponieważ proces danych jest
zintegrowany z BigQuery do przechowywania w chmurze
i chmura bigtable to świetna rzecz
dataproc to nie musisz uczyć się nowego
narzędzia lub interfejs API, aby z niego korzystać
Spark hadoop pig i Hive to wszystko
obsługiwane i często aktualizowane oraz
jeśli chodzi o ceny, jesteś rozliczany
za jeden cent na vcpu w twoim klastrze na
godzinę oprócz innych zasobów
używać masz również elastyczność
używanie instancji z możliwością wywłaszczania dla parzystych
niższe koszty obliczeniowe teraz, chociaż chmura
proces przetwarzania danych i przepływ danych w chmurze mogą działać jedno i drugie
być używany do implementacji danych etl
rozwiązań magazynowych, które każdy z nich posiada
ich mocne i słabe strony, a więc i
chciałem poświęcić chwilę na wskazanie
je teraz z dataproc możesz
łatwo obracać klastry przez
konsola sdk lub api i włącz ją
wyłączony, gdy nie jest potrzebny, z przepływem danych
jest bezserwerowy iw pełni zarządzany
nigdy nie ma żadnych serwerów, którymi można się martwić
o i kiedy chodzi o posiadanie
zależności do narzędzi w hadoop lub
proces danych ekosystemu iskrowego byłby
droga do zrobienia, ale jeśli chcesz to zrobić
Twoje zadania są bardziej przenośne w różnych miejscach
silniki wykonawcze, na które pozwala Apache Beam
aby to zrobić i jest dostępny tylko dla danych
przepływ przechodzi do następnej usługi
Laboratorium danych w chmurze jest teraz laboratorium danych w chmurze
interaktywne narzędzie programistyczne stworzone do
eksploruj analizuj przekształcaj i wizualizuj
danych i budować modele uczenia maszynowego
z twojego laboratorium danych używa open
źródłowe notebooki jupyter są dobrze znane
format używany w świecie nauki o danych
działa na silniku obliczeniowym i łączy się
do wielu usług w chmurze, dzięki czemu
może skupić się na zadaniach związanych z nauką o danych
integruje się również ze wszystkimi usługami Google
usługi ułatwiające upraszczanie danych
przetwarzanie takie jak bigquery i chmura
laboratorium danych w chmurze jest spakowane jako plik
kontenera i uruchomić w chmurze instancji maszyny wirtualnej
laboratorium danych używa notatników zamiast tekstu
pliki zawierające notatniki kodu
razem dokumentacja kodu napisana jako
Markdown i wyniki kodu
wykonanie, niezależnie od tego, czy jest to obraz tekstowy, czy
html lub javascript jak edytor kodu lub
Notatniki ide pomagają w pisaniu kodu i
pozwalają na wykonanie kodu w pliku
sposób interaktywny i iteracyjny
renderowanie wyników obok kodu
notebooki laboratorium danych w chmurze mogą być przechowywane
w repozytorium Google Cloud Source this
repozytorium git jest klonowane na trwałe
disk po podłączeniu do maszyny wirtualnej teraz, kiedy to
przychodzi do przygotowania danych przed
konsumpcji, czy to czyszczenia danych
przygotowanie do czyszczenia lub zmiana
gdzie przygotowanie danych uderza go z parku
dataprep to inteligentna aplikacja bezserwerowa
usługa danych do eksploracji wizualnej
czyszczenie i przygotowywanie strukturyzowanych i
nieustrukturyzowane dane do raportowania analiz
i automatyczne uczenie maszynowe
wykrywa możliwe schematy typów danych
łączeń i anomalii, takich jak braki
wartości odstające i duplikaty, więc ty
nie mam do architektury, którą jestem
zaraz wam pokażę, jak przygotowuje się dane
pokazuje surowe dane, które są dostępne
z różnych źródeł jest
pobrane do chmury dane przygotowujące do oczyszczenia
a następnie przygotuj dane do przygotowania danych
wysyła dane do chmury, do której przepływ danych
udoskonalić te dane, a następnie wysłać do
przechowywanie w chmurze lub bigquery do przechowywania
zanim zostanie przeanalizowany przez jednego z wielu
dostępne narzędzia bi teraz te duże zbiory danych
usługi są wykorzystywane przez wielu analityków danych
w terenie i dobrze wiedzieć co
usług, z których można skorzystać
przetwarzać dane niezbędne do ich
konkretna praca, jak również do egzaminu ty
wystarczy znać te usługi w
wysokim poziomie i nie znać ich dogłębnie
ale jeśli wydajesz się zainteresowany nurkowaniem
do którejkolwiek z tych usług, aby dowiedzieć się więcej
o nich gorąco zachęcam
zanurkuj po kursie i naprawdę weź
spójrz na nie i to całkiem sporo
wszystko, co muszę omówić w tej lekcji
usług dostępnych dla
ekosystem big data w chmurze google tzw
możesz teraz oznaczyć tę lekcję jako zakończoną
i przejdźmy do następnego
[Muzyka]
Witamy spowrotem
ta lekcja będzie oparta na
podstawy uczenia maszynowego idę
omówić, czym jest uczenie maszynowe
może zrobić dla nas uczenie maszynowe
ekosystem w chmurze Google
i miejmy nadzieję, że odpowiesz na wszelkie pytania
sposób ta lekcja będzie na wysokim poziomie
przegląd usług dostępnych na
Google Cloud jeszcze te usługi, które są
dostępne są trzeba wiedzieć, jak oni
przyjdź na egzamin i miejmy nadzieję, że będzie
dać ci kilka naprawdę fajnych pomysłów na temat
możliwości zbudowania czegoś
naprawdę fantastyczne w chmurze Google, co z tego
jest uczenie maszynowe
cóż, uczenie maszynowe to funkcjonalność
które pomagają oprogramowaniu działać
zadania bez jawnego programowania
lub zasady tradycyjnie uważane za
podkategoria sztucznej inteligencji
uczenie maszynowe obejmuje statystyki
techniki, takie jak głębokie uczenie się
znane jako sieci neuronowe
inspirowane teoriami o tym, jak człowiek
mózg przetwarza informacje, to jest to
wyszkolony w rozpoznawaniu wzorców w
zebrane dane za pomocą modeli algorytmicznych
a te zebrane dane obejmują wideo
obrazy mowy lub tekstu i ponieważ
uczenie maszynowe jest bardzo drogie
uruchamiać lokalnie
jest wydajnym miejscem
do uczenia maszynowego dzięki wykorzystaniu
masowe obliczenia na dużą skalę
i jak wyjaśniono przed uczeniem maszynowym
jest zawsze lepszy w przypadku dużych zbiorów danych, więc teraz ja
chciałem dotknąć tego, co można obrabiać
nauka dla nas
dobrze może kategoryzować obrazy, takie jak
zdjęcia twarzy lub zdjęcia satelitarne
może szukać słów kluczowych w tekście
dokumenty lub e-maile
może oznaczać potencjalnie fałszywe
transakcji, jeśli chodzi o kredyt
karty lub karty debetowe, które może włączyć
oprogramowanie, aby dokładnie reagować na głos
polecenia może również tłumaczyć języki
w tekście lub dźwięku, a to tylko niektóre
typowych funkcji tej maszyny
nauka może nam pomóc, więc wejdź
platforma uczenia maszynowego Google
samo uczenie maszynowe było
kamień węgielny wewnętrznych systemów Google
od lat przede wszystkim ze względu na ich potrzebę
do automatyzacji systemów opartych na danych na a
ogromna skala
i robienie tego zapewniło wyjątkowe
wgląd we właściwe techniki
infrastrukturę i ramy, które pomagają
ich klienci uzyskują optymalną wartość
uczenie maszynowe pierwotnie
opracowane ramy open source do użytku
wewnątrz google
zwany tensorflow
jest obecnie standardem w nauce o danych
społeczność oprócz mocno
przyczyniając się do akademickiego i otwartego
społeczności źródłowe
badacze uczenia maszynowego Google
pomógł wprowadzić tę funkcjonalność do
produkty Google, takie jak wyszukiwanie G Suite
i zdjęcia oprócz Google
jeśli chodzi o operacje wewnętrzne
automatyzacja centrum danych
teraz jest przegląd wszystkich
usługi uczenia maszynowego, które będziemy
zakrywać i że będziesz potrzebować
wiedzieć
tylko na wysokim poziomie do egzaminu i
zaczniemy od interfejsu API witryny
usługi
zaczynając od interfejsu API wizji
api wizyjne oferuje potężne możliwości
wstępnie wytrenowane modele uczenia maszynowego
które umożliwiają przypisanie etykiet
obrazy
i szybko podzielić je na miliony
z predefiniowanych kategorii
wizja API
potrafi czytać tekst drukowany i pisany odręcznie
może wykrywać przedmioty i twarze
i wbudować metadane w katalog obrazów
twojego wyboru teraz, jeśli chodzi o
inteligencja wideo
ma wstępnie wytrenowane uczenie maszynowe
modele, które automatycznie rozpoznają
ponad 20 000 obiektów
miejsca i czynności w przechowywanych i
przesyłając strumieniowo wideo, możesz uzyskać wgląd
z wideo w czasie zbliżonym do rzeczywistego za pomocą
interfejs API przesyłania strumieniowego wideo inteligencji
i wyzwalaj zdarzenia na podstawie obiektów
wykryte, możesz łatwo wyszukać wideo
katalogu w ten sam sposób, w jaki wyszukujesz tekst
dokumentów i wyodrębnić metadane, które mogą
być używany do organizowania i wyszukiwania indeksów
zawartość wideo
teraz przechodzimy do języka apis
zaczynamy od języka naturalnego
api i wykorzystuje uczenie maszynowe do
ujawnić strukturę i znaczenie tekstu
możesz wyodrębnić informacje o ludziach
miejsca i wydarzenia
i lepiej zrozumieć media społecznościowe
sentymenty i rozmowy z klientami
język naturalny umożliwia analizę
tekst, a także zintegrować go ze swoim
przechowywanie dokumentów w chmurze
z interfejsem API do tłumaczenia, który ci to umożliwia
dynamicznie tłumaczyć pomiędzy
języki przy użyciu wstępnie wyszkolonych lub
niestandardowe modele uczenia maszynowego
interfejs API tłumaczenia
natychmiast tłumaczy tekst na więcej niż
100 języków dla Twojej witryny i aplikacji
z opcjonalnymi funkcjami dostosowywania
za inną grupą maszyn
uczenie się to rozmowa apis pierwsza
w górę mamy przepływ dialogu Przepływ dialogu to a
platforma rozumienia języka naturalnego
co ułatwia projektowanie i
zintegrować konwersacyjnego użytkownika
interfejs do swojej aplikacji lub
urządzenie może to być aplikacja mobilna lub sieć
aplikacja bota lub interaktywna
system odpowiedzi głosowych za pomocą dialogflow
możesz zapewnić nowe i atrakcyjne sposoby
aby użytkownicy mogli wchodzić w interakcje z Twoim produktem
Dialogflow może analizować wiele typów
informacje od Twoich klientów
w tym wejścia tekstowe lub audio
jak z telefonu lub nagrania głosowego i
może również odpowiadać Twoim klientom w
na kilka sposobów albo przez tekst, albo
z mową syntetyczną teraz z
api zamiany mowy na tekst dokładnie
potrafi konwertować mowę na tekst
transkrybuj zawartość z dokładnością
napisy i dostarczyć lepszego użytkownika
doświadczenie w produktach za pomocą głosu
polecenia idące w drugą stronę z tekstu
na mowę ten interfejs API umożliwia programistom
syntetyzować naturalnie brzmiącą mowę
ponad sto różnych głosów
dostępne w wielu językach i
warianty tekstu na mowę
pozwala tworzyć realistyczne
interakcje z ich użytkownikami w całej
wielu aplikacji i urządzeń oraz do
zakończyć nasz segment uczenia maszynowego
chciałem dotknąć auto ml automl to a
pakiet produktów do uczenia maszynowego, który
umożliwia programistom z bardzo ograniczonymi możliwościami
ekspertyzy uczenia maszynowego
trenować wysokiej jakości modele specyficzne dla
innymi słowy ich potrzeby biznesowe
użycie automl umożliwia głębokie uczenie się
łatwiejszy w użyciu i polega na Google
najnowocześniejsze nauczanie transferowe i
technologia wyszukiwania architektury neuronowej tzw
możesz teraz generować wysokiej jakości
danych szkoleniowych i być w stanie wdrażać nowe
modele oparte na Twoich danych w ciągu kilku minut
automl jest dostępny dla wizji
tłumaczenie wywiadu wideo
tablice języka naturalnego
API wnioskowania i rekomendacji
teraz wiem, że było dużo do omówienia
za tę lekcję uczenia maszynowego i
otaczającego go ekosystemu, ale jest koniecznością
do egzaminu, a także pomoże
tworzyć naprawdę fajne produkty, jeśli chodzi
do twojej roli inżyniera ponownie
usługi, o których mówiłem
ta lekcja powinna być znana na wysokim poziomie
tylko poziom, chociaż moja rekomendacja
byłoby zanurzyć się w nich głębiej
usługi, sprawdzając łącza w
tekst lekcji poniżej i trochę
zabawy z poznawaniem tych produktów
te usługi naprawdę pomogą ci
gra, jeśli chodzi o poznawanie
te usługi trochę więcej
głębokość i naprawdę pomoże Ci zyskać więcej
rozmachu, jeśli chodzi o budowanie jakichkolwiek
aplikacji lub stosowania ich do jakichkolwiek
aktualnie uruchomione aplikacje i
osobiście uznał to za niezwykle cenne
i naprawdę ugruntowałem swoją wiedzę, kiedy to
przyszedł do uczenia maszynowego, też miałem
mnóstwo zabawy, robiąc to i to wszystko
na tę lekcję dotyczącą uczenia maszynowego
więc możesz teraz oznaczyć tę lekcję jako
zakończyć i przejść do następnego
jeden
[Muzyka]
witaj z powrotem i na tej lekcji będziemy
nurkowanie w zestawie narzędzi używanych w
platforma chmurowa Google, która na to pozwala
obsługiwać monitor i rozwiązywać problemy
środowisko znane jako pakiet operacyjny i
wcześniej znany jako stackdriver
lekcja będzie miała głównie charakter koncepcyjny i
bieg bardziej w kierunku tego, co jest w zestawie
narzędzia robią, ponieważ odgrywa dużą rolę nie tylko
na egzaminie, ale dla potrzeb zdobycia
wgląd ze wszystkich zasobów, które
istnieją teraz w twoim środowisku
kilka narzędzi do pokrycia tutaj, więc z tym
mówiąc, zanurzmy się
teraz zestaw operacyjny to zestaw
narzędzia do monitorowania logów i
diagnostyka aplikacji
pakiet operacyjny pobiera te dane i
generuje spostrzeżenia za pomocą pulpitów nawigacyjnych
wykresy i alerty tego zestawu narzędzi
są dostępne zarówno dla gcp, jak i aws you
może łączyć się z aws przy użyciu roli aws i
konto usługi gcp też możesz
monitoruj maszyny wirtualne za pomocą określonych agentów, które
ponownie oba działają na gcp dla silnika obliczeniowego
i pakiet operacyjny aws ec2 również na to pozwala
dodana funkcjonalność monitoringu
wszelkie aplikacje, które na nich działają
Dostępny jest również pakiet operacyjny vms
dla dowolnej infrastruktury lokalnej lub
działanie środowisk chmury hybrydowej
suite ma natywną integrację
gcp po wyjęciu z pudełka, więc nie ma prawdziwego
konfiguracje, które musisz wykonać i
integruje się z prawie wszystkimi zasobami
w chmurze Google, takiej jak poprzednio
wspomniany silnik aplikacji gke silnika obliczeniowego
i bigquery i możesz znaleźć i naprawić
problemy szybciej ze względu na wiele różnych
narzędzi, które pakiet operacyjny może zredukować
przestojów dzięki alertom w czasie rzeczywistym
również znaleźć wsparcie ze strony rozwijającego się partnera
ekosystem integracji technologii
narzędzia zwiększające bezpieczeństwo operacji
i możliwości zgodności teraz
zestaw operacyjny składa się z sześciu
dostępne produkty, które obejmują całą gamę
wszystkich dostępnych narzędzi, których będziesz potrzebować
który pozwala monitorować rozwiązywanie problemów
i poprawić wydajność aplikacji na
Twoje środowisko Google Cloud i zrobię to
omówię te produkty za chwilę
szczegóły zaczynając od monitoringu teraz
monitorowanie chmury zbiera pomiary
lub metryki, które pomogą Ci zrozumieć, jak to zrobić
Twoje aplikacje i usługi systemowe
wykonują dając ci
informacje o źródle
pomiary wartości ze stemplem czasowym i
informacje o tych wartościach, które mogą być
w podziale na dane szeregów czasowych
monitorowanie chmury może następnie pobrać dane
dostarczone i korzystać z predefiniowanych pulpitów nawigacyjnych
które nie wymagają instalacji ani konfiguracji
monitorowanie chmury nakładu pracy również Ci to daje
elastyczność tworzenia niestandardowych
pulpity nawigacyjne, które wyświetlają zawartość
wybierz, możesz użyć dostępnych widżetów
lub możesz zainstalować pulpit nawigacyjny
konfiguracja przechowywana w github
teraz, abyś mógł zacząć używać
monitorowanie chmury, które musisz skonfigurować
obszar roboczy
teraz obszary robocze organizują monitorowanie
to jest informacja w monitorowaniu chmury
pojedyncza tafla szkła, gdzie możesz
przeglądaj wszystko, co monitorujesz
w twoim środowisku też jest najlepiej
ćwiczyć korzystanie z wielu projektów
obszar roboczy, dzięki czemu można monitorować wiele
projekty z jednej tafli szkła
jak wspomniałem wcześniej monitorowanie chmury
ma agenta, który gromadzi system i
metryki aplikacji z maszyny wirtualnej i
wysyła je do monitorowania w chmurze, możesz
monitoruj swoje maszyny wirtualne bez agenta, ale
otrzymasz tylko określone dane, takie jak
jako procesor
ruch na dysku ruch sieciowy i czas pracy
użycie agenta jest opcjonalne, ale jest
zalecane przez google i z agentem
pozwala monitorować wiele
aplikacje stron trzecich i tak jak a
uwaga rejestrowanie w chmurze ma również agenta
i dobrze współpracuje z chmurą
monitorowanie w celu tworzenia wizualizacji i alertów
na metrykach opartych na danych dziennika, ale więcej
że trochę później monitorowanie chmury
jest również dostępny dla gke i to będzie
pozwalają monitorować klastry jako to
zarządza monitorowaniem i logowaniem
razem, a to będzie monitorować klastry
infrastrukturę, swoje obciążenia i
services, a także twoje węzły i
pojemniki, więc jeśli chodzi o alerty
jest to określone przez zasady i
warunki, a więc polityka uczenia się
określa warunki, w których a
usługa jest uważana za niezdrową, gdy
warunki te są spełnione, polityka jest
uruchamiany i otwiera nowy incydent
i wysyła powiadomienie o polityce
należy do indywidualnego obszaru roboczego i
każdy obszar roboczy może zawierać do 500
zasady teraz warunki określają kiedy
uruchamiana jest zasada alertów, więc wszystko
warunki oglądać przez trzy oddzielne
rzeczy pierwsza to metryka
drugi to zachowanie w jakiś sposób i
trzeci jest na pewien czas
opis warunku zawiera metrykę
do zmierzenia i przetestowania
określanie, kiedy metryka osiąga a
oświadcz, że chcesz o tym wiedzieć
kiedy zostanie uruchomiony alert, możesz być
powiadamiani za pomocą kanałów powiadomień
takich jak e-mail
sms
a także narzędzia stron trzecich, takie jak
pagerduty i slack przechodzą teraz do
logowanie w chmurze logowanie w chmurze to podstawa
repozytorium danych dziennika z wielu
source i zgodnie z wcześniejszym opisem logowania
może pochodzić nie tylko z Google, ale z
aws, jak również w środowiskach lokalnych
rejestrowanie w chmurze obsługuje dziennik w czasie rzeczywistym
zarządzania i analizy i ma ścisłe
integracja z chmurą monitorującą to
gromadzi system platformy i aplikację
dzienniki i masz również opcję
eksportowanie logów do innych źródeł, np
przechowywanie długoterminowe, takie jak przechowywanie w chmurze lub
do analizy, takiej jak bigquery, możesz również
eksportować do narzędzi innych firm, jak również teraz
zagłębiając się w pojęcia chmury
logowanie są one związane przede wszystkim
z projektami gcp, więc loguje tylko przeglądarkę
pokazuje teraz logi z jednego konkretnego projektu
jeśli chodzi o wpisy w dzienniku wpis w dzienniku
rejestruje stan lub zdarzenie projektu
odbiera wpisy dziennika, gdy usługi są
używane do tworzenia wpisów dziennika i zejścia na dół
do podstaw
logi są nazwaną kolekcją dzienników
wpisy w zasobie Google Cloud
i tak jako notatkę każdy wpis w dzienniku
zawiera tylko nazwę swoich dzienników dziennika
istnieją, jeśli mają wpisy w dzienniku i plik
okres przechowywania to długość czasu
dla którego twoje dzienniki są przechowywane, więc kopiąc
do typów dzienników, które są w chmurze
uchwyty rejestrowania są trzy
różne rodzaje dzienników są audytowane
dzienniki dzienniki przejrzystości i dzienniki agenta
teraz z dziennikami kontroli są to dzienniki
określić, kto co, gdzie i kiedy zrobił
pokaż także aktywność administratora i dostęp do danych
a także trwające zdarzenia systemowe
aby uzyskać dostęp do dzienników przejrzystości
dzienniki działań podjętych przez Google, więc kiedy
pracownicy Google mają dostęp do Twoich danych
do zgłoszenia pomocy technicznej działania, które są
wykonane przez pracowników Google są rejestrowane
w ramach rejestrowania w chmurze teraz, gdy nadejdzie
do dzienników agenta są to dzienniki, które
pochodzą z agentów zainstalowanych na
vms
agent rejestrowania wysyła system i
dzienniki innych firm w instancji maszyny wirtualnej do
logowanie w chmurze przechodzi do błędu
zgłaszanie tego dotyczy błędu w czasie rzeczywistym
liczy się monitorowanie i ostrzeganie
analizuje i agreguje błędy, które
dzieje się w twoim środowisku gcp, a następnie
ostrzega, gdy nowy błąd aplikacji
wystąpią szczegóły błędu mogą zostać przesłane
przez api i powiadomienia są
nadal jest w wersji beta zgłaszania błędów
zintegrowane z funkcjami chmury i
standard silnika aplikacji Google, który jest
włączone jest automatyczne raportowanie błędów
w wersji beta dla kubernetes silnika obliczeniowego
elastyczny silnik i silnik aplikacji
jakie może być raportowanie powietrza aws ec2
zainstalowane w różnych językach, np
jak idź java.net
node.js python php i ruby ​​są teraz w ruchu
do debuggera to narzędzie debuguje uruchomione
aplikacji bez spowalniania jej
przechwytuje i sprawdza stos wywołań i
lokalne zmienne w twojej aplikacji this
Narzędzie debuguje działającą aplikację
bez spowalniania go przechwytuje i
sprawdza stos wywołań i lokalne
zmienne w twojej aplikacji to jest
znany również jako robienie migawki po
zrobiono zdjęcie
punkt dziennika można wstrzyknąć, aby ci na to pozwolić
aby rozpocząć debugowanie, można użyć debuggera
z lub bez dostępu do Twojego
kod źródłowy aplikacji i jeśli twoje repozytorium
nie jest lokalny, można go podłączyć do
zdalne repozytorium git, takie jak github git lab
lub bitbucket debugger jest zintegrowany z
silnik aplikacji Google automatycznie i może
zainstalować na silniku Google Compute
gke
a debugger silnika aplikacji Google to
zintegrowany z silnikiem aplikacji Google
automatycznie i może być zainstalowany na
debugger gke jest zintegrowany z google
silnik aplikacji automatycznie i może być
zainstalowany w silniku obliczeniowym Google
google kubernetes engine aplikacja google
działa silnik i chmura i tylko jako notatka
Instalacja na tych produktach to wszystko
zależne od biblioteki i znowu
debugger można zainstalować jak w przypadku śledzenia
środowiskach innych niż gcp i jest dostępny dla
instalować za pomocą różnych
w różnych językach następny jest ślad i
ślad pomaga zrozumieć, jak długo to trwa
zajmuje się Twoją aplikacją
żądania przychodzące od użytkowników i
Śledzenie aplikacji zbiera dane o opóźnieniach
z modułów równoważenia obciążenia https silnika aplikacji i
aplikacje używające śledzenia api to jest
również zintegrowany z silnikiem aplikacji Google
standard i jest stosowany automatycznie tzw
użyłbyś śledzenia dla czegoś takiego jak a
strona internetowa, która ładuje się w nieskończoność
aby rozwiązać ten konkretny problem
trace można zainstalować w Google Compute
silnik google kubernetes silnik i
silnik aplikacji Google, jak również może być
zainstalowany w środowiskach innych niż gcp i to
można zainstalować za pomocą różnych
różnych językach, jak pokazano tutaj i
zbliża się do ostatniego narzędzia z grupy
jest profilerem, teraz profiler gromadzi procesor
informacje o wykorzystaniu i alokacji pamięci
z aplikacji w sposób ciągły i
pomaga to odkryć wzorce
zużycie zasobów, aby pomóc Ci lepiej
narzędzie do rozwiązywania problemów jest niskoprofilowe i
dlatego nie zajmie dużo pamięci
lub cpu w twoim systemie również w kolejności
aby używać profilera, agent musi być
zainstalowany profiler można zainstalować na
silnik i aplikacja kubernetes silnika obliczeniowego
silnik też i oczywiście może być
zainstalowane w środowiskach innych niż gcp i
profilera można zainstalować za pomocą
następujące języki po prostu idą
java node.js i python, a więc tak samo jak a
uwaga na egzamin tylko wysoki poziom
przegląd tych narzędzi są potrzebne i
więc to kończy tę lekcję na wysokim poziomie
przegląd poziomu pakietu operacyjnego, więc ty
może teraz oznaczyć tę lekcję jako ukończoną i
przejdźmy do następnego

